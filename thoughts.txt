Questions:
-how do genes interact with long distance regulatory elements (i.e. enhancers)?
--what forces drive these interactions? (ie which epigenetic marks?)
--what are the dynamics of these interactions
--are TADs the only answer?
-how do TADs and plaid patterns interact?
-what is a single cell contact map
--is it just a single structure draw from the bulk?
--can we run max ent on a single structure draw from the bulk and retrieve the bulk parameters? or the bulk structural ensemble?
--if two sc hic maps are close, by definition, their (estimated) structures must be close (no comment on real structures), but if the two hic maps are far away, are the structures different? by how much?
--is the space of structures of a sc hic map the same as the bulk (A), a subset of the bulk (B), or a different distribution entirely (C)??
---A) suggests model is not capturing differences in hic maps properly
---B) suggests that sc hic maps can be considered draws from the bulk
---C) suggests that sc hic maps are not simply draws from the bulk

Datasets:
-nagano 2017: cell cycle dataset
--major difference is diagonal effect
--also observe changes to insulation profile of TADs
--and A/B compartmentalization
--"Overall, the ordering of TADs according to A-association score is significantly correlated with a linear model weighting H3K4me1 and H3K4me3 scores (Pearson’s r= 0.79, P< 0.001). "
--can we model these epi marks and show how changes to their interactions causes changes in A-association score
--what proportion of the time does a given TAD spend in A vs B? - do they switch compartments between cells or within cells?
-Amat 2019: salt shock - only two conditions - disruption of A/B compartments - major TAD disruption
--experimental paper with more insight into effect of osmolarity: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3576538/
--osmolarity and disease: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3438915/
--could we get a salt shock dataset with single cell resolution over gradient of concentrations??
-ramani: 4 human cell lines
-flymer: mouse zygotes and oocytes
-tan: lymphoblast and blood cell
--structure determination via approach from Stevens 2017
--uses radii of gyration of structure to measure TADs
--can identify lymphblast cell types based on specific E-P loops OR from the compartment profile - what is the mechanism of this difference?
-salt shock sc-hic: perform sc-hi on cells treated to different levels of osmotic shock
-collombet: embryogenesis
--maternal vs paternal domains
--compares epigenetic marks to different domain types (i.e. at what stage a domain appears) - can we model these changes as causal?
--parentally preformed domains are depleted of CTCF - so we could get away without modelling it?
---de novo domains still have CTCF though...
--UMAP in figure 1f only shows clustering by embryonic stage - what about cell differentiation as shown by diffusion map on RNA-seq in Haghverdi et al 2015

Methods:
-GNN: relevant for settings where we want to model many contact maps AND the prominent variation is the plaid/diagonal pattern - ie no TADs
-Diffusion Map: relevant for any setting with sufficent contact maps where we want to determine their collective variables
--potentiall useful in setting where we expect transition to occur but don't know what it is a priori
--can potentially be performed iteratively to impute sc-contact maps
-TICG model: simulation model of plaid/diagonal effect
-Higashi: used to impute/embed sc-contact maps

TODOS:
-how does diffusion map imputation method compare to using higashi + diffusion map

Thoughts:
-order parameters:
--quantify 3d locations of genes - e.g. peripheral vs central or distance between promoters and enhancers
---hic already identifies promoter enhancer contacts - but not distances or durations
---hic already identifies A/B separation
-density of A vs B?

-diffusion map on 100s of bulk hic datasets to see variation accross cell types
--could combine with gene expression to find structural patterns that predict gene expression

-can we do something interesting with higher-order chromatin interactions?
--does our model reproduce this? - even though hic only contains pairwise interactions?

-cannot estimate structure exactly, but we can use simulation to robustly estimate structural properties of sc-hic-map

-TADS:
--hybrid MC-MD for TADs??
--can we do TADs in TICG in 'unsupervised' manner (i.e. requiring only hic data)?
---e.g. use TAD caller and define start and end as those loci
--does a TICG simulation with only diagonal effect show TAD-like patterns for single frames??
---look at pairwise spatial distance matrix
---if using a term like Bin Zhang CTCF, if you delete term 3 do you see weaker TAD boundaries????

Finite size effect:
2) I think this result is more of a commentary on the parameters of our model than of the biological implications. This means that we can’t take parameters used to simulate a given amount of DNA and re-use them to simulate a longer stretch of DNA. Therefore, our parameters aren’t thermodynamically meaningful, but that’s ok because we don’t care about the thermodynamic meaning of the diagonal parameters. 3) If we scale up to simulate entire chromosomes, the deviation is no longer an artifact - it's a result. 4) With large simulations, the interactions at longer distance will become increasingly rare and are generally less interesting. So simulation artifacts aren’t as concerning.

Challenge: I’m not sure how to leverage this to train the MLP. If only the first 25% of the contact probability curve can be considered as genuine, what can we say about the parameters for the remaining 75% of the chain? If the parameters have some function relationship (e.g. Aln(Bd+C) where d is distance*), then I could reasonably expect to estimate A,B,C given a subset of the contact probability curve. That is, I could generate simulations of size 2048, crop the probability curve to the first 25% (512) and train on that. At test time, if I want to predict parameters for 8192, I would need to crop to 512.

*I’ve explored this particular functional form with synthetic data, but I suspect that what we really want is the parameters to decay/plateau to some value rather than increase to infinity as d increases.

Can we use the GNN and the MLP as initial guesses for max entropy? How much faster is this than the regular max ent approach?



Problem with GNN:
Even given the same plaid params, if you change the diag params, you get a different diag normalized contact map. The eigenvectors/PCs of the diag normalized contact map are unchanged, but the magnitudes are changed. The totally makes sense based on the physics of the model. For example, if all diag params are 0, then plaid params in [-1, 1] will have a huge effect. If diag params, are in [0, 40], plaid params in [-1, 1] are rapidly washed out.

Solution(?): jointly estimate the params, we can think of the parameters as one big matrix. If Y is contact map, E is plaid params, and D is diag params, then W = E + D is net param. Really what the GNN should be doing is learning the appropriate E given D such that the simulation outputs Y. Accordingly, we can use the MLP to estimate D, use this as edge features in the GNN and then use the GNN to learn plaid parameters, E. The GNN can return E or W. 

To test this, we need a dataset with a range of plaid patterns AND a range of diag patterns. Imagine that we had solved the diag problem - i.e. we had a really good MLP that could estimate D from Y. Since our MLP isn't quite that good, let's just use the ground truth D as input to the GNN. Does this help the GNN? It shouldn't hurt the GNN...

Unrelated, should also probably crop to the first 200? subdiagonals, anythign past that is more likely to be noise, and likely unneeded even if there is information there. This really shouldn't cause any issues.
