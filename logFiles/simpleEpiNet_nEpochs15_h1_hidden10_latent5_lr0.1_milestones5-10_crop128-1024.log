Namespace(batch_size=16, crop=[128, 1024], cuda=True, data_folder='/../../../project2/depablo/erschultz/dataset_04_06_21', device=device(type='cuda'), gamma=0.1, gpus=1, height=1, hidden=10, ifile=None, ifile_folder='models/', k=2, latent=5, lr=0.001, milestones=[5, 10], n_epochs=15, num_workers=2, ofile='simpleEpiNet_nEpochs15_h1_hidden10_latent5_lr0.1_milestones5-10_crop128-1024', ofile_folder='models/', pretrained=False, print_mod=2, resume_training=False, save_mod=5, seed=42, start_epoch=1, use_parallel=False, y_diag_norm=True)
Adjusting learning rate of group 0 to 1.0000e-03.
Namespace(batch_size=16, crop=[128, 1024], cuda=True, data_folder='/../../../project2/depablo/erschultz/dataset_04_06_21', device=device(type='cuda'), gamma=0.1, gpus=1, height=1, hidden=10, ifile=None, ifile_folder='models/', k=2, latent=5, lr=0.001, milestones=[5, 10], n_epochs=15, num_workers=2, ofile='simpleEpiNet_nEpochs15_h1_hidden10_latent5_lr0.1_milestones5-10_crop128-1024', ofile_folder='models/', pretrained=False, print_mod=2, resume_training=False, save_mod=5, seed=42, start_epoch=1, use_parallel=False, y_diag_norm=True)
Adjusting learning rate of group 0 to 1.0000e-03.
Namespace(batch_size=16, crop=[128, 1024], cuda=True, data_folder='/../../../project2/depablo/skyhl/dataset_04_07_21', device=device(type='cuda'), gamma=0.1, gpus=1, height=1, hidden=10, ifile=None, ifile_folder='models/', k=2, latent=5, lr=0.001, milestones=[5, 10], n=896, n_epochs=15, num_workers=2, ofile='simpleEpiNet_nEpochs15_h1_hidden10_latent5_lr0.1_milestones5-10_crop128-1024', ofile_folder='models/', pretrained=False, print_mod=2, resume_training=False, save_mod=5, seed=42, start_epoch=1, use_parallel=False, y_diag_norm=True)
Skipping hi_eric.txt
Adjusting learning rate of group 0 to 1.0000e-03.
Namespace(batch_size=16, crop=[128, 1024], cuda=True, data_folder='/../../../project2/depablo/skyhl/dataset_04_07_21', device=device(type='cuda'), gamma=0.1, gpus=1, height=1, hidden=10, ifile=None, ifile_folder='models/', k=2, latent=5, lr=0.001, milestones=[5, 10], n=896, n_epochs=15, num_workers=2, ofile='simpleEpiNet_nEpochs15_h1_hidden10_latent5_lr0.1_milestones5-10_crop128-1024', ofile_folder='models/', pretrained=False, print_mod=2, resume_training=False, save_mod=5, seed=42, start_epoch=1, use_parallel=False, y_diag_norm=True)
Skipping hi_eric.txt
Adjusting learning rate of group 0 to 1.0000e-03.
<class 'torch.Tensor'> torch.float32
<class 'torch.Tensor'> torch.float32
Namespace(batch_size=16, crop=[128, 1024], cuda=True, data_folder='/../../../project2/depablo/skyhl/dataset_04_07_21', device=device(type='cuda'), gamma=0.1, gpus=1, height=1, hidden=10, ifile=None, ifile_folder='models/', k=2, latent=5, lr=0.001, milestones=[5, 10], n=896, n_epochs=15, num_workers=2, ofile='simpleEpiNet_nEpochs15_h1_hidden10_latent5_lr0.1_milestones5-10_crop128-1024', ofile_folder='models/', pretrained=False, print_mod=2, resume_training=False, save_mod=5, seed=42, start_epoch=1, use_parallel=False, y_diag_norm=True)
Skipping hi_eric.txt
Adjusting learning rate of group 0 to 1.0000e-03.
Adjusting learning rate of group 0 to 1.0000e-03.
Adjusting learning rate of group 0 to 1.0000e-03.
Epoch 2, loss = 0.1611
Adjusting learning rate of group 0 to 1.0000e-03.
Adjusting learning rate of group 0 to 1.0000e-03.
Epoch 4, loss = 0.1605
Adjusting learning rate of group 0 to 1.0000e-04.
Namespace(batch_size=16, crop=[128, 1024], cuda=True, data_folder='/../../../project2/depablo/skyhl/dataset_04_07_21', device=device(type='cuda'), gamma=0.1, gpus=1, height=1, hidden=10, ifile=None, ifile_folder='models/', k=2, latent=5, lr=0.001, milestones=[5, 10], n=896, n_epochs=15, num_workers=2, ofile='simpleEpiNet_nEpochs15_h1_hidden10_latent5_lr0.1_milestones5-10_crop128-1024', ofile_folder='models/', pretrained=False, print_mod=2, resume_training=False, save_mod=5, seed=42, start_epoch=1, use_parallel=False, y_diag_norm=True)

























































































































































































































































































































































































































































































































































































































Skipping hi_eric.txt















































































































































































































































































































































































































Adjusting learning rate of group 0 to 1.0000e-03.
Adjusting learning rate of group 0 to 1.0000e-03.
Adjusting learning rate of group 0 to 1.0000e-03.
Epoch 2, loss = 0.1611
Adjusting learning rate of group 0 to 1.0000e-03.
Adjusting learning rate of group 0 to 1.0000e-03.
Epoch 4, loss = 0.1605
Adjusting learning rate of group 0 to 1.0000e-04.
Adjusting learning rate of group 0 to 1.0000e-04.
Epoch 6, loss = 0.1604
Adjusting learning rate of group 0 to 1.0000e-04.
Adjusting learning rate of group 0 to 1.0000e-04.
Epoch 8, loss = 0.1604
Adjusting learning rate of group 0 to 1.0000e-04.
Adjusting learning rate of group 0 to 1.0000e-05.
Epoch 10, loss = 0.1604
Adjusting learning rate of group 0 to 1.0000e-05.
