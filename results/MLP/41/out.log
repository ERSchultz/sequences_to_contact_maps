Took 3.0 seconds to move data to scratch
#### ARCHITECTURE ####
Sequential(
  (0): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1024, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (1): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (2): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (3): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (4): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (5): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (6): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=33, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
)
Namespace(GNN_mode=False, transforms=[], pre_transforms=[], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=True, use_edge_attr=False, relabel_11_to_00=False, split_edges_for_feature_augmentation=False, data_folder='/home/erschultz/scratch/dataset_test_log', scratch='/home/erschultz/scratch', root_name=None, delete_root=True, toxx=False, toxx_mode='mean', y_preprocessing=None, y_zero_diag_count=0, log_preprocessing=None, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=True, use_scratch_parallel=False, split_percents=[0.8, 0.2, 0], split_sizes=None, random_split=True, shuffle=True, batch_size=32, num_workers=8, start_epoch=1, n_epochs=80, save_mod=5, print_mod=2, lr=0.001, gpus=1, milestones=[50], gamma=0.1, loss='mse', autoencoder_mode=False, verbose=False, print_params=True, output_mode='diag_chis_bond_length', model_type='MLP', id=41, pretrained=False, resume_training=False, k=None, m=1024, seed=42, act='prelu', inner_act=None, out_act='prelu', training_norm=None, dropout=None, dropout_p=0.2, parameter_sharing=False, use_bias=True, message_passing='GCN', head_architecture=None, head_hidden_sizes_list=None, encoder_hidden_sizes_list=None, update_hidden_sizes_list=None, head_act='relu', num_heads=1, concat_heads=True, kernel_w_list=None, hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000, 33], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/MLP/41', log_file_path='/home/erschultz/sequences_to_contact_maps/results/MLP/41/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/MLP/41/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/MLP/41/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7f792c1a6310>, channels=1, edge_transforms=[], node_transforms=[], edge_dim=0, transforms_processed=None, pre_transforms_processed=None, cuda=True, use_parallel=False, device=device(type='cuda'))

#### TRAINING/VALIDATION ####
Epoch 2, loss = 473.9833
Mean test/val loss: 370.5422

Epoch 4, loss = 337.6312
Mean test/val loss: 540.5996

Epoch 6, loss = 308.6913
Mean test/val loss: 356.4560

Epoch 8, loss = 340.5773
Mean test/val loss: 292.8836

Epoch 10, loss = 279.1467
Mean test/val loss: 315.3064

Epoch 12, loss = 224.0060
Mean test/val loss: 315.4134

Epoch 14, loss = 241.1405
Mean test/val loss: 247.9740

Epoch 16, loss = 201.0702
Mean test/val loss: 198.4509

Epoch 18, loss = 172.1960
Mean test/val loss: 171.6252

Epoch 20, loss = 182.6717
Mean test/val loss: 225.9941

Epoch 22, loss = 146.8196
Mean test/val loss: 157.5536

Epoch 24, loss = 189.5405
Mean test/val loss: 183.6647

Epoch 26, loss = 136.1556
Mean test/val loss: 160.2586

Epoch 28, loss = 149.8049
Mean test/val loss: 291.0840

Epoch 30, loss = 122.0921
Mean test/val loss: 236.0650

Epoch 32, loss = 168.3142
Mean test/val loss: 154.7500

Epoch 34, loss = 166.6944
Mean test/val loss: 246.9666

Epoch 36, loss = 122.6103
Mean test/val loss: 148.5529

Epoch 38, loss = 186.7982
Mean test/val loss: 168.8526

Epoch 40, loss = 119.7422
Mean test/val loss: 159.7258

Epoch 42, loss = 146.1473
Mean test/val loss: 141.1345

Epoch 44, loss = 103.4233
Mean test/val loss: 145.4543

Epoch 46, loss = 100.9447
Mean test/val loss: 138.5598

Epoch 48, loss = 120.2788
Mean test/val loss: 162.2126

Epoch 50, loss = 123.5695
Mean test/val loss: 157.2295

Epoch 52, loss = 71.5270
Mean test/val loss: 122.3841

Epoch 54, loss = 71.8582
Mean test/val loss: 127.0874

Epoch 56, loss = 70.4583
Mean test/val loss: 126.2936

Epoch 58, loss = 67.7930
Mean test/val loss: 123.3435

Epoch 60, loss = 69.0587
Mean test/val loss: 129.9071

Epoch 62, loss = 69.0543
Mean test/val loss: 130.2748

Epoch 64, loss = 69.8324
Mean test/val loss: 124.8393

Epoch 66, loss = 65.0281
Mean test/val loss: 121.3257

Epoch 68, loss = 64.5252
Mean test/val loss: 123.3609

Epoch 70, loss = 63.9734
Mean test/val loss: 128.4808

Epoch 72, loss = 64.2555
Mean test/val loss: 121.3253

Epoch 74, loss = 62.4121
Mean test/val loss: 123.2161

Epoch 76, loss = 64.5595
Mean test/val loss: 121.8571

Epoch 78, loss = 62.8372
Mean test/val loss: 130.1989

Epoch 80, loss = 62.4753
Mean test/val loss: 126.6985


Total parameters: 6,063,040
Total training + validation time: 0.0 hours
Final val loss: 126.69849113796069

#### Plotting Script ####
Prediction Results:
/home/erschultz/sequences_to_contact_maps/results/MLP/41/sample436: 13.373456001281738
/home/erschultz/sequences_to_contact_maps/results/MLP/41/sample1049: 6.9317450523376465
/home/erschultz/sequences_to_contact_maps/results/MLP/41/sample1507: 426.25604248046875
/home/erschultz/sequences_to_contact_maps/results/MLP/41/sample143: 13.43568229675293
/home/erschultz/sequences_to_contact_maps/results/MLP/41/sample1107: 1.2576019763946533
Loss: 92.25090556144714 +- 167.06409752126584

