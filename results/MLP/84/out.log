Took 223.0 seconds to move data to scratch
#### ARCHITECTURE ####
Sequential(
  (0): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1024, out_features=2000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (1): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=2000, out_features=2000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (2): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=2000, out_features=2000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (3): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=2000, out_features=2000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (4): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=2000, out_features=2000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (5): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=2000, out_features=2000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (6): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=2000, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
)
Namespace(GNN_mode=False, transforms=[], pre_transforms=[], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=True, use_edge_attr=False, relabel_11_to_00=False, split_edges_for_feature_augmentation=False, data_folder='/scratch/midway2/erschultz/MLP3/dataset_09_30_22', scratch='/scratch/midway2/erschultz/MLP3', root_name=None, delete_root=True, toxx=False, toxx_mode='mean', y_preprocessing=None, y_zero_diag_count=0, log_preprocessing='ln', preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=True, use_scratch_parallel=False, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=False, shuffle=True, batch_size=32, num_workers=8, start_epoch=1, n_epochs=70, save_mod=5, print_mod=2, lr=0.001, gpus=1, milestones=[50], gamma=0.1, loss='mse', autoencoder_mode=False, verbose=False, print_params=True, output_mode='diag_chi_continuous', model_type='MLP', id=84, pretrained=False, resume_training=False, k=None, m=1024, seed=42, act='prelu', inner_act=None, out_act='prelu', training_norm=None, dropout=None, dropout_p=0.2, parameter_sharing=False, use_bias=True, message_passing='GCN', head_architecture=None, head_hidden_sizes_list=None, encoder_hidden_sizes_list=None, update_hidden_sizes_list=None, head_act='relu', num_heads=1, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[2000, 2000, 2000, 2000, 2000, 2000, 1024], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/MLP/84', log_file_path='/home/erschultz/sequences_to_contact_maps/results/MLP/84/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/MLP/84/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/MLP/84/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7f28d4ceb670>, channels=1, edge_transforms=[], node_transforms=[], edge_dim=0, transforms_processed=None, pre_transforms_processed=None, cuda=True, use_parallel=False, device=device(type='cuda'))

#### TRAINING/VALIDATION ####
Epoch 2, loss = 7646.3396
Mean test/val loss: 189.1185

Epoch 4, loss = 39.3950
Mean test/val loss: 16.4061

Epoch 6, loss = 11.4724
Mean test/val loss: 9.2594

Epoch 8, loss = 15.8236
Mean test/val loss: 11.3518

Epoch 10, loss = 11.3263
Mean test/val loss: 11.3347

Epoch 12, loss = 12.9423
Mean test/val loss: 15.4660

Epoch 14, loss = 11.3964
Mean test/val loss: 9.7650

Epoch 16, loss = 10.9154
Mean test/val loss: 11.8517

Epoch 18, loss = 10.9152
Mean test/val loss: 9.2142

Epoch 20, loss = 10.4527
Mean test/val loss: 9.9908

Epoch 22, loss = 10.7438
Mean test/val loss: 10.0492

Epoch 24, loss = 10.4274
Mean test/val loss: 9.8329

Epoch 26, loss = 10.9733
Mean test/val loss: 9.3625

Epoch 28, loss = 10.4086
Mean test/val loss: 9.3120

Epoch 30, loss = 10.2651
Mean test/val loss: 12.8230

Epoch 32, loss = 10.0269
Mean test/val loss: 9.2811

Epoch 34, loss = 10.2748
Mean test/val loss: 13.0470

Epoch 36, loss = 10.0330
Mean test/val loss: 9.1341

Epoch 38, loss = 10.3079
Mean test/val loss: 9.9199

Epoch 40, loss = 10.1637
Mean test/val loss: 9.1441

Epoch 42, loss = 10.0284
Mean test/val loss: 9.3769

Epoch 44, loss = 10.0710
Mean test/val loss: 9.0141

Epoch 46, loss = 10.1787
Mean test/val loss: 9.1146

Epoch 48, loss = 9.9328
Mean test/val loss: 9.0181

Epoch 50, loss = 9.9858
Mean test/val loss: 9.0340

Epoch 52, loss = 9.7150
Mean test/val loss: 9.0480

Epoch 54, loss = 9.7265
Mean test/val loss: 8.9436

Epoch 56, loss = 9.7417
Mean test/val loss: 9.0005

Epoch 58, loss = 9.7461
Mean test/val loss: 8.9853

Epoch 60, loss = 9.7154
Mean test/val loss: 9.0115

Epoch 62, loss = 9.7366
Mean test/val loss: 9.0245

Epoch 64, loss = 9.7689
Mean test/val loss: 9.0043

Epoch 66, loss = 9.7393
Mean test/val loss: 9.0127

Epoch 68, loss = 9.7361
Mean test/val loss: 8.9617

Epoch 70, loss = 9.7349
Mean test/val loss: 9.1967


Total parameters: 24,109,031
Total training + validation time: 0.0 hours
Final val loss: 9.196669340133667

#### Plotting Script ####
Prediction Results:
/home/erschultz/sequences_to_contact_maps/results/MLP/84/sample1: <function plot_diag_chi at 0x7f28a7dab4c0>
/home/erschultz/sequences_to_contact_maps/results/MLP/84/sample10: <function plot_diag_chi at 0x7f28a7dab4c0>
/home/erschultz/sequences_to_contact_maps/results/MLP/84/sample100: <function plot_diag_chi at 0x7f28a7dab4c0>
/home/erschultz/sequences_to_contact_maps/results/MLP/84/sample1000: <function plot_diag_chi at 0x7f28a7dab4c0>
/home/erschultz/sequences_to_contact_maps/results/MLP/84/sample1001: <function plot_diag_chi at 0x7f28a7dab4c0>
Loss: 8.886516725448743 +- 5.187410524760838

