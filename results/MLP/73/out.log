Took 2.0 seconds to move data to scratch
#### ARCHITECTURE ####
Sequential(
  (0): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1024, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (1): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (2): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (3): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (4): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (5): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (6): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
)
Namespace(GNN_mode=False, transforms=[], pre_transforms=[], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=True, use_edge_attr=False, relabel_11_to_00=False, split_edges_for_feature_augmentation=False, data_folder='/home/erschultz/scratch/dataset_test_logistic', scratch='/home/erschultz/scratch', root_name=None, delete_root=True, toxx=False, toxx_mode='mean', y_preprocessing=None, y_zero_diag_count=0, log_preprocessing='ln', preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=True, use_scratch_parallel=False, split_percents=[0.8, 0.2, 0], split_sizes=None, random_split=True, shuffle=True, batch_size=32, num_workers=8, start_epoch=1, n_epochs=80, save_mod=5, print_mod=2, lr=0.001, gpus=1, milestones=[30], gamma=0.1, loss='mse', autoencoder_mode=False, verbose=False, print_params=True, output_mode='diag_chi_continuous', model_type='MLP', id=73, pretrained=False, resume_training=False, k=None, m=1024, seed=42, act='prelu', inner_act=None, out_act='prelu', training_norm=None, dropout=None, dropout_p=0.2, parameter_sharing=False, use_bias=True, message_passing='GCN', head_architecture=None, head_hidden_sizes_list=None, encoder_hidden_sizes_list=None, update_hidden_sizes_list=None, head_act='relu', num_heads=1, concat_heads=True, kernel_w_list=None, hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000, 1024], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/MLP/73', log_file_path='/home/erschultz/sequences_to_contact_maps/results/MLP/73/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/MLP/73/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/MLP/73/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7f55800e6310>, channels=1, edge_transforms=[], node_transforms=[], edge_dim=0, transforms_processed=None, pre_transforms_processed=None, cuda=True, use_parallel=False, device=device(type='cuda'))

#### TRAINING/VALIDATION ####
Epoch 2, loss = 128.4887
Mean test/val loss: 140.8299

Epoch 4, loss = 143.5641
Mean test/val loss: 135.6292

Epoch 6, loss = 146.1943
Mean test/val loss: 158.4048

Epoch 8, loss = 131.2677
Mean test/val loss: 121.9127

Epoch 10, loss = 143.7205
Mean test/val loss: 120.7373

Epoch 12, loss = 162.9080
Mean test/val loss: 126.5103

Epoch 14, loss = 127.4826
Mean test/val loss: 132.1554

Epoch 16, loss = 135.2088
Mean test/val loss: 119.6998

Epoch 18, loss = 132.4118
Mean test/val loss: 126.2060

Epoch 20, loss = 143.3983
Mean test/val loss: 132.4933

Epoch 22, loss = 124.2291
Mean test/val loss: 153.1024

Epoch 24, loss = 125.9758
Mean test/val loss: 168.0874

Epoch 26, loss = 129.8329
Mean test/val loss: 140.9634

Epoch 28, loss = 122.7687
Mean test/val loss: 123.4054

Epoch 30, loss = 129.6446
Mean test/val loss: 131.3372

Epoch 32, loss = 117.9890
Mean test/val loss: 121.0132

Epoch 34, loss = 118.3201
Mean test/val loss: 118.6708

Epoch 36, loss = 118.2202
Mean test/val loss: 122.1972

Epoch 38, loss = 121.5911
Mean test/val loss: 120.3040

Epoch 40, loss = 119.0818
Mean test/val loss: 120.3779

Epoch 42, loss = 119.0285
Mean test/val loss: 121.5925

Epoch 44, loss = 117.3269
Mean test/val loss: 123.8711

Epoch 46, loss = 118.7638
Mean test/val loss: 118.9290

Epoch 48, loss = 117.4530
Mean test/val loss: 119.4894

Epoch 50, loss = 117.5869
Mean test/val loss: 119.3228

Epoch 52, loss = 116.3453
Mean test/val loss: 121.3750

Epoch 54, loss = 118.2860
Mean test/val loss: 120.1057

Epoch 56, loss = 116.8051
Mean test/val loss: 119.3290

Epoch 58, loss = 117.5030
Mean test/val loss: 123.1365

Epoch 60, loss = 117.1654
Mean test/val loss: 130.6278

Epoch 62, loss = 117.0010
Mean test/val loss: 126.2182

Epoch 64, loss = 119.5394
Mean test/val loss: 122.9226

Epoch 66, loss = 116.2227
Mean test/val loss: 124.0527

Epoch 68, loss = 115.7745
Mean test/val loss: 122.1413

Epoch 70, loss = 117.8868
Mean test/val loss: 125.7141

Epoch 72, loss = 120.0344
Mean test/val loss: 119.1304

Epoch 74, loss = 115.4758
Mean test/val loss: 120.3668

Epoch 76, loss = 120.1746
Mean test/val loss: 119.5433

Epoch 78, loss = 117.3706
Mean test/val loss: 119.6108

Epoch 80, loss = 116.5966
Mean test/val loss: 125.0641


Total parameters: 7,055,031
Total training + validation time: 0.0 hours
Final val loss: 125.06407873971122

#### Plotting Script ####
Prediction Results:
/home/erschultz/sequences_to_contact_maps/results/MLP/73/sample3665: <function plot_diag_chi at 0x7f543ad00280>
/home/erschultz/sequences_to_contact_maps/results/MLP/73/sample2481: <function plot_diag_chi at 0x7f543ad00280>
/home/erschultz/sequences_to_contact_maps/results/MLP/73/sample2886: <function plot_diag_chi at 0x7f543ad00280>
/home/erschultz/sequences_to_contact_maps/results/MLP/73/sample2141: <function plot_diag_chi at 0x7f543ad00280>
/home/erschultz/sequences_to_contact_maps/results/MLP/73/sample3962: <function plot_diag_chi at 0x7f543ad00280>
Loss: 125.46740238794094 +- 108.46820236306479

