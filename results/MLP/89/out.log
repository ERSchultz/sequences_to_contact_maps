Took 2.0 seconds to move data to scratch
#### ARCHITECTURE ####
Sequential(
  (0): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1024, out_features=2000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (1): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=2000, out_features=2000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (2): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=2000, out_features=2000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (3): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=2000, out_features=2000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (4): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=2000, out_features=2000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (5): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=2000, out_features=2000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (6): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=2000, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
)
Namespace(GNN_mode=False, transforms=[], pre_transforms=[], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=True, use_edge_attr=False, relabel_11_to_00=False, split_edges_for_feature_augmentation=False, data_folder='/home/erschultz/scratch/MLP1/dataset_09_30_22', scratch='/home/erschultz/scratch/MLP1', root_name=None, delete_root=True, toxx=False, toxx_mode='mean', y_preprocessing='log', y_zero_diag_count=0, log_preprocessing=None, preprocessing_norm=None, min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=True, use_scratch_parallel=False, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=32, num_workers=8, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.001, gpus=1, milestones=[50], gamma=0.1, loss='mse', autoencoder_mode=False, verbose=False, print_params=True, output_mode='diag_chi_continuous', model_type='MLP', id=89, pretrained=False, resume_training=False, k=None, m=1024, seed=42, act='prelu', inner_act=None, out_act='prelu', training_norm=None, dropout=None, dropout_p=0.2, parameter_sharing=False, use_bias=True, message_passing='GCN', head_architecture=None, head_architecture_2=None, head_hidden_sizes_list=None, encoder_hidden_sizes_list=None, update_hidden_sizes_list=None, head_act='relu', num_heads=1, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[2000, 2000, 2000, 2000, 2000, 2000, 1024], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/MLP/89', log_file_path='/home/erschultz/sequences_to_contact_maps/results/MLP/89/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/MLP/89/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/MLP/89/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7fadaf2a6310>, channels=1, edge_transforms=[], node_transforms=[], edge_dim=0, transforms_processed=None, pre_transforms_processed=None, cuda=True, use_parallel=False, device=device(type='cuda'))

split sizes: train=2268, val=252, test=0, N=2520
#### TRAINING/VALIDATION ####
Epoch 2, loss = 12.2575
Mean test/val loss: 8.9322

Epoch 4, loss = 10.0453
Mean test/val loss: 8.2704

Epoch 6, loss = 8.9333
Mean test/val loss: 8.4649

Epoch 8, loss = 8.6318
Mean test/val loss: 9.1059

Epoch 10, loss = 8.4674
Mean test/val loss: 9.3997

Epoch 12, loss = 8.5602
Mean test/val loss: 7.2304

Epoch 14, loss = 7.5012
Mean test/val loss: 7.1008

Epoch 16, loss = 7.7902
Mean test/val loss: 6.7768

Epoch 18, loss = 7.2523
Mean test/val loss: 6.7588

Epoch 20, loss = 8.4197
Mean test/val loss: 12.1041

Epoch 22, loss = 6.8815
Mean test/val loss: 7.1228

Epoch 24, loss = 7.3013
Mean test/val loss: 9.4585

Epoch 26, loss = 6.8994
Mean test/val loss: 9.1171

Epoch 28, loss = 5.9345
Mean test/val loss: 5.4763

Epoch 30, loss = 7.7224
Mean test/val loss: 6.4447

Epoch 32, loss = 6.2726
Mean test/val loss: 5.5557

Epoch 34, loss = 6.3164
Mean test/val loss: 5.2998

Epoch 36, loss = 5.5907
Mean test/val loss: 6.3171

Epoch 38, loss = 5.8255
Mean test/val loss: 7.8313

Epoch 40, loss = 4.9743
Mean test/val loss: 7.7742

Epoch 42, loss = 6.9101
Mean test/val loss: 8.4290

Epoch 44, loss = 417386966.3662
Mean test/val loss: 48870432.0000

Epoch 46, loss = 15572506.1408
Mean test/val loss: 10527830.2500

Epoch 48, loss = 8519175.3310
Mean test/val loss: 7553342.5625

Epoch 50, loss = 6510339.1127
Mean test/val loss: 5960202.3750

Epoch 52, loss = 5730074.2324
Mean test/val loss: 5250680.1250

Epoch 54, loss = 5659965.5458
Mean test/val loss: 4990315.5000

Epoch 56, loss = 5499246.7218
Mean test/val loss: 4800684.3750

Epoch 58, loss = 5361252.9965
Mean test/val loss: 4785120.6250

Epoch 60, loss = 5247776.0810
Mean test/val loss: 4686707.8125

Epoch 62, loss = 5091525.5739
Mean test/val loss: 4610881.4062

Epoch 64, loss = 4904533.6444
Mean test/val loss: 4502838.5625

Epoch 66, loss = 4812728.4472
Mean test/val loss: 4192564.2500

Epoch 68, loss = 4688469.2852
Mean test/val loss: 4050201.8125

Epoch 70, loss = 4490601.0176
Mean test/val loss: 4087372.7500

Epoch 72, loss = 4377759.9613
Mean test/val loss: 3821020.5000

Epoch 74, loss = 4141011.5739
Mean test/val loss: 3646398.5000

Epoch 76, loss = 4077142.3380
Mean test/val loss: 3860467.2188

Epoch 78, loss = 3892392.2535
Mean test/val loss: 3368032.4375

Epoch 80, loss = 3857869.8944
Mean test/val loss: 3442294.1562

Epoch 82, loss = 3593359.3063
Mean test/val loss: 3236454.8750

Epoch 84, loss = 3525581.8556
Mean test/val loss: 3126973.5625

Epoch 86, loss = 3373308.8944
Mean test/val loss: 2895337.8750

Epoch 88, loss = 3295420.7606
Mean test/val loss: 2852961.8750

Epoch 90, loss = 3074226.9437
Mean test/val loss: 2674273.4375

Epoch 92, loss = 2885018.9085
Mean test/val loss: 2532354.7188

Epoch 94, loss = 2966454.3768
Mean test/val loss: 2765819.9688

Epoch 96, loss = 2669827.4965
Mean test/val loss: 2339993.1250

Epoch 98, loss = 2642958.7218
Mean test/val loss: 2200322.4531

Epoch 100, loss = 2398610.5722
Mean test/val loss: 2366835.2188


Total parameters: 24,109,031
Total training + validation time: 0.0 hours
Final val loss: 2366835.21875

split sizes: train=2268, val=252, test=0, N=2520
#### Plotting Script ####
Prediction Results:
/home/erschultz/sequences_to_contact_maps/results/MLP/89/sample552: <function plot_diag_chi at 0x7fac69ebd550>
/home/erschultz/sequences_to_contact_maps/results/MLP/89/sample1794: <function plot_diag_chi at 0x7fac69ebd550>
/home/erschultz/sequences_to_contact_maps/results/MLP/89/sample1128: <function plot_diag_chi at 0x7fac69ebd550>
/home/erschultz/sequences_to_contact_maps/results/MLP/89/sample1938: <function plot_diag_chi at 0x7fac69ebd550>
/home/erschultz/sequences_to_contact_maps/results/MLP/89/sample1131: <function plot_diag_chi at 0x7fac69ebd550>
Loss: 2010265.8882546038 +- 1023614.0546514109

