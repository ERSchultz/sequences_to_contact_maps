Namespace(mode=None, verbose=False, data_folder='/../../../project2/depablo/erschultz/dataset_04_18_21', toxx=True, toxx_mode='mean', y_preprocessing='diag', y_norm='batch', x_reshape=False, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, split=[0.8, 0.1, 0.1], shuffle=True, batch_size=32, num_workers=4, start_epoch=1, n_epochs=20, save_mod=5, print_mod=2, lr=0.1, gpus=1, milestones=None, gamma=0.1, loss='mse', model_type='UNet', pretrained=False, resume_training=False, ifile_folder=None, ifile=None, k=2, n=1024, seed=42, out_act='sigmoid', plot=True, plot_predictions=False, kernel_w_list=None, hidden_sizes_list=None, nf=8, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, id=4, ofile_folder='results/UNet/4', log_file=<_io.TextIOWrapper name='results/UNet/4/out.log' mode='w' encoding='UTF-8'>, cuda=True, use_parallel=False, device=device(type='cuda'), criterion=<function mse_loss at 0x7fc6c5dec0d0>)

Epoch 2, loss = 0.0027
Mean test/val loss: 0.0030
Epoch 4, loss = 0.0025
Mean test/val loss: 0.0027
Epoch 6, loss = 0.0025
Mean test/val loss: 0.0027
Epoch 8, loss = 0.0025
Mean test/val loss: 0.0031
Epoch 10, loss = 0.0024
Mean test/val loss: 0.0025
Epoch 12, loss = 0.0024
Mean test/val loss: 0.0025
Epoch 14, loss = 0.0023
Mean test/val loss: 0.0023
Epoch 16, loss = 0.0022
Mean test/val loss: 0.0025
Epoch 18, loss = 0.0023
Mean test/val loss: 0.0024
Epoch 20, loss = 0.0023
Mean test/val loss: 0.0024

to_device_time:  0
test_time:  0
forward_time:  0
backward_time: 0

Total parameters: 655361
Total time: 3798.028924703598
Final val loss: 0.002386056784806507

#### Plotting Script ####
PCA Results:
Accuracy: 0.901 +- 0.039
Spearman R: 0.885 +- 0.046
Pearson R: 0.929 +- 0.016

Distance Stratified Pearson Correlation Results:
Overall Pearson R: 0.772 $\pm$ 0.115

Class Accuracy Results:
prcntDist [0.75067625 0.86077441 0.91623315 0.98192538 1.05521968 1.17607021
 1.26702019 1.41689416 1.70505444 5.05148524]
Accuracy: 0.2654385471343994 +- 0.017692575148330322
Loss: 0.0024198544392129407 +- 0.002507773670495565
acc arr [[0.23277074 0.56304324 0.24060532 ... 0.25670395 0.32695952 0.62500521]
 [0.18836103 0.51640958 0.29535853 ... 0.13881318 0.23429441 0.47883462]
 [0.23968403 0.56417623 0.27938841 ... 0.2039472  0.31484595 0.46743524]
 ...
 [0.24736575 0.50789517 0.24734903 ... 0.21273445 0.29626619 0.85105163]
 [0.24973785 0.49503172 0.28103879 ... 0.21262021 0.30155051 0.80242073]
 [0.24412675 0.61758976 0.13247148 ... 0.17752871 0.23452812 0.9049505 ]]
freq arr [[0.20217323 0.18937874 0.09024429 ... 0.06394386 0.06643295 0.04575157]
 [0.22844315 0.155056   0.06953049 ... 0.05808067 0.08024406 0.12661362]
 [0.19316673 0.15268898 0.07447433 ... 0.07412529 0.08735085 0.07974434]
 ...
 [0.2030983  0.21827126 0.1108017  ... 0.04637146 0.0351963  0.00997543]
 [0.19826698 0.19963074 0.09848976 ... 0.05791473 0.04772949 0.02237701]
 [0.22440338 0.25749016 0.12540817 ... 0.02756882 0.01420784 0.00096321]]

Namespace(mode=None, verbose=False, data_folder='/../../../project2/depablo/erschultz/dataset_04_18_21', toxx=True, toxx_mode='mean', y_preprocessing='diag', y_norm='batch', x_reshape=False, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, split=[0.8, 0.1, 0.1], shuffle=True, batch_size=16, num_workers=4, start_epoch=1, n_epochs=20, save_mod=5, print_mod=2, lr=0.1, gpus=1, milestones=None, gamma=0.1, loss='mse', model_type='UNet', id=4, pretrained=True, resume_training=False, ifile_folder=None, ifile=None, k=2, n=1024, seed=42, out_act='sigmoid', training_norm=None, plot=True, plot_predictions=False, kernel_w_list=None, hidden_sizes_list=None, nf=8, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, ofile_folder='results/UNet/4', log_file=<_io.TextIOWrapper name='results/UNet/4/out.log' mode='a' encoding='UTF-8'>, criterion=<function mse_loss at 0x7fe5ea532430>, channels=1, cuda=True, use_parallel=False, device=device(type='cuda'))
Model is loaded: results/UNet/4/model.pt
Prediction Results:
results/UNet/4/sample115
results/UNet/4/sample521
results/UNet/4/sample645
results/UNet/4/sample1524
results/UNet/4/sample1595
Loss: 6.96637702640146e-05 +- 0.00048265054000579013

