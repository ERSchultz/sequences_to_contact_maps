Namespace(mode=None, verbose=False, data_folder='/../../../project2/depablo/erschultz/dataset_04_18_21', toxx=True, toxx_mode='mean', y_preprocessing='prcnt', y_norm='instance', x_reshape=False, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, split=[0.8, 0.1, 0.1], shuffle=True, batch_size=16, num_workers=4, start_epoch=1, n_epochs=20, save_mod=5, print_mod=2, lr=0.001, gpus=1, milestones=None, gamma=0.1, loss='mse', model_type='UNet', id=37, pretrained=False, resume_training=False, ifile_folder=None, ifile=None, k=2, n=1024, seed=42, out_act='sigmoid', training_norm='batch', kernel_w_list=None, hidden_sizes_list=None, nf=8, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='results/UNet/37', log_file=<_io.TextIOWrapper name='results/UNet/37/out.log' mode='a' encoding='UTF-8'>, criterion=<function mse_loss at 0x7f4ce7d37550>, channels=1, cuda=True, use_parallel=False, device=device(type='cuda'))

Epoch 2, loss = 0.0292
Mean test/val loss: 0.0279
Epoch 4, loss = 0.0265
Mean test/val loss: 0.0263
Epoch 6, loss = 0.0257
Mean test/val loss: 0.0254
Epoch 8, loss = 0.0253
Mean test/val loss: 0.0251
Epoch 10, loss = 0.0250
Mean test/val loss: 0.0252
Epoch 12, loss = 0.0247
Mean test/val loss: 0.0250
Epoch 14, loss = 0.0247
Mean test/val loss: 0.0250
Epoch 16, loss = 0.0244
Mean test/val loss: 0.0254
Epoch 18, loss = 0.0242
Mean test/val loss: 0.0253
Epoch 20, loss = 0.0239
Mean test/val loss: 0.0252

to_device_time:  0
test_time:  0
forward_time:  0
backward_time: 0

Total parameters: 655361
Total time: 1585.155030965805
Final val loss: 0.025177193232453786

#### Plotting Script ####
PCA Results:
Accuracy: 0.946 +- 0.025
Spearman R: 0.96 +- 0.022
Pearson R: 0.98 +- 0.009

Distance Stratified Pearson Correlation Results:
Overall Pearson R: 0.811 $\pm$ 0.109

Prediction Results:
results/UNet/37/sample189
results/UNet/37/sample662
results/UNet/37/sample997
results/UNet/37/sample1950
results/UNet/37/sample898
Loss: 0.0006425172928720712 +- 0.00402651013656162

