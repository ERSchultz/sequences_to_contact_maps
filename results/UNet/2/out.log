Namespace(mode=None, verbose=False, data_folder='/../../../project2/depablo/erschultz/dataset_04_18_21', toxx=True, toxx_mode='mean', y_preprocessing='diag', y_norm='instance', x_reshape=False, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, split=[0.8, 0.1, 0.1], shuffle=True, batch_size=32, num_workers=4, start_epoch=1, n_epochs=20, save_mod=5, print_mod=2, lr=0.01, gpus=1, milestones=None, gamma=0.1, loss='mse', model_type='UNet', pretrained=False, resume_training=False, ifile_folder=None, ifile=None, k=2, n=1024, seed=42, out_act='sigmoid', plot=True, plot_predictions=False, kernel_w_list=None, hidden_sizes_list=None, nf=8, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, id=2, ofile_folder='results/UNet/2', log_file=<_io.TextIOWrapper name='results/UNet/2/out.log' mode='w' encoding='UTF-8'>, cuda=True, use_parallel=False, device=device(type='cuda'), criterion=<function mse_loss at 0x7f5229c440d0>)

Epoch 2, loss = 0.0091
Mean test/val loss: 0.0094
Epoch 4, loss = 0.0069
Mean test/val loss: 0.0071
Epoch 6, loss = 0.0062
Mean test/val loss: 0.0064
Epoch 8, loss = 0.0057
Mean test/val loss: 0.0060
Epoch 10, loss = 0.0052
Mean test/val loss: 0.0055
Epoch 12, loss = 0.0051
Mean test/val loss: 0.0052
Epoch 14, loss = 0.0050
Mean test/val loss: 0.0053
Epoch 16, loss = 0.0049
Mean test/val loss: 0.0051
Epoch 18, loss = 0.0048
Mean test/val loss: 0.0056
Epoch 20, loss = 0.0047
Mean test/val loss: 0.0053

to_device_time:  0
test_time:  0
forward_time:  0
backward_time: 0

Total parameters: 655361
Total time: 3609.989865541458
Final val loss: 0.005318136353577886

#### Plotting Script ####
PCA Results:
Accuracy: 0.924 +- 0.034
Spearman R: 0.964 +- 0.017
Pearson R: 0.975 +- 0.012

Distance Stratified Pearson Correlation Results:
Overall Pearson R: 0.811 $\pm$ 0.12

Class Accuracy Results:
prcntDist [0.75067625 0.86077441 0.91623315 0.98192538 1.05521968 1.17607021
 1.26702019 1.41689416 1.70505444 5.05148524]
Accuracy: 0.30088947296142576 +- 0.04241509928596029
Loss: 0.005337862302549183 +- 0.0021122828222671017
acc arr [[0.61479098 0.35126751 0.14657395 ... 0.34123788 0.37416021 0.7917622 ]
 [0.00581114 0.10778163 0.07719317 ... 0.21368756 0.29497754 0.97116688]
 [0.00436435 0.10944    0.07527019 ... 0.25306847 0.56278796 0.88877993]
 ...
 [0.10338837 0.43058626 0.22672657 ... 0.3014972  0.52002384 0.25602294]
 [0.34964261 0.27850073 0.13705289 ... 0.26379924 0.33955403 0.57927037]
 [0.41699249 0.40422522 0.17857034 ... 0.2047876  0.57484226 0.        ]]
freq arr [[0.20217323 0.18937874 0.09024429 ... 0.06394386 0.06643295 0.04575157]
 [0.22844315 0.155056   0.06953049 ... 0.05808067 0.08024406 0.12661362]
 [0.19316673 0.15268898 0.07447433 ... 0.07412529 0.08735085 0.07974434]
 ...
 [0.2030983  0.21827126 0.1108017  ... 0.04637146 0.0351963  0.00997543]
 [0.19826698 0.19963074 0.09848976 ... 0.05791473 0.04772949 0.02237701]
 [0.22440338 0.25749016 0.12540817 ... 0.02756882 0.01420784 0.00096321]]

Namespace(mode=None, verbose=False, data_folder='/../../../project2/depablo/erschultz/dataset_04_18_21', toxx=True, toxx_mode='mean', y_preprocessing='diag', y_norm='instance', x_reshape=False, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, split=[0.8, 0.1, 0.1], shuffle=True, batch_size=16, num_workers=4, start_epoch=1, n_epochs=20, save_mod=5, print_mod=2, lr=0.01, gpus=1, milestones=None, gamma=0.1, loss='mse', model_type='UNet', id=2, pretrained=True, resume_training=False, ifile_folder=None, ifile=None, k=2, n=1024, seed=42, out_act='sigmoid', training_norm=None, plot=True, plot_predictions=False, kernel_w_list=None, hidden_sizes_list=None, nf=8, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, ofile_folder='results/UNet/2', log_file=<_io.TextIOWrapper name='results/UNet/2/out.log' mode='a' encoding='UTF-8'>, criterion=<function mse_loss at 0x7f354a18c430>, channels=1, cuda=True, use_parallel=False, device=device(type='cuda'))
Model is loaded: results/UNet/2/model.pt
Prediction Results:
results/UNet/2/sample1697
results/UNet/2/sample94
results/UNet/2/sample1083
results/UNet/2/sample1170
results/UNet/2/sample20
Loss: 0.0001641201041638851 +- 0.0011304287888104572

