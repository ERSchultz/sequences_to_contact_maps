Namespace(mode=None, verbose=False, data_folder='/../../../project2/depablo/erschultz/dataset_04_18_21', toxx=True, toxx_mode='mean', y_preprocessing='diag', y_norm='batch', x_reshape=False, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, split=[0.8, 0.1, 0.1], shuffle=True, batch_size=32, num_workers=4, start_epoch=1, n_epochs=15, save_mod=5, print_mod=2, lr=0.1, gpus=1, milestones=[5, 10], gamma=0.1, loss='mse', model_type='UNet', id=36, pretrained=False, resume_training=False, ifile_folder=None, ifile=None, k=2, n=1024, seed=42, out_act='sigmoid', training_norm='batch', kernel_w_list=None, hidden_sizes_list=None, nf=8, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='results/UNet/36', log_file=<_io.TextIOWrapper name='results/UNet/36/out.log' mode='a' encoding='UTF-8'>, criterion=<function mse_loss at 0x7f4bdf2de550>, channels=1, cuda=True, use_parallel=False, device=device(type='cuda'))

Epoch 2, loss = 0.0026
Mean test/val loss: 0.0028
Epoch 4, loss = 0.0025
Mean test/val loss: 0.0026
Epoch 6, loss = 0.0024
Mean test/val loss: 0.0026
Epoch 8, loss = 0.0024
Mean test/val loss: 0.0025
Epoch 10, loss = 0.0024
Mean test/val loss: 0.0026
Epoch 12, loss = 0.0024
Mean test/val loss: 0.0026
Epoch 14, loss = 0.0024
Mean test/val loss: 0.0029
Epoch 15, loss = 0.0024
Mean test/val loss: 0.0028

to_device_time:  0
test_time:  0
forward_time:  0
backward_time: 0

Total parameters: 655361
Total time: 2642.3201582431793
Final val loss: 0.002772257763094136

#### Plotting Script ####
PCA Results:
Accuracy: 0.888 +- 0.038
Spearman R: 0.819 +- 0.049
Pearson R: 0.891 +- 0.02

Distance Stratified Pearson Correlation Results:
Overall Pearson R: 0.75 $\pm$ 0.112

Class Accuracy Results:
prcntDist [0.75067625 0.86077441 0.91623315 0.98192538 1.05521968 1.17607021
 1.26702019 1.41689416 1.70505444 5.05148524]
Accuracy: 23.3% +- 1.4000000000000001
Loss: 0.003 +- 0.003
Prediction Results:
results/UNet/36/sample189
results/UNet/36/sample662
results/UNet/36/sample997
results/UNet/36/sample1950
results/UNet/36/sample898
Loss: 5.004931765142828e-05 +- 0.0003339358269461246

