#### INITIAL PARAMETERS ####
W torch.Size([16, 16])
Parameter containing:
tensor([[-1.1143,  0.3367, -0.0509,  0.8461, -0.2468,  0.2902,  0.6421, -1.3222,
          2.1435,  0.2325, -0.8231, -0.3118, -0.5364,  0.4480, -0.0475, -0.2673],
        [-1.0607,  1.0506, -1.2073, -0.7482,  0.5792,  0.3837,  0.3979, -0.8620,
          0.4085, -0.6797,  2.0249,  0.0976,  0.1969, -1.4671,  0.2872, -0.0840],
        [-0.4201,  0.0197, -1.1887, -1.0660, -0.6067, -0.3759, -0.5172, -0.0929,
          1.3147, -0.9256,  0.7715,  0.7459, -0.2317,  0.1986, -2.5898,  0.3454],
        [-1.1050,  0.0592,  0.8749, -1.3656,  0.3332, -0.6121, -0.5417,  1.5595,
          0.8486, -0.2308, -0.5880,  1.5124, -1.5960, -1.0115,  1.2087,  1.8653],
        [ 0.4507, -1.7446,  0.5640, -2.0243, -0.4364, -0.2604,  0.0753,  0.0907,
         -0.9007,  1.3189,  1.5858,  0.5701,  0.4407, -0.0094, -0.9781,  0.2069],
        [ 1.3780, -1.1759, -1.7735,  1.2009,  1.3145, -0.3829, -1.1913,  0.1760,
         -0.6799, -0.2819, -0.1830, -0.4130,  0.9765,  0.0958, -1.2718,  1.9211],
        [-2.2790, -1.9799, -2.0507,  1.5184,  0.1379,  1.2712, -1.5537, -1.1584,
          0.0779, -0.0265, -0.5204,  0.6694, -1.5005, -0.6693, -1.0278, -0.5176],
        [-0.8145,  0.3040,  0.0245,  0.3815, -0.2552,  0.3016,  1.0297, -0.2072,
          0.6462, -0.3358, -0.2952, -0.3684, -0.6002, -0.2417, -1.0118,  3.0701],
        [-1.4133, -0.3707,  0.2631,  0.5066,  0.6554,  0.8003, -0.4707,  0.3322,
          0.0370,  1.8072,  0.3590,  0.4349,  1.6250, -0.1016, -0.4400,  1.0259],
        [-2.4870,  1.1063,  0.5106, -1.0290, -0.3153,  0.8649,  0.5190, -0.0490,
         -1.0504, -1.3519,  1.0266, -0.3877, -0.4631, -0.0461,  2.1643,  0.6484],
        [ 0.5681, -0.2995, -1.1212, -0.7190,  0.5908, -2.3821,  0.4528,  1.4383,
         -1.3098,  1.4623,  2.0723, -1.4677, -2.1611, -1.5601,  0.8207,  0.8925],
        [ 1.0692,  0.4514,  1.2376,  0.3669, -2.4112,  0.6280,  2.4437,  1.7134,
          1.0600, -0.4647, -0.6753, -1.1699,  0.4089,  1.8574,  0.7920, -0.8328],
        [ 1.3978,  0.4254, -1.8333, -2.2971, -0.8066, -1.7669,  0.0062,  0.5448,
          0.2921,  0.1114, -0.4298,  0.9307,  1.0761, -0.2229, -0.0947, -0.4103],
        [-0.7524, -1.4637, -0.6343,  1.0678,  0.6935,  0.2167,  1.2845,  0.0803,
         -0.1221,  1.0257,  0.6135,  1.2995, -0.1423,  0.4921, -0.1896,  1.0267],
        [-1.4625, -0.0162, -2.4101,  2.1450,  2.9878,  2.2852,  3.0286, -0.4822,
          1.1236, -0.4518, -0.0446,  1.5994,  1.6631, -0.0828, -0.1995, -0.3388],
        [-1.1921, -1.4848,  0.5355,  0.1985,  2.0039,  0.9079, -0.0706,  0.1082,
         -1.2471,  2.3405,  0.1438,  0.4348,  0.6213, -2.9694,  0.5972, -0.1695]],
       device='cuda:0', requires_grad=True) 

act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

inner_act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

out_act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

encoder.module_0.weight torch.Size([100, 11])
Parameter containing:
tensor([[ 0.2305,  0.2503, -0.0706,  ...,  0.2658, -0.2212,  0.2621],
        [ 0.0564,  0.2228,  0.0408,  ...,  0.0769, -0.1389, -0.0354],
        [-0.1225,  0.2000, -0.2380,  ...,  0.2723, -0.2561,  0.2328],
        ...,
        [ 0.1799,  0.2176,  0.2333,  ...,  0.1313, -0.0969, -0.0051],
        [-0.2624, -0.0788, -0.1586,  ...,  0.2746,  0.1759, -0.1563],
        [-0.2982,  0.1144,  0.1689,  ...,  0.2472,  0.1288,  0.1997]],
       device='cuda:0', requires_grad=True) 

encoder.module_0.bias torch.Size([100])
Parameter containing:
tensor([-0.2039,  0.1755, -0.2060,  0.2983, -0.1278,  0.1817,  0.0604,  0.0799,
        -0.0462,  0.1238, -0.1257, -0.2842, -0.1158,  0.2362, -0.0794,  0.0948,
        -0.1115,  0.2262,  0.1805,  0.1064, -0.1541, -0.2464,  0.0114, -0.1769,
         0.2479, -0.2897,  0.1347,  0.3006,  0.1510,  0.1028, -0.2901,  0.2900,
        -0.0516, -0.2817,  0.2976, -0.1227, -0.0213,  0.2760, -0.2090, -0.2133,
         0.0490, -0.0404,  0.0695, -0.2529,  0.0090, -0.1341, -0.1482, -0.2761,
         0.1599,  0.0581, -0.2549,  0.2393,  0.0909,  0.0559, -0.1770,  0.0455,
         0.2905,  0.2068, -0.2348,  0.2752,  0.0234,  0.1450,  0.2342,  0.2570,
        -0.2350,  0.2640, -0.2048,  0.0226, -0.2107, -0.0661, -0.0137, -0.0361,
        -0.0476,  0.0238,  0.2974,  0.1752,  0.1687,  0.1207,  0.2334, -0.0139,
         0.0240,  0.0621, -0.2630, -0.2429,  0.0370, -0.1180, -0.0055, -0.0692,
         0.0469,  0.1962, -0.1000,  0.2415,  0.2381, -0.2314, -0.2328, -0.2439,
        -0.1652, -0.1174, -0.0227, -0.0733], device='cuda:0',
       requires_grad=True) 

encoder.module_2.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0505, -0.0318, -0.0362,  ..., -0.0803,  0.0202,  0.0546],
        [-0.0497,  0.0110, -0.0001,  ...,  0.0191, -0.0656, -0.0831],
        [-0.0314, -0.0932, -0.0466,  ...,  0.0261,  0.0610,  0.0939],
        ...,
        [-0.0659, -0.0734, -0.0759,  ..., -0.0997,  0.0442,  0.0803],
        [ 0.0599,  0.0649, -0.0803,  ...,  0.0758,  0.0459, -0.0501],
        [ 0.0145, -0.0630,  0.0150,  ..., -0.0838, -0.0755,  0.0149]],
       device='cuda:0', requires_grad=True) 

encoder.module_2.bias torch.Size([100])
Parameter containing:
tensor([ 0.0289,  0.0232,  0.0622,  0.0642, -0.0871,  0.0471,  0.0621, -0.0505,
        -0.0624, -0.0898, -0.0987,  0.0522,  0.0284, -0.0543, -0.0894, -0.0930,
         0.0907,  0.0329,  0.0163, -0.0083,  0.0408,  0.0108,  0.0432,  0.0255,
        -0.0515, -0.0467,  0.0263,  0.0253,  0.0706, -0.0740,  0.0486, -0.0917,
         0.0086, -0.0812, -0.0492, -0.0572,  0.0892,  0.0890, -0.0444, -0.0042,
        -0.0838, -0.0819, -0.0506,  0.0097, -0.0900, -0.0208,  0.0138,  0.0011,
        -0.0032,  0.0180,  0.0989, -0.0854, -0.0721,  0.0523,  0.0306,  0.0850,
         0.0796, -0.0743, -0.0227, -0.0900,  0.0403,  0.0597, -0.0793, -0.0544,
         0.0534,  0.0244, -0.0625, -0.0005, -0.0665,  0.0388,  0.0185,  0.0272,
        -0.0047,  0.0054, -0.0742,  0.0933, -0.0041,  0.0028,  0.0090, -0.0941,
         0.0258,  0.0861,  0.0582,  0.0139,  0.0290,  0.0178,  0.0003,  0.0438,
         0.0329,  0.0325, -0.0603, -0.0122,  0.0623,  0.0658, -0.0563,  0.0326,
        -0.0667,  0.0261,  0.0347, -0.0602], device='cuda:0',
       requires_grad=True) 

encoder.module_4.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0742,  0.0714,  0.0718,  ...,  0.0190,  0.0631,  0.0773],
        [-0.0054,  0.0942,  0.0529,  ...,  0.0854,  0.0579,  0.0485],
        [-0.0269, -0.0834, -0.0139,  ...,  0.0622,  0.0829,  0.0987],
        ...,
        [-0.0143, -0.0962, -0.0361,  ...,  0.0344,  0.0385,  0.0660],
        [ 0.0767,  0.0771,  0.0321,  ..., -0.0601, -0.0242,  0.0472],
        [-0.0685, -0.0025,  0.0810,  ...,  0.0540, -0.0536,  0.0207]],
       device='cuda:0', requires_grad=True) 

encoder.module_4.bias torch.Size([16])
Parameter containing:
tensor([-0.0359,  0.0392, -0.0613, -0.0523, -0.0664, -0.0177,  0.0993,  0.0575,
        -0.0794,  0.0511,  0.0916,  0.0990,  0.0100,  0.0267,  0.0726,  0.0962],
       device='cuda:0', requires_grad=True) 

model.module_0.bias torch.Size([8])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

model.module_0.lin.weight torch.Size([8, 16])
Parameter containing:
tensor([[ 0.3902,  0.2047,  0.3483, -0.4037, -0.4351, -0.1158,  0.1316,  0.3213,
         -0.1468, -0.2213,  0.3225, -0.0153,  0.0339, -0.4771, -0.0464,  0.2426],
        [ 0.4828,  0.0466,  0.3176,  0.0695, -0.3946, -0.0168, -0.1709, -0.0679,
         -0.1945,  0.3738, -0.4082, -0.3005, -0.1553,  0.4189, -0.1023,  0.2040],
        [ 0.2451,  0.4280, -0.1149,  0.0934, -0.2440, -0.0380, -0.4285, -0.4080,
          0.1360, -0.3832,  0.2613,  0.3696,  0.1754,  0.1914, -0.4543, -0.2312],
        [-0.3610, -0.4741,  0.2126,  0.1145,  0.4757, -0.1378, -0.3310, -0.4304,
          0.0308, -0.2740,  0.0887,  0.3307,  0.4275, -0.0815, -0.3251, -0.2715],
        [ 0.3175,  0.1294,  0.0317, -0.4858,  0.2693,  0.3163,  0.0516, -0.0901,
         -0.2373,  0.0041,  0.0248,  0.1410, -0.0212,  0.4740,  0.3223,  0.1129],
        [-0.4439, -0.2387,  0.1956, -0.3231,  0.1394,  0.1228, -0.3144,  0.0992,
         -0.0647,  0.3724, -0.1103,  0.4363,  0.4344, -0.1658,  0.0839, -0.1367],
        [ 0.4004,  0.2397,  0.0014,  0.3024, -0.4015, -0.1279,  0.1021, -0.4737,
          0.4370,  0.0411,  0.4417, -0.1455,  0.0298, -0.1379, -0.2050, -0.1853],
        [ 0.3458,  0.4492,  0.1439,  0.2792,  0.2175,  0.0006, -0.3722,  0.1254,
         -0.1718,  0.1914, -0.3253, -0.0340, -0.1965, -0.4625, -0.4622,  0.4613]],
       device='cuda:0', requires_grad=True) 

model.module_1.weight torch.Size([100, 8])
Parameter containing:
tensor([[-3.8463e-04, -3.0478e-01,  5.7974e-02, -2.2189e-02,  2.9126e-01,
          3.3321e-01, -9.0874e-02, -2.1215e-01],
        [-2.0261e-01, -9.4006e-02, -1.9408e-01,  3.1867e-01, -1.3514e-01,
          1.8215e-01,  1.6000e-01,  8.2664e-02],
        [ 1.7236e-01,  2.9939e-01,  1.5043e-01,  1.5557e-01, -2.9665e-01,
         -3.1333e-02,  8.1635e-03,  2.7689e-01],
        [ 1.5107e-01,  2.7496e-01,  2.7347e-01, -1.6492e-01,  5.0157e-02,
          3.3712e-01,  1.2499e-01,  1.9990e-01],
        [ 1.4371e-01, -1.1098e-01,  8.4426e-02, -2.4429e-01,  3.2617e-01,
          2.0229e-02,  2.7398e-01, -2.4854e-01],
        [-3.2479e-01,  4.2333e-02, -4.5297e-02, -1.4301e-01,  1.8524e-01,
         -2.2999e-01,  3.0981e-01, -3.4514e-01],
        [ 7.2507e-02, -2.0672e-01,  7.6700e-02,  3.4916e-01, -4.2436e-02,
          8.2207e-02, -1.3914e-01, -1.8142e-01],
        [-3.0201e-01,  2.0407e-01, -3.9265e-03,  1.2243e-01, -2.7192e-01,
         -2.9436e-01, -3.2148e-01, -2.0375e-01],
        [-4.5971e-02, -5.3346e-02,  1.5546e-01, -1.6988e-01,  3.4450e-01,
         -1.6112e-01, -3.3248e-01,  2.6745e-01],
        [-2.2722e-01,  3.3695e-02, -3.4134e-02, -7.3750e-02,  2.2907e-04,
         -3.4767e-01,  3.1793e-01, -2.2952e-01],
        [ 2.1556e-01, -2.0906e-01, -8.7061e-02, -8.3615e-03, -1.3935e-01,
         -1.5317e-01, -2.9760e-01, -2.4283e-01],
        [-1.6589e-02, -1.0335e-01, -4.9652e-02,  9.0191e-02, -4.5326e-02,
         -3.3469e-01, -1.3003e-01,  1.0822e-01],
        [ 1.2724e-01,  1.7109e-01,  1.9579e-02,  2.4172e-01, -2.4194e-01,
         -2.9670e-01, -9.4266e-02,  2.3843e-03],
        [ 2.5670e-01, -2.0389e-01, -2.4761e-01, -9.5649e-03,  8.9909e-02,
         -3.2247e-01, -1.4252e-01, -2.7773e-01],
        [ 8.2623e-02,  3.2981e-02, -3.1440e-01, -2.3543e-01,  1.6349e-02,
         -9.3688e-02, -2.7346e-01, -1.0714e-01],
        [-3.2470e-01, -4.0371e-02, -4.1210e-02,  1.8533e-02,  3.0029e-02,
         -6.1585e-02,  2.8215e-01, -1.2658e-01],
        [ 1.5978e-01,  1.3348e-01, -4.3336e-02, -2.5910e-01, -2.9791e-01,
          9.7866e-02,  1.0809e-01,  2.1443e-01],
        [-1.5650e-01,  2.8545e-01,  3.5351e-01, -5.6234e-02, -1.3778e-01,
         -1.1105e-01, -3.0738e-01,  2.0382e-01],
        [ 3.8531e-02,  1.6289e-01,  2.2716e-01, -1.5015e-01,  3.2922e-03,
          2.8581e-01, -2.7256e-01,  3.1085e-01],
        [ 1.8385e-01, -1.1104e-01, -2.8868e-01,  1.8884e-01,  1.6868e-01,
         -1.6011e-01,  1.6832e-01,  1.0493e-01],
        [ 3.4802e-01,  1.8085e-01,  5.4585e-02, -3.4995e-01,  2.8774e-01,
          3.0356e-01, -9.8001e-02, -2.7648e-02],
        [-1.3774e-02, -2.1589e-02,  1.9220e-01,  4.7789e-02, -3.0748e-01,
          1.1375e-01, -2.1717e-01,  1.0094e-01],
        [ 1.5390e-01, -1.6882e-01,  2.3951e-01,  9.0288e-03, -1.7782e-01,
          3.0296e-01,  2.2592e-01,  2.5854e-01],
        [-2.4343e-01, -2.6945e-01, -3.1086e-01,  2.2858e-01,  2.0620e-01,
         -2.1552e-01,  1.3860e-01,  7.1063e-02],
        [-1.5050e-01,  1.2134e-02, -2.1330e-01, -1.0351e-01,  1.3980e-01,
          4.9927e-02, -2.6311e-01,  8.8973e-02],
        [-7.0552e-02, -2.5973e-01, -3.2689e-01,  1.5247e-02, -2.6021e-01,
         -2.1612e-01,  8.5194e-02,  2.1801e-02],
        [-1.6007e-01,  5.4810e-02,  1.7811e-01, -1.3652e-01, -1.2609e-01,
          6.2430e-02,  8.6483e-02,  1.2220e-01],
        [ 2.4077e-01, -2.3633e-02,  1.1745e-01, -2.0345e-01, -4.5085e-02,
          2.6190e-01, -3.4250e-01, -2.3257e-01],
        [-3.0562e-01,  2.9417e-01, -3.9916e-02,  3.2381e-01, -1.9056e-01,
         -9.6141e-02,  2.2756e-01, -3.5213e-01],
        [-3.4456e-01, -2.3676e-01,  6.0155e-03, -3.2526e-01,  6.5462e-02,
          2.9901e-01, -7.1662e-02, -6.2251e-02],
        [-3.1115e-01, -7.4736e-02,  2.9242e-02,  7.2375e-02, -1.1643e-01,
         -2.1606e-01, -1.8523e-01,  2.4378e-01],
        [-1.9234e-01,  2.7487e-02, -6.2144e-02, -1.4216e-01, -1.5272e-02,
          2.6724e-01,  2.6770e-01, -7.3850e-02],
        [-7.1112e-02, -1.9805e-01, -1.6445e-01, -6.0395e-02,  2.6235e-01,
          5.0368e-02, -3.0260e-01, -9.0882e-02],
        [-3.0543e-01,  3.2673e-01,  3.2733e-02, -8.9736e-02,  1.4177e-01,
         -3.3144e-01, -1.1672e-01,  3.3166e-02],
        [ 2.5512e-01,  2.8838e-01, -1.1818e-02, -3.5342e-01,  6.5313e-02,
         -1.9938e-01,  3.1888e-01, -9.5198e-02],
        [-9.6219e-02, -5.2510e-02,  3.2770e-01,  1.5504e-01, -2.4382e-01,
          6.1957e-02,  1.1242e-01, -9.1831e-02],
        [ 1.1737e-01, -3.1736e-01, -1.8225e-01,  2.2586e-01,  3.2846e-01,
          1.1231e-01, -2.0030e-01,  1.2885e-01],
        [-2.0364e-01, -2.8329e-01, -2.3329e-01, -3.3509e-02,  7.5078e-02,
          2.6324e-02,  3.3980e-01, -2.5086e-02],
        [ 3.2524e-01, -2.6276e-01, -1.8201e-01,  4.8474e-02,  2.1072e-01,
          1.0494e-01,  3.4671e-01, -1.8846e-01],
        [ 3.3087e-01,  1.1288e-01,  9.3351e-02, -9.0644e-03, -2.5448e-01,
          1.8914e-01,  7.6684e-02,  2.4372e-01],
        [ 2.6018e-01, -3.0028e-01,  3.2752e-01, -8.1414e-02, -2.3686e-01,
          3.0858e-01, -5.5915e-02,  5.8256e-02],
        [ 5.3068e-02, -1.9018e-01,  2.2420e-01,  1.3406e-01,  2.8478e-01,
         -9.8263e-02, -2.5942e-01,  6.9250e-02],
        [-9.4996e-02,  1.8254e-04, -2.8755e-01,  3.1708e-01, -1.8594e-01,
         -3.1942e-02,  8.9711e-03, -1.5359e-01],
        [ 2.1006e-01, -2.8808e-01, -4.7558e-02, -2.2896e-01,  2.0965e-01,
         -2.5739e-01,  2.7992e-01, -3.0579e-01],
        [-3.5336e-01,  8.6224e-03, -3.4806e-01,  3.2934e-01,  3.3025e-01,
         -1.6145e-01,  2.6427e-01, -1.3597e-01],
        [ 8.6490e-02, -2.4781e-01, -2.3935e-02, -1.0795e-01,  7.9318e-02,
          1.1366e-01, -3.3000e-01,  2.3890e-02],
        [ 2.7378e-01,  2.8483e-01,  1.6008e-01,  8.1867e-03,  2.4257e-01,
          1.8762e-01, -2.3256e-01, -2.0168e-02],
        [-3.2753e-01,  2.4894e-02,  2.6849e-02, -2.3277e-01,  8.4436e-02,
          2.4450e-01, -3.0083e-01, -3.1494e-01],
        [-1.7277e-01,  4.5813e-02, -3.4315e-01, -7.0363e-02,  2.7146e-01,
         -2.9180e-01, -9.4440e-02, -7.4739e-02],
        [ 2.1368e-01, -1.3147e-01,  2.6840e-01, -1.7720e-01,  1.3117e-01,
         -6.5346e-02,  3.0777e-01, -1.7335e-01],
        [-1.3284e-01,  3.1888e-01, -2.8008e-01,  9.9959e-02,  1.7574e-01,
         -3.0706e-02,  3.1084e-01, -3.2884e-01],
        [-5.1345e-02, -1.8604e-01,  1.3930e-01,  3.4569e-01, -3.4608e-01,
         -1.5760e-01, -2.6182e-01, -1.9831e-01],
        [ 1.0689e-01,  5.2120e-03, -2.7692e-01, -2.1680e-01, -2.3156e-01,
          2.6824e-02, -2.9117e-01, -2.7645e-01],
        [-2.8327e-01,  2.8518e-01,  2.5823e-01, -1.6729e-01,  8.2989e-02,
         -4.9378e-02, -1.4209e-01,  1.6486e-01],
        [-2.3781e-01, -1.1667e-03,  2.6422e-01, -3.0702e-01,  2.9150e-01,
          2.3354e-01,  1.5635e-01, -4.6198e-02],
        [-1.3752e-01, -1.9411e-01, -2.5634e-01, -3.4464e-01, -5.0716e-02,
          7.0292e-02, -3.4223e-01,  3.4803e-01],
        [-2.5262e-01,  2.7910e-02, -1.1983e-01,  3.2177e-01, -1.5391e-01,
          9.2357e-02,  1.1269e-01,  1.6213e-01],
        [-2.4786e-01, -1.9580e-01,  3.9397e-03, -3.4873e-01, -1.3797e-01,
         -2.9666e-01,  1.5628e-01,  3.6636e-02],
        [-3.3039e-01,  3.4576e-01,  1.4494e-01, -2.0263e-01, -3.5597e-02,
          2.3976e-01, -2.1012e-01,  8.8422e-02],
        [ 1.1498e-01, -2.2729e-01, -1.8580e-01, -6.2697e-02, -2.7657e-01,
          3.0426e-01,  1.0095e-01, -1.1254e-01],
        [-4.1566e-03,  3.8640e-03,  1.1709e-01,  2.5113e-01, -2.9712e-01,
         -1.2576e-01,  1.2748e-01, -1.9747e-01],
        [-1.7418e-02, -1.0344e-01,  2.0258e-01, -1.8957e-01,  3.1860e-01,
          1.6810e-01, -2.5349e-01, -7.0291e-02],
        [-3.3165e-02, -3.4607e-01, -3.0301e-01,  2.9253e-01,  2.5403e-01,
         -2.4077e-01, -3.4799e-03,  9.4997e-02],
        [ 2.1573e-01,  3.1317e-01,  2.2180e-01,  2.9321e-01, -2.2922e-01,
         -8.0584e-02,  1.6917e-01, -2.7215e-01],
        [-3.4238e-01,  1.9928e-01,  2.5779e-01,  1.4130e-01,  2.2456e-01,
          1.6542e-01,  4.7867e-02, -7.9599e-02],
        [ 4.8749e-02, -1.2331e-01,  2.8705e-01,  2.9863e-01, -1.0831e-01,
          1.5603e-01, -9.5992e-02,  2.8289e-01],
        [-3.1805e-01,  5.0306e-02, -2.7196e-02,  2.4140e-01,  3.7468e-02,
          6.7080e-02, -3.4620e-01, -1.9451e-01],
        [ 3.3002e-01, -3.1686e-02,  1.5113e-01, -2.8905e-01,  1.8203e-01,
         -1.5382e-01, -3.6279e-02,  3.3315e-01],
        [ 2.5045e-01, -3.1000e-01, -1.5860e-01,  2.0861e-01, -6.4968e-02,
          2.7917e-01,  1.4526e-01, -3.9216e-02],
        [-2.2043e-01,  2.0291e-02,  2.7887e-01,  2.7170e-01, -1.5258e-01,
         -9.7712e-02,  1.1403e-01, -3.0051e-01],
        [ 4.7237e-02,  9.0318e-02,  3.4699e-01, -4.3776e-02,  3.4398e-01,
          3.4387e-01, -1.8193e-01,  5.4965e-02],
        [ 2.0265e-01, -4.1058e-02, -1.9365e-01,  7.5388e-02,  1.5581e-01,
         -2.8647e-01, -2.8490e-01, -2.6678e-01],
        [-2.7093e-01,  3.0957e-01, -1.5726e-01, -4.1988e-02, -9.4088e-02,
         -1.8173e-01,  2.9913e-01, -1.2624e-01],
        [ 2.1470e-01, -1.6338e-01,  3.4678e-01,  8.9356e-02, -6.2403e-02,
          2.4897e-03,  1.4648e-01, -1.8988e-01],
        [-1.0486e-01, -2.6235e-01, -2.3712e-01,  1.7006e-01, -2.9601e-02,
         -1.7648e-01,  1.6436e-02,  2.0173e-01],
        [ 3.2470e-01, -2.0697e-01,  1.4430e-01,  3.3788e-02, -1.7943e-01,
          7.8361e-02,  3.9725e-02,  2.0894e-01],
        [ 2.8930e-01,  1.6606e-01,  6.6893e-02, -2.6563e-01, -2.9601e-01,
          1.6564e-01, -2.1690e-01,  4.8882e-03],
        [ 2.7217e-01,  1.7746e-01, -4.4915e-02,  5.5719e-02,  1.2162e-02,
          3.0517e-02,  3.0831e-01, -2.1630e-01],
        [ 3.0777e-01,  1.6970e-02,  3.3531e-01, -1.5074e-01,  2.1734e-01,
         -1.9437e-01, -2.8968e-01,  2.5699e-01],
        [ 1.2221e-01,  3.4756e-01,  1.4330e-01, -1.4916e-01, -2.1027e-01,
          2.8939e-01, -7.0089e-02, -2.1006e-01],
        [-2.6113e-01, -2.3667e-01, -1.4851e-01, -2.8426e-01,  3.4028e-01,
          4.0850e-02,  1.1664e-01, -1.7394e-01],
        [ 9.9650e-03,  2.4099e-01, -1.1982e-01,  2.8545e-01, -1.0992e-01,
         -1.3218e-01, -2.6023e-01, -3.5040e-01],
        [ 1.5415e-01, -2.2809e-01, -1.9384e-01, -1.4463e-01, -2.7040e-01,
         -2.7177e-01, -2.3083e-01,  3.4469e-01],
        [ 2.0540e-02, -1.3324e-01, -2.9475e-02,  2.9555e-01, -2.0565e-01,
          1.4279e-01, -6.5871e-02, -3.0039e-01],
        [ 2.3384e-01,  1.6333e-01,  2.5985e-01,  1.6187e-01,  5.7608e-02,
          1.0870e-01, -2.6395e-01,  3.4071e-01],
        [-2.2774e-01,  2.4943e-01, -2.2386e-01, -2.5551e-01,  1.4571e-01,
          2.3171e-01, -9.6297e-02,  9.9023e-02],
        [-3.0817e-01, -3.9701e-02,  3.1194e-01,  3.3036e-01, -1.1258e-01,
          1.3063e-01,  3.2607e-01,  1.3112e-01],
        [ 6.4811e-02, -2.8489e-01,  1.0164e-01,  9.4391e-02, -1.9916e-01,
          1.7654e-01, -2.3063e-01,  3.3847e-01],
        [-1.7792e-02,  2.4071e-01, -9.2835e-02, -1.7959e-01,  2.5720e-01,
          2.1466e-01,  3.4715e-01,  1.0393e-01],
        [-1.4843e-01, -2.0762e-01, -3.3737e-01,  2.2405e-02,  3.3846e-01,
         -1.1720e-01, -6.8238e-02,  2.4903e-01],
        [ 3.1450e-01,  9.6046e-02,  2.8080e-02,  3.4574e-01,  2.9610e-01,
         -2.2497e-01, -2.4667e-01, -8.1110e-02],
        [ 1.4011e-01, -2.1637e-01, -1.5135e-01,  2.9349e-02, -8.9327e-02,
          2.3719e-01,  2.2395e-01,  2.4348e-01],
        [ 1.8805e-01, -2.0455e-01, -2.7211e-01, -2.3757e-01, -4.5254e-02,
          2.7790e-01, -7.8506e-02,  3.2534e-01],
        [ 2.6387e-01, -3.3556e-01,  1.6327e-01, -1.4913e-01, -3.3727e-01,
          1.2392e-01, -1.2148e-01, -3.1412e-01],
        [-2.4881e-01,  2.6013e-01, -8.4698e-02,  2.7711e-01, -1.2269e-01,
          3.4538e-01, -8.8496e-02,  3.3464e-01],
        [ 1.3714e-01, -2.6566e-01,  1.5449e-01,  1.4846e-01, -2.9681e-01,
         -3.0567e-01,  2.0509e-02,  1.9151e-01],
        [ 3.0124e-01, -9.8024e-02, -3.3109e-01,  1.6150e-01,  2.4653e-02,
          9.0166e-03,  2.2321e-01,  4.2219e-02],
        [ 3.0648e-01,  2.7142e-01,  9.0528e-02,  2.6336e-01,  1.1319e-01,
         -3.3553e-01,  3.1734e-01,  1.0770e-02],
        [-4.3679e-02,  2.9137e-01,  3.0838e-01, -2.7976e-01,  1.3927e-01,
         -1.9436e-01, -9.0848e-02,  7.5960e-02],
        [-1.3121e-01, -1.4925e-01,  1.7602e-01, -8.5019e-02,  1.3353e-01,
          3.3900e-01,  8.5770e-02,  8.2222e-02]], device='cuda:0',
       requires_grad=True) 

model.module_1.bias torch.Size([100])
Parameter containing:
tensor([ 0.3102, -0.1329,  0.0005, -0.3272, -0.1505, -0.0277,  0.3206,  0.1997,
        -0.0657, -0.0962,  0.0866, -0.1535, -0.0517,  0.0936, -0.1096,  0.2588,
         0.1400, -0.0367, -0.0617,  0.0352,  0.1849,  0.0991, -0.0964,  0.1233,
        -0.0150, -0.2580, -0.2787,  0.0026,  0.3059, -0.1374,  0.2219, -0.1050,
         0.2114, -0.0792, -0.1466,  0.1037,  0.1871, -0.2695, -0.0258,  0.0734,
         0.0636,  0.3447, -0.3099,  0.3017,  0.1828, -0.3334, -0.1362,  0.1228,
        -0.2661,  0.3306, -0.1330,  0.1355,  0.0682, -0.1376, -0.3327,  0.0259,
        -0.2889, -0.0772,  0.0743, -0.1238,  0.2019, -0.3176, -0.2791,  0.1883,
        -0.1841,  0.2904, -0.0715, -0.0633,  0.3371, -0.0392, -0.2835, -0.1473,
         0.1100,  0.2408,  0.2981, -0.1298,  0.0520,  0.2576, -0.1446,  0.0236,
        -0.1713,  0.0504,  0.3440,  0.2988, -0.2325,  0.1735,  0.3326, -0.0626,
         0.1255, -0.3175,  0.1964, -0.0662,  0.3247,  0.2476, -0.2032, -0.1563,
        -0.2780, -0.3266, -0.3208,  0.1712], device='cuda:0',
       requires_grad=True) 

model.module_3.weight torch.Size([100, 100])
Parameter containing:
tensor([[ 0.0663, -0.0634,  0.0700,  ..., -0.0131,  0.0399, -0.0855],
        [-0.0155, -0.0633, -0.0284,  ..., -0.0400, -0.0868,  0.0892],
        [ 0.0830,  0.0094, -0.0355,  ..., -0.0264, -0.0822,  0.0340],
        ...,
        [-0.0154, -0.0118, -0.0487,  ..., -0.0799,  0.0029,  0.0092],
        [ 0.0618,  0.0168,  0.0028,  ...,  0.0698,  0.0707,  0.0514],
        [ 0.0151, -0.0352,  0.0715,  ..., -0.0003, -0.0706,  0.0747]],
       device='cuda:0', requires_grad=True) 

model.module_3.bias torch.Size([100])
Parameter containing:
tensor([ 9.9035e-02, -4.2346e-02,  7.5904e-02,  2.5031e-02,  2.9615e-02,
        -7.3705e-03,  9.0261e-02, -2.4345e-02,  2.3600e-02,  9.1922e-05,
         1.5098e-02, -4.6167e-02, -6.6433e-02,  6.5246e-02, -9.1053e-02,
        -6.4402e-02,  9.3797e-02, -4.6913e-02, -8.5461e-03, -8.9593e-02,
        -2.3554e-02, -3.8631e-02,  4.1961e-02,  5.3622e-02,  9.3167e-02,
        -2.9528e-02,  8.8969e-02,  3.9133e-02, -7.8481e-02, -8.5061e-02,
        -1.3431e-02,  8.6973e-02, -1.2836e-03, -6.3761e-02,  5.8132e-02,
        -9.7669e-02,  7.5762e-02, -1.1866e-03,  5.5518e-03, -3.6219e-02,
         1.4012e-02,  3.9848e-03,  7.8398e-02,  8.6779e-02,  4.2685e-02,
        -1.2910e-02, -5.7787e-04, -6.4578e-02,  5.7831e-02, -2.4366e-02,
        -9.8725e-02, -3.3662e-02, -7.0527e-02, -8.0481e-02,  1.6450e-02,
         7.2890e-03, -5.5224e-02, -7.2396e-02,  3.1151e-02,  2.0650e-02,
         6.7380e-02,  5.1532e-02, -6.5232e-02,  5.0059e-02, -9.1712e-02,
        -8.7770e-02,  3.9831e-02,  9.1209e-02,  4.5567e-02, -4.7877e-03,
        -4.8000e-02,  9.7386e-02, -6.6301e-02,  8.9974e-02, -5.9651e-02,
        -9.2349e-02,  7.9615e-04,  2.8182e-02, -8.3151e-02, -3.2005e-02,
        -4.9611e-03, -8.1810e-03, -4.9014e-02,  9.1789e-02, -7.3177e-02,
         6.0960e-02,  2.8089e-02, -4.2381e-02,  4.2791e-02, -8.4580e-02,
        -6.9813e-02,  5.3360e-02, -5.1891e-02,  4.7990e-02, -9.4837e-02,
         1.7523e-02, -9.4260e-02,  4.6844e-02,  9.2413e-02,  5.7740e-02],
       device='cuda:0', requires_grad=True) 

model.module_5.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 2.4877e-02,  6.7250e-02,  8.8722e-02,  ...,  9.0003e-02,
         -9.9207e-02,  6.3747e-02],
        [-4.1799e-02, -7.7012e-02,  2.8124e-02,  ...,  4.2493e-02,
          6.3022e-02, -4.7302e-05],
        [ 8.5962e-02,  2.4211e-02, -6.0968e-02,  ..., -1.5135e-02,
          9.3027e-02,  8.3280e-02],
        ...,
        [ 3.2165e-02,  8.8483e-02,  3.8556e-02,  ...,  4.5120e-02,
          9.3309e-03,  9.7113e-02],
        [-4.3749e-02,  8.6016e-02,  8.1729e-02,  ..., -8.5541e-04,
         -8.0956e-02,  1.6567e-02],
        [-5.4775e-02, -6.8748e-02,  1.0483e-02,  ..., -1.9430e-02,
         -1.6747e-03,  3.8295e-02]], device='cuda:0', requires_grad=True) 

model.module_5.bias torch.Size([16])
Parameter containing:
tensor([ 0.0857,  0.0066,  0.0153, -0.0447, -0.0728, -0.0893,  0.0215,  0.0142,
         0.0881,  0.0576,  0.0036, -0.0320,  0.0692, -0.0868, -0.0030,  0.0352],
       device='cuda:0', requires_grad=True) 

model.module_7.bias torch.Size([8])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

model.module_7.lin.weight torch.Size([8, 16])
Parameter containing:
tensor([[ 0.1628,  0.1379,  0.0387,  0.3232,  0.3972,  0.4950, -0.4268,  0.2489,
          0.4032, -0.2594, -0.4376,  0.2620,  0.0569,  0.4096,  0.2099,  0.3815],
        [-0.4184, -0.1531, -0.4750,  0.0773,  0.3299, -0.3531,  0.3310, -0.4383,
          0.3372, -0.4178, -0.3892, -0.2540,  0.1420, -0.4528,  0.2366, -0.4694],
        [-0.0403, -0.1600, -0.0932, -0.3215,  0.4870,  0.4608, -0.4989, -0.0701,
         -0.3876, -0.4239, -0.1689,  0.3166, -0.4628,  0.4632,  0.4406,  0.2091],
        [ 0.3746,  0.0816,  0.2469,  0.2583, -0.4461,  0.1281, -0.0182, -0.4829,
          0.3882, -0.1576,  0.0689, -0.2522,  0.3186,  0.0311, -0.1881, -0.2243],
        [ 0.1253, -0.4380,  0.2123, -0.4227, -0.3143,  0.0684, -0.2692,  0.1619,
         -0.3217, -0.1626,  0.2000,  0.2601, -0.1153,  0.1721, -0.3896, -0.1006],
        [ 0.3129, -0.0436, -0.4373, -0.0487, -0.0747,  0.1716, -0.1037, -0.3449,
          0.0988,  0.3689, -0.1186,  0.1449,  0.0831,  0.0790, -0.0757, -0.0307],
        [-0.4817,  0.2965, -0.2998, -0.3894, -0.3001,  0.1430, -0.1006, -0.2929,
          0.2780, -0.2458, -0.3500,  0.2409, -0.2090, -0.3284, -0.1511, -0.2449],
        [ 0.0058, -0.2162,  0.0172, -0.0309,  0.3440,  0.3128, -0.2432,  0.1909,
         -0.4451, -0.3918, -0.3412, -0.2142, -0.4769,  0.2911,  0.4196, -0.3894]],
       device='cuda:0', requires_grad=True) 

model.module_8.weight torch.Size([100, 8])
Parameter containing:
tensor([[-0.3233, -0.1064,  0.2763,  0.0960,  0.0200,  0.3375,  0.2820,  0.1690],
        [-0.1803, -0.0894, -0.0580, -0.0629,  0.0836,  0.2220, -0.1992, -0.3439],
        [-0.3088,  0.0937, -0.2286,  0.1752,  0.1115,  0.1058, -0.1345,  0.1773],
        [ 0.2437,  0.1136,  0.0211,  0.1520,  0.0408,  0.0872,  0.1421,  0.3164],
        [-0.0590,  0.1795,  0.2729, -0.2864, -0.0075, -0.2959, -0.2640,  0.2250],
        [-0.2726,  0.3309,  0.3139, -0.2354, -0.3138, -0.0575, -0.3200,  0.1830],
        [-0.1201,  0.0794, -0.0045, -0.0318, -0.1980,  0.0943,  0.1334,  0.0272],
        [-0.0174, -0.1344, -0.1572,  0.1005,  0.1444, -0.1456, -0.1553,  0.2988],
        [ 0.2269, -0.3357, -0.2056, -0.0105, -0.1481,  0.0335, -0.1307, -0.3535],
        [-0.2557,  0.2240,  0.0614,  0.3270,  0.2945, -0.0379,  0.2006, -0.0559],
        [ 0.1750, -0.2756, -0.1220,  0.0113,  0.0574,  0.1217,  0.3198,  0.3013],
        [-0.2438, -0.0514, -0.0133,  0.1297, -0.2389,  0.1500,  0.1110,  0.2116],
        [-0.1021,  0.0510,  0.1905,  0.3177, -0.1046,  0.1952, -0.1240,  0.1715],
        [-0.1125,  0.0654, -0.2816,  0.1119, -0.2518, -0.1930, -0.1333, -0.1180],
        [ 0.2680,  0.2716,  0.2043, -0.1912,  0.2602,  0.3305, -0.0472, -0.2030],
        [ 0.2840,  0.3239,  0.1250, -0.3468, -0.2397,  0.2397, -0.3182,  0.1484],
        [ 0.2060, -0.1068, -0.3338, -0.3058,  0.2911,  0.1345,  0.1692, -0.1825],
        [-0.1418,  0.1895, -0.2412,  0.1836, -0.0149,  0.2123, -0.2020, -0.1355],
        [-0.2644,  0.1927, -0.0718, -0.1217, -0.3442,  0.2986,  0.3237, -0.2040],
        [-0.0628, -0.1168, -0.2229, -0.2493, -0.0465,  0.1654, -0.2370,  0.3507],
        [-0.0545, -0.2453, -0.2046,  0.3521, -0.0566,  0.2004,  0.0336,  0.2916],
        [-0.2632,  0.1125,  0.1517, -0.1007, -0.2119, -0.0669, -0.0342, -0.2061],
        [-0.2890,  0.1193,  0.0435, -0.2153, -0.0989, -0.0219,  0.1632,  0.1377],
        [ 0.3101,  0.0353,  0.1067, -0.2643,  0.1503, -0.1509,  0.2589,  0.0931],
        [-0.0332, -0.1253,  0.1700,  0.1458,  0.0968,  0.0566, -0.2761, -0.1852],
        [-0.3517, -0.1235, -0.1640, -0.0704,  0.2577,  0.0854,  0.1561,  0.1498],
        [ 0.2880,  0.2810,  0.0717,  0.3020, -0.3145,  0.1909,  0.2365, -0.3351],
        [-0.3009, -0.0567,  0.1513,  0.2984, -0.3217,  0.3228, -0.0271, -0.0815],
        [-0.0900,  0.2332,  0.1651,  0.0320, -0.2962, -0.0265, -0.2856, -0.3510],
        [ 0.1219, -0.0891, -0.3382, -0.2933,  0.3394,  0.3308, -0.2493, -0.1774],
        [ 0.2128, -0.0746, -0.0287, -0.1053,  0.1710, -0.3288, -0.3213,  0.1357],
        [ 0.1761,  0.1978, -0.1049, -0.1557, -0.1714, -0.1909, -0.3081,  0.1343],
        [-0.1552, -0.3431,  0.0557,  0.2827, -0.0146, -0.2879,  0.1882, -0.1931],
        [ 0.2226, -0.2432,  0.3206, -0.0856,  0.3247,  0.1670,  0.2628,  0.0643],
        [-0.2059,  0.0370,  0.2888, -0.3073,  0.0976,  0.0521,  0.2370, -0.2427],
        [-0.2593,  0.0954, -0.1001, -0.1214,  0.0795,  0.2800, -0.2650, -0.0182],
        [-0.1474, -0.0435, -0.1546,  0.3368,  0.1965,  0.0766, -0.0997,  0.2188],
        [-0.1961, -0.3179, -0.2372, -0.1045, -0.2423,  0.2251, -0.0190, -0.1327],
        [-0.2417,  0.3091,  0.3252, -0.2126,  0.2938, -0.0319, -0.1307,  0.1316],
        [-0.2765, -0.3234, -0.0293,  0.2331,  0.2565,  0.3021,  0.1825,  0.0886],
        [ 0.0498, -0.2130,  0.2893,  0.2922, -0.3046, -0.3357, -0.0856, -0.2264],
        [-0.1241,  0.3073, -0.0697,  0.3197, -0.0308,  0.0288, -0.0144, -0.1049],
        [-0.0594, -0.1661, -0.2551,  0.0259,  0.0757,  0.0800,  0.0832, -0.1313],
        [-0.3377,  0.1696,  0.0663, -0.3353,  0.3350, -0.0866, -0.2911, -0.2162],
        [-0.0903, -0.2786,  0.0642, -0.1862, -0.1918,  0.3091, -0.1180, -0.0111],
        [-0.2031, -0.0414, -0.2233, -0.1970, -0.2321, -0.1306,  0.0820,  0.1546],
        [ 0.2046, -0.1708, -0.2644, -0.0525,  0.3290,  0.0104,  0.3295,  0.2723],
        [ 0.2382, -0.0327,  0.0563, -0.2317,  0.0562,  0.1256, -0.2233, -0.2479],
        [-0.1788,  0.0040, -0.0644,  0.1401, -0.1770,  0.3314, -0.1698,  0.2158],
        [ 0.3147,  0.3215, -0.1720, -0.1874, -0.1507, -0.2363, -0.0912, -0.1027],
        [ 0.1291,  0.3063,  0.1303,  0.0037, -0.1251, -0.1042,  0.2995, -0.3049],
        [-0.0445, -0.3420, -0.1276, -0.2615, -0.3435,  0.1192, -0.1838,  0.0779],
        [ 0.3103, -0.0592,  0.1280, -0.1452,  0.2306,  0.3371, -0.1316, -0.2761],
        [ 0.2707,  0.2470,  0.1548,  0.0222,  0.1086,  0.0806,  0.0499, -0.1193],
        [ 0.0892,  0.3128, -0.1109, -0.2792, -0.2532, -0.0094,  0.1306,  0.0372],
        [ 0.3255,  0.1037,  0.1564, -0.3179,  0.2081,  0.2322,  0.0739,  0.1307],
        [-0.3280,  0.3271, -0.0262, -0.3473,  0.1236,  0.2075,  0.2278,  0.3238],
        [ 0.0577,  0.2028,  0.3452,  0.1540,  0.1356, -0.0379, -0.2613,  0.1192],
        [-0.2571,  0.0046, -0.3316, -0.3410, -0.1580, -0.3493,  0.2089,  0.0871],
        [-0.0977,  0.3239,  0.1569,  0.2173, -0.2311, -0.2980, -0.1272,  0.2307],
        [-0.3050, -0.2444,  0.0158,  0.1286,  0.2004,  0.0649, -0.0519, -0.1360],
        [-0.0081,  0.2227, -0.2863, -0.3265, -0.0358,  0.0178,  0.1708,  0.1343],
        [ 0.3398, -0.1276,  0.1174, -0.2410, -0.2491, -0.1870,  0.3076, -0.2380],
        [-0.1272,  0.1055, -0.2327,  0.1204, -0.2732,  0.2945,  0.2656,  0.1525],
        [ 0.2567,  0.1957,  0.0905,  0.1119,  0.0119, -0.1154,  0.0385, -0.2616],
        [-0.3478,  0.0047, -0.1815, -0.1538,  0.1589, -0.1068,  0.3277, -0.1897],
        [-0.3254,  0.1166,  0.0397,  0.0710,  0.0902, -0.1003, -0.3480,  0.2291],
        [-0.1246,  0.2854, -0.1785,  0.2797,  0.0809, -0.0936, -0.1121,  0.3400],
        [ 0.2867, -0.3531, -0.1392, -0.0959,  0.0933, -0.2560, -0.2305,  0.0438],
        [ 0.0080, -0.2339,  0.1897,  0.3157, -0.1407,  0.3512,  0.1009,  0.0472],
        [-0.1231,  0.3059,  0.2494, -0.3088,  0.1010, -0.2357, -0.1769, -0.1877],
        [ 0.0027, -0.0979, -0.0849,  0.2498,  0.0474, -0.2625, -0.1717, -0.2894],
        [-0.1595,  0.2013,  0.1091, -0.1059,  0.1830,  0.0153,  0.2858, -0.1459],
        [-0.3368, -0.1276, -0.0389,  0.3208,  0.0692, -0.1515,  0.2021,  0.3166],
        [-0.1960, -0.0586,  0.3507,  0.3164, -0.0191,  0.2106,  0.2060, -0.0119],
        [-0.1546, -0.0040,  0.0207,  0.3297,  0.1678, -0.1736,  0.3163, -0.1497],
        [-0.1521,  0.2464,  0.1938,  0.2151,  0.0024, -0.3118,  0.3499,  0.0605],
        [ 0.1908,  0.3209,  0.1264,  0.2706,  0.0230,  0.2817,  0.3075,  0.3214],
        [ 0.1185,  0.1723, -0.0498, -0.1015, -0.1897,  0.2069, -0.0960,  0.2401],
        [ 0.0311, -0.0891, -0.1567, -0.0608, -0.2043, -0.0843, -0.1041, -0.2351],
        [ 0.3223, -0.1222,  0.3031,  0.3174,  0.1793,  0.3193,  0.1344, -0.3014],
        [-0.1932,  0.0652,  0.0577,  0.0782, -0.1673, -0.2121, -0.0453,  0.1727],
        [ 0.1445, -0.0369,  0.1936, -0.2692, -0.2375,  0.1276,  0.3011, -0.2018],
        [-0.2070,  0.1205,  0.0040, -0.2707, -0.2819, -0.2993, -0.1205,  0.0026],
        [-0.0743, -0.0794, -0.2687,  0.2380,  0.2809,  0.0310,  0.1053,  0.3221],
        [-0.2272,  0.0204, -0.1284, -0.1884, -0.0150, -0.1159, -0.3464,  0.3063],
        [-0.3171,  0.2190,  0.0504,  0.1184,  0.3359,  0.2328,  0.3392,  0.1078],
        [-0.1422,  0.0174, -0.1632, -0.2249, -0.0023, -0.1393,  0.0122, -0.0588],
        [-0.1946,  0.0379, -0.2163, -0.1191, -0.1903,  0.2857, -0.1408, -0.2417],
        [-0.0566,  0.1829,  0.0695,  0.3095, -0.0318,  0.1067, -0.2523,  0.0228],
        [ 0.1417, -0.1098, -0.0498, -0.0108, -0.2354, -0.1345, -0.3510, -0.1070],
        [-0.0119, -0.0495, -0.0691, -0.0710, -0.0067,  0.2584, -0.0053,  0.2293],
        [-0.1135,  0.1362,  0.0506,  0.0403, -0.2320,  0.1757,  0.0579, -0.2580],
        [-0.3054, -0.1103, -0.2029, -0.3159, -0.0196, -0.1939, -0.2452,  0.3167],
        [ 0.1684,  0.3532,  0.2522, -0.2594,  0.3149,  0.0660,  0.1143, -0.2904],
        [ 0.0311,  0.2409, -0.0490,  0.0560, -0.1861,  0.1896, -0.1501,  0.1279],
        [-0.2437,  0.0239,  0.3534, -0.1653, -0.2565,  0.1862, -0.2598,  0.0553],
        [-0.2698, -0.2520, -0.3267,  0.1073,  0.0119, -0.2539, -0.3197,  0.0894],
        [ 0.2331, -0.1497,  0.0822,  0.3036,  0.2704,  0.2330,  0.1344,  0.1885],
        [-0.3380, -0.3028, -0.2130,  0.3055,  0.3317,  0.3285, -0.1039, -0.3421]],
       device='cuda:0', requires_grad=True) 

model.module_8.bias torch.Size([100])
Parameter containing:
tensor([-2.7539e-01,  2.5152e-01,  9.7400e-02,  3.2334e-01,  1.1198e-01,
        -1.4581e-01, -3.4693e-01, -1.0607e-01,  1.4336e-01,  4.1960e-02,
        -1.7959e-01, -1.7772e-02, -2.2004e-01,  6.6023e-02, -2.6899e-01,
        -5.7157e-02,  8.7585e-02, -2.1718e-01, -8.5126e-02, -2.6607e-01,
        -2.2195e-03,  1.0020e-01, -1.5602e-01,  2.0809e-01, -2.2542e-01,
         2.0203e-01,  1.7084e-01, -1.1662e-01,  1.9275e-01,  2.5567e-01,
        -1.3595e-01,  5.8864e-02,  3.4403e-01,  2.7434e-01,  1.0793e-02,
         2.4525e-01,  2.2061e-01,  1.8000e-01, -5.4497e-02, -3.4615e-01,
         1.4239e-01,  1.4911e-02, -1.6792e-01, -3.0906e-01, -2.5148e-01,
        -2.0420e-01, -6.5914e-02, -1.9305e-01, -1.9735e-01, -9.7035e-02,
         1.0415e-02,  9.6422e-02,  2.4573e-01,  1.6518e-01, -1.9158e-01,
         1.9879e-01,  2.3660e-01,  3.0046e-01,  8.3210e-02,  3.1519e-01,
         1.3821e-01, -4.5123e-02, -3.3628e-01, -8.2052e-02,  1.3764e-01,
         2.0595e-01, -2.0659e-01,  3.2660e-04,  2.9933e-01, -2.5085e-01,
         1.5807e-01,  7.0358e-02,  5.9888e-02,  1.8644e-01,  1.9863e-01,
        -1.5930e-01,  1.6904e-01, -3.2656e-01,  1.6127e-01,  4.4750e-02,
        -4.2302e-02,  2.6215e-01,  1.6587e-01, -6.7752e-02, -7.6882e-02,
         2.2880e-01,  1.8903e-01, -1.0846e-01,  1.0903e-01, -2.9777e-01,
         2.9752e-01, -1.3413e-01, -2.4973e-01,  2.7788e-01, -1.6083e-01,
         3.1376e-01,  2.0915e-01, -2.1088e-01,  4.3167e-02,  2.9375e-01],
       device='cuda:0', requires_grad=True) 

model.module_10.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0721,  0.0048, -0.0073,  ..., -0.0547, -0.0395, -0.0324],
        [-0.0858, -0.0476, -0.0004,  ...,  0.0794,  0.0248,  0.0480],
        [ 0.0964, -0.0779,  0.0696,  ..., -0.0859, -0.0323,  0.0021],
        ...,
        [ 0.0238,  0.0892, -0.0614,  ..., -0.0696,  0.0608,  0.0498],
        [ 0.0633,  0.0273, -0.0548,  ...,  0.0827,  0.0606,  0.0437],
        [ 0.0868,  0.0048,  0.0529,  ...,  0.0989,  0.0801,  0.0565]],
       device='cuda:0', requires_grad=True) 

model.module_10.bias torch.Size([100])
Parameter containing:
tensor([ 0.0369, -0.0126,  0.0871, -0.0373,  0.0540, -0.0621,  0.0007, -0.0584,
         0.0890, -0.0463, -0.0902,  0.0659,  0.0154,  0.0931, -0.0134,  0.0709,
         0.0188,  0.0805,  0.0236,  0.0267,  0.0528,  0.0439,  0.0788, -0.0442,
         0.0121, -0.0861, -0.0425, -0.0061, -0.0333,  0.0588, -0.0462, -0.0129,
        -0.0732, -0.0973, -0.0681, -0.0904,  0.0722, -0.0220,  0.0731,  0.0092,
        -0.0726, -0.0678,  0.0246, -0.0907, -0.0374,  0.0290,  0.0284,  0.0300,
        -0.0344, -0.0543,  0.0307,  0.0112, -0.0463,  0.0443, -0.0274,  0.0935,
        -0.0237, -0.0485, -0.0190, -0.0510,  0.0457,  0.0030,  0.0601, -0.0832,
         0.0335,  0.0936, -0.0833,  0.0274, -0.0313, -0.0444, -0.0774, -0.0082,
         0.0176,  0.0783, -0.0680,  0.0438,  0.0438, -0.0919, -0.0466,  0.0861,
         0.0200, -0.0844, -0.0856, -0.0593, -0.0178, -0.0717, -0.0847,  0.0669,
         0.0257,  0.0144, -0.0612, -0.0518,  0.0088,  0.0757,  0.0566, -0.0792,
        -0.0666, -0.0856,  0.0870,  0.0573], device='cuda:0',
       requires_grad=True) 

model.module_12.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0900, -0.0628,  0.0206,  ...,  0.0875, -0.0196, -0.0094],
        [-0.0899,  0.0907,  0.0156,  ...,  0.0016,  0.0503, -0.0100],
        [-0.0184, -0.0989,  0.0144,  ...,  0.0284,  0.0528,  0.0686],
        ...,
        [ 0.0039,  0.0577,  0.0623,  ..., -0.0585,  0.0882, -0.0466],
        [ 0.0580,  0.0009, -0.0470,  ..., -0.0757,  0.0586, -0.0288],
        [-0.0550, -0.0749,  0.0998,  ...,  0.0920,  0.0470,  0.0818]],
       device='cuda:0', requires_grad=True) 

model.module_12.bias torch.Size([16])
Parameter containing:
tensor([-0.0453,  0.0910,  0.0463,  0.0797, -0.0134, -0.0338,  0.0992, -0.0397,
         0.0048,  0.0440,  0.0549,  0.0192, -0.0292,  0.0253, -0.0365, -0.0476],
       device='cuda:0', requires_grad=True) 

model.module_14.bias torch.Size([8])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

model.module_14.lin.weight torch.Size([8, 16])
Parameter containing:
tensor([[ 0.4521,  0.1286, -0.0390, -0.2729, -0.3169, -0.2860,  0.3797, -0.2144,
          0.1813,  0.1983, -0.3066, -0.2687, -0.1364, -0.3441,  0.4958, -0.2492],
        [-0.4339, -0.3356,  0.0039,  0.4681, -0.4408,  0.0523,  0.0082, -0.0169,
          0.0792, -0.1908,  0.1994,  0.1102,  0.4298,  0.3966,  0.0882, -0.2909],
        [ 0.0009, -0.3820,  0.1872,  0.1123, -0.0039, -0.4706, -0.2959,  0.2525,
          0.3747, -0.3130, -0.3315,  0.1011,  0.2618, -0.1718, -0.0484,  0.4648],
        [-0.2002,  0.2244, -0.0704,  0.4098,  0.2090,  0.1863,  0.3995, -0.0074,
         -0.1394, -0.4147,  0.4620,  0.3256, -0.0901, -0.4334,  0.4985,  0.3869],
        [-0.4216,  0.1514, -0.0261,  0.3020, -0.0284, -0.1872, -0.0315,  0.0550,
         -0.2876,  0.2926,  0.4625,  0.4896,  0.3340, -0.2876,  0.1806, -0.1789],
        [ 0.0275, -0.2994, -0.1487, -0.3770,  0.0093,  0.0422,  0.4533,  0.1819,
          0.2866, -0.2448,  0.0164, -0.0575,  0.0596, -0.2110,  0.2638,  0.4759],
        [ 0.2117,  0.0900, -0.0146, -0.3708, -0.2964, -0.2383, -0.2301, -0.4631,
          0.1052, -0.0162,  0.0769,  0.2314, -0.3230, -0.2726, -0.3815, -0.1094],
        [-0.1922,  0.3058,  0.0543, -0.1877,  0.1485, -0.0363, -0.0341,  0.2897,
          0.0705,  0.1363,  0.4098,  0.3620, -0.3008, -0.1148, -0.2499,  0.2255]],
       device='cuda:0', requires_grad=True) 

model.module_15.weight torch.Size([100, 8])
Parameter containing:
tensor([[-1.2562e-01, -1.4635e-01, -3.7081e-02,  2.0992e-01, -2.8058e-01,
         -2.8312e-01,  2.6233e-01,  8.0025e-02],
        [-9.0970e-02, -3.4684e-01, -7.2498e-02,  1.9860e-01, -1.8380e-01,
         -1.0247e-01, -2.0555e-01, -5.3314e-02],
        [ 5.2156e-02,  1.5988e-01, -2.0844e-01, -2.8952e-01,  9.0998e-02,
         -2.6824e-01,  1.9093e-01, -1.9831e-01],
        [-2.7425e-01, -6.0179e-02,  1.5950e-01, -2.6515e-01, -2.9885e-02,
         -1.6463e-01, -1.6494e-01, -2.4938e-01],
        [ 1.7033e-01, -1.7963e-01, -2.7016e-01, -3.1623e-01,  3.3842e-01,
          1.5360e-02, -1.1503e-02,  3.2078e-01],
        [ 2.5141e-01, -9.4196e-02,  2.5751e-01, -3.6147e-02,  2.8087e-01,
         -2.1683e-01,  1.1675e-01, -2.8727e-01],
        [-1.4310e-01, -4.7722e-03, -2.6175e-01,  1.1954e-02, -1.7756e-02,
          3.3894e-01,  4.9623e-02,  2.2026e-01],
        [ 2.0707e-01,  2.1170e-01,  1.8861e-01,  9.6927e-02,  2.6220e-01,
          3.0969e-01, -1.0540e-01,  1.8820e-01],
        [ 1.2875e-01,  2.0859e-01, -1.6307e-01,  2.5018e-02,  4.4299e-02,
          1.1091e-01,  5.9861e-02,  2.1841e-01],
        [-1.4652e-01, -6.8575e-02, -3.3216e-01,  2.5287e-01, -3.2948e-01,
          9.9366e-02, -2.6381e-01,  1.0876e-01],
        [-1.9029e-01,  2.1572e-01, -3.0231e-01,  2.1708e-01, -8.3712e-02,
         -3.1894e-01, -1.1060e-01, -1.1508e-01],
        [ 1.1580e-01,  3.0201e-01,  1.1540e-01, -6.7527e-03,  3.2158e-02,
         -2.7743e-01, -1.7272e-01,  2.9968e-01],
        [ 2.8223e-01, -1.8294e-02,  1.2051e-01,  2.6789e-01, -2.2439e-01,
          8.9328e-03, -2.5917e-01,  4.7536e-02],
        [-6.4829e-03, -7.1441e-02,  3.0889e-01, -2.2644e-01,  2.2675e-01,
         -8.1096e-02,  3.3710e-01,  3.0495e-03],
        [-8.8075e-02,  5.0828e-02,  1.3858e-01, -3.0040e-03, -8.1700e-02,
         -1.4218e-01, -1.6850e-02, -2.5847e-01],
        [-8.2578e-02,  5.2621e-02, -8.7183e-02,  2.4759e-01, -2.4232e-01,
          1.6075e-02, -3.7668e-02, -1.6857e-01],
        [ 2.5015e-01, -2.3386e-01,  4.1159e-02,  8.1101e-02,  2.9323e-01,
          2.1326e-01,  1.8162e-01, -2.5966e-01],
        [-6.5870e-02,  1.4059e-01,  8.1712e-02,  2.7157e-01,  2.4016e-01,
          2.0763e-01, -1.5467e-01,  1.7213e-01],
        [-9.4721e-02,  6.8230e-02,  2.5662e-01,  3.4032e-01, -3.0092e-01,
          1.5729e-01,  2.7744e-01, -2.9624e-01],
        [ 2.3151e-01, -2.5819e-01, -2.4556e-01,  1.4100e-01, -1.2968e-01,
          2.6308e-01, -1.3086e-01, -3.3593e-01],
        [-2.3702e-01, -9.7528e-02, -2.9620e-01, -2.0852e-01, -2.8991e-01,
         -1.6869e-01, -1.0064e-01,  1.7903e-01],
        [ 2.1251e-01, -2.9328e-01, -5.8507e-02, -1.7898e-01,  1.4105e-01,
         -3.1822e-01, -2.9988e-01,  1.0778e-01],
        [-1.5434e-01, -2.2386e-01,  3.7327e-02, -1.1323e-01,  1.5087e-01,
          3.3797e-01, -1.2504e-01,  3.5237e-01],
        [ 2.2596e-01,  3.3113e-01,  1.7620e-01,  2.9514e-01, -1.9263e-01,
          2.7969e-01,  2.3679e-01,  1.9697e-01],
        [-1.1399e-02, -2.1653e-01,  2.5314e-01,  2.1732e-01,  1.5660e-01,
          3.3722e-01,  1.6894e-01, -4.5106e-04],
        [ 1.8301e-01,  1.1522e-01,  1.9081e-02, -1.4142e-01,  3.1672e-01,
          1.2612e-01, -8.7756e-02, -3.1913e-01],
        [ 6.7479e-02,  1.7525e-01,  3.8408e-02,  1.6404e-01, -3.3886e-01,
          2.6713e-01, -1.1010e-01, -2.8455e-01],
        [-1.5937e-01,  2.9905e-01, -4.4652e-02, -3.1923e-01, -2.2390e-01,
         -1.6897e-01, -1.2637e-01,  8.8117e-02],
        [-9.6057e-02, -1.5154e-01, -1.0095e-01, -1.6744e-01,  9.1350e-02,
         -3.4654e-01, -4.4957e-02,  3.3162e-01],
        [-4.4868e-02, -3.8043e-02, -5.8041e-02,  1.7129e-01,  3.2393e-01,
         -3.5109e-01, -2.8109e-01,  7.6415e-02],
        [-2.7521e-01,  3.0982e-01,  2.2678e-01,  1.8630e-01, -3.2462e-01,
          1.8487e-01, -2.6009e-02,  1.5396e-01],
        [-1.5978e-01, -2.5023e-01,  2.9390e-01, -1.8347e-01, -2.5455e-01,
         -1.8899e-01, -1.7386e-01, -2.8236e-01],
        [-1.3669e-01, -2.2471e-01, -1.3860e-01,  1.2859e-01, -4.9541e-02,
         -1.1182e-01,  2.9547e-01, -2.2768e-01],
        [ 1.6511e-02, -5.4362e-02,  2.6300e-01,  4.9903e-02, -3.2492e-01,
          1.5836e-01, -2.4983e-01,  1.3076e-01],
        [ 2.8135e-01,  1.9557e-01, -1.9926e-01,  2.0093e-01, -2.6975e-02,
          8.7600e-02, -1.1717e-01,  2.2078e-01],
        [ 2.9564e-01,  2.2086e-01,  6.8156e-03,  2.6411e-01, -1.0792e-01,
          6.2443e-02,  3.3788e-01, -2.8574e-02],
        [ 1.9638e-01,  2.5148e-01, -1.5681e-01,  5.1387e-02,  3.7094e-02,
         -2.2105e-01,  2.1526e-01, -1.7381e-01],
        [-2.1689e-02, -3.2967e-02,  1.9425e-01,  2.9200e-01, -7.4973e-03,
          5.8836e-03, -2.4554e-01, -3.1686e-02],
        [ 4.4245e-02,  3.0376e-01, -3.0587e-01,  1.9598e-01, -1.3039e-01,
         -8.3328e-02,  3.0655e-01,  6.0996e-02],
        [ 3.0057e-01, -2.2618e-01, -1.9419e-01, -2.2487e-01, -2.8400e-01,
         -2.4972e-01,  3.1106e-01, -1.5691e-01],
        [-3.3226e-01, -2.4980e-01, -7.8196e-02,  1.8492e-01,  4.3242e-03,
          3.5068e-01, -1.0085e-01,  3.3476e-01],
        [ 2.4684e-01,  6.0963e-02, -1.9963e-01, -2.0803e-01,  1.0023e-01,
         -9.1840e-02, -2.2736e-01, -1.2698e-01],
        [-2.8948e-01, -3.0215e-01,  6.9156e-02,  3.3014e-01,  1.2475e-01,
          1.8032e-01, -3.2346e-01,  1.1201e-01],
        [-7.4971e-02,  2.3123e-01,  1.0167e-01,  2.0660e-04, -1.7012e-01,
          2.2302e-01,  3.3879e-01,  2.0713e-01],
        [-2.2282e-01, -2.1510e-01,  1.6912e-01,  5.4367e-02, -1.0299e-01,
          6.8713e-02,  3.0581e-01, -3.2434e-01],
        [ 2.2235e-01,  2.9713e-01, -2.3441e-01, -3.0526e-01,  2.7093e-02,
         -2.5552e-01, -1.2062e-02,  3.3242e-03],
        [ 2.6470e-01,  1.4071e-02,  1.8956e-01, -2.3185e-01,  4.7913e-03,
          6.3315e-02,  6.8106e-02, -2.3342e-03],
        [ 1.5757e-01, -1.8551e-02, -8.1424e-02,  4.1167e-02,  6.3001e-03,
         -2.4528e-01, -5.7749e-02, -4.1804e-02],
        [-3.0390e-01, -8.2584e-02, -1.0944e-02,  3.2766e-02,  3.1208e-01,
          8.5960e-02, -2.7761e-01,  1.8495e-01],
        [ 3.0333e-01, -3.1668e-01, -1.5844e-01, -3.5229e-01,  2.6703e-01,
         -2.2614e-01,  3.0734e-01,  2.6939e-01],
        [ 5.7651e-02, -1.6101e-01, -2.1559e-03, -1.8309e-01, -3.0478e-01,
         -2.4726e-01, -1.0622e-01,  5.1106e-02],
        [ 2.5510e-01, -2.0974e-02, -3.4595e-02, -1.3897e-01,  2.6930e-01,
          2.3377e-02, -3.0035e-01, -3.0069e-01],
        [ 3.3242e-01,  7.4298e-02,  3.3243e-01, -1.5842e-02,  1.0420e-01,
         -3.3628e-01, -2.4757e-01,  3.3498e-01],
        [-2.2256e-01, -1.8682e-01,  1.2746e-02, -1.9735e-02, -3.2541e-01,
          2.3043e-01, -3.4887e-01, -1.6621e-01],
        [ 3.1751e-01,  2.2273e-01,  9.3465e-02,  2.4258e-01, -2.4817e-01,
          3.3392e-01,  2.5868e-02,  1.0486e-01],
        [ 1.8142e-01,  2.9928e-01, -2.7539e-01,  3.0273e-01, -1.6058e-01,
         -2.4477e-02,  1.4108e-01,  2.8105e-01],
        [ 2.2167e-01,  3.0392e-01, -1.0657e-01,  3.0695e-01,  5.5733e-02,
          1.2158e-01,  1.9484e-01,  4.6326e-02],
        [ 2.1087e-01, -1.3906e-01, -3.4473e-01,  2.0240e-01,  2.9040e-01,
          2.4182e-01, -3.8599e-02, -1.3295e-01],
        [-1.4297e-01,  2.0918e-01,  2.5064e-01,  3.7325e-03,  3.1298e-01,
          2.3241e-01,  1.7057e-01, -3.1332e-01],
        [ 2.9133e-01,  1.0211e-01, -2.4540e-01,  8.2982e-02, -2.8696e-03,
         -2.2903e-01,  2.7906e-01, -2.4597e-01],
        [-1.1897e-01, -2.5892e-01,  1.7166e-01, -2.5275e-01, -1.2283e-01,
          2.4674e-01, -3.3172e-02, -5.2553e-02],
        [-2.1252e-01,  1.4657e-01,  1.9783e-03, -1.8728e-01, -1.2102e-01,
          2.0407e-03, -1.6164e-01,  3.2862e-02],
        [-1.5260e-01,  2.9702e-01,  2.4913e-01, -1.5341e-01,  8.4207e-03,
          7.1519e-02,  7.7641e-02, -1.4582e-01],
        [-2.4994e-01, -3.3208e-01, -2.9411e-01, -7.8157e-02, -9.7775e-02,
         -2.7630e-01,  2.5901e-01, -1.2538e-01],
        [ 2.5245e-01,  2.9355e-01, -3.0531e-01, -1.9571e-01, -1.9874e-01,
         -3.0556e-01, -3.0716e-01,  2.8694e-01],
        [ 4.2210e-02,  2.0112e-01, -2.3709e-01, -1.5181e-01, -3.1088e-01,
          1.1445e-01, -2.4233e-01, -1.6116e-01],
        [-1.0195e-01, -2.6605e-01,  1.9630e-01, -2.1383e-01,  2.6663e-01,
         -2.1224e-01, -1.4089e-01,  2.7988e-01],
        [-8.3661e-02, -2.3952e-01,  6.1259e-02,  2.6165e-01,  1.7615e-02,
          1.4285e-01, -1.5495e-02, -2.5694e-01],
        [ 8.6753e-02, -1.5321e-01,  1.7973e-01,  1.1547e-01, -1.1504e-01,
          6.4606e-02,  2.6740e-01, -1.6453e-01],
        [ 5.6871e-02,  4.3964e-02,  2.9755e-01, -2.7204e-01, -1.4150e-01,
          4.8160e-02, -2.6376e-01, -2.6377e-01],
        [-3.0474e-01, -1.6324e-01,  1.2236e-01,  1.8659e-01,  2.5907e-01,
         -3.3077e-01,  1.1772e-01,  3.5264e-01],
        [-1.0383e-01,  2.4882e-01, -3.1218e-01,  3.1036e-01,  1.6737e-01,
         -2.9863e-02, -1.6371e-01,  2.5386e-01],
        [-3.1393e-01,  2.5283e-02,  2.7626e-02, -3.1644e-01,  5.2320e-02,
          1.1346e-01,  1.7580e-01,  1.8829e-01],
        [ 1.1938e-01,  1.6462e-01, -6.0165e-03, -2.3822e-01, -4.6466e-02,
         -2.9891e-02, -1.7250e-01,  2.9992e-01],
        [ 1.9393e-01,  3.4355e-01,  2.8775e-01, -6.0604e-02, -1.5337e-01,
          8.5672e-02,  1.0331e-02, -1.0132e-01],
        [-2.8818e-01, -3.1900e-01,  1.3134e-01, -2.8745e-01,  3.4009e-01,
         -1.5887e-03,  9.1439e-02,  3.0578e-01],
        [ 8.6663e-02,  1.5651e-01,  1.0314e-01,  2.2245e-01,  9.9888e-02,
         -1.5746e-02, -2.7255e-01, -3.4349e-01],
        [-3.4966e-01,  3.3456e-01,  1.2855e-01, -7.1632e-03, -3.0937e-01,
         -8.8731e-02,  1.8986e-02, -1.9696e-01],
        [-1.8815e-01,  2.7715e-02, -1.4368e-01, -2.9852e-01, -1.7365e-01,
          2.1202e-01, -3.1340e-01,  1.3999e-01],
        [ 1.8796e-01,  1.2661e-01, -1.9770e-01,  2.5407e-01,  1.5490e-01,
          2.0768e-01,  1.7016e-01,  2.3805e-02],
        [-2.8006e-01,  1.2980e-01, -6.4997e-02,  3.9122e-02,  2.1422e-01,
         -3.3422e-01, -3.4833e-01,  6.7557e-04],
        [-8.2858e-03,  1.6484e-01,  1.0264e-02, -6.8568e-02, -5.1783e-03,
          2.4145e-01, -2.9513e-01,  1.0988e-01],
        [-2.1095e-01,  2.0261e-01,  3.7300e-03, -3.2718e-01,  1.3845e-01,
         -1.7777e-01,  1.8587e-02, -1.0389e-02],
        [ 8.6695e-02,  2.7422e-01,  2.1088e-01,  3.4386e-01, -1.4347e-01,
         -1.0727e-01, -2.6249e-02,  1.1543e-01],
        [-1.0176e-01,  2.6821e-01,  3.0516e-01,  2.7758e-01,  1.7399e-01,
          1.7400e-03,  3.2539e-01, -7.9496e-02],
        [ 1.7458e-01, -2.3786e-01,  1.3491e-01, -3.0871e-01, -1.3708e-01,
         -1.9016e-01, -9.3707e-02, -1.8940e-01],
        [-2.1620e-02,  2.0520e-01,  2.5727e-01,  3.3626e-01, -7.1825e-02,
         -7.2933e-02, -1.8860e-02,  1.3116e-01],
        [-1.0399e-02, -1.2322e-01,  9.6178e-02, -2.0799e-01,  1.7137e-01,
          9.3016e-02,  2.2516e-01, -2.2317e-01],
        [-2.2382e-01, -3.3911e-01,  2.9101e-01, -2.3667e-01,  1.2270e-01,
          3.0936e-01,  2.7009e-01,  2.3006e-01],
        [ 1.0010e-02, -2.3101e-01, -3.3619e-01, -1.9112e-01,  1.9029e-02,
          1.4931e-01, -2.3699e-01, -2.4277e-01],
        [ 2.5465e-01,  2.2723e-02, -1.9122e-01,  3.2299e-01,  6.5289e-02,
         -1.6723e-01,  1.7050e-02, -3.3683e-01],
        [-1.8668e-01,  3.0245e-01,  1.1568e-01, -2.2175e-01,  1.1108e-01,
         -1.3966e-01, -2.5229e-01, -3.0501e-01],
        [ 2.6584e-01,  1.8510e-01, -2.4963e-01, -2.9829e-01,  7.3352e-02,
         -2.5254e-01,  1.4400e-01, -2.8792e-01],
        [ 8.4222e-02,  1.2834e-01, -6.7451e-02,  6.2836e-02, -2.0486e-01,
         -3.0021e-01,  1.2547e-01, -6.2908e-02],
        [ 6.2365e-02, -2.0473e-02, -2.9559e-01, -1.9723e-02,  2.0281e-01,
         -2.0257e-02, -1.5401e-01, -2.2651e-01],
        [ 2.4874e-01, -3.2463e-01, -2.1812e-02, -2.0339e-01,  8.8615e-02,
          3.5101e-02,  4.0332e-02, -2.0136e-01],
        [-1.2922e-01, -2.9725e-01,  2.9262e-01,  1.3022e-01, -3.4370e-02,
          6.0652e-02, -1.3863e-01,  2.4299e-01],
        [-1.0298e-01,  9.2312e-02, -2.3106e-01,  2.9528e-01,  2.0633e-02,
         -7.0838e-02, -1.1662e-01, -3.8018e-02],
        [-4.0216e-02, -1.6140e-01,  1.4398e-01,  3.3339e-01,  2.7429e-02,
          7.2620e-02,  1.0250e-01, -3.4785e-01],
        [ 3.3216e-01,  1.0400e-01,  2.0189e-01, -1.2791e-01, -3.1009e-01,
         -1.9717e-01,  1.3218e-01, -2.0873e-01]], device='cuda:0',
       requires_grad=True) 

model.module_15.bias torch.Size([100])
Parameter containing:
tensor([-0.0587, -0.0222, -0.1198, -0.2773,  0.2212,  0.1115,  0.3479,  0.2795,
         0.0157, -0.2252,  0.0769, -0.0227, -0.3456,  0.1078, -0.3521,  0.3503,
        -0.0430, -0.0510,  0.1549,  0.1285, -0.0686, -0.1744,  0.2176, -0.1301,
        -0.0169,  0.0345, -0.2901, -0.3288, -0.3210, -0.2925, -0.2800,  0.3028,
         0.1563, -0.3398, -0.2174,  0.0937,  0.0463,  0.3051,  0.2080, -0.1297,
        -0.1265, -0.2187, -0.2673,  0.2031, -0.1462, -0.0657,  0.2845, -0.1028,
        -0.2842, -0.0414, -0.1752,  0.1894,  0.0516, -0.1441,  0.0775, -0.1071,
         0.0085,  0.3124, -0.0679, -0.2873, -0.0742,  0.1814,  0.2178, -0.2872,
         0.1443, -0.2477,  0.2796, -0.3176,  0.1412,  0.3504, -0.2349, -0.1220,
         0.0361,  0.1409,  0.0978,  0.0983, -0.1719,  0.2627,  0.3038,  0.2864,
         0.2519,  0.0268, -0.3412, -0.2035,  0.0629,  0.0137, -0.1555, -0.2955,
        -0.0719, -0.1745,  0.3034,  0.1901, -0.0449,  0.0276,  0.0659, -0.1712,
        -0.2535, -0.0282,  0.2684, -0.1985], device='cuda:0',
       requires_grad=True) 

model.module_17.weight torch.Size([100, 100])
Parameter containing:
tensor([[ 0.0564, -0.0397,  0.0804,  ...,  0.0870,  0.0128,  0.0209],
        [-0.0878, -0.0465,  0.0090,  ..., -0.0456,  0.0672,  0.0102],
        [ 0.0299,  0.0633,  0.0936,  ...,  0.0741,  0.0547, -0.0739],
        ...,
        [ 0.0427,  0.0745, -0.0068,  ...,  0.0948, -0.0331,  0.0310],
        [ 0.0635,  0.0427,  0.0731,  ...,  0.0208, -0.0577,  0.0261],
        [ 0.0525,  0.0782, -0.0189,  ...,  0.0189, -0.0958, -0.0120]],
       device='cuda:0', requires_grad=True) 

model.module_17.bias torch.Size([100])
Parameter containing:
tensor([ 0.0755,  0.0322,  0.0067, -0.0779, -0.0126,  0.0269,  0.0092, -0.0761,
         0.0149,  0.0130, -0.0193,  0.0014,  0.0116, -0.0434, -0.0035, -0.0183,
        -0.0722,  0.0383, -0.0798,  0.0038,  0.0048,  0.0144, -0.0598,  0.0434,
         0.0990, -0.0601,  0.0603, -0.0916,  0.0575,  0.0219, -0.0761, -0.0287,
         0.0684,  0.0354,  0.0540,  0.0727, -0.0743, -0.0098,  0.0819,  0.0174,
        -0.0939,  0.0921, -0.0071, -0.0281,  0.0112, -0.0875,  0.0103,  0.0459,
        -0.0547, -0.0596, -0.0686, -0.0761,  0.0340, -0.0511, -0.0873, -0.0858,
         0.0191,  0.0767, -0.0947,  0.0916,  0.0066,  0.0215,  0.0673, -0.0238,
         0.0124, -0.0922, -0.0559, -0.0415, -0.0062, -0.0393,  0.0107,  0.0996,
        -0.0095,  0.0472, -0.0244,  0.0562,  0.0559, -0.0444, -0.0441, -0.0433,
        -0.0250,  0.0360,  0.0187,  0.0323, -0.0212,  0.0745,  0.0488, -0.0242,
        -0.0191,  0.0489, -0.0010, -0.0142,  0.0362, -0.0699, -0.0071, -0.0029,
         0.0774, -0.0592,  0.0102,  0.0614], device='cuda:0',
       requires_grad=True) 

model.module_19.weight torch.Size([16, 100])
Parameter containing:
tensor([[-0.0510, -0.0036,  0.0401,  ...,  0.0884,  0.0334,  0.0576],
        [-0.0017,  0.0818, -0.0675,  ...,  0.0396,  0.0354, -0.0121],
        [-0.0517, -0.0638,  0.0727,  ...,  0.0426, -0.0782,  0.0544],
        ...,
        [ 0.0065, -0.0966,  0.0587,  ...,  0.0753,  0.0218, -0.0091],
        [ 0.0750,  0.0551,  0.0260,  ..., -0.0807, -0.0453,  0.0258],
        [ 0.0717, -0.0616,  0.0820,  ...,  0.0378,  0.0170, -0.0797]],
       device='cuda:0', requires_grad=True) 

model.module_19.bias torch.Size([16])
Parameter containing:
tensor([ 0.0570, -0.0850,  0.0519, -0.0660, -0.0935,  0.0163, -0.0140,  0.0785,
        -0.0467,  0.0946,  0.0244,  0.0120,  0.0190,  0.0277,  0.0531,  0.0085],
       device='cuda:0', requires_grad=True) 



#### FINAL PARAMETERS ####
W 256 torch.Size([16, 16])
Parameter containing:
tensor([[-9.0608e-01,  5.3349e-01,  1.1985e-01,  6.9280e-01, -9.4164e-02,
          3.0103e-01,  6.9167e-01, -1.2459e+00,  1.7796e+00,  5.8759e-01,
         -1.0567e+00, -5.2551e-01, -4.7347e-01,  3.0585e-01,  9.3297e-02,
         -2.4904e-01],
        [-8.6390e-01,  5.3097e-01, -9.4985e-01, -8.6084e-01,  5.8401e-02,
          2.8486e-01,  5.1214e-01, -5.8122e-01,  3.4709e-01, -9.5849e-01,
          1.6715e+00,  3.5092e-01,  5.9287e-02, -1.1201e+00,  6.2895e-01,
         -3.6681e-01],
        [-2.4940e-01,  2.7714e-01, -1.0503e+00, -1.0780e+00, -4.4033e-01,
         -4.1229e-01, -6.2515e-01, -6.5942e-02,  1.2237e+00, -7.9022e-01,
          5.1140e-01,  4.6317e-01, -2.0214e-01,  7.5050e-02, -2.4098e+00,
          4.0849e-01],
        [-1.2583e+00, -5.3450e-02,  8.6293e-01, -1.1213e+00,  6.0156e-01,
         -8.9855e-01, -8.4510e-01,  1.4822e+00,  1.1825e+00, -2.2056e-01,
          2.4402e-02,  1.2638e+00, -1.8623e+00, -1.3622e+00,  1.0684e+00,
          2.0780e+00],
        [ 6.0334e-01, -2.2654e+00,  7.3040e-01, -1.7560e+00, -6.1805e-01,
         -3.4940e-01,  1.5717e-02,  2.9454e-01, -5.8340e-01,  1.3986e+00,
          1.5551e+00,  5.2901e-01,  3.7391e-01, -4.3273e-02, -8.2351e-01,
          3.5312e-02],
        [ 1.3888e+00, -1.2747e+00, -1.8099e+00,  9.1447e-01,  1.2256e+00,
         -4.3910e-01, -1.1333e+00,  3.4419e-01, -6.3803e-01, -1.5129e-01,
         -2.0258e-01, -3.8735e-01,  8.5387e-01,  1.6118e-01, -1.1556e+00,
          1.7447e+00],
        [-2.2295e+00, -1.8657e+00, -2.1587e+00,  1.2150e+00,  7.8279e-02,
          1.3292e+00, -1.5635e+00, -1.1914e+00, -1.3829e-01, -1.8341e-01,
         -5.3446e-01,  6.4069e-01, -1.5238e+00, -7.2724e-01, -1.1717e+00,
         -5.7214e-01],
        [-7.3818e-01,  5.8480e-01,  5.1449e-02,  3.0423e-01, -5.1309e-02,
          4.6971e-01,  9.9676e-01, -2.5480e-01,  4.5251e-01, -2.3756e-01,
         -5.1801e-01, -5.2043e-01, -4.3037e-01, -2.5803e-01, -1.0492e+00,
          3.1158e+00],
        [-1.7772e+00, -4.3215e-01,  1.7217e-01,  8.4048e-01,  9.7263e-01,
          8.4216e-01, -6.8698e-01,  1.3845e-01,  1.7213e-01,  2.3025e+00,
          8.8782e-01,  2.1274e-01,  1.5285e+00, -3.9043e-01, -7.8717e-01,
          1.1935e+00],
        [-2.1320e+00,  8.2753e-01,  6.4594e-01, -1.0188e+00, -2.3564e-01,
          9.9552e-01,  3.6203e-01,  4.9232e-02, -5.5510e-01, -1.1326e+00,
          1.3626e+00, -4.8607e-01, -1.0131e-01, -2.1369e-01,  2.4602e+00,
          5.8892e-01],
        [ 3.3440e-01, -6.5285e-01, -1.3812e+00, -1.0656e-01,  5.6018e-01,
         -2.4017e+00,  4.3876e-01,  1.2155e+00, -7.8094e-01,  1.7983e+00,
          1.4930e+00, -1.4377e+00, -1.8914e+00, -1.4943e+00,  6.0771e-01,
          8.1509e-01],
        [ 8.5554e-01,  7.0467e-01,  9.5490e-01,  1.1831e-01, -2.4523e+00,
          6.5360e-01,  2.4150e+00,  1.5614e+00,  8.3784e-01, -5.6301e-01,
         -6.4531e-01, -1.1550e+00,  3.6000e-01,  1.8223e+00,  4.9428e-01,
         -8.5153e-01],
        [ 1.4607e+00,  2.8771e-01, -1.8038e+00, -2.5634e+00, -8.7339e-01,
         -1.8896e+00, -1.7077e-02,  7.1460e-01,  1.9557e-01,  4.7317e-01,
         -1.6018e-01,  8.8185e-01,  8.6683e-01, -2.6042e-01,  3.2139e-04,
         -4.9934e-01],
        [-8.9450e-01, -1.1168e+00, -7.5791e-01,  7.1708e-01,  6.5957e-01,
          2.8207e-01,  1.2265e+00,  6.3967e-02, -4.1100e-01,  8.5819e-01,
          6.7936e-01,  1.2644e+00, -1.7987e-01,  4.6874e-01, -4.0393e-01,
          1.1066e+00],
        [-1.3217e+00,  3.2551e-01, -2.2300e+00,  2.0046e+00,  3.1424e+00,
          2.4014e+00,  2.8847e+00, -5.1964e-01,  7.7642e-01, -1.5588e-01,
         -2.5762e-01,  1.3016e+00,  1.7580e+00, -2.9711e-01, -2.0191e-01,
         -2.9846e-01],
        [-1.1738e+00, -1.7676e+00,  5.9867e-01,  4.1118e-01,  1.8323e+00,
          7.3152e-01, -1.2514e-01,  1.5398e-01, -1.0795e+00,  2.2810e+00,
          6.6415e-02,  4.1605e-01,  5.3226e-01, -2.8895e+00,  6.3760e-01,
         -2.6945e-01]], device='cuda:0', requires_grad=True) 
grad:  tensor([[ 1.9726e-02,  2.0876e-04,  2.0406e-02, -1.0718e-03,  5.2840e-05,
         -4.0675e-04, -2.1442e-03,  2.8078e-02, -2.7621e-04, -1.5958e-04,
          1.0227e-04,  2.4967e-03, -3.0616e-04,  1.6877e-03,  2.0590e-02,
         -2.6844e-04],
        [ 2.0876e-04,  1.3664e-05,  2.8763e-04, -1.0652e-05,  1.1651e-05,
          5.5467e-05,  1.4946e-04,  2.8659e-04,  5.9035e-05, -1.0994e-04,
         -1.0374e-05,  3.0331e-04,  6.0896e-05,  6.1407e-04,  3.2238e-05,
          4.5576e-06],
        [ 2.0406e-02,  2.8763e-04,  2.1312e-02, -1.0827e-03,  2.0434e-04,
         -5.6738e-04, -2.8641e-03,  2.7842e-02, -2.6962e-04, -7.1745e-04,
          1.6780e-04,  1.5968e-03, -2.8852e-04,  8.9876e-04,  2.0629e-02,
         -1.9585e-04],
        [-1.0718e-03, -1.0652e-05, -1.0827e-03,  5.3353e-05, -1.8965e-05,
          1.3899e-04,  5.3581e-04, -1.3300e-03,  9.3959e-05,  3.8767e-06,
         -3.4910e-05,  3.8168e-04,  1.0047e-04,  8.3624e-04, -1.2963e-03,
          5.1050e-06],
        [ 5.2840e-05,  1.1651e-05,  2.0434e-04, -1.8965e-05, -3.1870e-05,
          3.3087e-04,  1.1165e-03,  7.3896e-04,  2.2466e-04, -6.7703e-05,
         -8.0174e-05,  1.6457e-03,  2.3082e-04,  2.7652e-03, -3.0860e-04,
         -1.8138e-05],
        [-4.0675e-04,  5.5467e-05, -5.6738e-04,  1.3899e-04,  3.3087e-04,
         -1.7872e-03, -5.3132e-03, -5.1904e-03, -5.7891e-04, -1.0882e-03,
          3.6315e-04, -7.6119e-03, -6.7246e-04, -9.7848e-03, -5.6878e-04,
          2.2218e-04],
        [-2.1442e-03,  1.4946e-04, -2.8641e-03,  5.3581e-04,  1.1165e-03,
         -5.3132e-03, -1.8271e-02, -1.9160e-02, -2.4022e-03, -3.0680e-03,
          1.3148e-03, -2.6515e-02, -2.5419e-03, -3.7615e-02, -2.3956e-03,
          7.1591e-04],
        [ 2.8078e-02,  2.8659e-04,  2.7842e-02, -1.3300e-03,  7.3896e-04,
         -5.1904e-03, -1.9160e-02,  3.1425e-02, -3.4767e-03, -2.0305e-04,
          1.3084e-03, -1.7781e-02, -3.6649e-03, -3.4524e-02,  3.5264e-02,
         -9.1831e-06],
        [-2.7621e-04,  5.9035e-05, -2.6962e-04,  9.3959e-05,  2.2466e-04,
         -5.7891e-04, -2.4022e-03, -3.4767e-03, -2.2294e-04, -7.9749e-04,
          1.8902e-04, -3.8950e-03, -1.8046e-04, -4.9339e-03, -1.2120e-03,
          1.3392e-04],
        [-1.5958e-04, -1.0994e-04, -7.1745e-04,  3.8767e-06, -6.7703e-05,
         -1.0882e-03, -3.0680e-03, -2.0305e-04, -7.9749e-04,  8.6860e-04,
          1.9745e-04, -3.7088e-03, -9.2176e-04, -7.9387e-03,  2.7034e-03,
         -2.7686e-05],
        [ 1.0227e-04, -1.0374e-05,  1.6780e-04, -3.4910e-05, -8.0174e-05,
          3.6315e-04,  1.3148e-03,  1.3084e-03,  1.8902e-04,  1.9745e-04,
         -9.7270e-05,  1.9439e-03,  1.9091e-04,  2.8549e-03,  9.6446e-05,
         -4.8458e-05],
        [ 2.4967e-03,  3.0331e-04,  1.5968e-03,  3.8168e-04,  1.6457e-03,
         -7.6119e-03, -2.6515e-02, -1.7781e-02, -3.8950e-03, -3.7088e-03,
          1.9439e-03, -3.6995e-02, -4.0304e-03, -5.5323e-02,  4.3341e-03,
          9.1856e-04],
        [-3.0616e-04,  6.0896e-05, -2.8852e-04,  1.0047e-04,  2.3082e-04,
         -6.7246e-04, -2.5419e-03, -3.6649e-03, -1.8046e-04, -9.2176e-04,
          1.9091e-04, -4.0304e-03, -1.6361e-04, -4.7968e-03, -1.2968e-03,
          1.4552e-04],
        [ 1.6877e-03,  6.1407e-04,  8.9876e-04,  8.3624e-04,  2.7652e-03,
         -9.7848e-03, -3.7615e-02, -3.4524e-02, -4.9339e-03, -7.9387e-03,
          2.8549e-03, -5.5323e-02, -4.7968e-03, -7.8808e-02, -1.9942e-03,
          1.5601e-03],
        [ 2.0590e-02,  3.2238e-05,  2.0629e-02, -1.2963e-03, -3.0860e-04,
         -5.6878e-04, -2.3956e-03,  3.5264e-02, -1.2120e-03,  2.7034e-03,
          9.6446e-05,  4.3341e-03, -1.2968e-03, -1.9942e-03,  2.8065e-02,
         -5.1583e-04],
        [-2.6844e-04,  4.5576e-06, -1.9585e-04,  5.1050e-06, -1.8138e-05,
          2.2218e-04,  7.1591e-04, -9.1831e-06,  1.3392e-04, -2.7686e-05,
         -4.8458e-05,  9.1856e-04,  1.4552e-04,  1.5601e-03, -5.1583e-04,
         -7.3336e-06]], device='cuda:0') 

act.weight 1 torch.Size([1])
Parameter containing:
tensor([9.2389e-05], device='cuda:0', requires_grad=True) 
grad:  tensor([-1.8438], device='cuda:0') 

inner_act.weight 1 torch.Size([1])
Parameter containing:
tensor([0.0504], device='cuda:0', requires_grad=True) 
grad:  tensor([-0.5539], device='cuda:0') 

out_act.weight 1 torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 
grad:  None 

encoder.module_0.weight 1100 torch.Size([100, 11])
Parameter containing:
tensor([[ 0.2309,  0.3486, -0.2081,  ...,  0.4527, -0.0683,  0.4641],
        [ 0.0439,  0.2120,  0.1884,  ..., -0.0173,  0.0526, -0.1093],
        [-0.0300,  0.2919, -0.3915,  ..., -0.0250, -0.2150,  0.2634],
        ...,
        [ 0.0069,  0.1279,  0.1384,  ...,  0.2779,  0.2604, -0.4128],
        [-0.2019,  0.0091, -0.1813,  ...,  0.3715,  0.0998, -0.1919],
        [-0.0329,  0.1393,  0.1615,  ...,  0.0923,  0.1323, -0.4026]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-0.0833, -0.0330,  0.0148,  ...,  0.0002,  0.0016, -0.0062],
        [-0.0166, -0.0252, -0.0232,  ..., -0.0007, -0.0015, -0.0038],
        [-0.0118,  0.0184,  0.0069,  ...,  0.0034,  0.0006,  0.0008],
        ...,
        [-0.0194,  0.0043, -0.0227,  ..., -0.0008, -0.0007, -0.0011],
        [ 0.0065,  0.0251, -0.0106,  ..., -0.0007,  0.0019,  0.0012],
        [ 0.0214, -0.0086,  0.0020,  ..., -0.0028, -0.0027, -0.0002]],
       device='cuda:0') 

encoder.module_0.bias 100 torch.Size([100])
Parameter containing:
tensor([-1.7509e-01, -4.0127e-02, -2.9580e-01, -2.9806e-01, -7.0620e-01,
         2.5064e-02, -3.9705e-01, -1.7365e-01, -5.9584e-01,  2.1524e-01,
        -1.4910e-01, -8.7967e-01, -9.5981e-02, -7.0911e-01, -2.0992e-01,
        -2.1872e-01, -8.6458e-01, -4.2610e-04, -4.9834e-01, -2.4775e-01,
        -1.7911e-01, -9.4890e-01, -6.6441e-01, -6.5821e-01,  2.4423e-01,
        -6.3108e-01, -3.3669e-01,  3.8655e-01, -3.8493e-01, -6.1662e-01,
        -5.1422e-01, -1.1126e-01, -2.3946e-01, -8.0648e-01,  3.3770e-01,
        -1.3568e-01, -6.6927e-02, -1.0193e-01, -4.4561e-01, -5.0291e-01,
        -5.3559e-01, -3.3680e-02, -5.2934e-01, -5.4628e-01,  6.9885e-02,
        -4.8306e-01, -1.2154e-01, -6.0520e-01, -1.0281e-01, -6.3904e-01,
        -5.2175e-01, -1.0752e-01, -4.9212e-01, -1.1687e-01, -8.3793e-01,
         3.5225e-02, -4.8849e-01, -3.8404e-01, -6.1591e-01,  6.4907e-02,
         6.1011e-02, -2.0857e-01,  1.7489e-01,  3.2337e-02, -7.7924e-01,
         2.4068e-01, -4.9532e-01, -3.8566e-01, -6.9146e-01, -6.8574e-02,
        -3.4225e-01, -8.0195e-01, -5.7914e-01, -2.0151e-01, -1.0667e-01,
         1.0860e-02, -3.1881e-01, -3.0874e-01,  2.4287e-01, -7.8802e-02,
        -3.4259e-01, -6.5400e-02, -5.2383e-01, -3.1753e-01, -5.1801e-01,
        -1.6225e-01,  7.5121e-02, -7.0520e-01, -6.3727e-01,  1.3524e-01,
        -6.4036e-01, -1.5694e-01,  1.9448e-01, -7.6218e-01, -5.8694e-01,
        -8.0042e-01, -6.3309e-01, -7.0157e-01, -8.8147e-04, -6.9066e-01],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-8.3886e-03, -6.2468e-03,  7.3168e-04, -5.2770e-03, -9.6442e-04,
        -4.6801e-03, -1.9164e-04, -4.7847e-03,  2.5117e-03,  4.1129e-03,
        -9.4924e-03, -8.1684e-04,  1.6302e-03,  2.5020e-03, -7.4232e-03,
        -2.2533e-03,  1.3275e-03,  1.3307e-04, -1.0437e-03, -3.6938e-04,
         4.9210e-03, -1.7985e-03, -2.6198e-04,  1.0937e-03, -9.2589e-03,
         2.2470e-04, -4.5539e-04,  5.8382e-03, -1.3866e-03,  1.7153e-03,
        -2.2578e-03, -2.4338e-03, -2.0834e-03, -9.2190e-04,  4.8022e-03,
        -9.0095e-03,  5.4795e-03,  1.8303e-03,  3.0334e-03, -4.0205e-03,
        -1.1106e-03,  2.3186e-03, -1.3176e-03,  9.4764e-04,  1.1144e-03,
        -3.0537e-03,  3.0434e-03,  3.6305e-03, -6.3007e-05,  1.0140e-03,
         1.0953e-03, -1.9371e-03,  1.2002e-03, -5.7778e-03,  3.9609e-03,
         3.7813e-03,  1.6139e-03,  2.4185e-03,  5.2939e-03, -5.3636e-04,
         4.3806e-03, -3.8341e-03,  3.7963e-04, -1.7825e-03, -1.8241e-03,
        -9.8071e-03, -3.1395e-03, -1.8988e-03, -8.6578e-04, -1.2555e-02,
         1.6265e-03,  2.9898e-03,  3.0510e-03, -5.4214e-03,  1.4606e-05,
         9.0595e-04, -2.5395e-04, -3.2143e-03, -1.1392e-02,  8.1133e-03,
        -1.9420e-04,  2.1366e-03, -2.2341e-03, -7.7996e-03,  2.8331e-03,
         4.7236e-03,  4.2599e-03, -2.9609e-04,  1.4618e-04, -5.3452e-03,
         3.4069e-04,  2.0265e-04,  5.7048e-03, -4.2826e-04, -3.8869e-03,
         3.2426e-04,  1.5490e-03, -2.0004e-03,  1.6067e-03, -1.1115e-03],
       device='cuda:0') 

encoder.module_2.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[-0.1652, -0.4065, -0.0805,  ..., -0.4242, -0.1647,  0.0324],
        [-0.1613,  0.0389, -0.2883,  ...,  0.1446, -0.2544, -0.0256],
        [ 0.0264, -0.3203, -0.0389,  ..., -0.2570, -0.2003,  0.0450],
        ...,
        [-0.1122, -0.3702,  0.0005,  ..., -0.2419,  0.0232, -0.0856],
        [ 0.0589, -0.1299, -0.0131,  ..., -0.0878, -0.2122,  0.1218],
        [ 0.0287, -0.2786,  0.1949,  ..., -0.3279, -0.3377, -0.2003]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-1.7681e-06, -1.6173e-06, -5.4127e-04,  ..., -1.0496e-06,
         -6.1339e-04, -7.8731e-04],
        [-6.2787e-04, -6.2521e-04, -7.4856e-04,  ..., -8.1564e-04,
         -1.1926e-03,  2.7878e-04],
        [-2.5148e-04, -7.7424e-04,  3.2836e-05,  ..., -3.5584e-04,
          8.2053e-06,  1.4307e-04],
        ...,
        [ 5.9301e-04,  3.1768e-04,  1.8085e-04,  ..., -4.1755e-04,
          7.0461e-04,  1.7707e-05],
        [ 5.2967e-05, -6.8858e-07,  1.4572e-07,  ...,  5.0602e-05,
         -1.0026e-06,  4.3968e-04],
        [ 4.9142e-04,  1.0505e-03, -2.8364e-03,  ...,  1.1001e-04,
         -1.0478e-03, -1.0766e-03]], device='cuda:0') 

encoder.module_2.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.2496, -0.3050, -0.1170,  0.0610, -0.0271,  0.3498, -0.0839,  0.0925,
         0.0016, -0.3840, -0.1930,  0.1450,  0.0853, -0.1044, -0.1839, -0.2920,
         0.0548,  0.1639, -0.0179, -0.1244,  0.1630,  0.3519,  0.1635, -0.0973,
        -0.1452,  0.0450,  0.1984, -0.0944,  0.0450, -0.4011, -0.0108, -0.0616,
         0.0851, -0.1431, -0.1204,  0.0439, -0.3451,  0.2215, -0.0359,  0.1320,
        -0.6203, -0.2272, -0.0365, -0.2466, -0.3033,  0.0811,  0.0681,  0.1725,
         0.1310, -0.0906,  0.0815, -0.0874, -0.1516,  0.1267, -0.3159,  0.0685,
         0.1802, -0.1898,  0.0696, -0.1984,  0.1056,  0.2293, -0.2386, -0.1709,
         0.1802,  0.0017, -0.1323, -0.2391, -0.1718, -0.2170, -0.2505, -0.5069,
         0.0345, -0.2856,  0.1661,  0.1379, -0.1235, -0.0206, -0.0538,  0.0077,
         0.1615,  0.1306, -0.0008, -0.2201, -0.2191, -0.6116,  0.0388,  0.0090,
         0.1107, -0.2288,  0.2117, -0.0157, -0.0470,  0.1494, -0.1881,  0.0347,
        -0.1002, -0.1338, -0.3135, -0.2223], device='cuda:0',
       requires_grad=True) 
grad:  tensor([-2.3301e-04,  4.6639e-04,  5.3418e-04,  7.6040e-04, -4.0895e-04,
        -5.5880e-04, -1.1154e-03, -1.4294e-04,  9.1676e-04,  1.9964e-03,
         1.8590e-04,  2.4090e-03, -7.4503e-04,  1.0886e-04,  8.1906e-04,
        -1.2894e-03,  2.1086e-06,  2.2337e-03,  1.6190e-04, -6.7775e-05,
        -3.1021e-03, -1.3208e-03,  1.2599e-03,  1.3032e-04, -1.0301e-03,
         1.3735e-03,  5.0636e-04,  2.6671e-08, -3.5523e-03,  6.3457e-04,
         2.2246e-03, -1.9641e-03,  4.5675e-04, -1.5728e-03,  1.9294e-04,
         8.5763e-04, -3.3815e-04,  9.1595e-04,  1.4098e-03,  1.0783e-04,
        -1.0326e-04, -1.4727e-04,  6.6631e-04, -6.4405e-04, -1.3695e-04,
        -2.1987e-03, -1.0887e-04, -1.8103e-02,  3.3459e-03,  1.3957e-04,
         5.0396e-04,  4.1859e-04, -2.7170e-04, -1.4331e-03,  9.8025e-04,
        -6.4644e-04,  1.6538e-03,  5.4100e-05,  1.4528e-03,  2.3800e-03,
         4.3899e-04, -9.5676e-03, -3.7109e-04, -4.0157e-04,  4.3176e-04,
         2.6806e-04,  7.8569e-04, -1.0748e-04,  9.3831e-04, -4.0542e-03,
         1.3531e-03, -9.3976e-05, -3.7824e-04,  8.8632e-06, -6.5993e-04,
         4.9343e-05, -1.1815e-03, -5.1564e-04, -3.1072e-04, -1.3524e-03,
         2.5020e-03, -1.0818e-03,  3.3935e-04, -1.8222e-03, -1.1906e-03,
        -3.1630e-03, -1.9720e-02, -1.7192e-04,  1.2946e-03,  1.5270e-03,
        -5.2769e-03, -1.2810e-04, -3.2185e-04, -1.1107e-03,  5.2487e-04,
         4.3741e-05,  1.4528e-04,  1.6323e-03,  2.1163e-03,  1.8771e-03],
       device='cuda:0') 

encoder.module_4.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[ 0.3838,  0.1035,  0.3885,  ..., -0.1975,  0.2268,  0.1864],
        [ 0.1570,  0.1225,  0.3209,  ...,  0.1687,  0.2079,  0.2937],
        [-0.0040, -0.2873, -0.0207,  ..., -0.0097, -0.1706,  0.0715],
        ...,
        [ 0.0441, -0.0073, -0.0057,  ..., -0.0127,  0.1260, -0.0410],
        [-0.0318, -0.0040,  0.0033,  ..., -0.3119, -0.4218, -0.0939],
        [-0.1532,  0.1388,  0.3759,  ...,  0.1147,  0.0325,  0.3833]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-9.5682e-04, -8.3096e-04, -1.0727e-04,  ...,  1.3011e-05,
          1.2622e-04, -1.0220e-03],
        [-2.4715e-03, -2.7096e-03,  1.0248e-03,  ...,  3.0683e-03,
          2.2130e-03, -1.3368e-03],
        [ 7.8112e-07,  1.1089e-06,  9.5397e-07,  ..., -1.4790e-04,
         -7.1481e-06,  1.0043e-04],
        ...,
        [ 1.7545e-03,  1.4095e-03, -1.2684e-05,  ..., -2.1593e-03,
         -1.1422e-05,  2.6321e-03],
        [-3.9103e-05, -3.8527e-04,  7.1417e-06,  ..., -1.0187e-03,
         -1.2200e-04, -5.3396e-04],
        [-2.3606e-04,  5.8911e-04,  6.0377e-04,  ...,  1.1569e-03,
          1.8480e-04,  1.9078e-03]], device='cuda:0') 

encoder.module_4.bias 16 torch.Size([16])
Parameter containing:
tensor([-0.0967, -0.0556, -0.0618, -0.1853, -0.0300,  0.0236,  0.2117,  0.1907,
        -0.1794,  0.0449,  0.2974,  0.0789, -0.1691,  0.2390,  0.1205,  0.1717],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-0.0073,  0.0112, -0.0015, -0.0046,  0.0030, -0.0039, -0.0307,  0.0020,
        -0.0016,  0.0139, -0.1162,  0.0002, -0.0007,  0.0090, -0.0107,  0.0201],
       device='cuda:0') 

model.module_0.bias 8 torch.Size([8])
Parameter containing:
tensor([-0.0896, -0.0404,  0.2522,  0.1131, -0.4204,  0.0924, -0.4353,  0.3796],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-0.1213,  0.0837,  0.0557,  0.0052,  0.0303,  0.0162, -0.1356,  0.1689],
       device='cuda:0') 

model.module_0.lin.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[ 0.4213,  0.2586,  0.2289, -0.0393, -0.1337,  0.0951,  0.1614,  0.3647,
         -0.2499, -0.1681,  0.3315,  0.2104,  0.0010, -0.5122, -0.0696,  0.3063],
        [ 0.5054, -0.0022,  0.4227, -0.2536, -0.6444,  0.0284, -0.1217, -0.0501,
         -0.1023,  0.3371, -0.3665, -0.2903, -0.0665,  0.4915,  0.0812,  0.2336],
        [ 0.1833,  0.4929, -0.2698, -0.0941, -0.2087, -0.2143, -0.4584, -0.5470,
          0.0964, -0.6024,  0.0644,  0.8151,  0.1980,  0.0884, -0.5166, -0.2951],
        [-0.3809, -0.5082,  0.4422, -0.0271,  0.3378, -0.6251, -0.4039, -0.3412,
         -0.0813, -0.1479,  0.1675,  0.0514,  0.4180,  0.1639, -0.7297,  0.0153],
        [ 0.1637,  0.0938,  0.1171, -0.6470,  0.4770,  0.1276, -0.0242,  0.0464,
         -0.3844, -0.1520,  0.0281,  0.5264,  0.1277,  0.4522,  0.1740,  0.1906],
        [-0.4243, -0.2141,  0.2139, -0.1995, -0.1448,  0.3787, -0.1506,  0.1615,
          0.1497,  0.5611,  0.0150,  0.3004,  0.5494, -0.1596,  0.3867, -0.4326],
        [ 0.4701,  0.2183,  0.1291,  0.3495, -0.2856, -0.0209,  0.0394, -0.4078,
          0.3112,  0.0946,  0.4781,  0.0247,  0.1228, -0.1687, -0.2438, -0.1175],
        [ 0.3631,  0.5744,  0.0939,  0.2721,  0.3702, -0.1366, -0.3437,  0.0998,
         -0.1150,  0.1157, -0.3846, -0.0672, -0.0894, -0.4287, -0.4310,  0.4547]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-8.4143e-02, -7.1318e-02, -1.1141e-02, -2.3375e-02, -2.9711e-03,
         -1.5689e-02, -8.6514e-02, -3.6413e-02, -7.9979e-03, -1.0447e-01,
         -3.1712e-01, -5.3778e-02, -8.9235e-03, -2.3952e-01, -3.0424e-02,
         -9.9796e-02],
        [ 5.2171e-02,  3.9880e-02,  7.8208e-03,  1.3769e-02,  2.0211e-03,
          8.9241e-03,  6.5845e-02,  2.8275e-02,  5.4791e-03,  5.0020e-02,
          2.3793e-01,  2.0016e-02,  6.0007e-03,  1.0565e-01,  1.7819e-02,
          5.7989e-02],
        [ 8.8584e-03,  4.5177e-03,  6.0645e-03, -5.4947e-03,  1.7935e-03,
          8.2132e-03, -1.6151e-02,  9.2474e-03, -9.7068e-04,  3.6937e-02,
          4.9474e-03,  1.6457e-02, -2.6301e-03,  1.0169e-01,  1.6171e-02,
          2.7960e-02],
        [ 4.9916e-03,  7.7989e-03, -3.5883e-04,  4.3839e-03,  1.7484e-04,
         -1.7022e-03, -3.0186e-03,  4.2416e-04,  8.1884e-04,  1.8958e-02,
          3.8447e-03,  8.8840e-03,  7.2882e-04,  5.0284e-02, -5.7632e-04,
          7.5720e-03],
        [ 4.1668e-03,  7.7587e-03,  2.3697e-04,  3.2657e-03,  4.5354e-04,
         -3.7959e-03,  2.7026e-02,  1.8084e-02,  1.5042e-03, -3.5533e-02,
          1.1564e-01, -1.7530e-03,  8.1542e-04, -1.1074e-01, -4.8085e-03,
         -6.6751e-03],
        [ 1.4660e-02,  1.4629e-02,  1.8765e-03,  2.7951e-03,  4.8005e-04,
          5.3912e-03,  1.1264e-02,  2.7575e-03,  8.5004e-04,  3.5973e-02,
          3.5601e-02,  2.0654e-02,  9.9950e-04,  9.2814e-02,  8.5854e-03,
          2.1295e-02],
        [-6.6835e-02, -4.9118e-02, -1.3862e-02, -8.3952e-03, -3.5474e-03,
         -2.1784e-02, -6.0567e-02, -4.0166e-02, -4.9587e-03, -1.1912e-01,
         -2.1957e-01, -4.3816e-02, -5.3443e-03, -2.8038e-01, -4.1152e-02,
         -9.7884e-02],
        [ 5.5971e-02,  2.8111e-02,  1.7296e-02, -3.7915e-03,  4.1757e-03,
          2.8157e-02,  4.8596e-02,  5.1137e-02,  2.7384e-03,  1.3809e-01,
          1.7824e-01,  2.4023e-02,  2.5404e-03,  3.1596e-01,  5.2877e-02,
          9.4838e-02]], device='cuda:0') 

model.module_1.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[-1.6606e-01, -2.1249e-01,  4.4370e-01, -8.3770e-02,  1.3221e-01,
          2.0065e-01, -3.2773e-01,  1.5957e-01],
        [-2.5447e-01, -8.1422e-02, -1.4018e-01,  2.2799e-01, -7.8220e-02,
          4.4031e-01,  1.4686e-01,  1.4523e-01],
        [-1.3763e-01,  3.7685e-01,  1.6065e-01,  4.5404e-01, -2.7049e-01,
          1.3285e-01, -1.1452e-01,  3.7582e-01],
        [ 9.3158e-02,  3.1810e-01,  1.4926e-01, -5.0111e-01,  1.9884e-01,
          4.8606e-01,  6.3962e-02,  1.8893e-01],
        [ 7.0162e-02, -1.1116e-01,  1.0022e-01, -1.2322e-01,  3.3906e-01,
          8.4989e-02,  1.5490e-01, -2.5463e-01],
        [-4.5522e-01, -6.3823e-02,  2.6822e-01,  2.0554e-01, -2.1424e-02,
          1.1804e-01,  2.3440e-01, -1.7014e-01],
        [-9.2412e-02, -3.0638e-01,  2.3741e-01,  1.2878e-01, -9.7245e-01,
          4.4857e-01, -3.0864e-01,  8.3786e-02],
        [-3.9209e-01,  1.1720e-01,  4.7015e-01,  5.6683e-01, -4.3697e-01,
         -3.4929e-01, -5.4636e-01,  2.8874e-02],
        [-1.0126e-01, -5.2316e-02,  5.5285e-02, -1.4505e-01,  3.0395e-01,
          3.6573e-02, -3.6870e-01,  3.5720e-01],
        [-3.8226e-01,  8.6534e-02, -6.7774e-03, -1.0224e-01, -1.1556e-01,
          5.4491e-02,  1.2453e-01, -5.9250e-02],
        [ 3.9118e-02, -3.6852e-02,  2.5954e-01, -1.5885e-01, -1.7034e-01,
          1.4068e-02, -5.6327e-01,  6.6413e-02],
        [-1.3433e-01, -7.3811e-02, -3.5145e-02,  2.2139e-01, -9.9143e-02,
         -2.2528e-01, -2.4780e-01,  2.5857e-01],
        [-1.4969e-01,  2.8042e-01,  5.1082e-02,  5.5926e-01, -3.0161e-01,
         -2.5278e-01, -3.7803e-01,  3.6277e-01],
        [ 9.5682e-02, -1.8405e-01, -1.1333e-01,  2.3028e-02,  3.5335e-02,
         -5.1465e-02, -2.9462e-01, -2.1007e-01],
        [-1.2704e-01,  5.3229e-02, -2.5544e-01, -7.0817e-02, -6.4317e-02,
         -1.1474e-01, -4.2406e-01, -1.1050e-01],
        [-3.8956e-01, -1.7867e-01, -6.7867e-02, -2.2822e-02, -3.5181e-01,
          7.7982e-02,  1.9196e-01,  7.5249e-02],
        [ 2.4924e-02,  8.3655e-02, -5.3070e-02,  5.9611e-02, -3.4687e-01,
          7.1737e-02, -1.1597e-01,  3.1750e-01],
        [-1.7172e-01,  2.3451e-01,  5.1830e-01,  7.6988e-02, -2.2868e-01,
         -3.5205e-03, -2.8424e-01,  3.4421e-01],
        [-8.0360e-02,  2.6618e-01,  2.0754e-01, -2.4401e-01,  7.8508e-02,
          4.4360e-01, -1.2125e-01,  3.6057e-01],
        [ 6.0209e-02,  4.9904e-02, -3.5763e-01,  2.7457e-01,  1.8930e-01,
         -8.3951e-02, -5.5833e-03,  3.8450e-01],
        [ 5.1832e-02,  4.6106e-02,  1.6156e-01, -3.2838e-02, -1.1945e-02,
          4.5504e-01, -4.4100e-01,  2.0240e-01],
        [-1.1131e-01,  1.9709e-02,  1.1441e-01,  2.2840e-02, -3.2597e-01,
          2.5423e-01, -2.5727e-01,  1.0129e-01],
        [ 1.5988e-02, -2.8325e-02,  7.3862e-02,  1.4963e-01, -1.4493e-01,
          4.4177e-01,  6.8531e-02,  3.2130e-01],
        [-4.7847e-01, -4.1675e-01,  3.0280e-02,  4.2400e-02,  6.5562e-02,
         -3.0251e-01, -9.4132e-03,  2.9708e-01],
        [-2.7111e-01,  9.6412e-02,  1.6724e-01,  4.6812e-01,  7.5630e-02,
          5.5133e-02, -3.6639e-01,  4.3366e-01],
        [-1.4840e-01, -8.9597e-02, -1.6637e-01,  4.6797e-01,  4.3132e-02,
         -2.7402e-01,  7.3522e-02,  1.5758e-01],
        [-1.8870e-01, -5.8077e-02, -2.0515e-02, -2.0118e-01, -2.1628e-01,
          1.7064e-01, -7.1736e-02,  1.7397e-01],
        [ 1.7090e-01,  3.4541e-02,  4.3999e-01, -1.5814e-01, -1.8947e-02,
          2.8683e-01, -4.0639e-01, -1.1160e-01],
        [-3.7246e-01,  5.2052e-01,  3.7745e-01,  2.9453e-01,  2.7960e-02,
         -9.6151e-02,  2.1730e-01, -5.8918e-02],
        [-4.1352e-01, -2.6020e-01,  3.9814e-02, -1.6328e-01,  3.3685e-02,
          4.5112e-01, -2.5700e-01, -1.2731e-01],
        [-4.3780e-01, -1.1281e-02,  1.5240e-01,  3.4032e-02, -9.7382e-02,
         -1.7743e-01, -2.5714e-01,  3.4052e-01],
        [-2.8011e-01,  4.0363e-02, -1.7338e-01,  2.0535e-01, -1.3152e-01,
          8.3431e-01,  1.9388e-01, -1.8375e-01],
        [-1.9430e-01, -1.6812e-01,  1.0530e-01,  1.1316e-01,  2.8337e-02,
          3.2112e-01, -3.8676e-01,  2.4879e-01],
        [-3.0085e-01,  1.9347e-01,  4.2421e-01, -8.3415e-02, -3.6208e-02,
         -1.6786e-01, -5.0630e-02,  3.8302e-01],
        [ 1.2823e-01,  2.5588e-01,  7.5835e-02, -1.5783e-01,  4.6310e-02,
         -7.3671e-02,  1.3227e-01, -3.6220e-02],
        [-2.2595e-01,  1.1408e-01,  2.5036e-01, -5.2550e-02, -2.9408e-01,
          1.8308e-01, -1.2402e-01,  2.6383e-01],
        [-1.6691e-01, -2.4653e-01, -9.2634e-02, -9.0933e-03,  5.2453e-02,
         -1.9044e-02, -3.8474e-01,  3.1503e-01],
        [-2.5502e-01, -2.7843e-01, -2.5381e-01,  3.2615e-01, -4.1489e-02,
          4.7280e-01,  2.5470e-01, -8.3513e-02],
        [ 3.2667e-01, -2.7910e-01, -1.1587e-01,  1.9461e-01,  2.5875e-01,
          1.7431e-01,  3.2743e-01, -2.6200e-01],
        [ 1.9613e-01,  8.0316e-02, -9.0348e-02,  2.1767e-01, -2.6510e-01,
          2.9094e-01, -1.6627e-01,  3.2707e-01],
        [ 2.5634e-01, -2.6192e-01,  4.3352e-01, -5.8604e-02, -3.8860e-02,
          1.5799e-01, -7.8419e-02,  1.5472e-01],
        [-8.4248e-02, -1.3365e-01,  5.9514e-01,  2.4229e-01,  2.3829e-01,
          1.1445e-01, -4.3016e-01,  2.3794e-01],
        [-1.3653e-01,  5.2548e-02, -1.5633e-01,  4.4271e-01, -1.6654e-01,
          9.4732e-03,  2.5574e-02, -8.8502e-02],
        [ 2.4975e-01, -3.6779e-01, -3.2478e-02, -1.1755e-01,  6.0043e-02,
         -1.6572e-01,  2.8268e-01, -2.6787e-01],
        [-4.3058e-01,  2.3057e-01, -1.7128e-02,  3.0934e-01,  6.4814e-01,
         -2.2448e-01,  2.1800e-01, -8.8903e-03],
        [-6.9617e-02, -2.2910e-01,  2.4984e-01,  2.3216e-01,  8.0055e-03,
          1.1950e-01, -3.5028e-01,  3.1249e-02],
        [ 2.1506e-01,  3.6877e-01,  2.7162e-01, -2.7366e-02,  4.7883e-01,
          2.1608e-02, -2.4392e-01, -1.6444e-01],
        [-4.1890e-01, -6.4110e-02,  5.0241e-01,  1.9955e-01, -1.3568e-01,
          3.0848e-01, -5.7797e-01, -5.1105e-02],
        [-1.8647e-01,  3.3918e-02, -9.9737e-02, -1.1749e-01,  1.9261e-01,
         -5.3884e-02, -2.7171e-02,  2.6816e-03],
        [ 1.7380e-01, -9.8414e-02,  3.6678e-01,  3.2955e-02,  2.6074e-02,
         -4.7946e-02,  2.1841e-01,  5.9241e-02],
        [-1.2883e-01,  2.9020e-01, -3.5153e-01,  9.5925e-02,  1.8895e-01,
         -2.3210e-02,  3.7313e-01, -4.5472e-01],
        [-9.6602e-02, -2.6316e-01,  1.9437e-01, -5.4365e-02, -1.0851e+00,
          3.6071e-03, -3.2508e-01, -2.6660e-02],
        [-1.1335e-01, -6.0372e-02, -1.4716e-01, -8.9642e-02, -3.6410e-01,
          1.7275e-01, -4.7795e-01, -1.5561e-01],
        [-2.7171e-01,  2.5167e-01,  5.4846e-01, -1.8419e-01,  3.6644e-03,
          1.8113e-02, -4.0439e-02,  4.0111e-01],
        [-1.8081e-01, -1.8339e-02,  5.0027e-01, -1.2149e-01,  3.1284e-01,
          2.2617e-01,  1.6017e-01, -7.3143e-02],
        [-3.0060e-02, -2.7785e-01, -4.6071e-01, -4.8097e-01, -3.4359e-03,
          1.7105e-01, -2.6519e-01,  2.9737e-01],
        [-2.9880e-01,  3.7550e-02, -3.3286e-01,  4.3014e-01, -6.8069e-02,
          3.4933e-01, -3.1785e-03, -2.3334e-02],
        [-3.7349e-01, -2.7844e-01, -1.5565e-01, -1.8016e-01, -3.5933e-01,
         -9.1958e-02,  1.8839e-02,  1.0299e-01],
        [-2.7460e-01,  2.7863e-01,  3.2573e-01, -2.3840e-01, -1.4865e-01,
          3.2177e-01, -1.5097e-01,  3.4085e-01],
        [-7.3258e-02, -5.2057e-02,  1.3074e-01,  7.0488e-02, -7.5457e-02,
          1.8837e-01, -9.4209e-02,  1.3771e-01],
        [-8.8693e-02,  1.2676e-01, -3.2175e-02,  2.8058e-02, -4.1096e-01,
         -1.3400e-01, -5.7211e-02,  2.2946e-01],
        [ 7.2963e-02, -7.3828e-02,  4.4611e-01, -3.2256e-01,  4.3606e-01,
          1.4199e-02, -1.2123e-01, -7.3684e-02],
        [-2.1886e-02, -4.3574e-01, -3.8160e-01,  3.9466e-01, -3.1870e-02,
          2.1116e-01, -1.3993e-02, -1.1993e-02],
        [-2.0374e-02,  1.7435e-01,  2.8263e-01,  2.6532e-01, -4.3905e-01,
          4.4689e-01, -4.7273e-02, -1.3497e-01],
        [-3.9924e-01,  9.4993e-02,  4.1387e-01,  3.0913e-02,  6.3184e-02,
          3.1923e-01,  5.3580e-03,  2.6671e-01],
        [-1.8067e-01, -3.0723e-02,  7.1224e-02,  1.1826e-01, -1.1310e-01,
          2.5028e-01, -2.8641e-01,  3.4217e-01],
        [-3.2114e-01, -4.6123e-02,  1.4954e-01,  4.8933e-01, -1.4996e-01,
          1.7428e-01, -5.8814e-01, -6.9145e-02],
        [ 2.8289e-01, -2.6075e-02,  3.3468e-01, -8.4006e-02,  1.0490e-01,
         -1.5609e-01, -6.9008e-02,  4.5310e-01],
        [ 2.2815e-01, -3.0889e-01, -9.0676e-02,  2.8728e-01, -1.8959e-01,
          2.8965e-01,  9.9581e-02,  6.3930e-02],
        [-2.0668e-01, -7.0503e-02,  5.4462e-01,  5.4461e-01, -2.6927e-01,
          6.2290e-02,  1.5981e-01, -2.8468e-01],
        [ 4.6096e-02, -7.0360e-03,  2.6143e-01, -2.9668e-02,  1.6567e-01,
          7.0859e-01, -2.2874e-01,  1.0675e-01],
        [ 1.6405e-01,  3.0932e-03, -1.0061e-01, -2.0565e-01,  1.8145e-01,
         -1.8209e-01, -2.8172e-01, -1.6325e-01],
        [-2.9616e-01,  4.3206e-01, -6.0678e-02,  1.1371e-01,  2.7273e-01,
         -2.3149e-01,  2.9990e-01, -2.1146e-01],
        [ 2.8164e-01, -1.8391e-01,  3.7186e-01,  1.6115e-01, -1.1724e-01,
         -2.0117e-03,  1.6594e-01, -9.9347e-02],
        [-2.7138e-01, -2.3317e-01, -2.1168e-01,  2.3284e-01, -1.5161e-01,
         -6.0121e-02, -1.0659e-01,  2.6776e-01],
        [ 1.3903e-01, -6.7104e-02,  1.9950e-01,  2.4703e-01, -2.4229e-01,
          1.0561e-01, -1.5002e-01,  2.9855e-01],
        [ 1.3921e-01,  1.6743e-01,  2.8768e-01, -2.5337e-02, -2.1703e-01,
          1.9769e-01, -5.4495e-01,  6.0678e-02],
        [ 2.4594e-01,  1.7203e-01, -3.0047e-02,  2.0790e-01, -1.2059e-01,
          1.7824e-01,  2.2969e-01, -4.2252e-02],
        [ 1.9072e-01, -2.1192e-01,  1.9791e-01,  4.5066e-02, -1.1848e-01,
          1.0870e-01, -3.0428e-01,  8.2299e-02],
        [ 7.0992e-02,  2.4778e-01,  6.8321e-02,  5.8938e-02, -3.9012e-01,
          6.3967e-01, -1.3539e-01, -2.3791e-01],
        [-3.6409e-01, -1.8161e-01, -1.1102e-01, -2.4624e-01,  3.3884e-01,
          1.6322e-01, -7.4666e-03, -1.1845e-01],
        [-2.4567e-03,  1.0126e-01, -1.1497e-01,  1.5869e-01, -3.3998e-01,
          9.9028e-02, -2.1661e-01, -2.9958e-01],
        [ 2.1431e-03, -2.9995e-02, -1.7324e-01,  4.0244e-02, -1.9592e-01,
         -1.1821e-01, -3.3425e-01,  4.4014e-01],
        [-2.2754e-01, -5.3555e-02,  1.5488e-01,  1.6835e-01, -6.2895e-01,
          1.9094e-01, -2.6793e-01, -1.0199e-02],
        [ 3.0244e-01,  1.6741e-01,  1.6799e-01,  3.7687e-01,  2.4942e-02,
          2.2240e-01, -2.0434e-01,  3.6928e-01],
        [-2.4849e-01,  1.6247e-01,  7.8045e-02, -1.9436e-01, -4.4328e-03,
          3.1642e-01, -3.8257e-02,  4.1733e-01],
        [-4.2992e-01, -4.2170e-02,  4.3040e-01,  4.6353e-01, -1.4095e-01,
          4.0991e-01,  1.7193e-01,  1.9972e-01],
        [ 1.6417e-02, -4.6994e-01,  9.4014e-02,  4.1373e-02, -1.2662e+00,
          6.6619e-01, -2.8680e-01,  3.6247e-01],
        [-9.1266e-02,  4.3051e-02, -1.3062e-01, -1.3523e-01,  4.7161e-03,
          3.4049e-01,  2.8556e-01,  4.6887e-01],
        [-5.5896e-02, -1.5428e-01, -2.9810e-01,  5.8909e-01,  3.4497e-01,
         -1.5783e-01,  8.3505e-02,  3.5595e-01],
        [ 1.1716e-01,  1.3681e-01,  9.5493e-02,  7.9664e-02,  3.2051e-01,
         -1.9338e-02, -4.7211e-01,  9.5615e-02],
        [ 1.8789e-01, -1.5499e-01, -3.3725e-02,  1.0701e-01, -4.0135e-02,
         -2.9052e-02,  2.5607e-01,  4.2093e-01],
        [-8.7769e-02, -1.2288e-01, -1.0731e-01, -9.9289e-02, -9.4824e-02,
          3.9653e-01, -3.7948e-01,  5.1369e-01],
        [ 1.3939e-02, -2.2142e-01,  3.2794e-01, -5.8206e-02, -1.0931e+00,
          4.0253e-01, -3.6421e-01, -1.0043e-02],
        [-2.5382e-01,  3.0287e-01, -2.7455e-01,  5.9311e-01, -8.9778e-02,
          3.6927e-01, -1.5115e-01,  2.4089e-01],
        [ 1.9616e-01, -2.1469e-01,  2.7826e-01,  1.6870e-01, -7.8951e-02,
         -5.9784e-01,  7.6853e-02,  3.0929e-01],
        [ 2.4598e-01,  2.3446e-04, -7.7183e-02,  2.7480e-01, -1.2224e-01,
         -2.4599e-01,  1.5229e-01,  3.0407e-01],
        [ 3.0950e-01,  2.7140e-01,  8.5696e-02,  4.4479e-01,  6.0073e-03,
         -4.7793e-01,  2.8062e-01,  1.7040e-01],
        [-6.0659e-02,  3.1476e-01,  3.7993e-01, -4.9857e-01,  1.0782e-01,
         -9.8392e-02, -3.0861e-02,  3.5835e-01],
        [-3.0432e-01, -8.2416e-02,  1.2228e-01, -1.1271e-01,  1.3977e-02,
          4.4544e-01, -1.1518e-01,  2.9449e-01]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[ 1.4067e-03, -1.2359e-03,  2.0147e-03, -2.2826e-04,  4.2128e-04,
         -2.1284e-04,  4.1449e-04,  8.9395e-04],
        [-8.9867e-05,  1.4749e-04, -1.8722e-05, -1.2838e-05,  9.4291e-05,
          2.2716e-05, -1.4489e-05, -3.9968e-05],
        [-5.3011e-03,  1.0389e-02,  1.1438e-04, -1.0449e-03,  7.4687e-03,
          1.5446e-05, -5.6829e-05, -2.3547e-03],
        [ 4.0225e-03,  1.5188e-03, -1.3517e-02, -2.2280e-03,  9.8502e-04,
          3.7754e-03, -1.5076e-03, -1.2818e-02],
        [-1.0537e-03, -2.7799e-02,  9.0643e-03,  7.8650e-03, -2.9686e-02,
          2.1451e-03, -8.5163e-03,  2.3950e-02],
        [-2.3964e-03,  3.4595e-03, -1.5639e-04,  1.8040e-04,  2.4587e-03,
         -2.1868e-04, -4.1451e-04, -1.4083e-03],
        [-7.5901e-03,  4.6508e-03,  1.7693e-03,  1.5493e-03,  7.9014e-04,
         -8.1969e-04, -3.7830e-03,  3.6188e-03],
        [-5.9646e-03,  7.7920e-03,  3.9641e-04,  1.0391e-03,  6.1426e-03,
         -7.5270e-04, -1.3554e-03, -3.8284e-03],
        [-3.8322e-04,  5.3717e-04, -1.4793e-03,  9.1374e-05, -7.2258e-05,
          2.6740e-04, -2.8054e-04, -1.1595e-03],
        [-1.5251e-03,  2.7318e-03, -4.2411e-04, -1.2881e-04,  1.7326e-03,
         -2.7942e-04,  3.0872e-05, -9.4885e-04],
        [-1.0515e-03,  2.4922e-05, -2.5828e-03,  5.9890e-04, -1.6197e-03,
         -3.8638e-05, -3.7577e-04, -1.0448e-03],
        [ 8.4121e-06,  6.2924e-05,  3.8883e-05, -3.7234e-05,  4.3322e-05,
         -3.0467e-05,  9.0941e-06,  5.6725e-05],
        [-6.8832e-03,  1.0608e-02, -7.1743e-04,  1.8387e-04,  7.0346e-03,
         -1.1073e-03, -1.0093e-03, -3.5499e-03],
        [-1.9537e-03, -8.4341e-04,  2.2962e-03,  1.3759e-03, -2.2072e-03,
         -3.1013e-04, -1.7289e-03,  3.9595e-03],
        [-9.4039e-04,  1.4439e-03, -2.2243e-04, -1.5641e-06,  9.0684e-04,
         -6.5761e-05, -1.1407e-04, -5.3888e-04],
        [-1.6117e-06, -5.4675e-07,  6.4744e-07,  7.4848e-07, -1.1034e-06,
          4.2560e-07, -1.5374e-06,  1.2448e-06],
        [-3.6681e-05, -1.3021e-04, -9.9763e-05,  9.3053e-05, -9.3689e-05,
          7.2538e-05, -2.9857e-05, -1.4508e-04],
        [-3.0802e-03,  5.1038e-03, -8.1905e-04,  1.0598e-04,  3.2763e-03,
         -1.9891e-04, -2.8891e-05, -2.2618e-03],
        [ 2.3731e-03,  2.0643e-02, -1.1147e-02, -7.5905e-03,  1.8863e-02,
          1.9368e-03,  2.9879e-03, -1.7401e-02],
        [ 9.7283e-04,  1.5313e-03,  4.7907e-04, -1.4796e-03,  8.5447e-04,
         -1.9659e-04,  1.0783e-03,  1.6740e-03],
        [ 2.9481e-04, -5.0002e-04,  4.7901e-04,  3.6267e-05, -5.5963e-06,
          5.2019e-05, -2.6195e-05,  1.4669e-04],
        [ 1.0576e-02,  2.5877e-02, -1.9167e-02, -1.4755e-02,  2.5297e-02,
          2.9628e-03,  7.7934e-03, -2.6153e-02],
        [ 4.6247e-04, -2.2920e-04,  1.2857e-03, -1.9330e-04,  7.1357e-04,
          1.6456e-04,  7.4206e-05,  3.9671e-04],
        [ 1.3890e-04,  2.5416e-04,  3.4816e-04, -2.0145e-04,  2.9027e-04,
         -1.4261e-04,  1.4040e-04,  2.8979e-04],
        [-6.1816e-03,  1.5899e-02,  9.3056e-03, -2.5172e-03,  1.7734e-02,
          5.3163e-04,  4.8562e-05, -1.7063e-03],
        [-3.1865e-04,  1.7429e-04, -9.0029e-05,  1.0214e-05, -9.1499e-06,
          1.0354e-04, -3.3941e-04,  3.7280e-05],
        [-4.7909e-08, -3.8842e-07, -6.1133e-07,  1.6420e-07, -5.8863e-07,
          3.4113e-07, -5.6124e-07, -1.9365e-07],
        [ 8.3386e-04, -9.8799e-04,  1.1761e-03, -8.3170e-05,  3.4119e-05,
         -9.9619e-05,  6.2460e-05,  5.9184e-04],
        [ 1.3314e-02,  1.2716e-02, -5.4599e-03, -7.8665e-03,  1.4623e-02,
         -3.1040e-03,  1.1276e-02, -1.0642e-02],
        [-2.6783e-03,  3.8495e-03,  7.5815e-04,  1.8790e-04,  3.4875e-03,
          2.1644e-04, -6.4143e-04, -1.5310e-03],
        [ 4.5333e-04,  1.9111e-02, -5.2271e-03, -4.2848e-03,  1.6819e-02,
         -4.8579e-04,  2.8098e-03, -1.2251e-02],
        [-7.6159e-03,  9.3021e-03, -1.1166e-03,  1.4105e-03,  6.3489e-03,
         -7.2256e-04, -1.8192e-03, -4.9573e-03],
        [ 1.8551e-03, -6.3948e-04,  5.8035e-03, -9.1222e-04,  3.5280e-03,
          8.3319e-04,  2.5275e-04,  1.7215e-03],
        [-9.3805e-04,  3.4918e-03,  2.0609e-04, -4.5037e-04,  2.8458e-03,
         -8.2509e-04,  1.2993e-03, -1.2592e-03],
        [-2.0351e-03, -4.7749e-03,  1.2967e-04,  2.2094e-03, -4.0397e-03,
          3.3505e-03, -5.4408e-03,  1.2206e-03],
        [ 7.7229e-04, -5.8811e-04,  1.0749e-03, -8.4271e-05,  6.9553e-04,
          7.8521e-04,  1.0202e-04, -3.5774e-04],
        [-5.4735e-07,  2.0231e-07, -9.5030e-09, -2.3943e-08, -1.5000e-07,
          4.7326e-07, -9.6326e-07,  3.4336e-07],
        [ 9.3644e-03, -7.9047e-03, -2.3738e-03, -1.1977e-03,  3.7328e-04,
         -4.6592e-04,  8.9040e-03, -8.4760e-03],
        [-4.1547e-02, -3.3233e-02,  2.2803e-02,  2.4619e-02, -4.9090e-02,
          9.1989e-03, -4.4728e-02,  4.9739e-02],
        [-1.5656e-06, -4.5376e-08, -2.7158e-07,  5.0546e-07, -1.1462e-06,
          7.4695e-07, -2.1803e-06,  9.6555e-07],
        [-9.4712e-03,  9.8085e-03,  2.0356e-03,  1.3290e-03,  1.4211e-03,
          2.6640e-03, -1.1806e-02,  7.6482e-03],
        [ 3.4682e-03,  1.4099e-04, -1.7872e-03,  1.5643e-04,  2.6119e-04,
         -1.4982e-03,  2.3615e-03, -2.2709e-03],
        [-8.6457e-04,  1.1234e-03, -1.5775e-04,  1.1895e-04,  7.3838e-04,
         -7.4755e-05, -1.7815e-04, -5.4435e-04],
        [-3.6757e-02, -1.3120e-02,  6.5022e-03,  1.6594e-02, -3.3306e-02,
          1.1333e-02, -4.2781e-02,  3.2077e-02],
        [ 1.3379e-02,  1.5924e-02, -1.9620e-03, -8.3600e-03,  1.4751e-02,
         -4.1144e-03,  1.1617e-02, -4.5271e-03],
        [ 8.0612e-05, -1.0929e-05,  2.6553e-04, -3.6110e-05,  1.8605e-04,
          4.2814e-05,  3.3812e-05,  4.8731e-05],
        [ 6.3921e-03,  5.6668e-04,  2.1088e-03,  3.4742e-04, -3.3657e-04,
         -2.3382e-03,  3.0410e-03,  4.0042e-03],
        [-9.7265e-04,  4.9079e-03,  1.1320e-02, -9.5570e-04,  1.1667e-02,
          1.1215e-03, -3.8584e-04,  2.1637e-04],
        [-1.3938e-03,  4.0265e-03, -2.1430e-04, -8.4071e-04,  2.5955e-03,
         -3.9183e-04,  5.6840e-04, -4.3173e-04],
        [-1.2416e-02, -1.1854e-04, -5.2533e-03,  4.1083e-03, -8.3504e-03,
          6.8198e-03, -1.7917e-02,  4.0686e-03],
        [ 6.9981e-02, -8.9838e-02,  1.9348e-02,  5.2438e-04, -3.4816e-02,
         -2.1801e-02,  7.6848e-02, -5.9539e-03],
        [-5.4912e-03,  3.6088e-03,  1.2581e-03,  1.0145e-03,  7.3743e-04,
         -5.9012e-04, -2.7291e-03,  2.6674e-03],
        [-7.1193e-05,  2.5951e-05,  8.6898e-05,  5.4335e-05,  1.2512e-05,
         -5.6874e-05, -2.2069e-05,  8.3300e-05],
        [ 4.1633e-05,  3.1247e-03,  2.2508e-03, -7.0708e-04,  4.2988e-03,
         -7.0352e-04,  1.6185e-03, -1.1496e-03],
        [ 2.6306e-03, -1.3139e-03,  2.2292e-03, -6.2588e-08,  1.2524e-03,
         -1.0297e-03,  2.7092e-03, -3.9531e-04],
        [-1.4621e-02,  1.6114e-02, -3.4978e-03, -5.1523e-04,  5.0012e-03,
          4.3346e-04, -7.8154e-03,  1.0260e-03],
        [-2.8085e-03,  3.8237e-03,  1.6403e-05,  2.5877e-04,  2.3616e-03,
         -2.3768e-04, -3.5017e-04, -8.9124e-04],
        [ 1.4700e-07, -3.0413e-07, -3.2618e-07,  8.2309e-08, -3.3249e-07,
          2.0849e-07, -1.3441e-07, -2.1467e-07],
        [-9.3426e-04,  1.5432e-02, -3.8759e-03, -5.0477e-03,  1.3729e-02,
          1.5314e-03,  1.5277e-03, -9.3276e-03],
        [-2.2865e-04,  2.3953e-04, -2.0068e-04,  1.4697e-05,  4.0754e-05,
          5.0486e-05, -6.9160e-05, -1.1669e-04],
        [ 5.4474e-05, -2.5621e-04, -1.3772e-04,  1.1893e-04, -1.8308e-04,
          1.0699e-04, -8.9771e-06, -2.0155e-04],
        [ 7.3852e-03, -4.0786e-03,  6.1868e-03, -3.5998e-04,  3.2642e-03,
         -1.7416e-03,  6.8154e-03, -5.8720e-04],
        [ 1.7983e-02, -1.4462e-02, -4.0828e-03, -2.5162e-03,  8.4397e-04,
         -1.1851e-03,  1.7149e-02, -1.5288e-02],
        [ 1.4572e-04, -1.1557e-04,  2.0723e-05,  1.0334e-05, -5.1577e-05,
          1.8326e-05,  6.4715e-05, -4.4198e-05],
        [-1.5026e-03,  2.4597e-03,  6.8722e-04, -3.7186e-05,  2.3951e-03,
          2.4591e-04, -2.0485e-04, -9.5003e-04],
        [ 1.3454e-02,  3.3048e-02, -2.0808e-02, -1.6191e-02,  3.1315e-02,
          1.6711e-03,  1.0276e-02, -2.8760e-02],
        [-4.6913e-03,  5.7123e-03, -6.1554e-04,  9.2955e-04,  3.9451e-03,
         -5.2398e-04, -1.1246e-03, -3.0719e-03],
        [-7.2650e-03,  1.9440e-03, -8.0884e-03,  2.5838e-03, -4.6857e-03,
          4.1283e-03, -1.0513e-02, -1.8955e-03],
        [-2.0133e-02,  1.3202e-02, -3.7164e-03,  3.2132e-03, -5.2226e-04,
          9.6863e-03, -2.7490e-02,  6.6081e-03],
        [ 2.2267e-02, -1.3211e-02,  6.6517e-03, -6.0123e-04,  5.6274e-03,
         -5.3791e-03,  2.4207e-02, -1.0309e-02],
        [ 2.3739e-03, -5.9306e-04,  7.4229e-03, -1.2230e-03,  4.7000e-03,
          1.0687e-03,  4.3584e-04,  2.1530e-03],
        [ 9.8787e-03, -6.9863e-03, -2.2903e-03, -3.4078e-03, -6.1182e-04,
         -7.7810e-04,  7.8304e-03, -5.0068e-03],
        [ 2.9115e-03,  4.6770e-03,  3.9596e-03, -1.3758e-04, -1.4359e-03,
         -7.4360e-03,  7.7960e-03,  8.7823e-03],
        [-2.9434e-02,  3.6033e-03,  2.8802e-03,  8.5899e-03, -1.1582e-02,
          1.0203e-02, -3.4828e-02,  1.7865e-02],
        [-6.3569e-04,  4.8747e-03, -3.0903e-03, -2.5073e-03,  2.6146e-03,
          1.0216e-03, -5.6938e-04, -2.6112e-03],
        [-5.9006e-04,  3.0918e-04, -1.5176e-03,  2.2082e-04, -8.2479e-04,
         -1.6612e-04, -1.0066e-04, -4.8108e-04],
        [ 7.8264e-05, -7.0343e-04,  1.1100e-04,  2.4706e-04, -2.7218e-04,
          2.5851e-04, -1.6486e-04, -2.0800e-04],
        [-1.8575e-02, -7.4328e-03,  7.6736e-03,  8.2310e-03, -1.5297e-02,
          5.0945e-03, -2.0627e-02,  1.8168e-02],
        [-1.4276e-03,  7.0449e-04, -3.4227e-03,  5.0861e-04, -1.8667e-03,
         -3.3713e-04, -3.8866e-04, -1.0484e-03],
        [-2.3119e-03,  2.8442e-03,  1.2685e-04,  3.6472e-04,  2.0201e-03,
         -1.0332e-04, -5.4763e-04, -9.0877e-04],
        [-1.1505e-03,  1.4900e-03,  2.0260e-03, -7.3088e-05,  8.0398e-04,
          1.0448e-04,  2.1563e-04,  2.1223e-03],
        [-1.1403e-03,  1.3615e-03, -1.6799e-04,  2.2644e-04,  9.2729e-04,
         -1.1317e-04, -2.8388e-04, -7.4437e-04],
        [ 3.5455e-02,  4.9338e-02, -4.2959e-02, -3.0360e-02,  5.5518e-02,
          2.3617e-03,  2.6545e-02, -6.2475e-02],
        [ 6.0064e-06, -1.0561e-05, -7.0832e-06, -2.1496e-07, -3.9617e-06,
          1.8696e-06,  2.4549e-06, -9.7725e-06],
        [-4.5009e-03,  1.7887e-03, -1.1270e-02,  1.8480e-03, -6.4041e-03,
         -9.9028e-04, -1.2185e-03, -3.6148e-03],
        [-1.8749e-04,  1.0637e-02, -3.4243e-03, -3.7198e-03,  1.0091e-02,
          1.8390e-03,  6.5309e-04, -8.0553e-03],
        [-8.9375e-04,  1.0228e-02, -6.4565e-03, -1.7141e-03,  6.3857e-03,
         -3.3657e-04,  1.7476e-03, -8.5642e-03],
        [-4.1550e-02,  2.3789e-02,  9.0651e-03,  9.4869e-03,  2.3290e-03,
         -3.2656e-03, -2.2281e-02,  1.9365e-02],
        [-9.0967e-04, -7.3800e-03, -1.7669e-03,  3.5083e-03, -5.9277e-03,
          1.9367e-03, -3.9161e-03, -1.3283e-03],
        [ 9.6752e-04, -2.3034e-03,  3.5162e-04, -3.1772e-04, -2.0896e-03,
          5.3655e-04, -6.1145e-04,  1.8950e-03],
        [ 1.1148e-02,  4.5227e-03, -4.7485e-03, -4.4647e-03,  7.3264e-03,
         -6.5448e-04,  6.2093e-03, -7.8886e-03],
        [-8.0975e-03,  9.0248e-03,  4.3802e-04,  6.2256e-04,  8.3808e-04,
          1.2666e-03, -8.7694e-03,  6.4426e-03],
        [-1.4275e-03,  4.3879e-04, -3.9902e-03,  7.1072e-04, -2.3578e-03,
         -4.3978e-04, -2.9244e-04, -1.3406e-03],
        [-1.3336e-02,  8.0935e-03,  3.0216e-03,  3.0562e-03,  1.3029e-03,
         -1.3732e-03, -6.8269e-03,  6.2916e-03],
        [-9.0235e-03,  1.4912e-02, -1.7460e-04, -7.8021e-04,  1.0065e-02,
         -3.0048e-04, -5.7503e-04, -3.6881e-03],
        [-3.2654e-02,  1.7160e-02, -6.3298e-03,  7.9969e-03, -7.0069e-03,
          8.3150e-03, -3.3671e-02,  1.1765e-02],
        [-8.8225e-03,  5.4861e-03,  4.8927e-04,  2.0100e-03, -6.5660e-04,
          1.6171e-03, -8.1790e-03,  4.5397e-03],
        [-2.1209e-02,  2.3167e-03, -7.4334e-03,  6.8431e-03, -9.4413e-03,
          8.9310e-03, -2.4561e-02,  2.8796e-03],
        [ 1.3133e-03, -3.8914e-03,  3.5946e-04,  1.8070e-03, -1.5467e-03,
          1.6244e-04,  2.0045e-04, -1.7092e-03],
        [ 5.4960e-03,  1.7083e-02, -1.2783e-02, -8.3095e-03,  1.5394e-02,
          2.0413e-03,  4.3341e-03, -1.7278e-02]], device='cuda:0') 

model.module_1.bias 100 torch.Size([100])
Parameter containing:
tensor([ 0.0507, -0.0795,  0.1024, -0.2392, -0.2993, -0.3550,  0.1375,  0.2640,
         0.0804, -0.3261,  0.0054,  0.0313,  0.0626, -0.1086, -0.3040, -0.0467,
        -0.0274,  0.1796,  0.1367, -0.1497, -0.1111,  0.4596, -0.1198,  0.1464,
         0.0925, -0.0429, -0.0614, -0.1260,  0.1783, -0.1661,  0.4380, -0.7566,
         0.1162,  0.0519, -0.5214,  0.1915, -0.1497, -1.1051, -0.0098, -0.1299,
         0.0486,  0.3406, -0.3053,  0.2106,  0.1267, -0.2600, -0.1756, -0.0522,
        -0.4350,  0.1284, -0.4069,  0.0596, -0.1950,  0.0242, -0.3824,  0.1277,
        -0.1081, -0.1321,  0.2094,  0.0052,  0.0774, -0.4402, -0.9214, -0.0653,
         0.0294,  0.5270, -0.1694, -0.0170,  0.2982, -0.2213, -0.4580, -0.4412,
         0.0038,  0.2514,  0.4208, -0.2520,  0.0186, -0.0054, -0.1977, -0.2304,
        -0.3964, -0.3915,  0.6539,  0.0332, -0.1289,  0.1571,  0.5057,  0.1426,
        -0.2152, -0.0437,  0.0763, -0.0549,  0.0467,  0.0534, -0.0104, -0.1254,
        -0.3748, -0.2933, -0.2200,  0.3729], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 3.5982e-04,  3.0128e-05,  2.2285e-03,  1.6960e-02, -2.7169e-02,
         5.3119e-04, -8.0609e-03,  1.3712e-03,  6.5883e-04,  4.5882e-04,
        -9.3296e-04,  4.3549e-05,  1.8199e-03, -3.7654e-03,  2.1723e-04,
        -2.0701e-06, -9.4879e-05,  1.0308e-03,  2.8995e-02,  1.0495e-03,
        -5.2832e-05,  4.7109e-02,  3.0408e-04,  2.6844e-04,  5.9136e-03,
        -6.9844e-05,  4.0244e-07,  7.1760e-05,  2.9055e-02,  8.4120e-04,
         2.4293e-02,  9.7124e-04,  1.4350e-03,  7.4211e-04, -1.5931e-03,
         1.0896e-03,  3.1675e-07,  1.8104e-03, -7.4878e-02, -5.1566e-07,
         4.7946e-03,  5.9958e-03,  1.2684e-04, -4.0126e-02,  3.1053e-02,
         8.4332e-05,  1.0170e-02,  3.8653e-03,  9.7122e-04, -2.0570e-03,
        -5.2167e-02, -5.6631e-03, -1.5604e-04,  1.6005e-03,  9.1267e-04,
        -2.1579e-03, -8.4214e-05,  4.6792e-07,  1.7046e-02, -2.2813e-05,
         6.8956e-06,  2.7497e-03,  4.0942e-03,  2.1984e-04,  4.6924e-04,
         5.8097e-02,  6.1245e-04,  2.8241e-03,  8.0071e-03,  6.1809e-03,
         2.0096e-03,  1.9636e-03, -4.1403e-04, -1.6406e-02,  6.3400e-03,
        -3.4904e-04, -3.3468e-04, -2.3908e-02, -8.7085e-04, -1.8627e-04,
        -1.3670e-03,  1.2920e-04,  1.0797e-01, -1.4568e-06, -3.0011e-03,
         1.4090e-02,  1.3276e-02, -4.0711e-02, -2.9218e-03, -9.9894e-04,
         2.2253e-02,  2.3000e-03, -1.0695e-03, -1.3647e-02,  1.7974e-03,
        -5.0305e-03, -2.1329e-03, -6.9283e-03, -1.3707e-04,  3.0656e-02],
       device='cuda:0') 

model.module_3.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[ 0.2963,  0.2320, -0.0746,  ..., -0.1817, -0.2102, -0.0524],
        [ 0.0219, -0.2115, -0.3112,  ..., -0.0086, -0.0693,  0.0499],
        [-0.1810,  0.1554,  0.0526,  ...,  0.0344,  0.0223, -0.0952],
        ...,
        [ 0.1656, -0.1313, -0.0184,  ..., -0.1725,  0.1321, -0.1085],
        [ 0.4570,  0.1589, -0.0661,  ..., -0.1374, -0.0209,  0.2065],
        [-0.0942, -0.1643, -0.2455,  ..., -0.1908, -0.2191,  0.0675]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 1.5111e-03,  4.7702e-07,  8.1329e-05,  ...,  1.1656e-04,
          1.3754e-03,  8.2546e-04],
        [-2.0583e-07,  1.3872e-08, -3.4354e-09,  ..., -5.2479e-06,
         -3.0294e-05, -3.6827e-05],
        [-2.5573e-07, -6.3080e-10, -9.9894e-08,  ...,  1.5166e-05,
          3.2161e-05, -2.8121e-07],
        ...,
        [ 3.4894e-07, -4.3580e-10,  3.9928e-08,  ..., -6.7082e-07,
          8.7315e-08,  2.7764e-07],
        [ 2.0456e-03,  2.3486e-07,  5.9161e-05,  ...,  1.6423e-04,
          1.7851e-03,  1.0398e-03],
        [-9.3570e-07, -5.3941e-07,  1.6412e-07,  ...,  5.2748e-05,
         -2.7554e-05,  1.7138e-03]], device='cuda:0') 

model.module_3.bias 100 torch.Size([100])
Parameter containing:
tensor([ 0.0749, -0.0342,  0.0331, -0.1709,  0.0368,  0.1420,  0.0923, -0.2204,
        -0.0442, -0.0264, -0.0081, -0.0007, -0.0164, -0.0481, -0.1398, -0.0841,
         0.0572, -0.2154, -0.0379, -0.0471, -0.0446, -0.1393, -0.0462,  0.0022,
         0.1604, -0.0906,  0.0076,  0.0626, -0.0942, -0.0832,  0.2874, -0.0036,
        -0.0324, -0.0400,  0.0373, -0.0040, -0.1118, -0.4405, -0.0446, -0.3155,
        -0.0091, -0.1684, -0.0460,  0.2055,  0.0043, -0.0830, -0.3368, -0.1197,
         0.0960,  0.0132, -0.0678, -0.1190, -0.0390, -0.1943, -0.0247, -0.0575,
        -0.2930, -0.1665,  0.1840, -0.0158,  0.1337, -0.0503, -0.4775,  0.2138,
        -0.1811, -0.0751, -0.0225, -0.1515, -0.0248, -0.2809, -0.0555,  0.0898,
        -0.0673, -0.0256, -0.0519, -0.0837, -0.1075, -0.0808, -0.1293, -0.1293,
        -0.0677, -0.0642, -0.2479, -0.0390, -0.0796,  0.0049, -0.0230, -0.0729,
        -0.0595, -0.0756, -0.1712,  0.2637, -0.0363, -0.0199, -0.3160, -0.0735,
         0.1375, -0.0413, -0.0024,  0.1698], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 7.6956e-04, -4.0891e-04,  1.8277e-06, -9.4173e-07, -2.8217e-04,
         2.8851e-02,  2.4638e-06,  2.2640e-04,  6.2744e-07, -4.4812e-05,
         7.9750e-07, -5.3626e-04,  4.4289e-03, -2.6242e-03, -1.5014e-04,
         1.8815e-04, -1.9894e-04, -8.7096e-07,  6.4132e-07,  2.1970e-03,
         9.2523e-07, -2.1872e-03, -6.4543e-08,  1.1250e-06,  2.5062e-02,
         9.8304e-07, -7.8646e-04, -1.7225e-03,  9.6352e-04,  2.6254e-07,
         3.6985e-03,  1.7453e-06, -9.8167e-08, -1.5308e-06, -1.5568e-06,
         2.7238e-02, -3.9119e-04, -5.4480e-05, -2.5099e-06, -1.6705e-05,
        -2.6005e-04,  2.1353e-03, -6.1136e-04,  4.2274e-02, -5.8304e-02,
        -4.6474e-04, -6.8555e-05, -3.2790e-06,  1.9569e-06, -1.0120e-06,
        -2.0831e-06,  9.6721e-07,  8.8597e-07, -2.6765e-03,  1.4898e-06,
        -8.5092e-07, -5.4650e-04, -1.5854e-03,  5.8302e-02,  2.9808e-06,
        -1.1846e-03,  6.1491e-06,  6.0438e-03,  3.6398e-02, -3.3337e-05,
        -4.9347e-07, -4.4758e-05,  2.3692e-03,  2.5687e-07,  5.1805e-05,
        -9.9233e-07,  7.0559e-07, -2.4164e-05,  2.2861e-06,  1.3084e-06,
         1.0041e-07, -3.1497e-03, -2.6945e-06, -1.0161e-04,  2.1672e-04,
        -3.7210e-04, -6.0996e-07, -1.4303e-08,  2.4586e-06, -1.5206e-05,
        -1.9196e-03,  1.8169e-06, -8.1552e-04, -3.5348e-04, -7.9615e-06,
         5.2767e-04,  1.5584e-02, -6.3619e-07,  3.4643e-06,  8.1990e-05,
        -2.0433e-04,  4.8933e-03,  1.5889e-06,  9.5981e-04,  2.0805e-02],
       device='cuda:0') 

model.module_5.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[-5.2402e-02, -2.1727e-02, -1.2420e-01,  ...,  2.3523e-02,
          6.2427e-03,  2.5905e-01],
        [-1.7015e-01, -1.8807e-01, -1.7533e-01,  ..., -7.0038e-02,
          3.9301e-02, -2.5974e-01],
        [ 1.9976e-01, -9.5042e-02, -3.7960e-01,  ...,  2.1351e-01,
          3.2265e-01,  5.3123e-02],
        ...,
        [ 2.4340e-01,  4.4351e-02, -3.0556e-01,  ...,  3.1716e-02,
          1.9910e-01,  2.0061e-01],
        [ 1.7704e-02,  5.1334e-02, -3.7870e-03,  ...,  1.0167e-01,
          4.4268e-02,  6.9383e-02],
        [ 1.3520e-01, -2.6205e-02,  5.8768e-05,  ..., -1.5086e-01,
         -1.6910e-02,  2.3231e-02]], device='cuda:0', requires_grad=True) 
grad:  tensor([[-1.1172e-03,  4.8565e-05, -4.8177e-06,  ..., -2.1058e-06,
         -2.1595e-03,  1.2874e-02],
        [ 1.8862e-06,  5.7397e-06,  6.0268e-06,  ...,  6.7539e-06,
         -1.1483e-05, -4.0960e-03],
        [ 3.1976e-03,  1.7206e-05, -2.7564e-06,  ..., -1.9131e-06,
          5.9194e-03,  8.8549e-03],
        ...,
        [ 5.4066e-04,  1.5271e-05, -3.0365e-06,  ..., -1.8751e-06,
          9.5267e-04,  3.6008e-03],
        [-5.6819e-03, -4.3891e-05, -1.2107e-03,  ...,  1.9745e-05,
         -1.0828e-02, -8.4061e-03],
        [-6.1321e-07,  1.2495e-07, -8.4216e-06,  ...,  2.0274e-07,
         -4.9659e-06,  2.6398e-07]], device='cuda:0') 

model.module_5.bias 16 torch.Size([16])
Parameter containing:
tensor([ 0.1522,  0.2954, -0.0021, -0.1217,  0.2137, -0.2382, -0.2535, -0.0196,
        -0.0605,  0.1335, -0.3787, -0.0684,  0.0549, -0.0138,  0.3414, -0.1310],
       device='cuda:0', requires_grad=True) 
grad:  tensor([ 8.9105e-02, -1.3084e-01,  3.2992e-02,  4.0758e-02,  1.3745e-01,
        -7.7912e-05,  1.2909e-03,  3.7196e-02, -4.3936e-03,  4.4368e-02,
        -1.0204e-04,  1.8199e-04,  3.7554e-02,  2.2604e-02, -1.6554e-02,
        -4.7013e-04], device='cuda:0') 

model.module_7.bias 8 torch.Size([8])
Parameter containing:
tensor([-0.1756, -0.1431, -0.2561,  0.1951,  0.2260, -0.1610,  0.1124, -0.2017],
       device='cuda:0', requires_grad=True) 
grad:  tensor([ 0.0456, -0.1087, -0.2744,  0.0008,  0.2801, -0.1438, -0.4302, -0.0796],
       device='cuda:0') 

model.module_7.lin.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[ 0.3176,  0.1720,  0.1660,  0.1443,  0.3619,  0.3415, -0.4642,  0.3115,
          0.5882, -0.1088, -0.4231,  0.2817,  0.2498,  0.3920,  0.1769,  0.1818],
        [-0.2968, -0.1261, -0.2268, -0.0771,  0.2960, -0.2209,  0.4389, -0.4284,
          0.3623, -0.1715, -0.0816, -0.1354,  0.2953, -0.5495,  0.2263, -0.3058],
        [ 0.0028,  0.0139, -0.0204, -0.5968,  0.3972,  0.3748, -0.4856, -0.0500,
         -0.4422, -0.2440,  0.0931,  0.4380, -0.3781,  0.4209,  0.3843,  0.1104],
        [ 0.2302,  0.0073,  0.1307,  0.5029, -0.3324,  0.2358, -0.0422, -0.5405,
          0.2378, -0.4252, -0.1044, -0.2355,  0.1292,  0.0902, -0.0876,  0.0272],
        [ 0.0910, -0.5491,  0.1243, -0.2579, -0.3369, -0.0124, -0.2952,  0.1473,
         -0.2887, -0.2864, -0.0673,  0.0795, -0.1974,  0.2610, -0.4181, -0.1412],
        [ 0.4161,  0.3646, -0.5239, -0.1675,  0.0039, -0.1402, -0.5118, -0.2271,
         -0.0595,  0.4333, -0.5966, -0.1806,  0.2315,  0.0690,  0.0608,  0.2082],
        [-0.6889,  0.3433, -0.5673, -0.2883, -0.2870,  0.1264, -0.4248, -0.3043,
          0.2825, -0.3870, -0.4694,  0.0585, -0.4168, -0.3195, -0.1030, -0.0920],
        [-0.0106, -0.1042,  0.0191, -0.2058,  0.2447,  0.4359, -0.0969,  0.1297,
         -0.4896, -0.3332,  0.1780, -0.0608, -0.4486,  0.1613,  0.3274, -0.4165]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-2.3374e-02,  3.7876e-02, -2.3682e-02, -6.2526e-03,  5.6213e-02,
         -6.4375e-05, -2.1376e-02, -8.6873e-03, -4.3947e-03, -4.1830e-03,
         -2.8954e-04, -9.1236e-06, -2.2949e-02,  5.5809e-04,  6.7616e-02,
         -1.0139e-04],
        [-2.5363e-02,  5.4171e-03, -1.8990e-02, -5.0836e-02, -5.3958e-02,
         -1.9555e-04, -1.8849e-02, -3.2052e-02, -3.8140e-03, -6.7185e-03,
         -1.2812e-03, -5.0860e-06, -2.2023e-02, -1.5095e-02, -8.3615e-02,
         -3.0617e-04],
        [-5.1406e-02, -9.0170e-03, -2.6145e-02, -2.5974e-02, -3.2643e-02,
         -1.4521e-04, -2.4035e-02, -2.2553e-02, -2.6735e-03, -1.6754e-02,
         -8.5932e-04,  4.4443e-06, -3.6137e-02, -8.7107e-03, -9.1197e-02,
         -2.1503e-04],
        [-2.0285e-03, -1.1422e-02, -7.3272e-03, -2.5495e-04, -2.2779e-02,
         -4.0666e-06, -2.7400e-03, -1.7136e-02, -3.2740e-03,  2.2650e-03,
         -1.3860e-04, -7.6942e-06, -5.4075e-03, -1.3319e-02, -3.2677e-02,
          1.6306e-05],
        [ 7.0489e-02, -3.7901e-03,  4.5277e-02,  5.4026e-02,  4.7251e-02,
          2.4944e-04,  4.2392e-02,  3.6885e-02,  6.6855e-03,  2.0385e-02,
          1.4830e-03,  1.9583e-06,  5.5230e-02,  1.2353e-02,  1.1510e-01,
          4.0418e-04],
        [-2.8020e-02, -1.1528e-02, -1.8077e-02, -2.2430e-02, -4.0557e-02,
         -7.2069e-05, -1.4793e-02, -1.5537e-02, -2.9842e-03, -7.3978e-03,
         -4.3932e-04, -7.4186e-06, -2.1830e-02, -7.7747e-03, -7.6942e-02,
         -1.2727e-04],
        [-3.1811e-02, -1.0405e-01, -5.8343e-03,  3.0662e-02, -1.1394e-01,
          1.5868e-04,  3.9873e-03, -6.8442e-03, -6.5141e-04, -1.1124e-02,
          8.3363e-04,  2.7111e-06, -1.6528e-02, -1.3700e-02, -2.1171e-01,
          2.2455e-04],
        [-1.1618e-02,  1.9775e-03, -8.6210e-04, -2.2148e-03,  3.5761e-03,
         -4.5898e-05, -2.3919e-03,  2.6473e-03,  1.3815e-03, -5.7601e-03,
         -2.3030e-04,  1.0117e-05, -5.2985e-03,  3.2642e-03, -8.7200e-03,
         -5.3122e-05]], device='cuda:0') 

model.module_8.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[-2.5027e-01, -2.2244e-01,  2.7387e-01,  4.5581e-02,  2.6196e-04,
          4.8676e-01,  2.2105e-01,  1.5126e-01],
        [-3.6114e-01,  6.5294e-02, -2.4445e-01, -2.6442e-02,  4.3849e-01,
         -4.5613e-02, -1.0656e-01, -3.5633e-01],
        [-5.1653e-01,  1.7334e-01,  5.3249e-02,  1.6663e-01,  7.6345e-02,
          5.2266e-02, -1.2230e-01,  4.5464e-01],
        [-2.5607e-01,  1.6947e-01, -1.6687e-01,  2.1817e-01,  3.6082e-01,
          2.3934e-01,  5.7703e-01,  1.3105e-01],
        [-7.5661e-02,  1.9617e-01,  3.0164e-01, -1.9767e-01, -3.0264e-02,
         -3.0252e-01, -2.6625e-01,  2.2175e-01],
        [-2.6506e-01,  1.9359e-01,  2.5792e-01, -1.3990e-01, -2.9313e-01,
         -2.1005e-01, -4.3678e-01,  1.3880e-01],
        [-6.2586e-02,  2.4490e-01,  2.7661e-02, -1.5780e-02, -3.0657e-01,
         -2.7550e-01, -5.2897e-04,  1.2713e-01],
        [-1.8016e-02, -2.6903e-01, -1.1500e-01, -1.9221e-01,  4.3428e-01,
         -4.0539e-01, -1.0517e-01,  4.3953e-01],
        [ 1.0093e-01, -2.1516e-01, -2.1187e-01,  4.4658e-02, -9.7638e-02,
         -2.0051e-01, -3.2257e-02, -3.2791e-01],
        [-4.9739e-01,  4.8973e-01,  8.0535e-03,  2.2428e-01,  2.6935e-01,
         -7.0288e-02,  7.2907e-01, -6.1037e-02],
        [ 2.6994e-01, -4.0826e-01, -1.9293e-01, -2.2828e-01,  7.8596e-02,
         -2.5452e-01,  2.0529e-01,  3.5336e-01],
        [-6.2678e-01, -7.9225e-02, -2.3972e-01,  1.5739e-01, -1.1262e-01,
          1.6582e-01,  4.8373e-01,  1.0183e-02],
        [-2.7412e-01,  3.7159e-03,  1.3228e-01,  4.2679e-01,  4.7574e-02,
          2.0360e-01,  5.0507e-02,  7.4963e-02],
        [-1.9597e-01, -6.0309e-02, -4.3893e-02, -9.1484e-02, -6.7427e-02,
          5.2847e-02,  4.2202e-02,  1.1144e-02],
        [ 4.2796e-01,  1.7468e-01,  1.5371e-01, -1.3148e-01,  2.0546e-01,
          5.6439e-01, -1.8864e-01, -2.4075e-01],
        [ 2.8418e-01,  3.4353e-01,  9.4179e-02, -2.2614e-01, -2.5385e-01,
          2.7006e-01, -3.8203e-01,  1.1258e-01],
        [ 2.1494e-01, -1.4674e-01, -8.8487e-01, -1.5952e-01,  5.8382e-01,
          4.0256e-03, -3.3669e-02, -4.8629e-01],
        [-1.8474e-01,  4.2779e-03, -2.8220e-01, -2.1355e-01,  4.0759e-01,
         -4.2788e-02, -2.3137e-01, -1.0877e-01],
        [-3.6003e-01,  8.6240e-02, -2.1125e-01, -1.0684e-01, -2.4354e-01,
          4.9390e-01,  2.7830e-01, -3.8914e-01],
        [-1.2388e-01, -1.4784e-01, -3.1489e-01, -3.2236e-01,  8.2466e-02,
          5.4442e-02, -1.7926e-01,  3.0727e-01],
        [-1.6163e-01, -2.0925e-01, -8.2010e-02,  2.1957e-01, -3.7786e-02,
          8.2054e-02,  1.0666e-01,  3.6839e-01],
        [-3.8105e-01, -8.3680e-02,  1.6602e-01, -1.0869e-01, -4.0137e-02,
          2.2089e-01,  9.1364e-02, -2.8148e-01],
        [-3.7889e-01, -7.3190e-02, -3.8142e-03, -6.5286e-02,  2.5164e-02,
          1.9352e-01,  1.7587e-01, -4.5206e-03],
        [ 1.1733e-01, -5.4150e-03,  2.0211e-02, -2.0468e-01,  1.9058e-01,
          8.8911e-02,  4.3936e-01, -1.0217e-01],
        [ 5.7804e-02, -2.5466e-01,  2.7129e-01, -1.1093e-01,  2.4073e-01,
         -1.6281e-01, -3.2114e-01,  2.5845e-02],
        [-3.4455e-01, -1.8333e-01, -3.4016e-01, -9.8281e-03,  3.5230e-01,
          2.0604e-02,  1.4625e-01,  7.0631e-02],
        [ 1.2717e-01, -1.9733e-02,  8.5170e-02,  3.3257e-01, -1.6615e-01,
          2.6512e-01,  4.0665e-01, -4.5503e-01],
        [-5.4154e-01, -1.6951e-01,  1.1494e-01,  2.5711e-01, -6.8115e-02,
          4.4845e-01,  1.3198e-01, -1.3793e-01],
        [-1.3230e-01,  2.9725e-01,  1.4092e-01,  1.3289e-01, -2.9570e-01,
          8.9114e-02, -2.3028e-01, -4.4915e-01],
        [ 1.4096e-02,  5.0207e-02, -5.7674e-01, -1.5283e-01,  6.5809e-01,
          4.1882e-01, -1.8701e-01, -3.3492e-01],
        [ 2.0225e-01,  1.4483e-01, -5.8282e-02, -1.3678e-02,  1.7498e-01,
         -4.7878e-01, -3.0636e-01,  1.6859e-01],
        [-1.3420e-03,  1.6491e-01, -2.4374e-01,  6.9613e-02,  2.2149e-02,
          4.4232e-02, -7.1081e-02, -7.0212e-02],
        [-2.9316e-01, -3.2579e-01, -1.7983e-01,  2.9454e-01,  2.5685e-01,
         -3.2117e-01,  2.8288e-01, -3.0223e-01],
        [-3.3819e-01,  1.9686e-01, -9.5592e-03,  2.9057e-02,  3.3853e-01,
          8.3741e-02,  9.2886e-01, -1.0318e-01],
        [-2.0345e-01, -2.4639e-01,  3.5495e-01, -3.6078e-01,  5.5300e-01,
          9.8265e-02,  3.0277e-01, -3.0203e-01],
        [-4.2666e-01,  2.8387e-01, -2.6807e-01, -1.1141e-01,  3.3054e-01,
          1.7201e-01, -1.4394e-01, -1.0826e-01],
        [-2.3826e-01,  1.5805e-01, -3.3022e-01,  3.1810e-01,  3.9185e-01,
         -1.7076e-01, -9.7321e-02,  1.6966e-01],
        [-3.4135e-01, -7.0022e-02, -1.6155e-01, -3.8435e-02, -2.2682e-01,
          4.1738e-01,  8.9516e-02, -1.0487e-01],
        [-5.5332e-01,  2.5392e-01,  2.2180e-01,  1.8363e-01,  3.0444e-01,
         -2.1743e-01, -1.0356e-01,  7.0952e-02],
        [-2.2270e-01, -9.2572e-02,  1.0306e-01,  1.5867e-01,  1.2142e-01,
          9.1039e-02,  1.4536e-01,  2.5902e-01],
        [-9.8696e-02, -1.8319e-01,  1.5586e-01,  3.5263e-01, -1.7767e-01,
         -2.2840e-01,  9.6326e-02, -3.5701e-01],
        [-1.9643e-01,  2.4387e-01, -8.8556e-02,  4.2465e-01,  6.8429e-03,
         -1.3890e-02, -3.7524e-02, -1.7891e-01],
        [-4.9877e-03, -2.8856e-01, -4.3429e-01, -1.8765e-01,  2.5747e-01,
          4.2409e-02,  1.7792e-02, -4.4222e-01],
        [-3.0659e-01,  2.0010e-01,  2.5782e-02, -4.1069e-01,  3.5640e-01,
         -1.9898e-01, -3.1746e-01, -3.2831e-01],
        [-1.2610e-01, -1.0064e-01,  1.1804e-01, -3.3389e-01, -2.3439e-01,
          9.3344e-02, -7.9630e-02,  8.9757e-02],
        [-1.5417e-01,  7.8539e-02, -1.1269e-01, -1.7504e-01, -3.5052e-01,
         -2.5648e-01,  5.6256e-02,  2.2674e-01],
        [ 1.5092e-01, -5.6922e-03, -9.2972e-02, -6.4402e-03,  1.3766e-01,
         -1.0307e-01,  4.7016e-01,  3.8050e-01],
        [-3.0349e-02,  4.7801e-01, -7.6375e-03, -2.0483e-01,  1.1626e-01,
          1.8288e-01,  5.4943e-02, -2.9003e-01],
        [-3.5382e-01,  1.9292e-02, -3.1184e-01,  6.3145e-02, -9.6535e-02,
          3.4643e-01, -1.5228e-01, -5.6211e-02],
        [ 2.1341e-01,  3.5160e-01, -4.5972e-01, -8.0195e-02, -2.2142e-02,
         -1.0526e-01, -4.2898e-02, -2.7987e-01],
        [-1.9723e-01,  3.2269e-01, -1.6524e-01,  1.1643e-01, -1.6127e-02,
         -8.1791e-02,  8.7875e-01, -5.4614e-01],
        [-1.6793e-01, -2.3044e-01, -2.0491e-01, -2.5501e-02, -2.7053e-01,
          2.2309e-01, -4.6041e-02, -4.8992e-02],
        [ 5.0232e-02,  2.7781e-02,  6.0400e-02, -4.7902e-02,  9.1807e-01,
          2.3561e-01,  8.3088e-02, -2.4832e-01],
        [-2.4346e-01,  3.9222e-01, -1.2430e-01,  1.2220e-01,  2.6545e-01,
          4.5917e-02,  8.0430e-01, -3.4373e-01],
        [-1.1763e-02,  2.3519e-01, -2.2897e-01, -3.5131e-02, -1.4669e-01,
          6.3659e-02,  2.4340e-01, -2.2612e-01],
        [ 3.1362e-01,  1.0766e-01,  1.5774e-01, -1.5429e-01,  1.8602e-01,
          4.4852e-01,  1.0878e-01,  6.1516e-02],
        [-4.0372e-01,  4.4857e-01, -7.5377e-02, -2.5926e-01,  1.0780e-01,
          3.0868e-01,  4.9266e-01,  2.6787e-01],
        [-1.9630e-01,  2.6670e-01,  2.1428e-01,  2.3001e-01,  3.8131e-01,
         -1.5158e-02, -8.1986e-02,  3.7957e-02],
        [-5.6473e-01,  1.5878e-01, -5.0323e-01, -3.1627e-01, -1.2288e-01,
         -2.0052e-01,  8.8213e-01, -1.2911e-01],
        [-1.0540e-01,  3.3892e-01,  2.0394e-01,  3.6133e-01, -2.8603e-01,
         -2.0501e-01, -1.2284e-01,  2.0999e-01],
        [-3.5973e-01, -1.1532e-02, -7.8305e-02,  1.1390e-01,  2.9710e-01,
         -1.4112e-01, -1.5042e-02, -7.5862e-02],
        [-1.5786e-01,  2.7645e-01, -3.4270e-01, -2.3593e-01, -1.2409e-01,
          1.7647e-01,  1.4455e-01, -2.1203e-02],
        [ 8.9967e-02, -2.4809e-01,  5.3477e-02, -1.0470e-01, -8.4220e-02,
         -1.6069e-01,  5.5982e-01, -3.7733e-01],
        [-5.7109e-01, -1.3888e-01, -4.2126e-01,  1.5144e-01,  1.1103e-02,
          3.2692e-01,  4.4818e-01, -2.5632e-02],
        [-2.0654e-01,  3.1911e-01, -1.1127e-01,  9.1419e-02,  1.6429e-01,
         -1.6446e-01,  7.1184e-01, -4.0196e-01],
        [-3.2048e-01,  1.6475e-01, -1.2173e-01, -3.0731e-01,  5.3588e-02,
         -4.7356e-02,  4.0470e-01, -1.0975e-01],
        [-4.4431e-01,  1.0434e-01,  3.1894e-02, -4.3124e-03,  1.5893e-01,
          1.3533e-01, -2.6179e-01,  1.2503e-01],
        [-2.0301e-01,  1.3465e-01, -1.4033e-01,  4.0295e-01,  2.1833e-01,
          2.3914e-01, -2.1750e-02,  2.5875e-01],
        [ 5.3013e-02, -8.7831e-03, -4.7732e-02,  5.9806e-02,  6.2410e-02,
         -9.4736e-02,  1.2630e-01,  9.0003e-02],
        [-1.6052e-01, -2.3728e-01,  1.5585e-01,  2.7472e-01,  1.3727e-02,
          1.7628e-01,  2.7234e-01, -5.0093e-03],
        [-3.6974e-01,  2.3611e-01,  2.8595e-01, -1.1117e-01,  1.5762e-01,
         -8.3569e-02,  2.4767e-02, -1.6259e-01],
        [-2.9329e-01,  4.2771e-02, -4.4930e-01,  3.6091e-01,  6.6038e-01,
         -5.0765e-01, -1.1578e-01, -4.3112e-01],
        [-4.9997e-01,  2.7267e-01, -5.6475e-02, -2.0548e-01,  2.4113e-01,
          2.2420e-02,  8.0339e-01, -2.4865e-01],
        [-4.5017e-01,  5.4665e-02, -1.5253e-01,  2.1790e-01,  1.1786e-01,
         -1.8852e-01,  3.7614e-01,  2.4179e-01],
        [-2.4841e-01, -1.9108e-01,  3.4086e-01,  2.3199e-01,  4.9473e-02,
          3.1702e-01,  1.9789e-01, -6.5211e-02],
        [-1.1907e-01, -3.6048e-02,  2.1526e-01,  1.2486e-01,  1.0880e-01,
         -1.0587e-01,  1.9365e-01,  6.2582e-03],
        [-2.4634e-01,  3.9144e-01,  1.3177e-01,  2.9080e-01,  1.8653e-02,
         -3.0258e-01,  6.1637e-01,  4.2402e-03],
        [ 2.6052e-01,  2.3772e-01,  1.0926e-02,  6.5461e-01, -2.4933e-02,
         -7.2347e-02,  2.1016e-01,  2.3648e-01],
        [ 1.5182e-01,  3.5926e-01,  4.4373e-02,  8.3277e-03, -3.0462e-01,
          3.2683e-01, -8.6264e-02,  2.5806e-01],
        [-1.6434e-01,  3.0343e-01, -1.3067e-01, -1.3932e-01, -8.8929e-02,
          1.9509e-01,  1.6308e-01, -2.8573e-01],
        [ 1.1577e-01,  3.7911e-02,  3.4379e-01,  3.2658e-01,  3.0412e-01,
          1.2250e-01,  3.7125e-01, -1.5105e-01],
        [-3.1186e-01, -8.9435e-02,  4.0802e-02,  9.8838e-02, -1.5075e-02,
          1.8790e-01,  9.1853e-02,  4.5590e-02],
        [-3.7084e-01, -5.9187e-02, -1.1452e-01, -1.4458e-01, -1.1451e-02,
          1.5806e-01,  9.4121e-01, -4.4030e-01],
        [-4.5247e-01, -3.3136e-03, -4.7185e-02, -2.0820e-01, -9.3789e-02,
         -9.6899e-02,  7.2671e-02, -1.9678e-01],
        [-1.8912e-01, -8.6595e-02, -7.4624e-01,  5.0338e-01,  9.8422e-01,
         -3.3093e-01, -4.0181e-02, -1.6316e-02],
        [-4.1354e-01,  1.1772e-01, -3.2925e-02, -7.1390e-02,  1.3911e-01,
          2.2822e-01, -6.7585e-02,  2.8832e-01],
        [-3.5407e-01,  3.4876e-01,  8.2022e-02,  3.7102e-02,  2.5493e-01,
          5.1495e-01,  8.2766e-01,  4.0441e-02],
        [-2.1701e-01,  8.8223e-02, -4.7342e-03, -1.9255e-01, -1.0610e-02,
          2.8702e-02,  1.5921e-01, -7.4298e-02],
        [-3.6628e-01,  1.6927e-01, -7.4934e-02, -3.4738e-01, -1.2767e-01,
          4.8301e-01,  5.6369e-02, -1.5285e-01],
        [-5.5141e-02,  4.9137e-01,  1.4526e-01,  4.0345e-01, -8.2544e-02,
         -3.0561e-02, -1.9662e-01,  1.4748e-01],
        [ 5.2879e-02, -3.3157e-02, -1.0749e-01,  1.5619e-01, -1.8252e-01,
         -2.0569e-01, -2.9317e-01, -1.6760e-01],
        [-1.4197e-01, -7.4093e-03, -2.2128e-01, -2.9989e-02, -6.1801e-02,
          4.9354e-02,  4.6619e-02,  1.4067e-02],
        [-1.1872e-01, -8.4860e-02,  1.0182e-01, -1.4645e-02, -1.4875e-01,
         -1.2503e-01,  5.0453e-02, -2.5771e-01],
        [-5.8326e-01, -2.7215e-02, -7.1883e-01, -1.6816e-02,  5.4741e-01,
         -2.6575e-01, -1.9970e-01, -1.1302e-01],
        [ 1.7118e-01,  3.4566e-01,  3.3509e-01, -2.1779e-01,  2.7081e-01,
         -1.7707e-01,  1.6854e-01, -3.2828e-01],
        [-7.7203e-02,  2.4375e-01, -2.0425e-01,  3.5226e-01, -1.1228e-01,
          2.3566e-01, -1.7789e-02, -1.6027e-02],
        [-3.3729e-01, -8.8213e-03,  3.2184e-01,  5.3778e-02, -2.4006e-01,
          3.1968e-01, -1.4798e-01, -8.0408e-02],
        [-3.1085e-01, -1.4987e-01, -2.6343e-01, -2.5729e-02,  1.1761e-01,
         -1.8058e-01, -2.5332e-01,  5.9241e-02],
        [ 1.8687e-01, -2.0716e-01,  1.8276e-02,  4.3131e-01,  8.2947e-01,
          2.7148e-01,  1.2680e-01,  1.2921e-01],
        [-4.2025e-01, -2.4384e-01, -3.5223e-01,  3.6638e-01,  5.6375e-01,
          2.0390e-01, -4.5437e-02, -3.5828e-01]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[ 1.1316e-06,  3.5153e-07,  3.3009e-07, -1.8430e-07, -1.2162e-06,
         -3.0729e-07, -1.5821e-06,  4.2506e-07],
        [ 7.3385e-03, -3.0359e-03, -2.5628e-03,  6.8328e-03, -1.2024e-02,
         -3.2547e-03, -1.0947e-02, -3.5166e-03],
        [ 1.9257e-03,  1.5300e-03,  1.6327e-03, -3.4202e-04, -3.2388e-03,
         -4.3136e-04, -1.7706e-03,  1.5434e-03],
        [ 4.8654e-05,  1.3278e-04,  1.5671e-04, -1.5144e-04, -7.1714e-05,
          6.9922e-05, -3.3726e-06,  1.4124e-04],
        [-5.1829e-03, -6.2865e-03,  5.9991e-03, -1.9701e-03,  5.5407e-03,
          7.0383e-03,  1.7143e-02, -3.0363e-03],
        [ 6.9935e-03, -1.8388e-03,  1.4737e-02, -1.3967e-03, -1.6473e-02,
          7.1932e-03,  7.1462e-03,  1.7327e-03],
        [ 1.6951e-02,  6.5643e-03,  2.5415e-03,  2.9804e-04, -1.9849e-02,
         -4.2438e-03, -2.2650e-02,  5.6388e-03],
        [ 8.7466e-03, -8.5560e-04, -2.7814e-03,  4.5620e-04, -5.6281e-03,
         -4.0267e-03, -1.6642e-02, -2.4747e-04],
        [-5.4031e-03,  2.7904e-04,  3.2915e-03, -4.6725e-04,  3.4054e-03,
          2.0815e-03,  1.1822e-02,  1.6356e-03],
        [ 2.4693e-04,  9.8654e-04,  1.1808e-03, -1.4391e-03,  2.3725e-05,
          7.8860e-04, -1.9013e-04,  1.1615e-03],
        [ 4.8310e-03, -5.2635e-03,  7.0953e-04, -2.6096e-03,  9.2844e-04,
         -2.3132e-03, -5.1925e-03,  1.4619e-03],
        [ 7.7570e-05,  2.2899e-04,  2.7014e-04, -2.7720e-04, -8.9520e-05,
          1.3383e-04, -1.8457e-05,  2.4960e-04],
        [ 7.6792e-07,  4.6155e-07,  5.7785e-07, -1.8860e-07, -1.1511e-06,
         -1.0997e-07, -7.3691e-07,  4.9639e-07],
        [-2.7341e-07, -1.8152e-09,  8.8645e-08, -5.4507e-08,  2.4130e-07,
          1.5280e-07,  5.0921e-07, -2.7571e-08],
        [ 6.2154e-03,  1.7354e-03,  4.0777e-04,  3.9117e-05, -6.1702e-03,
         -1.4894e-03, -8.3696e-03,  1.4102e-03],
        [-1.3461e-02, -4.3998e-03,  1.6084e-02, -9.4322e-04,  5.0541e-03,
          1.5783e-02,  4.3487e-02, -2.8705e-03],
        [-3.7522e-03, -2.1200e-04, -2.5448e-03,  5.2774e-03, -3.1597e-03,
          3.3805e-04,  4.2903e-03, -3.0408e-03],
        [ 1.2794e-02, -9.6965e-04, -5.7898e-03,  2.2547e-03, -5.1301e-03,
         -5.9147e-03, -2.6909e-02, -3.2326e-03],
        [-8.4047e-07, -4.1318e-07,  2.2263e-07, -6.0463e-08,  8.8352e-07,
          5.8408e-07,  1.4868e-06, -4.8544e-07],
        [ 1.2430e-02, -6.8137e-03, -3.0157e-03, -1.8515e-03, -7.5355e-04,
         -5.6222e-03, -2.1330e-02, -1.0370e-03],
        [ 6.9161e-07,  3.6960e-07, -5.5402e-08,  1.3334e-07, -9.6124e-07,
         -3.1539e-07, -1.1266e-06,  2.2153e-07],
        [-1.3696e-07,  5.1595e-08,  3.8393e-07, -3.2666e-08, -1.8743e-07,
          2.3574e-07,  5.6882e-07,  2.8007e-08],
        [-3.4024e-07,  1.3620e-07,  4.0168e-07,  5.2427e-08, -2.1771e-07,
          3.2649e-07,  8.4641e-07, -4.1639e-08],
        [-1.4634e-06, -6.8173e-07, -3.2076e-07,  2.8391e-07,  1.4401e-06,
          6.0164e-07,  2.0846e-06, -8.7179e-07],
        [ 1.0687e-02, -2.6408e-03,  1.5500e-03, -1.8510e-03, -7.0711e-03,
         -4.7357e-03, -1.4011e-02,  3.9240e-03],
        [-2.5124e-02, -1.0310e-02, -2.8149e-02,  1.0369e-02,  3.8569e-02,
         -4.8470e-03,  7.2143e-03, -1.8313e-02],
        [ 3.7429e-07,  2.0027e-07, -2.8999e-09, -1.4233e-07, -2.4211e-07,
         -1.1884e-07, -6.3485e-07,  1.7189e-07],
        [-1.3065e-06, -3.3455e-07,  3.9996e-08, -2.0132e-08,  1.3561e-06,
          4.4824e-07,  1.9518e-06, -3.7147e-07],
        [-3.2551e-02, -6.1885e-03,  3.1139e-03, -2.4488e-03,  3.1636e-02,
          1.4382e-02,  5.5186e-02, -6.3279e-03],
        [ 1.6763e-03, -2.3770e-03,  5.3275e-04,  7.2246e-03, -1.1195e-02,
         -2.4978e-04,  1.5373e-03, -2.4786e-03],
        [-2.6420e-03, -9.4950e-04,  3.6105e-03, -1.4140e-03,  1.9146e-03,
          6.9757e-04,  7.6881e-03,  2.3269e-03],
        [-2.7393e-03, -6.9909e-05,  9.9120e-04,  7.5979e-05,  2.0706e-03,
          8.6310e-04,  5.0910e-03,  2.6729e-04],
        [-2.6314e-02, -1.2781e-02, -2.9457e-02,  1.0520e-02,  4.2546e-02,
         -5.4812e-03,  8.5272e-03, -1.9230e-02],
        [ 2.1072e-04,  6.5765e-04,  7.9811e-04, -9.1445e-04, -8.1286e-05,
          4.9073e-04, -1.4752e-04,  7.6815e-04],
        [-9.4839e-04,  4.6867e-03,  2.5109e-03, -1.9913e-03, -1.3708e-03,
          2.1680e-03,  1.6773e-03,  2.2463e-03],
        [ 5.7106e-03, -6.5664e-03, -5.5250e-03,  6.0732e-03, -5.2434e-03,
         -4.4569e-03, -1.1739e-02, -5.1128e-03],
        [-1.8278e-03, -6.9780e-03, -6.3310e-03,  5.6858e-03,  2.0735e-03,
         -3.0694e-03, -8.0726e-04, -5.2041e-03],
        [ 4.1369e-07,  1.8936e-08,  5.5585e-07, -4.1502e-07, -1.9772e-07,
         -4.5479e-10, -1.3317e-07,  4.2077e-07],
        [-6.3998e-05, -2.6223e-04, -2.9800e-04,  3.3278e-04,  5.1628e-05,
         -1.6102e-04,  1.2377e-05, -2.8605e-04],
        [ 8.3332e-07,  3.0560e-07,  3.8207e-07, -9.9265e-08, -1.0934e-06,
         -1.8969e-07, -9.6914e-07,  3.7042e-07],
        [ 2.6330e-07, -5.6101e-08, -9.9326e-08, -6.6634e-08, -3.8341e-08,
         -1.6137e-07, -5.5755e-07,  3.1705e-08],
        [ 9.7377e-07,  5.3931e-07,  3.4396e-07, -4.9886e-08, -1.3283e-06,
         -4.3736e-07, -1.3789e-06,  5.7379e-07],
        [ 1.7421e-02, -1.1494e-02, -2.8554e-03, -4.0645e-03,  3.3763e-04,
         -7.5874e-03, -2.6755e-02, -4.8924e-04],
        [ 8.4219e-03, -6.0632e-04, -3.9130e-03,  1.5085e-03, -3.2348e-03,
         -3.7954e-03, -1.7612e-02, -2.3131e-03],
        [ 3.1531e-06, -7.2533e-07, -1.2962e-06, -2.5240e-07, -1.0416e-06,
         -1.4724e-06, -6.0101e-06, -1.0275e-07],
        [ 8.8374e-03,  4.4004e-03,  2.3605e-03,  2.3328e-04, -1.1912e-02,
         -1.8830e-03, -1.0001e-02,  4.0509e-03],
        [ 1.1481e-06,  2.4710e-07, -2.0998e-07,  8.9202e-08, -1.2124e-06,
         -3.1123e-07, -1.9850e-06,  2.2215e-08],
        [ 1.2532e-06,  1.9915e-07,  1.1272e-06, -4.0132e-07, -1.5769e-06,
         -2.2275e-08, -8.0837e-07,  7.0001e-07],
        [ 3.3112e-06,  1.0100e-06,  1.2524e-06, -9.6987e-07, -3.0809e-06,
         -7.5931e-07, -4.1854e-06,  1.5645e-06],
        [-1.6921e-02, -3.4938e-03, -2.2325e-04,  1.9888e-03,  1.4085e-02,
          5.3345e-03,  2.6226e-02, -4.1284e-03],
        [ 2.2047e-04,  1.3545e-03,  1.5328e-03, -1.8826e-03,  5.4327e-05,
          9.6492e-04, -6.8929e-05,  1.5254e-03],
        [-4.2402e-03,  1.4303e-03,  2.7753e-03,  2.6373e-04,  1.5520e-03,
          2.0720e-03,  1.0351e-02,  1.3147e-03],
        [-2.2982e-03,  2.9984e-03, -1.0688e-03,  2.6645e-03, -1.6623e-03,
          9.3669e-04,  2.3344e-03, -1.3775e-03],
        [ 3.2285e-04,  1.1100e-03,  1.3079e-03, -1.4624e-03, -2.1226e-04,
          7.4503e-04, -1.4396e-04,  1.2488e-03],
        [ 1.1430e-06,  4.6887e-07,  2.0191e-07, -4.3453e-08, -1.3699e-06,
         -3.7550e-07, -1.8275e-06,  3.4205e-07],
        [-4.0133e-04, -7.4784e-03,  1.6868e-03, -6.5405e-03,  9.2040e-03,
          4.2052e-04,  2.7649e-03,  1.0403e-03],
        [-2.2176e-02, -4.6171e-03, -1.5130e-02, -2.3100e-03,  3.7082e-02,
         -1.1664e-03,  1.3006e-02, -6.5903e-03],
        [-9.3959e-07, -1.9780e-07, -1.4632e-07,  7.6199e-08,  9.7168e-07,
          3.6176e-07,  1.2867e-06, -4.1164e-07],
        [ 3.1235e-04,  1.3467e-03,  1.5784e-03, -1.8889e-03, -2.9983e-05,
          1.0011e-03, -1.8023e-04,  1.5461e-03],
        [-2.6650e-02, -2.3956e-03,  5.6485e-03, -5.6721e-03,  2.6544e-02,
          1.4774e-02,  4.6777e-02, -4.1073e-03],
        [-5.8085e-03, -5.9506e-03, -1.2111e-02,  5.6319e-03,  1.0677e-02,
         -3.6793e-03, -3.7751e-03, -8.1594e-03],
        [-5.9271e-07, -3.0724e-07,  2.5998e-07, -2.0753e-07,  8.5003e-07,
          1.8460e-07,  1.0601e-06, -7.8757e-09],
        [-5.9755e-07, -1.9614e-07,  3.1554e-07, -3.2805e-08,  3.9846e-07,
          4.8297e-07,  1.2745e-06, -2.4636e-07],
        [ 2.2155e-04,  7.9160e-04,  8.8821e-04, -8.9277e-04, -3.3875e-04,
          3.9129e-04,  3.1068e-05,  8.2080e-04],
        [ 3.0069e-04,  1.0340e-03,  1.2173e-03, -1.3573e-03, -2.0449e-04,
          6.8967e-04, -1.2946e-04,  1.1612e-03],
        [-2.1021e-02, -1.1402e-02, -2.0948e-02,  4.7427e-03,  3.7299e-02,
         -3.5430e-03,  9.3755e-03, -1.3010e-02],
        [ 1.3423e-06,  4.0673e-07,  1.0074e-07, -5.6103e-07, -6.6931e-07,
         -6.0131e-07, -2.1900e-06,  7.1618e-07],
        [-6.6762e-07, -1.9623e-08, -4.0042e-08,  4.1293e-08,  5.8098e-07,
          9.1610e-08,  8.4284e-07, -9.3617e-08],
        [ 5.0454e-07,  1.8067e-07,  3.5570e-08,  3.5080e-09, -6.4300e-07,
         -1.3917e-07, -6.6562e-07,  1.7390e-07],
        [ 1.3385e-07,  2.1401e-07,  5.0396e-07, -1.2880e-07, -5.0043e-07,
          2.4761e-07,  2.4094e-07,  1.2719e-07],
        [-1.4503e-08, -4.9217e-08,  3.5178e-07, -1.5987e-07, -2.9320e-08,
          4.8603e-08,  3.9249e-07,  2.4032e-07],
        [ 5.0737e-03, -2.6285e-03, -9.9015e-03,  1.0960e-02, -9.8014e-03,
         -4.2308e-03, -1.6038e-02, -9.0051e-03],
        [ 3.8250e-04,  1.2505e-03,  1.4957e-03, -1.7014e-03, -1.8278e-04,
          8.9191e-04, -2.3090e-04,  1.4376e-03],
        [ 3.5296e-04, -6.3619e-04, -4.7273e-04,  8.2135e-04, -4.4894e-04,
         -3.0079e-04, -5.1968e-04, -5.8911e-04],
        [-1.3864e-06, -6.1825e-07,  3.3094e-07, -1.3159e-07,  1.3731e-06,
          7.6640e-07,  2.6563e-06, -3.9757e-07],
        [-4.4273e-07, -3.7178e-07,  1.0262e-07,  1.0935e-07,  3.8091e-07,
          2.8269e-07,  8.0172e-07, -3.6400e-07],
        [-2.2962e-02, -5.6039e-03, -1.6345e-02, -1.7050e-03,  3.8695e-02,
         -1.3289e-03,  1.3268e-02, -7.6074e-03],
        [ 3.8966e-03,  2.2260e-03,  1.2765e-03,  1.5475e-04, -5.5791e-03,
         -7.3315e-04, -4.0596e-03,  2.0176e-03],
        [-3.8748e-02, -7.5475e-03,  3.5837e-03, -7.2202e-03,  4.3760e-02,
          1.9336e-02,  6.2390e-02, -9.1816e-03],
        [ 4.6205e-07, -3.1524e-07,  5.9102e-07, -2.4885e-07, -3.1663e-07,
          1.5419e-07, -5.5734e-08,  6.5790e-08],
        [-8.8209e-07, -5.7631e-07,  5.1827e-07, -1.6661e-07,  8.7743e-07,
          6.6222e-07,  2.0967e-06, -2.5940e-07],
        [-6.5899e-07, -2.7458e-07,  3.0903e-08,  3.7252e-09,  6.8674e-07,
          1.7287e-07,  9.5160e-07, -2.0037e-07],
        [ 4.1166e-04,  1.4150e-03,  1.6612e-03, -1.8424e-03, -2.9973e-04,
          9.2953e-04, -1.6523e-04,  1.5821e-03],
        [-5.0497e-07, -3.2753e-07, -8.1369e-07, -2.4691e-08,  1.3780e-06,
         -2.2377e-07, -3.5706e-07, -4.4921e-07],
        [ 6.4560e-03, -1.5657e-03, -1.2628e-02,  1.3028e-02, -1.2081e-02,
         -5.3561e-03, -2.2060e-02, -1.0865e-02],
        [ 5.1573e-08,  2.0041e-07, -2.5506e-07,  1.8438e-07, -1.9483e-07,
         -1.6367e-07, -5.0055e-07, -6.2171e-08],
        [-3.2588e-03,  4.1097e-03,  2.6907e-03, -6.1247e-03,  5.2091e-03,
          2.3732e-03,  3.5560e-03,  3.9048e-03],
        [ 1.6239e-07, -1.7897e-07, -6.7227e-08,  1.6104e-07, -1.4382e-07,
         -1.2319e-07, -3.3806e-07, -1.5060e-07],
        [ 4.7695e-07, -1.4172e-07,  5.0300e-07, -3.1441e-07, -2.6722e-07,
          4.0419e-08, -1.7496e-07,  2.3102e-07],
        [ 1.3394e-02,  4.8768e-03,  1.4760e-03,  4.0814e-04, -1.5403e-02,
         -3.6142e-03, -1.8528e-02,  4.1491e-03],
        [-1.2754e-02, -5.8608e-03,  4.8519e-03, -3.3299e-03,  1.4461e-02,
          6.9089e-03,  2.5667e-02, -1.7376e-03],
        [ 5.7579e-07,  7.4073e-08, -1.7811e-07, -3.4133e-07,  1.0505e-07,
         -3.2134e-07, -1.2276e-06,  2.1787e-07],
        [ 5.8124e-07,  4.8358e-07,  1.9847e-07, -8.5171e-08, -9.0842e-07,
         -4.8668e-08, -8.5627e-07,  2.1397e-07],
        [ 1.0789e-02, -4.0084e-03, -1.3202e-02,  1.1305e-02, -1.2816e-02,
         -7.2364e-03, -2.9810e-02, -1.0376e-02],
        [-1.3845e-06, -3.2977e-07, -6.1958e-07,  1.1681e-08,  1.8450e-06,
          3.7499e-07,  1.4086e-06, -6.6813e-07],
        [-6.4349e-03, -2.6519e-03, -1.0007e-03,  2.5789e-05,  7.8230e-03,
          1.5749e-03,  8.6393e-03, -2.1386e-03],
        [-1.0542e-02, -6.3926e-04,  4.7464e-04, -4.9153e-03,  1.3569e-02,
          4.4617e-03,  1.4684e-02, -7.5113e-04],
        [ 8.1712e-03,  5.5610e-05, -3.2877e-03,  1.7411e-03, -3.5400e-03,
         -3.4350e-03, -1.6036e-02, -2.0051e-03],
        [-1.3059e-03,  1.6845e-03, -3.8577e-04,  1.0678e-03, -6.2575e-04,
          6.1647e-04,  1.3644e-03, -5.4720e-04],
        [-1.3348e-02, -1.1943e-02, -2.1411e-02,  6.4514e-03,  2.6919e-02,
         -6.1494e-03, -3.1412e-03, -1.3275e-02]], device='cuda:0') 

model.module_8.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.2300,  0.2603,  0.0293, -0.0322,  0.0093, -0.1359, -0.6566, -0.0670,
        -0.1190,  0.0051, -0.3185, -0.0735, -0.1946, -0.0329, -0.4683, -0.1284,
         0.0281, -0.8728, -0.0808, -0.7127, -0.0985, -0.0517, -0.1139, -0.0387,
        -0.2048,  0.3709, -0.1590, -0.1355, -0.0189,  0.2631, -0.0630, -0.0766,
         0.3983, -0.0118,  0.0639,  0.2277,  0.2269, -0.0956,  0.0200, -0.2164,
        -0.1484, -0.1362, -0.3508, -0.5824, -0.6874, -0.4060, -0.1237, -0.3460,
        -0.6169, -0.0052, -0.0238, -0.0755,  0.0669, -0.0250, -0.3796,  0.0682,
         0.2962, -0.0081, -0.0107,  0.2030,  0.2652, -0.1750, -0.2330, -0.0852,
        -0.0505,  0.3590, -0.3614, -0.0585, -0.0477, -0.1980,  0.0170,  0.0594,
         0.0049,  0.1506, -0.0711, -0.0381,  0.2270, -0.3973,  0.1165, -0.1023,
        -0.0525, -0.0636, -0.0445, -0.2505,  0.0780, -0.0011,  0.1980, -0.0561,
        -0.1345, -0.6398,  0.0913, -0.3511, -0.2580,  0.1197, -0.2150, -0.0386,
         0.0123, -0.6538, -0.0654,  0.4980], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 7.8888e-07,  8.1744e-02,  3.6064e-03, -9.5119e-04,  2.6194e-02,
         8.8383e-02,  9.7458e-03,  6.0106e-03, -3.0145e-03, -1.1037e-02,
         4.6333e-03, -1.8594e-03,  1.1684e-06, -4.2181e-07,  2.0952e-03,
         5.7700e-02,  4.1660e-02, -2.8960e-04,  1.1052e-06,  3.0440e-03,
         9.8452e-07,  1.6975e-06,  2.3479e-06,  1.8812e-06,  1.2483e-02,
        -4.8087e-02, -1.6173e-06, -4.6254e-07, -3.4159e-02,  9.1350e-02,
         3.6719e-03, -1.4822e-03, -4.9942e-02, -6.7396e-03, -2.3356e-02,
         6.8981e-02,  5.1372e-02, -8.6996e-07,  2.3893e-03,  1.6469e-06,
        -4.7923e-07,  1.3665e-06,  5.7690e-03, -7.4242e-04, -2.2364e-06,
         6.2606e-03,  1.1522e-06,  3.5162e-06, -1.7481e-06,  6.4883e-03,
        -1.4491e-02, -2.0471e-03,  4.6160e-03, -1.0531e-02,  1.3717e-06,
        -2.1799e-02, -1.1929e-01, -7.1795e-07, -1.4305e-02, -5.5279e-02,
         8.8122e-03, -6.1459e-07,  1.4571e-06, -5.8451e-03, -9.7534e-03,
        -6.1574e-02, -4.6901e-06, -3.2538e-07,  5.7411e-07,  1.4044e-06,
         4.2453e-07,  7.9905e-02, -1.2449e-02,  7.6021e-03,  9.0711e-07,
         2.5778e-06, -1.1821e-01,  2.5146e-03, -8.3586e-02,  2.6292e-06,
         1.8816e-06,  5.9818e-07, -1.3180e-02, -4.1674e-06,  8.5562e-02,
         6.1757e-08, -6.1358e-02,  2.2508e-06,  7.7321e-07,  7.8458e-03,
        -4.6439e-03, -4.0745e-06,  1.2656e-07,  8.5434e-02, -3.8281e-06,
        -4.7885e-03, -5.2427e-02, -1.2469e-03, -7.4360e-05, -1.9822e-02],
       device='cuda:0') 

model.module_10.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[-0.0129, -0.0408,  0.1737,  ..., -0.1733,  0.0370,  0.0038],
        [-0.0066, -0.0416,  0.0309,  ..., -0.0229,  0.0019,  0.0470],
        [ 0.3315, -0.0627,  0.2621,  ...,  0.0546, -0.0341, -0.0190],
        ...,
        [ 0.1729, -0.0263,  0.1026,  ..., -0.0370, -0.0120, -0.0954],
        [ 0.1111,  0.0402,  0.0317,  ...,  0.3148, -0.1360, -0.0973],
        [ 0.3371, -0.1241,  0.1322,  ...,  0.0108,  0.2712, -0.0518]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 2.0508e-10, -1.3722e-07, -9.3862e-09,  ..., -1.0601e-07,
          1.1325e-08, -3.0547e-07],
        [ 2.3469e-11, -2.0444e-07,  4.0459e-10,  ...,  1.3396e-07,
         -2.6834e-08, -6.3599e-07],
        [-8.7490e-11, -3.2113e-07,  5.3597e-09,  ...,  2.7312e-07,
         -7.3140e-08, -1.1034e-06],
        ...,
        [ 1.1885e-10, -5.8072e-07, -2.9773e-09,  ...,  1.8673e-07,
          4.2087e-08, -1.7092e-06],
        [-7.2535e-07,  1.1633e-04, -2.8779e-07,  ...,  2.6810e-03,
         -3.6005e-07, -5.6443e-05],
        [-1.5852e-11, -5.7903e-07,  3.8277e-09,  ...,  2.6019e-07,
          2.9113e-08, -1.7858e-06]], device='cuda:0') 

model.module_10.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.0138, -0.0309,  0.0012, -0.1875,  0.0094, -0.1195, -0.0147,  0.0327,
        -0.0057, -0.1893, -0.1651,  0.0313,  0.0035,  0.0016, -0.0333,  0.0088,
         0.0040, -0.0176, -0.0391, -0.0472, -0.0882,  0.1991, -0.0011, -0.0920,
        -0.0622, -0.0535, -0.1610, -0.0164, -0.0618,  0.0630, -0.0687,  0.0697,
        -0.0800, -0.0836, -0.1706, -0.2218, -0.0294, -0.0108, -0.0453,  0.0330,
        -0.0707, -0.0114, -0.0121, -0.0888, -0.0771, -0.0240, -0.4298,  0.0372,
        -0.0111, -0.3081, -0.0335, -0.0116,  0.0035, -0.1466, -0.1075, -0.0523,
        -0.0461, -0.0270, -0.6353, -0.0330, -0.0762, -0.1364, -0.0242, -0.0704,
         0.0112,  0.0825, -0.1181,  0.2231, -0.0749, -0.0857, -0.0380, -0.1175,
        -0.0119,  0.0215,  0.0437, -0.0140,  0.0044, -0.0617, -0.0612, -0.0045,
         0.0166, -0.0601, -0.1749, -0.1044, -0.0553, -0.0047, -0.0468,  0.0287,
        -0.0372,  0.1467, -0.0268, -0.0905, -0.0040,  0.0561,  0.0172, -0.0456,
        -0.2228, -0.1868, -0.1251, -0.0275], device='cuda:0',
       requires_grad=True) 
grad:  tensor([-3.1639e-06, -2.6912e-06, -3.6025e-06,  6.1273e-03, -8.3236e-06,
        -6.8861e-06, -1.5085e-07, -6.2905e-06, -1.1338e-05, -1.2136e-05,
        -7.6610e-06,  2.8200e-06, -2.4966e-06, -7.4863e-07, -4.4704e-06,
        -3.0829e-06, -6.1629e-06, -6.7100e-06, -5.4527e-06, -1.3290e-06,
        -1.1012e-04, -2.1336e-02, -8.6238e-07, -6.2916e-06, -7.4159e-06,
        -2.8771e-07,  1.5307e-04, -5.1670e-06, -2.1465e-06, -2.1646e-03,
        -2.9200e-06, -4.9270e-06, -2.5308e-06, -3.2693e-06,  5.3014e-02,
         1.8093e-02,  1.0919e-02, -1.3674e-06, -1.1542e-06, -4.0398e-06,
        -2.9176e-06,  5.3300e-07, -1.4030e-05,  2.0450e-06, -1.9318e-06,
        -1.8849e-06, -3.6739e-05, -2.9054e-06, -7.0032e-07,  9.6364e-05,
        -6.0414e-06, -3.4529e-06, -3.8555e-02,  3.1571e-02, -1.4015e-05,
         2.7497e-02, -2.6047e-06, -2.3564e-06,  3.4411e-03, -7.0955e-07,
         2.6896e-02,  1.6001e-02,  8.2149e-07, -4.2049e-06, -2.1123e-06,
        -6.0657e-03, -3.4625e-03,  1.2628e-02, -1.9658e-06,  2.0722e-04,
         6.8526e-02,  4.8611e-03, -3.3701e-06, -7.3053e-06,  4.3769e-03,
         1.5271e-06,  4.2048e-03, -1.3488e-06,  5.6466e-02, -3.0457e-06,
        -2.3911e-06, -9.8417e-07, -5.1833e-04,  1.2230e-06,  6.3793e-04,
        -3.6744e-06, -2.0366e-06, -1.8753e-05, -9.0364e-08, -7.9183e-02,
        -1.2977e-06,  4.2896e-02, -7.8432e-07, -2.9965e-06, -1.4504e-03,
        -3.7564e-06,  1.5955e-02, -7.8906e-06,  7.9943e-04, -5.9580e-06],
       device='cuda:0') 

model.module_12.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[ 0.1140, -0.0415,  0.0728,  ...,  0.0536, -0.0677,  0.0512],
        [-0.1064, -0.0154, -0.0414,  ..., -0.0657, -0.0857, -0.0885],
        [ 0.1113, -0.0191,  0.0629,  ..., -0.0054,  0.1708, -0.0303],
        ...,
        [ 0.1158,  0.2051,  0.3011,  ..., -0.0678,  0.2961,  0.0363],
        [-0.0357, -0.1275, -0.0466,  ..., -0.0402, -0.0784, -0.0401],
        [ 0.0539,  0.0062,  0.0631,  ...,  0.1427,  0.1196,  0.0871]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-1.3124e-09, -9.6488e-10, -1.4418e-09,  ..., -1.9112e-09,
          7.5859e-07, -9.7085e-10],
        [ 1.9005e-07, -1.4944e-06,  3.5925e-07,  ..., -7.0540e-06,
         -1.6017e-03, -6.5412e-06],
        [ 1.4589e-10,  1.2115e-10,  1.9311e-10,  ...,  2.2329e-10,
         -1.2662e-07,  1.0948e-10],
        ...,
        [ 4.8117e-08,  1.1031e-07,  2.5589e-07,  ...,  3.3356e-07,
         -1.1571e-07,  1.1176e-07],
        [-3.3012e-07, -3.0488e-07, -5.2098e-07,  ..., -7.7813e-07,
         -1.4465e-07, -2.0829e-07],
        [ 5.1254e-06,  2.9574e-06,  4.3952e-06,  ...,  7.0752e-06,
          5.4483e-06,  3.1208e-06]], device='cuda:0') 

model.module_12.bias 16 torch.Size([16])
Parameter containing:
tensor([-0.5775,  0.2442, -0.0272, -0.1043,  0.2181, -0.0892,  0.0060,  0.3449,
        -0.1370, -0.0532,  0.3505,  0.4211, -0.1563, -0.1269, -0.4373,  0.3221],
       device='cuda:0', requires_grad=True) 
grad:  tensor([ 2.0081e-05,  3.6404e-01, -1.2565e-06, -3.8869e-05,  2.0586e-01,
         1.3159e-01,  1.1100e-01, -1.5909e-01, -1.4883e-05,  1.1156e-01,
         6.1121e-02, -2.2781e-01, -4.0092e-05, -3.2242e-03,  7.3808e-03,
        -1.1252e-01], device='cuda:0') 

model.module_14.bias 8 torch.Size([8])
Parameter containing:
tensor([ 0.1877,  0.1182,  0.0738, -0.2056, -0.2897,  0.0651, -0.2290, -0.1782],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-0.1420, -0.7793, -1.1433,  0.2044, -0.1624,  0.0909, -0.1809,  0.3402],
       device='cuda:0') 

model.module_14.lin.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[ 0.3843,  0.0973,  0.0094, -0.2483, -0.4610, -0.2824,  0.3805, -0.2373,
          0.1104,  0.1799, -0.2591, -0.3216, -0.3553, -0.4010,  0.4451, -0.3790],
        [-0.4804, -0.3135,  0.0100,  0.6414, -0.6223,  0.0526, -0.0714,  0.0268,
          0.0504, -0.3091,  0.2857,  0.1143,  0.3435,  0.3171,  0.1270, -0.4125],
        [ 0.0892, -0.3647,  0.0107,  0.0805, -0.0065, -0.4927, -0.7974,  0.2969,
          0.2639, -0.8313, -0.3067,  0.1568,  0.3657, -0.1975,  0.0992,  0.4584],
        [-0.1322,  0.2204, -0.0100,  0.4936,  0.2619,  0.1561,  0.4410, -0.0129,
          0.0510, -0.3315,  0.4075,  0.3240,  0.1096, -0.2779,  0.5047,  0.4338],
        [-0.6625,  0.1035, -0.0471,  0.4852, -0.1252, -0.3532, -0.0092,  0.2969,
         -0.1921,  0.2557,  0.5239,  0.6003,  0.3219, -0.0519, -0.0355, -0.1971],
        [ 0.2859, -0.5127, -0.2884, -0.8829,  0.0636, -0.0791,  0.5909,  0.0414,
          0.1014, -0.0315, -0.2049, -0.1802, -0.0388, -0.2948,  0.4447,  0.5288],
        [-0.1974,  0.3305, -0.0234, -0.0300, -0.3102, -0.0307, -0.2314, -0.1672,
          0.1717, -0.0872,  0.3766,  0.4501, -0.3577, -0.1218, -0.7135, -0.0612],
        [-0.1597,  0.3378,  0.0482, -0.1675,  0.2439, -0.0511,  0.0459,  0.3135,
          0.2230,  0.2664,  0.3906,  0.3836, -0.1842, -0.0228, -0.2892,  0.3108]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 2.1106e-07,  5.1861e-03,  4.8588e-07, -7.0415e-07,  1.8118e-01,
         -1.0478e-02, -1.6511e-02, -1.4168e-02, -1.1330e-06, -3.2385e-02,
          2.3712e-02,  4.0903e-02, -4.3817e-06, -9.0797e-04,  1.0942e-04,
          9.8758e-02],
        [ 1.9254e-05, -2.4364e-01,  1.4822e-05,  4.5470e-05, -1.1390e-01,
         -1.7103e-01, -3.6484e-02, -7.2572e-02,  1.0477e-05, -8.5279e-02,
         -1.6061e-01, -1.5400e-01,  1.6419e-05, -8.6728e-04,  1.8516e-05,
         -1.0968e-01],
        [ 3.4136e-05, -2.4124e-01,  8.7464e-06,  3.8534e-05, -3.0732e-01,
         -4.5142e-02, -4.2247e-02, -1.3699e-01,  1.2889e-05, -3.6369e-02,
         -2.9833e-01, -3.3508e-01,  2.1469e-05,  3.1200e-04, -4.1373e-05,
         -2.6759e-01],
        [-4.0838e-06, -4.3774e-02,  4.2970e-06,  1.0924e-05, -1.9412e-01,
         -6.8950e-02,  3.0125e-02,  3.4651e-02,  2.1568e-06,  2.4243e-02,
          5.7827e-03, -1.5599e-03,  6.5237e-06,  4.9777e-04, -1.1015e-04,
         -9.2519e-02],
        [ 3.9516e-06, -1.3114e-01,  9.6118e-06,  2.6805e-05, -1.5909e-01,
         -1.2418e-01,  9.8620e-03, -4.7111e-04,  5.5175e-06, -2.4941e-02,
         -5.2164e-02, -5.0601e-02,  1.0826e-05,  1.2122e-04, -7.2646e-05,
         -9.1359e-02],
        [-1.9883e-06,  1.0978e-01, -8.5293e-06, -2.2495e-05,  8.2789e-02,
          1.1600e-01,  1.0529e-02, -5.7789e-03, -4.1206e-06,  5.0895e-02,
          2.8735e-02,  1.6722e-02, -7.6388e-06,  1.7045e-04,  7.9312e-05,
          4.0843e-02],
        [ 2.8463e-06, -1.4192e-01,  1.0770e-05,  2.9308e-05, -1.8657e-01,
         -1.4840e-01,  1.4947e-02,  2.2271e-03,  5.9616e-06, -2.4483e-02,
         -4.4085e-02, -4.4087e-02,  1.1716e-05,  7.7588e-07, -9.3418e-05,
         -1.0572e-01],
        [-8.9393e-06, -9.4175e-03,  3.1232e-06,  5.0341e-06, -1.4567e-01,
         -6.1065e-02,  3.3839e-02,  5.3518e-02,  1.6527e-07,  2.2966e-02,
          4.9387e-02,  4.8718e-02,  3.1740e-06,  4.4615e-04, -1.2086e-04,
         -5.0493e-02]], device='cuda:0') 

model.module_15.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[ 1.0541e-01,  1.4344e-01,  2.7144e-01, -2.5250e-02, -2.3083e-01,
         -4.1637e-01,  3.9376e-01, -1.4457e-01],
        [ 1.1365e-01, -9.9558e-02,  1.4247e-01,  4.6276e-02,  6.2220e-02,
         -2.4937e-01,  8.1425e-02, -1.7750e-01],
        [-2.0909e-01,  1.3068e-01, -1.5963e-02, -2.2373e-01,  2.2744e-01,
         -2.1291e-02,  9.4106e-02, -1.5650e-01],
        [-2.3861e-01, -9.4963e-02,  1.2658e-01, -3.3718e-01, -2.0539e-02,
          3.5530e-02, -2.1889e-01, -3.5089e-01],
        [ 2.9594e-01,  2.4101e-01,  8.8951e-03, -6.5160e-01,  1.2857e-01,
         -1.7165e-01,  1.1279e-01,  1.2931e-02],
        [ 3.0642e-01,  8.1226e-02,  2.3764e-01, -8.1099e-02,  2.8816e-01,
         -2.1181e-01,  6.3871e-02, -3.2699e-01],
        [ 2.5317e-02,  2.7000e-01, -4.1230e-02, -3.4596e-01,  8.4655e-03,
          5.9167e-01,  5.2569e-02, -7.8311e-02],
        [ 3.8389e-01,  2.6692e-01,  1.6073e-01, -2.2578e-01,  1.4168e-01,
          6.5056e-01, -2.7407e-01, -7.7576e-02],
        [-8.5531e-02,  2.7206e-01,  1.7488e-01,  1.8402e-03, -2.1744e-01,
          4.7905e-01, -2.0875e-01,  1.5282e-01],
        [-2.8048e-01, -1.9594e-01, -2.7370e-01,  3.2503e-01, -4.2240e-01,
         -2.4098e-02, -2.1778e-01,  1.6971e-01],
        [-1.0727e-01,  4.0962e-01, -7.1583e-02,  5.6093e-02,  9.8201e-02,
         -3.2567e-02, -2.1207e-02, -2.5687e-01],
        [ 2.0860e-01,  3.9374e-01,  8.0890e-03,  6.6322e-02,  4.3031e-01,
         -1.5123e-01,  2.3373e-01,  3.8822e-01],
        [ 2.8823e-01,  6.7909e-02,  2.2773e-01,  2.3967e-01, -1.5858e-02,
         -2.4324e-01,  2.3154e-02,  4.1991e-02],
        [-1.0591e-01, -5.4957e-02,  1.1695e+00, -3.4786e-01, -3.6587e-01,
          2.9016e-02, -1.0730e-03, -1.4081e-01],
        [-7.4139e-03,  2.3093e-02,  1.1353e-01,  1.8106e-03,  2.1760e-01,
         -2.9309e-01,  1.8203e-01, -2.1580e-01],
        [ 1.7707e-02,  1.2689e-01,  2.0964e-01,  7.2920e-02, -4.0775e-01,
          2.8164e-01, -2.0354e-01, -3.4466e-01],
        [ 1.0871e-01, -2.2289e-01,  1.2782e-01,  9.3658e-02,  2.9372e-01,
          1.8079e-01,  5.8112e-02, -2.6090e-01],
        [-2.2256e-03,  2.6783e-01,  1.9751e-01,  2.6460e-01,  5.6368e-01,
          3.0737e-01,  1.6404e-01,  1.9872e-01],
        [-2.5053e-01,  7.6131e-02,  1.3284e+00,  2.6725e-01, -7.7535e-01,
          1.2450e-01,  1.2075e-01, -4.1878e-01],
        [ 2.7816e-01, -2.3546e-01, -1.9638e-01,  3.6952e-02, -3.5474e-01,
          3.0804e-01, -2.2145e-01, -4.2301e-01],
        [ 7.8248e-02,  1.2572e-01, -5.9084e-02, -4.9280e-01, -9.3824e-02,
         -1.0151e-01, -2.8741e-02,  4.1697e-02],
        [ 1.4729e-01, -2.7842e-01,  1.0323e-01, -2.9211e-01,  1.8626e-01,
         -2.8819e-01, -1.4763e-01,  3.9535e-02],
        [ 5.2048e-02, -6.6703e-02,  1.7672e-01, -2.7333e-01,  1.7191e-01,
          4.1394e-01,  6.2777e-03,  1.6200e-01],
        [ 3.3382e-01,  2.4248e-01, -1.9883e-02,  4.0925e-01,  1.6693e-01,
          5.3294e-01,  2.8722e-01,  3.3116e-01],
        [ 1.3770e-01, -1.2073e-01,  4.1019e-01,  1.1953e-01,  2.9630e-01,
          1.5140e-02,  4.0338e-01, -1.0818e-01],
        [ 1.8452e-01,  1.1817e-01,  4.5390e-02, -3.5169e-01,  2.7736e-01,
          4.2678e-01, -2.7337e-01, -4.3062e-01],
        [ 2.5423e-01,  5.3010e-02, -4.9000e-02,  3.6691e-02, -9.1429e-01,
          2.8918e-01, -3.0510e-01, -5.4508e-01],
        [-8.9180e-02,  4.1685e-01, -1.0348e-01, -3.8409e-01,  2.2092e-02,
         -1.7169e-01,  3.1879e-02,  4.8625e-02],
        [-1.2474e-01, -1.1994e-01, -5.1226e-03, -1.2767e-01,  8.7590e-02,
         -1.4743e-01,  6.5679e-02,  3.1927e-01],
        [ 1.9515e-01,  1.4091e-01, -9.4234e-03,  1.3345e-01,  5.4134e-01,
         -3.4590e-01,  7.8271e-02,  5.3482e-02],
        [-5.1594e-02,  4.8963e-01,  2.6134e-01,  6.0815e-02, -1.1223e-01,
         -5.6595e-03,  2.2954e-01,  4.7097e-02],
        [-2.1172e-01, -1.5100e-01,  8.9266e-01, -2.6315e-01, -3.3675e-01,
         -5.1760e-01, -9.3574e-02, -3.6107e-01],
        [ 3.4858e-02, -2.2605e-01, -1.8077e-02, -1.7371e-02, -7.8813e-01,
         -8.0043e-03,  8.2135e-02, -5.4737e-01],
        [ 9.6250e-02,  3.5590e-02,  2.6186e-01,  2.9645e-02, -1.9231e-02,
         -1.5590e-01, -3.3014e-02,  1.2496e-01],
        [ 1.8777e-01,  2.3529e-02, -1.9405e-01,  2.6818e-01, -3.1839e-02,
         -3.4777e-02,  1.9858e-01,  3.0333e-01],
        [ 6.3112e-01,  5.4757e-01, -5.0278e-02,  1.5381e-01,  8.2348e-02,
         -1.0913e-01,  6.2813e-01, -1.4864e-01],
        [ 4.1005e-01,  5.8164e-01, -1.0313e-01, -1.6501e-02,  1.3467e-01,
         -2.3761e-01,  3.8215e-01, -2.4720e-01],
        [ 9.0702e-02,  2.0587e-01,  9.2381e-01,  1.1004e-03, -3.6477e-01,
          3.3830e-01, -3.5083e-01, -3.3977e-01],
        [ 2.7139e-01,  8.3868e-01, -7.4062e-02,  1.3726e-02, -3.0934e-02,
         -1.2440e-01,  5.8015e-01, -1.7343e-01],
        [ 2.5242e-01, -2.4590e-01, -1.6143e-01, -1.6679e-01, -4.4859e-01,
         -5.8915e-01,  3.4882e-01, -1.8363e-01],
        [-3.2566e-01, -2.7477e-01,  1.1225e-02,  2.0027e-01,  2.5715e-02,
          3.2759e-01, -5.8548e-03,  3.3108e-01],
        [ 3.8668e-01,  2.3376e-01, -2.0871e-01, -2.7873e-01, -1.2341e-01,
         -1.4786e-01, -2.5506e-01, -2.3370e-01],
        [-2.1709e-02, -2.1243e-02,  2.9483e-01,  1.3121e-01,  2.7512e-01,
         -1.7574e-01, -1.9033e-02, -7.7623e-02],
        [ 4.7351e-02,  5.1463e-01,  7.2266e-01, -2.7208e-01, -3.5788e-01,
          1.8149e-01,  3.4714e-01, -6.7898e-02],
        [-6.9795e-02, -1.1326e-01,  1.5804e-01,  3.6548e-04,  1.0610e-01,
         -1.2150e-01,  4.0741e-01, -3.6476e-01],
        [ 3.2202e-01,  6.3292e-01, -2.0395e-01, -3.4437e-01,  1.2450e-01,
         -3.3092e-01,  1.6171e-01, -2.5255e-02],
        [ 4.6583e-01,  2.7995e-01,  1.6253e-01, -3.4862e-01,  9.3769e-02,
          1.4925e-01,  1.4410e-01, -1.0115e-01],
        [ 6.5586e-02,  1.2264e-02,  4.3253e-02,  1.5447e-02,  7.4465e-02,
         -3.7593e-02, -1.4057e-02, -8.0397e-02],
        [-1.9925e-01,  4.0544e-02,  7.1753e-02, -3.4752e-02,  3.9113e-01,
         -7.3086e-02, -1.0686e-01,  1.0366e-01],
        [ 1.4719e-01, -3.4715e-01,  2.6552e-03, -4.6048e-01, -2.8949e-02,
         -3.1834e-01,  2.8677e-01,  2.3208e-01],
        [ 8.6833e-02, -3.0976e-02,  1.3603e-01, -2.5691e-01,  3.8366e-02,
         -3.0555e-01,  7.3199e-02,  6.1441e-02],
        [ 3.8816e-01,  2.2773e-01,  5.8937e-02, -2.3895e-01,  2.6882e-01,
          2.4631e-01, -3.1959e-01, -3.8905e-01],
        [ 4.8084e-01,  3.4657e-01,  7.4072e-01, -2.4527e-01, -2.6998e-01,
          4.1222e-02, -4.6283e-01,  1.2863e-01],
        [-2.8856e-02, -4.1922e-02, -6.5152e-03, -6.9158e-02,  1.8781e-01,
         -1.0347e-01,  9.7134e-02, -1.7730e-01],
        [ 5.1643e-01,  3.4850e-01,  1.4117e-01, -7.2682e-02, -2.3159e-01,
          6.9393e-01, -1.2823e-01, -9.5767e-02],
        [ 5.0498e-01,  6.7481e-01, -1.0507e-01,  1.1074e-01, -3.5663e-01,
         -3.0774e-02,  2.0657e-01,  7.4038e-02],
        [ 1.4551e-01,  3.4997e-01,  5.3751e-02,  2.3420e-01, -7.5140e-02,
          3.8831e-01, -3.9346e-03, -1.9552e-02],
        [ 2.3909e-01,  2.2159e-01,  1.6141e-02, -1.6993e-01, -4.6097e-03,
          3.8124e-01, -2.0608e-01, -4.7204e-01],
        [-1.5240e-01,  1.9570e-01,  1.4324e-01,  3.2962e-02,  4.6658e-01,
          1.3194e-01,  1.3878e-01, -2.7685e-01],
        [ 1.0301e-01,  4.2283e-01, -1.1794e-01,  1.7543e-01,  1.9461e-01,
         -7.2564e-01,  8.5939e-01, -1.7699e-01],
        [ 5.6940e-02, -2.9482e-01,  3.0060e-02, -3.4643e-01, -1.3462e-01,
          3.9304e-01, -1.2751e-01, -1.8893e-01],
        [-1.0073e-01,  4.4092e-01,  5.5245e-01, -4.0712e-01, -1.6616e-01,
          3.1056e-01, -2.8268e-01, -1.6456e-01],
        [-2.2723e-01,  4.5167e-01,  5.7146e-01, -1.8912e-01,  8.5989e-02,
         -2.3983e-01,  3.6871e-01, -1.8798e-01],
        [-1.7146e-01, -2.5446e-01, -1.4245e-01, -1.9504e-01,  7.9989e-03,
         -5.8406e-02,  4.2192e-01, -1.9594e-01],
        [ 4.0740e-01,  6.0472e-01, -1.9119e-01, -3.4093e-01, -9.3676e-02,
         -3.1747e-01, -2.2980e-01,  1.6598e-01],
        [-1.1245e-01,  9.3397e-02, -1.9788e-01, -9.1353e-02, -1.1523e+00,
         -7.1697e-02, -4.0526e-01, -2.9024e-01],
        [ 1.4581e-01,  1.1910e-01,  5.1636e-01, -5.3147e-01,  1.8785e-01,
         -1.7805e-01, -5.9297e-02,  3.6310e-03],
        [-8.7948e-02, -2.2588e-01,  8.6852e-02,  2.7593e-01,  1.0296e-01,
          2.1608e-01,  3.6678e-02, -2.4229e-01],
        [ 1.6087e-01,  1.3309e-01,  8.2632e-01, -1.0733e-01, -2.9417e-01,
          3.6522e-01,  8.2277e-02, -3.6631e-01],
        [ 1.1747e-01,  2.7552e-01,  3.7509e-01, -3.5650e-01, -2.0114e-02,
         -7.1262e-02, -7.4564e-02, -3.3090e-01],
        [-3.8534e-01, -2.2260e-01,  1.5552e-01,  2.7137e-01,  4.2919e-01,
         -4.3871e-01,  2.7135e-01,  4.4056e-01],
        [-5.2987e-02,  3.8895e-01, -1.4581e-01,  2.3393e-01,  1.3015e-01,
         -1.1876e-01, -4.1367e-02,  1.5562e-01],
        [-1.9542e-01,  9.9534e-02, -1.2230e-02, -3.7698e-01,  1.6147e-01,
          3.1181e-01,  2.1503e-01,  1.1066e-01],
        [ 3.8191e-01,  5.0288e-01,  8.0917e-02, -4.7653e-01, -1.3100e-02,
         -5.1545e-03, -1.2770e-01,  7.7338e-02],
        [ 1.7232e-01,  4.1746e-01,  8.5036e-01, -2.0752e-01, -4.8938e-01,
          3.0892e-01, -2.4164e-01, -2.4285e-01],
        [-2.1680e-01, -1.4887e-01,  3.5756e-01, -3.7493e-01,  6.7653e-01,
         -1.3196e-01,  4.2047e-01,  2.1342e-01],
        [ 2.3366e-02,  5.4099e-02,  7.0704e-02,  2.9135e-01,  1.4853e-01,
         -8.8509e-02, -2.9992e-01, -2.9115e-01],
        [-4.9617e-01,  3.1156e-01,  5.2141e-01,  5.3325e-03, -4.0384e-01,
         -1.3769e-01, -7.1999e-02, -2.4889e-01],
        [-1.1271e-01,  9.8903e-02, -2.4949e-02, -4.3884e-01, -2.9029e-01,
          5.0487e-01, -4.3148e-01, -4.4737e-03],
        [ 5.8065e-01,  5.5575e-01, -1.0026e-01,  1.3731e-02,  1.6307e-01,
          2.6401e-01,  3.6955e-01, -1.9337e-01],
        [-9.2334e-02,  1.3993e-01, -6.2069e-02, -7.1115e-02,  2.6918e-01,
         -1.3401e-02, -3.4714e-01, -1.1500e-01],
        [ 7.1149e-02,  1.9778e-01, -2.8757e-03, -2.6931e-01,  3.4317e-02,
          4.5259e-01, -3.6123e-01, -2.6403e-02],
        [-1.8851e-01,  1.9649e-01, -1.6420e-02, -2.9987e-01,  4.3608e-01,
         -6.8424e-02,  2.0117e-01,  3.9346e-02],
        [ 2.7558e-01,  3.6094e-01,  1.9814e-01,  2.6108e-01,  6.1972e-02,
         -1.7504e-01,  2.0692e-01,  5.0491e-02],
        [-3.1181e-01,  2.4612e-01,  6.7823e-01,  3.5820e-01,  1.6731e-01,
          1.9301e-01,  2.3810e-01, -2.9216e-02],
        [ 1.4686e-01, -3.7700e-01,  6.1710e-02, -3.0096e-01, -1.1654e-02,
         -1.7444e-01, -1.8205e-01, -1.8102e-01],
        [-2.8207e-02,  2.5883e-01,  2.5952e-01,  3.9955e-01,  3.1606e-01,
         -4.3959e-02,  2.7664e-01,  2.2962e-01],
        [-2.0287e-02, -8.0156e-02,  2.9883e-02, -2.0479e-01,  1.5436e-01,
          1.5329e-01,  8.7683e-02, -2.2092e-01],
        [-2.7629e-02, -1.1111e-01,  4.6362e-01, -3.8210e-01,  3.7044e-01,
          9.8061e-02,  4.9006e-01,  1.0633e-01],
        [ 1.6203e-02, -3.7037e-01, -1.9086e-01, -1.6606e-01, -4.7586e-01,
          2.1014e-01, -3.8909e-01, -2.9848e-01],
        [ 4.8196e-01,  4.2417e-01, -7.1964e-02,  1.4005e-01,  1.2951e-01,
         -1.4491e-01,  1.7197e-01, -5.0444e-01],
        [-2.6611e-01,  3.3110e-01,  6.0315e-01, -3.0205e-01, -1.1959e-02,
         -1.7034e-01, -2.9670e-01, -3.9399e-01],
        [ 2.4148e-01,  4.8571e-01, -1.4669e-01, -3.3760e-01,  5.3761e-02,
         -2.5887e-01,  2.0742e-01, -3.4727e-01],
        [ 2.0447e-02,  6.8393e-02,  7.5855e-02,  8.7222e-02,  1.9779e-02,
         -6.5827e-02, -7.6425e-03, -4.8846e-02],
        [ 3.0362e-02,  4.4010e-02, -1.3923e-01, -1.5471e-01, -8.2355e-02,
          2.7310e-01, -3.3669e-01, -3.2195e-01],
        [ 1.7347e-01, -4.0381e-01,  5.8721e-02, -2.9939e-01, -2.2340e-01,
          2.1560e-01, -2.3956e-01, -4.0519e-01],
        [ 1.7414e-01, -7.6042e-02,  3.8025e-01, -3.5465e-02,  1.0331e-01,
         -3.7166e-01,  1.5973e-01,  9.6025e-02],
        [-5.0752e-02,  2.6819e-01, -1.4929e-02,  1.2087e-01, -2.2626e-02,
          9.4784e-03, -2.4487e-02, -1.5820e-01],
        [ 1.3376e-01, -7.6538e-02,  5.6149e-02,  2.1167e-01,  2.3148e-01,
          1.7110e-01,  1.2991e-01, -4.7134e-01],
        [ 1.9815e-01, -1.5010e-01,  1.3837e-01, -2.1329e-01, -7.4328e-01,
         -1.0822e-01, -2.6373e-01, -3.5914e-01]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[ 9.4313e-06,  9.2981e-06,  1.7071e-06, -8.8708e-06,  1.0446e-06,
          3.7417e-07,  2.6358e-07, -8.2740e-06],
        [ 2.4341e-06,  2.2616e-06,  1.1684e-07, -2.2834e-06,  3.4523e-07,
         -7.1592e-09,  1.7914e-07, -2.1144e-06],
        [ 4.6789e-06,  4.9964e-06,  3.0891e-06, -5.0556e-06,  8.4233e-07,
          7.1479e-07,  1.8706e-07, -5.1328e-06],
        [ 1.4877e-05,  7.5547e-06, -1.1716e-05, -1.5725e-05,  1.5004e-05,
         -5.6770e-06,  1.9458e-05, -2.7076e-05],
        [-1.1989e-05,  4.6827e-05,  1.7179e-04,  1.1470e-05,  1.8991e-05,
          6.6469e-05, -4.1467e-05,  1.9568e-05],
        [ 5.6043e-03, -1.2566e-05,  4.3732e-03, -1.2397e-02, -5.5502e-03,
          1.6259e-03,  1.6281e-04, -1.9254e-02],
        [ 1.2167e-05,  1.2756e-05,  6.2177e-06, -1.2602e-05,  1.7373e-06,
          1.4032e-06,  4.2429e-07, -1.2650e-05],
        [ 1.2058e-05,  1.2412e-05,  5.8416e-06, -1.2634e-05,  1.4734e-06,
          1.2564e-06,  4.2055e-07, -1.2751e-05],
        [ 1.5787e-06,  1.8798e-06,  2.3468e-06, -1.8768e-06,  8.3088e-07,
          8.0165e-07,  9.0658e-08, -2.0761e-06],
        [ 6.8483e-02,  6.6239e-02,  2.8792e-02, -7.6273e-02, -1.7838e-03,
          4.0007e-03,  1.1079e-03, -8.0620e-02],
        [ 5.9649e-06,  6.5526e-06,  3.9269e-06, -6.3928e-06,  9.7754e-07,
          7.5577e-07,  2.2513e-07, -6.3938e-06],
        [-5.1483e-03, -2.1227e-03, -7.1014e-03,  1.0843e-02,  8.0223e-03,
         -1.9284e-03,  3.3400e-03,  1.4785e-02],
        [ 6.9270e-06,  7.1625e-06,  2.4085e-06, -6.7216e-06,  7.8619e-07,
          5.3456e-07,  6.9297e-08, -6.3783e-06],
        [ 7.3735e-03,  1.2054e-03, -4.8142e-03, -1.0643e-02,  3.9545e-03,
         -1.9509e-03,  8.5159e-03, -1.8524e-02],
        [ 6.7353e-06,  6.8003e-06,  2.4755e-06, -6.8284e-06,  6.2802e-07,
          4.8744e-07,  1.2223e-07, -6.6534e-06],
        [ 3.0787e-03,  3.2823e-04,  1.2412e-03, -6.0266e-03, -9.0472e-04,
          4.0105e-04,  1.6069e-03, -9.7428e-03],
        [ 1.1775e-06,  1.3327e-06,  7.9363e-07, -1.1535e-06,  4.1442e-07,
          2.1469e-07, -9.2485e-09, -9.2479e-07],
        [ 2.4903e-03,  3.9678e-03,  3.5287e-03, -3.4009e-03, -2.9356e-04,
         -3.3464e-04,  8.0588e-05, -3.3352e-03],
        [ 5.5996e-02,  4.4495e-02,  1.8473e-03, -5.9881e-02,  9.9828e-03,
         -6.4608e-04,  1.2349e-02, -6.7429e-02],
        [-1.3686e-01, -1.4317e-01, -6.2399e-02,  1.3807e-01, -2.2961e-02,
         -1.4719e-02, -7.7425e-03,  1.3857e-01],
        [-4.9687e-05, -6.1622e-04, -3.6841e-03,  2.3437e-04, -3.7251e-04,
         -1.8693e-03,  1.1478e-03,  2.2821e-04],
        [ 6.7438e-06,  7.4888e-06,  5.4275e-06, -7.7295e-06,  3.1360e-07,
          9.8796e-07, -2.3030e-07, -7.8344e-06],
        [ 1.5680e-06,  1.8374e-06,  5.8743e-07, -1.3567e-06,  5.8951e-07,
          5.5354e-08,  1.6403e-07, -1.0693e-06],
        [-5.5660e-04, -5.0276e-03, -1.6030e-02,  6.1042e-03,  2.7847e-03,
         -5.7620e-04,  5.2753e-04,  8.8260e-03],
        [ 3.8314e-06,  4.1643e-06,  2.5692e-06, -4.0520e-06,  6.5615e-07,
          6.4261e-07,  1.3349e-07, -4.2023e-06],
        [ 1.3850e-05,  1.1973e-05, -7.4043e-06, -2.2801e-05,  4.1712e-05,
         -1.8068e-05,  5.1430e-05, -4.7636e-05],
        [-2.8800e-04, -5.6563e-04, -1.3742e-03,  7.3707e-04, -1.9530e-03,
         -8.3008e-05, -1.7451e-03,  1.9138e-03],
        [ 8.3594e-06,  8.0391e-06,  2.4297e-06, -8.5562e-06,  5.5966e-07,
          5.0412e-07,  2.4352e-07, -8.5758e-06],
        [-7.5560e-03, -9.2842e-03, -8.4383e-03,  9.8612e-03,  1.1190e-03,
         -6.6685e-04,  5.9821e-04,  1.0383e-02],
        [-1.0417e-03,  1.5471e-03,  6.1471e-03, -1.0840e-03,  5.7437e-04,
         -5.7635e-04,  5.5314e-04, -6.3920e-04],
        [ 1.3987e-05,  1.4207e-05,  5.9292e-06, -1.4143e-05,  2.0991e-06,
          1.5800e-06,  5.5614e-07, -1.4183e-05],
        [-7.5128e-02, -7.9006e-02, -1.2920e-02,  6.5128e-02, -1.5897e-02,
         -2.3709e-03, -9.0034e-05,  4.9111e-02],
        [ 3.3858e-03, -5.9719e-04, -1.5843e-02,  5.9030e-04, -5.3095e-03,
         -3.6935e-03, -3.5158e-03,  6.1534e-03],
        [ 1.0238e-05,  1.0169e-05,  2.1544e-06, -9.6590e-06,  1.0550e-06,
          5.2272e-07,  2.0235e-07, -9.0924e-06],
        [-2.0835e-02, -2.3892e-02, -1.3768e-02,  2.5143e-02,  2.0801e-03,
          1.4459e-03, -5.8224e-04,  2.5424e-02],
        [-1.5862e-04,  1.0821e-05,  4.9681e-03,  2.7841e-03,  1.3894e-02,
          5.9216e-03,  5.2779e-03,  2.7561e-04],
        [ 8.6349e-04,  1.7161e-02,  7.7693e-02, -7.6208e-03,  3.0982e-02,
          3.2490e-02,  3.4211e-03, -2.2287e-02],
        [ 3.0028e-03,  7.6304e-04, -2.7820e-03, -3.8086e-03,  2.6371e-03,
         -1.3008e-03,  4.2991e-03, -6.9202e-03],
        [-3.2562e-03, -2.6420e-03, -1.5942e-02,  1.3906e-02,  1.4328e-02,
         -1.6727e-03,  6.1639e-03,  1.8600e-02],
        [ 6.2084e-03,  1.2308e-02,  1.5984e-02, -1.1601e-02, -1.4287e-03,
         -2.2038e-03,  1.4947e-03, -1.2537e-02],
        [ 8.7605e-02,  8.9525e-02,  4.9963e-02, -9.2602e-02,  7.9637e-03,
          1.5972e-02,  9.1095e-05, -9.9464e-02],
        [-4.9475e-04,  1.3594e-02,  5.7780e-02, -1.0158e-02,  8.3834e-03,
          1.6047e-02, -2.7948e-03, -1.6188e-02],
        [ 8.5230e-06,  8.4662e-06,  3.0628e-06, -8.5857e-06,  8.1264e-07,
          8.1613e-07,  1.7457e-07, -8.6203e-06],
        [ 7.8773e-04,  2.1336e-04, -7.3928e-04, -9.7093e-04,  6.8328e-04,
         -3.3587e-04,  1.0997e-03, -1.7573e-03],
        [-1.7123e-06, -1.9596e-06, -2.4188e-06,  2.0417e-06, -5.7755e-07,
         -9.0338e-07,  1.2334e-07,  2.2321e-06],
        [-2.4168e-03,  1.9470e-02,  9.1038e-02, -1.2718e-02,  2.6296e-02,
          2.7879e-02,  3.4988e-03, -2.5338e-02],
        [ 1.3175e-02, -1.6323e-03,  3.9145e-03, -2.7205e-02, -3.7587e-03,
          2.4241e-03,  8.3764e-03, -4.6276e-02],
        [-2.9643e-07,  7.4293e-08,  1.0229e-06,  2.5604e-08, -9.0993e-09,
          9.1001e-08, -8.3714e-09, -9.8302e-08],
        [ 5.0468e-06,  5.2332e-06,  1.9544e-06, -4.7506e-06,  7.6767e-07,
          6.8424e-07, -5.5794e-08, -4.4889e-06],
        [ 7.3323e-03,  9.3006e-03,  8.4724e-03, -8.4836e-03,  1.7318e-03,
          1.8029e-03,  3.1036e-04, -8.9140e-03],
        [ 2.6566e-06,  2.6471e-06,  9.7156e-08, -2.5176e-06,  1.2490e-07,
         -2.5524e-07,  1.1554e-07, -2.1567e-06],
        [ 1.6759e-02, -7.2613e-04,  4.6279e-03, -3.3630e-02, -8.1746e-03,
          2.4370e-03,  7.1074e-03, -5.4546e-02],
        [ 2.7304e-03,  6.9003e-04, -2.6952e-03, -3.5083e-03,  2.8498e-03,
         -1.3696e-03,  4.4255e-03, -6.5534e-03],
        [ 3.6151e-06,  3.9143e-06,  2.1310e-06, -3.7502e-06,  7.0401e-07,
          4.6360e-07,  1.3478e-07, -3.6516e-06],
        [ 4.5217e-04,  1.7091e-04, -5.6862e-04, -5.8611e-04,  8.5781e-04,
         -4.1762e-04,  1.1660e-03, -1.2355e-03],
        [-6.6612e-04,  1.2104e-03,  5.3870e-03, -1.3080e-03, -3.6870e-04,
         -1.7587e-04,  1.1684e-04, -1.6178e-03],
        [ 5.8674e-06,  6.4721e-06,  5.0985e-06, -6.6188e-06,  9.7043e-07,
          1.2965e-06,  7.1321e-09, -6.8993e-06],
        [ 2.3365e-04,  4.8018e-05, -3.2117e-05, -4.7557e-04,  2.1280e-04,
         -1.2308e-04,  4.5684e-04, -8.7716e-04],
        [ 3.0929e-05,  1.0882e-05,  1.9155e-05, -5.0803e-05, -3.3953e-05,
          1.1729e-05, -1.7195e-05, -6.5844e-05],
        [-7.4238e-03, -1.9234e-03, -5.9296e-03,  1.4880e-02,  1.1477e-02,
         -1.9244e-03,  4.4885e-03,  1.9855e-02],
        [-4.6991e-07,  1.3010e-07, -1.2321e-06,  1.3812e-06,  2.4541e-07,
         -6.0040e-07, -2.6901e-07,  2.6967e-06],
        [ 2.3107e-03,  5.9361e-04, -2.2914e-03, -2.9652e-03,  2.4493e-03,
         -1.1773e-03,  3.7845e-03, -5.5525e-03],
        [ 1.0636e-02, -1.3193e-04,  6.1408e-03, -2.3538e-02, -5.9862e-03,
          1.1575e-03,  5.4228e-03, -3.8636e-02],
        [-2.6878e-06, -2.4554e-06, -1.1959e-06,  2.6719e-06, -1.2056e-06,
         -7.1975e-07, -4.9553e-07,  3.0148e-06],
        [-2.1616e-03,  2.1499e-03,  3.2041e-02, -6.3991e-03,  7.0999e-03,
          1.0638e-02,  6.8615e-04, -1.2433e-02],
        [ 8.4869e-04,  8.0736e-03,  9.4402e-03, -1.8033e-03, -7.5481e-03,
         -2.0263e-03, -6.5123e-03,  4.4838e-03],
        [-5.2888e-04,  2.5512e-04, -6.9850e-04,  1.5046e-03,  8.5329e-04,
         -4.4133e-04,  2.2996e-04,  2.3144e-03],
        [-5.3978e-06, -5.5929e-06, -4.2689e-06,  6.4354e-06, -8.2523e-07,
         -9.3904e-07, -3.8909e-07,  7.0464e-06],
        [ 3.2082e-03,  7.6461e-04, -3.2324e-03, -4.1608e-03,  3.4826e-03,
         -1.6487e-03,  5.3654e-03, -7.8368e-03],
        [ 1.8710e-02,  3.6768e-04,  1.3808e-02, -4.1786e-02, -1.5052e-02,
          3.5419e-03,  4.8351e-03, -6.6461e-02],
        [ 1.5500e-01,  1.4661e-01,  3.3722e-02, -1.5226e-01,  1.4910e-02,
          1.2460e-02,  5.7756e-03, -1.5375e-01],
        [-4.2464e-03, -5.0851e-03, -4.0543e-03,  5.3898e-03,  1.2719e-03,
         -1.6678e-04,  3.8075e-04,  6.1432e-03],
        [ 2.9419e-06,  3.1657e-06,  1.4139e-06, -2.9053e-06,  6.3776e-07,
          3.0826e-07,  1.5434e-07, -2.7695e-06],
        [ 4.9589e-04, -1.4041e-04,  6.2234e-04, -1.4579e-03, -4.1484e-04,
          1.9189e-04,  2.5139e-04, -2.3874e-03],
        [ 5.4162e-03,  8.8052e-04, -2.9657e-03, -8.5695e-03,  3.4320e-03,
         -1.7360e-03,  7.3046e-03, -1.5213e-02],
        [-5.1996e-03, -1.5205e-03, -6.4999e-03,  1.1082e-02,  8.3747e-03,
         -2.1162e-03,  3.4866e-03,  1.5253e-02],
        [-1.6564e-06, -1.4576e-06,  4.3969e-07,  1.4936e-06,  1.9741e-07,
          1.9787e-07,  1.4076e-08,  1.3527e-06],
        [ 1.9487e-02,  1.4578e-02,  1.2681e-03, -2.1851e-02,  2.1291e-03,
          1.2831e-04,  4.0268e-03, -2.5697e-02],
        [-8.0398e-02, -8.8519e-02, -4.2358e-02,  7.9017e-02, -1.7348e-02,
         -1.0009e-02, -3.6590e-03,  7.5522e-02],
        [ 4.2860e-03, -8.1040e-05,  7.3785e-03, -1.4023e-02,  9.5112e-04,
         -9.2634e-04,  6.7848e-03, -2.2209e-02],
        [ 1.6513e-05, -6.5559e-06, -9.7346e-05,  3.3943e-05,  4.6631e-05,
          3.6316e-06,  1.1103e-05,  5.5794e-05],
        [ 1.1158e-05,  1.1658e-05,  5.8354e-06, -1.1502e-05,  1.8114e-06,
          1.4873e-06,  3.3530e-07, -1.1480e-05],
        [ 6.6595e-06,  7.1626e-06,  4.2750e-06, -6.8665e-06,  1.5946e-06,
          1.2292e-06,  2.6336e-07, -6.8617e-06],
        [ 9.6491e-06,  1.0199e-05,  5.8223e-06, -1.0104e-05,  1.5477e-06,
          1.5719e-06,  1.5502e-07, -1.0202e-05],
        [ 1.2376e-01,  1.1329e-01,  2.2991e-02, -1.2488e-01,  1.1505e-02,
          5.0212e-03,  4.8563e-03, -1.2153e-01],
        [-3.4382e-04, -2.0636e-03, -7.5127e-03,  1.1736e-03, -1.9554e-03,
         -2.7929e-03,  1.7423e-04,  2.2914e-03],
        [ 5.5154e-02,  5.4422e-02,  2.4220e-02, -6.1341e-02,  8.3852e-04,
          3.0887e-03,  5.3761e-04, -6.1832e-02],
        [ 3.3975e-05,  1.1656e-05, -5.5952e-05, -5.3947e-05,  1.1408e-04,
         -5.3572e-05,  1.4855e-04, -1.3176e-04],
        [ 7.2343e-06,  7.6360e-06,  3.8984e-06, -7.4013e-06,  1.2240e-06,
          1.0164e-06,  2.4469e-07, -7.4636e-06],
        [-3.9089e-02, -2.9998e-02, -1.1268e-02,  4.4229e-02, -9.4760e-03,
         -6.5870e-03, -8.5110e-03,  5.4608e-02],
        [ 4.3588e-03,  7.8525e-03,  4.0589e-02, -1.3871e-02,  6.4011e-03,
          1.6171e-02, -2.9254e-04, -2.5726e-02],
        [ 1.5055e-02,  9.4028e-04,  3.8952e-03, -2.8847e-02, -6.9483e-03,
          1.6431e-03,  5.8807e-03, -4.5911e-02],
        [ 1.1421e-03,  8.9300e-03,  3.7773e-02, -6.7415e-03,  7.8129e-03,
          1.3562e-02, -1.3266e-03, -1.3092e-02],
        [-1.4760e-06, -1.3287e-06, -3.8740e-07,  1.5471e-06,  1.9879e-08,
         -1.5517e-07,  1.4743e-08,  1.6408e-06],
        [-1.9506e-03, -4.5493e-03, -2.4260e-03,  1.5697e-03, -1.0921e-03,
          1.2981e-03, -1.2928e-03,  1.2907e-03],
        [-2.2059e-05, -9.3475e-06,  6.2320e-05,  6.7899e-05, -2.1128e-04,
          9.8997e-05, -2.6745e-04,  1.9910e-04],
        [ 9.0335e-06,  8.9425e-06,  2.5051e-06, -9.0510e-06,  5.7616e-07,
          3.6932e-07,  1.7051e-07, -8.7487e-06],
        [ 3.1434e-06,  3.0194e-06,  1.0546e-06, -3.1804e-06,  3.6213e-07,
          3.4146e-07,  1.2189e-07, -3.2692e-06],
        [ 4.2956e-06,  4.8776e-06,  3.5427e-06, -4.5252e-06,  1.1400e-06,
          9.8466e-07,  1.3342e-07, -4.5864e-06],
        [-3.6857e-04, -8.8416e-04, -2.7235e-03,  1.0026e-03, -2.5530e-03,
         -5.9974e-04, -1.9353e-03,  2.5377e-03]], device='cuda:0') 

model.module_15.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.2200, -0.0259,  0.0138,  0.0127,  0.0714,  0.2347, -0.0523, -0.0667,
        -0.1167, -0.2071, -0.0225, -0.2971, -0.4017,  0.0984, -0.2489,  0.2695,
        -0.0026, -0.2060,  0.1078,  0.3487,  0.0272, -0.1686, -0.0482, -0.2905,
        -0.1094,  0.0357, -0.0710, -0.2266, -0.6589, -0.3021, -0.3518,  0.3413,
         0.0187, -0.5509, -0.4885,  0.0718,  0.1375,  0.0170,  0.0718,  0.0618,
        -0.2177, -0.1350, -0.4309,  0.0657,  0.0407,  0.1458,  0.3670, -0.0318,
        -0.4283, -0.0176, -0.0070,  0.2939, -0.0102, -0.0090, -0.0031, -0.1852,
        -0.0723,  0.1242, -0.0180, -0.1014, -0.0372,  0.0388,  0.2710, -0.6610,
         0.2229,  0.0087,  0.0883, -0.6636,  0.0601,  0.4418, -0.2554, -0.3346,
        -0.0232,  0.0732,  0.1161, -0.1323, -0.0580,  0.1140,  0.3488,  0.1762,
        -0.0203, -0.0844, -0.1934, -0.2386, -0.0792,  0.0242, -0.1728,  0.0544,
        -0.1578,  0.1447,  0.3147,  0.2524,  0.1301, -0.0554,  0.2145, -0.0173,
        -0.2774, -0.0680,  0.0272, -0.0395], device='cuda:0',
       requires_grad=True) 
grad:  tensor([-4.4509e-06, -1.9337e-06, -5.7726e-06, -1.6991e-04,  3.1879e-04,
        -7.0516e-02, -1.2202e-05, -1.3270e-05, -3.8347e-06, -1.0117e-01,
        -5.8520e-06,  2.7991e-02, -3.0046e-06, -1.0481e-01, -5.1607e-06,
        -4.2716e-02,  2.4104e-07,  1.1736e-03, -1.7642e-01,  1.4193e-01,
        -3.7925e-03, -5.7435e-06,  5.1080e-07,  9.7161e-03, -4.4821e-06,
        -3.8500e-04,  1.4894e-02, -9.0668e-06,  5.4661e-03,  2.0367e-03,
        -1.4701e-05, -4.6261e-02,  4.4375e-02, -4.7255e-06,  1.6718e-02,
        -4.3449e-02, -1.1039e-01, -4.3209e-02,  2.2061e-02, -7.3353e-03,
        -1.2008e-01, -2.6733e-02, -8.2112e-06, -1.0940e-02,  3.1901e-06,
        -9.9941e-02, -2.1792e-01,  9.2202e-09, -1.6432e-06, -8.5897e-03,
        -3.1392e-08, -2.3611e-01, -4.2782e-02, -3.0509e-06, -9.4771e-03,
        -1.0064e-03, -7.6099e-06, -5.2276e-03, -1.1838e-04,  4.0109e-02,
         1.2404e-05, -3.6380e-02, -1.6641e-01,  7.8902e-06, -6.0231e-02,
         8.2140e-02,  8.6408e-03,  1.2148e-05, -5.1776e-02, -2.6171e-01,
        -1.7644e-01,  3.8879e-03, -1.9543e-06, -1.0685e-02, -8.7949e-02,
         3.1379e-02,  1.2487e-07, -7.0440e-02,  4.7809e-02, -1.1234e-01,
         7.8644e-05, -1.1081e-05, -7.1042e-06, -9.9099e-06, -1.3680e-01,
         6.1606e-03, -6.6906e-02, -1.1515e-03, -7.2337e-06,  1.6706e-01,
        -9.5671e-02, -1.9233e-01, -3.6709e-02,  2.1712e-06, -5.4174e-03,
         1.9762e-03, -6.3384e-06, -4.0599e-06, -4.4254e-06,  1.8195e-02],
       device='cuda:0') 

model.module_17.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[ 0.0670, -0.0544,  0.1082,  ...,  0.1576,  0.0229,  0.0107],
        [-0.1469, -0.0267, -0.0217,  ...,  0.1203,  0.1639, -0.1087],
        [ 0.0699,  0.0729,  0.1068,  ...,  0.0648,  0.0247, -0.1794],
        ...,
        [ 0.0011,  0.0684,  0.0948,  ...,  0.1561,  0.0028, -0.3762],
        [ 0.0689,  0.0870, -0.0111,  ..., -0.0640, -0.1769,  0.2070],
        [ 0.1176,  0.1320, -0.0215,  ..., -0.0093, -0.1445, -0.1109]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-1.1249e-06, -2.9992e-07, -1.1720e-07,  ..., -3.4947e-07,
         -2.9190e-07, -1.8600e-06],
        [ 1.7002e-07,  7.9462e-08,  1.0120e-07,  ...,  5.0797e-08,
          1.2054e-07, -3.1934e-06],
        [ 3.0207e-10,  9.2314e-11,  1.3298e-10,  ...,  1.3494e-10,
          1.5491e-10, -1.8460e-10],
        ...,
        [ 2.6395e-06,  6.4012e-07,  2.9868e-07,  ...,  7.7141e-07,
          5.6550e-07, -6.6410e-05],
        [ 2.0690e-10,  6.2310e-11,  8.5027e-11,  ...,  8.9788e-11,
          8.9469e-11,  2.3061e-09],
        [ 2.3377e-10,  7.2601e-11,  1.0637e-10,  ...,  1.0727e-10,
          1.2941e-10, -1.8204e-09]], device='cuda:0') 

model.module_17.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.0429,  0.0911, -0.0894, -0.3764, -0.2673, -0.0337, -0.0687, -0.1265,
         0.0030, -0.1531, -0.0851, -0.1146, -0.0565,  0.0403, -0.1726, -0.0763,
        -0.3955, -0.2856, -0.1042, -0.0434,  0.1847, -0.2530, -0.2476, -0.1118,
        -0.0524,  0.0008,  0.1180, -0.1519,  0.0535, -0.2359, -0.1799, -0.1154,
        -0.2970, -0.1412, -0.0816,  0.0338,  0.0683, -0.0592, -0.0767,  0.1020,
        -0.3681, -0.1244, -0.0623, -0.2977, -0.0824, -0.2597, -0.1118, -0.1270,
        -0.4944, -0.3318, -0.2694, -0.3826, -0.1600, -0.0225, -0.2322, -0.1650,
        -0.0284,  0.0376, -0.2537,  0.0646, -0.1803, -0.0199,  0.0779, -0.2138,
        -0.2227, -0.3040, -0.1301, -0.0538,  0.1557, -0.2924,  0.0048,  0.1601,
        -0.0752, -0.1534, -0.0922, -0.1398, -0.0521, -0.1587, -0.1638, -0.1507,
        -0.3332, -0.0918, -0.1138,  0.0790,  0.0885,  0.2005, -0.1444, -0.0153,
        -0.2365, -0.1188,  0.0157, -0.1348,  0.0141, -0.2535, -0.1020,  0.1119,
         0.0684,  0.0321, -0.0897, -0.0385], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 3.0481e-02, -1.8030e-04, -5.2343e-06, -5.6027e-06,  1.2445e-06,
         2.5822e-06, -3.7660e-06,  3.3731e-06, -1.5160e-02,  1.6547e-06,
        -2.0124e-02, -1.1358e-06,  3.1854e-06, -1.1979e-01, -1.2645e-05,
        -2.3339e-02,  2.8057e-03, -7.5778e-04, -7.4883e-04, -7.1751e-06,
        -4.0764e-02, -1.3408e-03, -5.9266e-06,  6.1858e-03, -7.8120e-07,
        -2.7392e-01, -1.0860e-01, -2.1053e-06, -1.7428e-02,  1.6236e-03,
        -1.3378e-02, -2.6349e-06,  1.4885e-05,  6.4518e-06, -1.6021e-06,
        -3.9885e-02, -1.1413e-01, -2.2851e-06,  1.3467e-06, -2.5906e-03,
         1.5812e-06,  5.4079e-06, -2.0553e-04,  3.9579e-06,  2.0781e-06,
        -1.2557e-03, -2.6323e-06,  7.0524e-03,  5.2598e-03,  1.3360e-02,
        -5.5842e-06,  2.2584e-04,  5.5536e-06, -9.4999e-03, -6.2140e-07,
         6.2209e-06,  7.6269e-07,  7.1572e-03, -1.1023e-06, -7.6135e-03,
        -6.5036e-06, -2.9345e-06, -5.2595e-02,  1.3029e-02,  4.4160e-04,
        -3.1113e-03, -1.1971e-01, -1.5802e-06, -1.9062e-02,  6.3600e-05,
        -1.0436e-01, -2.6599e-02, -7.6580e-06,  3.9591e-07,  5.2699e-06,
         1.0309e-03, -5.4268e-06,  1.9830e-06, -3.8595e-06, -3.7176e-03,
        -1.6114e-02,  1.9535e-03,  1.1998e-05, -6.1920e-02, -2.2304e-01,
        -5.0484e-02,  2.2825e-06, -5.3465e-02, -3.0414e-04, -1.1560e-06,
        -1.7927e-03, -4.5325e-06, -1.1637e-02, -1.0051e-05, -1.2512e-06,
        -7.0478e-02,  5.2622e-05, -9.8998e-02, -2.8139e-06, -4.0025e-06],
       device='cuda:0') 

model.module_19.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[-0.2985, -0.0346,  0.0435,  ...,  0.0243,  0.1026,  0.1400],
        [-0.0083,  0.0032,  0.0220,  ...,  0.0219,  0.0557,  0.0656],
        [-0.0219, -0.2071,  0.1022,  ...,  0.0934, -0.0618,  0.0964],
        ...,
        [ 0.0874, -0.0928, -0.0126,  ...,  0.1768, -0.0823, -0.1068],
        [-0.0547, -0.0234,  0.0716,  ..., -0.1744,  0.0383, -0.0133],
        [ 0.1567, -0.4087,  0.0971,  ..., -0.1186, -0.0037, -0.0373]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-2.3801e-03,  7.6108e-03,  6.3037e-06,  ...,  3.0865e-03,
          1.2405e-05,  4.7246e-06],
        [-2.4736e-06,  2.0114e-04, -2.7965e-07,  ...,  3.3581e-03,
         -4.0287e-07, -2.2509e-07],
        [-8.0170e-05,  2.4234e-03,  7.3689e-06,  ...,  2.5387e-03,
          1.4430e-05,  5.6829e-06],
        ...,
        [ 1.3171e-03, -3.8572e-03,  4.2077e-06,  ..., -1.1083e-01,
          4.6930e-06,  3.5658e-06],
        [-2.5364e-05,  7.4690e-03,  8.8211e-06,  ..., -1.0887e-02,
          1.8464e-05,  6.4264e-06],
        [ 7.7175e-05, -9.3573e-05, -5.9569e-07,  ...,  4.6307e-04,
         -1.0847e-06, -4.6653e-07]], device='cuda:0') 

model.module_19.bias 16 torch.Size([16])
Parameter containing:
tensor([ 0.1723, -0.1951,  0.1037, -0.1697, -0.4345,  0.0331,  0.1196,  0.2988,
        -0.1111,  0.1428, -0.1648,  0.1087, -0.0861,  0.0483,  0.2226, -0.3382],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-0.3392,  0.0131, -0.3728,  0.0136,  0.0218, -0.0448, -0.0291, -0.2653,
        -0.0005,  0.0076,  0.0055, -0.1039, -0.0065, -0.2284, -0.4478,  0.0246],
       device='cuda:0') 

