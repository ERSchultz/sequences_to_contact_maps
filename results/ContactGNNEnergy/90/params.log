#### INITIAL PARAMETERS ####
W torch.Size([16, 16])
Parameter containing:
tensor([[-0.4302,  0.3687,  0.9997, -0.5315,  0.2587, -1.8771,  0.0354, -0.1098,
          0.5318,  0.4770,  0.8545,  1.9892,  0.1874, -0.0602,  0.0605,  1.0036],
        [-0.0509, -1.1180, -0.6479, -0.9024,  1.6939, -0.5068, -0.6197,  0.0553,
         -0.7579,  0.9126, -0.6797, -1.5200, -0.6306,  0.1642,  0.8298, -0.0099],
        [ 0.5138,  0.8090,  0.7490,  0.7136, -1.7597,  0.4196, -1.6468, -1.6494,
         -0.9853,  1.0660, -1.0165, -0.1740,  0.0920,  0.0711,  0.2465,  0.0279],
        [-0.3550, -1.1083, -0.8363,  0.2644, -0.4524, -1.2884, -0.3272,  0.1582,
         -0.0572, -0.1943, -0.3406,  0.1606,  1.8108, -0.5807,  0.7546, -2.4746],
        [ 0.7404, -0.6631,  2.2499,  0.3662,  1.0253,  0.4002,  0.3449, -0.1774,
         -0.9444, -1.1926,  1.7913, -0.7337,  0.2869,  0.5506, -0.1002,  1.3686],
        [-0.7237, -0.8309,  0.7761, -0.9057,  0.1455, -0.0898,  0.1767, -1.2597,
         -0.1483, -0.0254,  0.0058,  1.1066,  0.7200,  0.0846,  0.9092,  0.1236],
        [ 1.0233,  0.1312,  1.2629, -0.4656,  1.2234, -0.8773, -0.3385, -0.4783,
          0.0750, -0.2637, -0.9865,  1.3847, -0.7035,  1.2508, -1.0840,  1.2586],
        [ 0.1273,  0.2554,  0.8209, -0.3454, -0.2103, -0.9320,  0.5793, -0.4634,
          0.6938,  0.6985,  1.7294, -0.8537,  0.4289, -0.8783, -0.2913, -0.4424],
        [ 0.0663, -1.2942, -1.0915,  0.3428, -1.0596, -0.5278, -0.6353,  1.8757,
         -3.0936, -1.7709, -0.6082,  1.5911, -2.5802,  0.1412, -0.0818, -0.6422],
        [ 0.7586,  1.0863,  0.9513, -0.6014,  1.4494, -2.6784, -0.4512,  0.5662,
         -1.5024,  0.4728, -0.2670, -0.2529, -0.6152, -0.6547, -0.5988,  0.1134],
        [-0.6253,  0.3280, -0.2258, -1.4381,  0.0868,  0.4622,  0.5160,  0.1490,
         -0.8435,  2.0036, -0.8173,  1.6728, -1.0500, -0.5932,  0.5634,  0.4628],
        [-1.5930, -0.9079, -0.4167,  0.2177, -0.0195,  0.3395, -0.6057,  1.6921,
         -1.0462, -0.2805,  0.0358,  0.6549, -0.2078, -0.5423, -1.0097, -0.9926],
        [-0.2325,  0.4165,  0.5214, -1.9139,  1.2638, -0.3496, -0.1001, -1.2562,
          2.9700, -1.2055,  0.4904, -0.5113,  0.0605, -0.9475,  1.0742,  0.3113],
        [ 1.0038, -1.1845,  1.0597, -1.3078,  0.8231,  1.8300,  1.2250, -1.2046,
         -1.8280,  0.6049, -0.6198, -0.8339, -0.9242,  0.3385,  0.2359, -1.3993],
        [-0.8548, -0.8408, -0.6414,  0.8846,  0.4203, -1.3742, -0.6026, -1.6693,
         -1.1850, -0.2326,  0.7188,  1.0783, -2.3696, -0.0140,  2.1216,  1.6650],
        [ 0.1255,  0.8953,  1.5457,  1.9523, -0.2798, -1.0217, -0.4126,  0.1354,
         -0.6747, -0.6496, -0.8285, -0.9308,  0.5570, -0.8284, -0.7417,  0.1958]],
       device='cuda:0', requires_grad=True) 

act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

inner_act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

out_act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

encoder.module_0.weight torch.Size([100, 3])
Parameter containing:
tensor([[ 0.4414,  0.4792, -0.1353],
        [ 0.5304, -0.1265,  0.1165],
        [-0.2811,  0.3391,  0.5090],
        [-0.4236,  0.5018,  0.1081],
        [ 0.4266,  0.0782,  0.2784],
        [-0.0815,  0.4451,  0.0853],
        [-0.2695,  0.1472, -0.2660],
        [-0.0677, -0.2345,  0.3830],
        [-0.4557, -0.2662, -0.1630],
        [-0.3471,  0.0545, -0.5702],
        [ 0.5214, -0.4904,  0.4457],
        [ 0.0961, -0.1875,  0.3568],
        [ 0.0900,  0.4665,  0.0631],
        [-0.1821,  0.1551, -0.1566],
        [ 0.2430,  0.5155,  0.3337],
        [-0.2524,  0.3333,  0.1033],
        [ 0.2932, -0.3519, -0.5715],
        [-0.2231, -0.4428,  0.4737],
        [ 0.1663,  0.2391,  0.1826],
        [-0.0100,  0.4518, -0.4102],
        [ 0.0364, -0.3941,  0.1780],
        [-0.1988,  0.1769, -0.1203],
        [ 0.4788, -0.3422, -0.3443],
        [-0.3444,  0.5193,  0.1924],
        [ 0.5556, -0.4765, -0.5727],
        [-0.4517, -0.3884,  0.2339],
        [ 0.2067,  0.4797, -0.2982],
        [-0.3936,  0.3063, -0.2334],
        [ 0.3504, -0.1370,  0.3303],
        [-0.4486, -0.2914,  0.1760],
        [ 0.1221, -0.1472,  0.3441],
        [ 0.3925, -0.4187, -0.3082],
        [ 0.5287, -0.1948, -0.2047],
        [-0.5586, -0.3306,  0.1442],
        [-0.0762, -0.4191,  0.0135],
        [-0.3944, -0.4898, -0.3179],
        [-0.5053, -0.3676,  0.5771],
        [ 0.1090,  0.1779, -0.5385],
        [-0.3792, -0.1922,  0.0903],
        [-0.5080, -0.2488, -0.3456],
        [ 0.0016, -0.2148, -0.0400],
        [-0.3912, -0.3963, -0.3368],
        [-0.1976, -0.4557,  0.4841],
        [-0.1146,  0.4968,  0.1799],
        [-0.4889,  0.3995, -0.1589],
        [-0.2213, -0.4792, -0.5740],
        [ 0.1652, -0.1261,  0.2248],
        [-0.4738,  0.4286, -0.4238],
        [-0.0997,  0.1206,  0.2981],
        [ 0.4661,  0.5259, -0.4578],
        [ 0.1453, -0.2483, -0.0633],
        [-0.4321,  0.5259, -0.4237],
        [ 0.3086,  0.2029,  0.1876],
        [-0.3121,  0.5248,  0.1269],
        [ 0.0743, -0.5088,  0.2424],
        [-0.0866, -0.2645,  0.4959],
        [ 0.1287, -0.3194, -0.2922],
        [-0.0276,  0.3224, -0.1475],
        [-0.3294, -0.1977, -0.4313],
        [ 0.2059,  0.4469, -0.5435],
        [ 0.1341,  0.2983,  0.1047],
        [-0.2056,  0.3013,  0.3034],
        [ 0.2159, -0.1015, -0.1529],
        [ 0.0618, -0.1020, -0.1721],
        [ 0.3690,  0.4962, -0.0572],
        [-0.1293,  0.0084, -0.0345],
        [ 0.1388,  0.1618, -0.5244],
        [-0.2131,  0.4862,  0.2249],
        [-0.0287, -0.3481, -0.3532],
        [-0.5172, -0.1882,  0.1950],
        [ 0.3681,  0.2666, -0.5103],
        [-0.3472, -0.0911,  0.5585],
        [ 0.0835, -0.1495,  0.2389],
        [-0.2199, -0.3737,  0.4214],
        [-0.2625, -0.1157, -0.5744],
        [ 0.3864,  0.4374,  0.2104],
        [-0.4026, -0.5698, -0.4689],
        [ 0.4305,  0.2772,  0.4858],
        [ 0.3025,  0.1461, -0.0057],
        [-0.4391, -0.4947, -0.5400],
        [ 0.2363, -0.2835, -0.1162],
        [-0.3323, -0.1052, -0.4064],
        [-0.3772,  0.1915, -0.1716],
        [ 0.3564, -0.1852, -0.4235],
        [-0.1019, -0.2799, -0.1766],
        [-0.5496,  0.3230, -0.4020],
        [ 0.2902,  0.2620,  0.4125],
        [-0.4429,  0.4152, -0.2729],
        [ 0.2142,  0.5422, -0.0814],
        [-0.0045, -0.1329, -0.4821],
        [ 0.2771, -0.5731,  0.3584],
        [ 0.4320,  0.5460, -0.1362],
        [-0.4744,  0.1298,  0.3189],
        [-0.5746, -0.1310, -0.3461],
        [-0.0505, -0.2842, -0.2360],
        [-0.1833, -0.5487,  0.4737],
        [ 0.4840, -0.0906, -0.0657],
        [-0.2356, -0.5214, -0.5618],
        [ 0.2146, -0.3170, -0.3712],
        [-0.0450, -0.1923, -0.1868]], device='cuda:0', requires_grad=True) 

encoder.module_0.bias torch.Size([100])
Parameter containing:
tensor([ 0.0186, -0.1225, -0.1988, -0.2764, -0.4699,  0.4841, -0.2310,  0.1530,
        -0.2003,  0.0469,  0.5383,  0.2660, -0.5003,  0.2292,  0.5480,  0.1519,
         0.3871,  0.5692, -0.0885,  0.1198, -0.4013, -0.1190,  0.4276,  0.2960,
        -0.3653, -0.4630, -0.3945, -0.5698, -0.4455, -0.1428,  0.3896,  0.0966,
        -0.4391, -0.4632,  0.2872, -0.4295, -0.0711,  0.2770, -0.2672, -0.0630,
        -0.0503, -0.1366, -0.2927, -0.5147, -0.4667, -0.3091,  0.5576, -0.2789,
        -0.3877,  0.1399,  0.1591,  0.3163,  0.4389,  0.3215, -0.5724,  0.0512,
         0.3497, -0.0534, -0.3402,  0.5504, -0.2159, -0.3287, -0.5205,  0.0258,
         0.2558,  0.1278,  0.1142, -0.4379, -0.5392,  0.0102,  0.5264,  0.3331,
        -0.3362, -0.0749, -0.4256, -0.2785,  0.1046,  0.3144,  0.4783, -0.5301,
         0.3860, -0.4072,  0.2162,  0.4886,  0.0081,  0.5253, -0.4919, -0.2205,
         0.3367, -0.1258, -0.1182, -0.2406,  0.3980,  0.2832,  0.1850, -0.3244,
        -0.4687,  0.0624,  0.1711, -0.2666], device='cuda:0',
       requires_grad=True) 

encoder.module_2.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0280,  0.0675,  0.0080,  ...,  0.0930, -0.0259, -0.0423],
        [-0.0242, -0.0483,  0.0170,  ..., -0.0880,  0.0698,  0.0116],
        [-0.0539,  0.0523, -0.0946,  ...,  0.0836, -0.0560,  0.0919],
        ...,
        [ 0.0149, -0.0668, -0.0751,  ...,  0.0350, -0.0560,  0.0757],
        [ 0.0928, -0.0271,  0.0738,  ...,  0.0034,  0.0219,  0.0902],
        [-0.0438, -0.0375,  0.0319,  ..., -0.0964, -0.0224, -0.0814]],
       device='cuda:0', requires_grad=True) 

encoder.module_2.bias torch.Size([100])
Parameter containing:
tensor([ 0.0899, -0.0268,  0.0269, -0.0717,  0.0102, -0.0940,  0.0450,  0.0472,
        -0.0972,  0.0436,  0.0127, -0.0625, -0.0458,  0.0983, -0.0520,  0.0875,
         0.0201,  0.0458, -0.0503,  0.0325,  0.0215,  0.0798, -0.0989, -0.0364,
         0.0025, -0.0718,  0.0170,  0.0645,  0.0603, -0.0516,  0.0404, -0.0728,
         0.0622, -0.0817, -0.0907,  0.0347, -0.0094,  0.0246,  0.0930,  0.0958,
         0.0564, -0.0907, -0.0154,  0.0109, -0.0974,  0.0836,  0.0656, -0.0462,
        -0.0209, -0.0580,  0.0385,  0.0172, -0.0347,  0.0535, -0.0216,  0.0107,
         0.0692, -0.0470, -0.0922,  0.0540, -0.0654,  0.0378, -0.0301,  0.0671,
        -0.0038, -0.0455, -0.0705,  0.0672, -0.0626,  0.0283,  0.0765, -0.0803,
        -0.0839,  0.0102, -0.0393, -0.0734,  0.0661, -0.0930, -0.0456, -0.0831,
         0.0264,  0.0086,  0.0417,  0.0419, -0.0004, -0.0300,  0.0884,  0.0042,
         0.0238, -0.0823, -0.0980, -0.0488, -0.0524,  0.0290, -0.0444,  0.0104,
         0.0927, -0.0295,  0.0255,  0.0012], device='cuda:0',
       requires_grad=True) 

encoder.module_4.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0658,  0.0437, -0.0046,  ..., -0.0985,  0.0879, -0.0389],
        [ 0.0153,  0.0711,  0.0383,  ..., -0.0571, -0.0231,  0.0334],
        [ 0.0378,  0.0129,  0.0656,  ...,  0.0582,  0.0935,  0.0702],
        ...,
        [ 0.0351, -0.0812,  0.0986,  ...,  0.0367, -0.0375, -0.0136],
        [ 0.0063,  0.0894,  0.0749,  ...,  0.0603, -0.0517,  0.0448],
        [ 0.0908, -0.0299, -0.0738,  ..., -0.0864,  0.0315, -0.0033]],
       device='cuda:0', requires_grad=True) 

encoder.module_4.bias torch.Size([16])
Parameter containing:
tensor([-0.0079,  0.0081, -0.0457,  0.0668, -0.0727, -0.0015,  0.0826,  0.0211,
        -0.0720,  0.0993, -0.0593, -0.0425,  0.0614, -0.0601,  0.0040,  0.0369],
       device='cuda:0', requires_grad=True) 

model.module_0.bias torch.Size([8])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

model.module_0.lin.weight torch.Size([8, 16])
Parameter containing:
tensor([[-0.4969, -0.3527,  0.3619, -0.1865, -0.1179,  0.0154, -0.0989, -0.1713,
         -0.0101, -0.2507,  0.3172, -0.0201,  0.2237,  0.0603,  0.3767,  0.2432],
        [-0.2514, -0.1175,  0.1154, -0.1804, -0.3466,  0.4192,  0.3358, -0.2498,
          0.1154,  0.3626, -0.3030, -0.0824, -0.4123, -0.4575,  0.3974,  0.1750],
        [-0.3250, -0.0371, -0.2326, -0.0911, -0.1081,  0.1584,  0.0865, -0.3390,
          0.2505,  0.0368, -0.2611, -0.2905, -0.0110,  0.1740, -0.4618, -0.1163],
        [-0.3613, -0.4675,  0.2680, -0.1718, -0.4766, -0.1440, -0.2762,  0.2703,
         -0.0785, -0.3030, -0.2044, -0.1106,  0.3827,  0.0455, -0.3957, -0.1295],
        [ 0.4608, -0.4272, -0.1875,  0.4355, -0.2017,  0.3809, -0.3274,  0.3785,
          0.3304, -0.0935, -0.4638, -0.1691,  0.1252, -0.1675, -0.3990, -0.4419],
        [ 0.2381,  0.3604, -0.1894,  0.0191, -0.3061,  0.2887, -0.3286, -0.2836,
         -0.2036, -0.0918,  0.0618, -0.4713, -0.1829, -0.2170, -0.1016, -0.0285],
        [ 0.0234,  0.2553, -0.2847,  0.0109,  0.4544,  0.0641, -0.3714,  0.3422,
         -0.4437,  0.2032,  0.4140,  0.0627,  0.2682,  0.3968,  0.2283, -0.1502],
        [ 0.1087,  0.4044,  0.1172, -0.3974,  0.4351,  0.4846,  0.2902,  0.2718,
          0.2809, -0.3036, -0.1501,  0.2161,  0.1273,  0.2125, -0.0095, -0.4818]],
       device='cuda:0', requires_grad=True) 

model.module_1.weight torch.Size([100, 8])
Parameter containing:
tensor([[ 1.6758e-01, -2.2238e-01, -2.9217e-01,  3.4964e-01,  1.5586e-01,
          1.7571e-01, -1.5490e-01,  1.3029e-01],
        [ 3.0048e-02,  2.4116e-01,  4.1357e-02,  3.1600e-01, -8.2809e-02,
          3.2626e-01,  3.5015e-01,  4.1818e-02],
        [-2.5922e-01,  1.3845e-04,  2.8142e-01, -2.4156e-01, -1.2635e-01,
          1.2785e-01,  7.1839e-02,  3.3235e-01],
        [ 5.8234e-02, -2.7037e-03,  4.6467e-02, -7.2723e-02, -3.2548e-01,
         -1.2401e-01, -3.2050e-01,  2.5869e-01],
        [ 2.1392e-02,  4.1168e-02, -2.4537e-02, -1.8141e-01, -2.4943e-01,
         -5.4116e-02,  1.0697e-01, -1.9348e-01],
        [-2.1874e-01,  2.2970e-01, -1.2276e-01,  1.9918e-01,  3.3847e-01,
          3.3231e-01, -2.7335e-01,  2.6224e-02],
        [-2.7722e-01,  1.4592e-02,  4.9167e-02, -1.5303e-01,  1.0494e-01,
         -1.1084e-01,  1.9920e-01,  3.3705e-03],
        [ 2.4541e-01,  2.3897e-01,  7.8949e-02,  6.6004e-02, -1.6002e-01,
         -2.3347e-01,  2.3837e-01,  2.3332e-01],
        [ 5.5444e-02,  2.9664e-01,  1.8461e-01,  2.3095e-01, -6.7814e-02,
          5.0539e-02, -3.1788e-01, -3.2304e-01],
        [ 1.6811e-01, -2.1312e-01,  2.6927e-01, -2.8528e-01, -2.9268e-01,
         -2.9022e-01,  2.2690e-01, -2.3435e-01],
        [-3.0320e-01,  1.4935e-01, -7.1314e-02, -3.3674e-01,  2.5075e-01,
          2.5625e-01,  2.8360e-01,  2.2194e-01],
        [-2.7410e-01, -1.5564e-01, -1.3894e-01, -3.4383e-01,  2.4707e-01,
         -1.4308e-01,  1.2135e-01, -1.7978e-01],
        [ 3.1682e-01,  2.4912e-01,  2.4401e-01,  1.7305e-01,  2.9595e-01,
          1.1559e-01,  6.0417e-02, -7.9720e-02],
        [ 2.8730e-01, -3.4115e-01,  2.5251e-01, -3.3452e-02, -2.3405e-02,
         -2.3243e-01, -1.5458e-01,  6.6692e-02],
        [-1.4407e-01,  1.2587e-01,  4.9807e-02, -3.0096e-01,  1.9323e-01,
         -1.5567e-01, -1.2774e-01, -1.3012e-01],
        [ 1.3969e-01, -3.4863e-01, -2.5480e-01,  1.4228e-01, -1.0713e-01,
         -6.7086e-02, -3.1766e-01,  3.5855e-02],
        [ 1.6639e-01, -1.2762e-01,  2.7022e-02,  1.0027e-02, -7.4866e-02,
          2.8517e-01,  9.1047e-02,  6.7201e-02],
        [-1.0997e-02, -7.4096e-03,  1.8985e-01,  2.0334e-02,  8.0005e-02,
          2.8693e-01,  2.4998e-01, -1.2975e-01],
        [-2.8951e-01,  9.3123e-02, -2.4148e-01, -3.5162e-01,  2.4278e-01,
         -2.9303e-01,  3.4897e-01, -3.2572e-01],
        [-2.8788e-01,  2.0327e-01,  2.7280e-02, -1.5410e-01,  1.3420e-01,
         -2.2971e-01, -1.9487e-01, -3.4049e-01],
        [-1.8110e-01, -3.0367e-01,  3.0295e-01, -1.5370e-01,  5.9986e-02,
         -1.5891e-01, -8.0999e-02,  2.5828e-01],
        [ 7.1954e-02,  1.7070e-01,  1.1552e-01, -2.8815e-01,  2.1233e-01,
          2.8646e-01,  1.0566e-01,  2.8164e-01],
        [-1.6846e-01, -2.3132e-01, -2.8397e-01, -5.5903e-02, -3.4965e-02,
         -2.0096e-01, -1.2091e-01, -1.1386e-01],
        [ 3.4098e-01, -2.5247e-02,  2.8662e-01,  3.4057e-02,  1.2598e-01,
          2.0374e-01, -3.2542e-01, -1.5936e-01],
        [-2.6870e-01,  3.4347e-01,  1.2974e-01, -1.4818e-01, -2.6662e-01,
          1.9579e-01,  8.2067e-02, -1.7394e-01],
        [-2.5659e-01, -1.8451e-01,  8.6095e-02, -2.9767e-01, -3.7308e-02,
          2.0985e-01,  1.8884e-01,  3.8158e-02],
        [ 3.7564e-02,  8.2609e-02,  1.3808e-01,  2.7905e-01,  9.6036e-02,
          1.9436e-01,  2.4645e-01, -2.7426e-01],
        [-1.8871e-01,  1.9411e-01,  7.0835e-02, -2.0408e-01,  1.0448e-01,
         -3.2141e-01, -1.3155e-01,  1.7828e-01],
        [-9.3158e-03, -2.3893e-01,  1.7476e-01,  2.4569e-02, -5.0597e-02,
         -3.4002e-01, -1.2753e-01,  3.9049e-02],
        [-1.9213e-01,  5.9501e-02, -2.5116e-01,  2.7282e-01,  2.7224e-01,
          2.0824e-01, -4.2002e-02, -3.5233e-01],
        [-1.3805e-01, -2.8643e-02, -3.2585e-01,  2.7835e-01,  1.0064e-01,
          2.6823e-01, -3.1632e-01, -1.8153e-01],
        [ 7.9682e-02, -5.3881e-03, -2.0562e-01,  2.5851e-01,  1.4580e-01,
         -1.6859e-02,  3.3694e-01, -3.4480e-01],
        [-3.2114e-01,  7.0511e-02,  3.2086e-01,  1.9987e-01, -1.9456e-01,
          2.5365e-01,  1.8370e-01,  2.0098e-02],
        [ 2.2368e-01,  6.9968e-02,  4.6433e-04, -9.7894e-02, -1.8784e-01,
         -2.2287e-01, -4.6477e-02, -2.4179e-01],
        [ 1.4985e-01,  9.9837e-02, -3.4471e-01, -2.6006e-01,  2.5266e-01,
         -1.8535e-01, -3.6465e-03, -2.2645e-01],
        [-7.7324e-02,  1.7437e-01,  8.9864e-02,  1.7353e-01, -2.0586e-02,
         -2.8209e-01, -4.4497e-03,  2.0961e-01],
        [ 8.2699e-02,  7.3119e-02,  6.9615e-02,  2.9009e-01,  1.7836e-01,
         -5.7825e-02, -1.9182e-01,  2.8770e-01],
        [-1.8393e-01, -2.3635e-01,  1.1044e-01, -2.2577e-01, -3.0507e-01,
         -2.8630e-01,  8.7182e-02, -2.2217e-01],
        [ 3.1276e-01, -1.4188e-02, -1.5016e-01, -2.1679e-01, -1.0570e-01,
          3.0844e-01, -2.2568e-01, -3.2735e-01],
        [ 1.0519e-01,  1.1989e-01, -2.9955e-01, -1.5870e-01,  3.0645e-01,
         -1.6712e-01,  1.4834e-01, -1.6971e-01],
        [-3.1212e-01, -3.4106e-01,  2.6969e-01,  1.0839e-01,  1.0055e-01,
          1.2169e-01,  1.3625e-01,  2.3341e-01],
        [ 2.7125e-01,  2.7264e-01,  1.1361e-01,  6.3141e-02,  7.5899e-02,
         -2.8636e-01,  1.5764e-01,  8.7190e-02],
        [ 1.5368e-01, -8.7242e-02,  2.9366e-01,  4.2472e-02, -8.3804e-02,
         -9.9935e-03, -1.4112e-01, -5.1948e-02],
        [ 3.0008e-01,  1.1728e-01, -3.9515e-02,  1.3352e-02,  8.0762e-02,
         -2.0404e-01, -1.9393e-01,  3.1175e-01],
        [ 1.9266e-03,  1.0523e-01, -1.6270e-01, -2.5988e-01,  7.0136e-02,
          1.9096e-01, -3.3300e-01, -3.4967e-01],
        [-1.1791e-01,  2.2864e-01, -3.1591e-01,  2.8246e-01,  3.1974e-01,
         -7.9345e-02,  2.2583e-02, -1.4602e-02],
        [ 3.4445e-01,  3.9289e-02,  8.6390e-02, -1.2097e-01, -4.3182e-03,
         -1.8749e-01,  1.7775e-02, -4.9060e-02],
        [ 6.5896e-02,  6.8736e-02, -2.8928e-01,  2.3621e-01,  1.9448e-01,
          2.4905e-01,  2.6038e-01,  9.1225e-02],
        [ 1.9327e-01,  1.7427e-01,  2.1080e-01, -2.1291e-01,  1.6751e-01,
         -2.8328e-02,  1.3675e-01,  1.2996e-01],
        [-2.6353e-01, -1.6084e-01, -2.5170e-01, -9.3997e-02,  1.1411e-01,
          8.2468e-02,  2.8072e-01, -2.5526e-01],
        [ 1.1064e-01,  2.8916e-01, -2.7237e-01, -2.6613e-01,  8.5088e-02,
         -1.4350e-01,  9.0416e-02, -1.7088e-01],
        [ 4.5548e-02, -2.9968e-01,  2.8169e-01, -2.2576e-01, -3.2444e-01,
         -1.8311e-01,  7.5088e-03,  3.3225e-01],
        [ 7.3921e-02, -7.3922e-02, -2.5447e-01,  1.6138e-01,  2.5782e-02,
         -1.0239e-01, -9.9146e-02,  5.1839e-02],
        [ 2.0817e-01, -2.1262e-01, -8.5395e-02,  1.6674e-01, -2.4217e-01,
         -8.7369e-03,  2.8634e-01,  2.4688e-01],
        [-2.8366e-01, -1.6594e-01,  5.6884e-02,  2.2332e-01, -1.4203e-01,
         -3.2105e-01, -1.3141e-02,  2.2176e-01],
        [-1.8181e-01, -3.2559e-01,  2.4348e-02,  2.9389e-01, -2.8661e-01,
          7.6081e-02,  2.2393e-01,  1.0643e-02],
        [-1.8948e-01, -1.2793e-01, -2.3255e-01,  2.5698e-02, -1.5385e-01,
          1.1933e-02, -7.7819e-02, -2.4212e-01],
        [ 3.4236e-01,  8.3292e-02,  1.7487e-01,  2.0935e-01,  1.4244e-01,
         -8.3659e-02, -1.0851e-01, -1.9494e-01],
        [-3.1452e-01, -2.6996e-01, -1.3464e-01,  3.3303e-01, -3.3739e-01,
         -2.2269e-01, -2.7503e-01, -2.4772e-01],
        [ 2.8912e-01, -2.7966e-01, -2.5298e-01, -2.0682e-01,  9.4783e-02,
         -1.1052e-01, -2.3542e-01,  2.9227e-01],
        [ 5.4216e-02, -2.5810e-01, -1.3200e-01,  2.1768e-01,  1.2836e-01,
         -2.2525e-01, -1.7963e-01, -1.3868e-01],
        [ 1.3505e-01, -2.8353e-01,  3.3051e-01,  3.4543e-02,  1.4047e-01,
          1.0425e-01,  2.7521e-01, -1.1560e-01],
        [-1.3359e-01, -2.3061e-01,  2.8925e-01, -2.8575e-02, -5.5187e-03,
          3.1155e-01, -8.9138e-02, -1.1863e-01],
        [-1.4762e-01,  2.0311e-01,  4.2854e-02, -1.8889e-01,  2.3232e-01,
          1.3784e-01, -8.1000e-02,  8.1203e-02],
        [-3.2043e-01, -2.5123e-01, -1.2970e-01,  1.7027e-01, -7.7166e-02,
          2.5797e-01, -3.2979e-01,  2.5723e-01],
        [-3.4184e-01, -1.2145e-01,  3.2425e-01, -1.1816e-01, -1.5417e-01,
          1.9100e-01, -1.8942e-01,  7.3279e-02],
        [-1.2684e-01,  1.3855e-01, -2.1679e-01, -1.8503e-01, -2.3486e-01,
         -6.2710e-02,  3.5106e-01,  2.0328e-01],
        [-2.8055e-01,  1.8052e-01,  3.2384e-01,  3.4989e-01,  3.5216e-02,
          9.4374e-02,  2.5660e-01,  3.4022e-01],
        [ 1.2081e-02, -6.2528e-02,  2.8698e-01, -9.4987e-02,  2.8178e-01,
          2.9918e-01,  9.8524e-02, -2.8467e-01],
        [ 2.7603e-01,  1.6887e-01,  8.4909e-02,  7.6556e-02,  1.6637e-01,
          2.0874e-01, -2.3185e-01, -2.7992e-01],
        [ 1.8313e-01, -1.4716e-01, -3.1055e-01,  2.9537e-01, -2.7404e-01,
         -1.2075e-01, -2.2208e-01,  3.0667e-01],
        [-4.5836e-02, -1.8482e-01,  2.9520e-01,  3.2905e-01,  1.8743e-01,
          2.7694e-01, -3.1836e-01, -3.1952e-01],
        [ 1.9321e-01, -7.9382e-02,  1.5033e-01,  3.2856e-01, -8.0777e-02,
         -1.8784e-01,  3.3127e-01, -1.6949e-01],
        [-2.0259e-01,  2.8373e-01, -1.4535e-02, -1.7244e-01,  1.2610e-01,
         -1.7866e-01,  1.2886e-02, -2.7854e-01],
        [-8.5346e-02,  2.7428e-01,  5.0930e-02, -4.7893e-02,  2.6811e-01,
          1.9148e-01,  1.9841e-01,  1.6777e-01],
        [-1.2098e-01, -3.1477e-01, -2.0936e-01, -2.1015e-01,  9.8457e-02,
          2.8353e-01,  3.2682e-01,  2.8311e-01],
        [ 5.0167e-02,  2.4349e-01,  1.7744e-02,  1.6421e-01, -2.3405e-01,
          3.4055e-01,  1.6345e-01,  5.1992e-04],
        [-1.4037e-01,  6.1922e-02, -4.0729e-02, -2.2884e-01, -2.1905e-01,
         -1.4103e-01,  8.1160e-02, -2.2797e-01],
        [ 1.9484e-01, -1.9472e-01,  2.1256e-01,  1.2196e-02,  6.0814e-04,
          4.7747e-02, -2.6664e-03,  1.7475e-01],
        [-2.8274e-02, -1.2482e-01,  3.6858e-02, -2.0702e-01,  1.4152e-01,
          3.5564e-02,  1.7835e-01, -6.2000e-02],
        [-1.9973e-03, -1.6835e-01, -1.5872e-01,  8.7455e-03,  1.8099e-01,
         -1.3377e-01,  2.7785e-01, -1.1937e-01],
        [-7.2682e-02,  2.8331e-01, -6.4173e-02,  1.9229e-01, -3.4812e-02,
          2.1015e-01,  4.5983e-02, -1.6660e-01],
        [-2.3290e-01,  2.0988e-01,  8.6883e-02, -5.4911e-02, -6.7548e-02,
         -1.4676e-01, -2.4489e-01,  7.8434e-02],
        [-3.0062e-01, -4.6911e-03,  2.5265e-01,  1.6131e-01,  1.9101e-01,
          6.5350e-02, -1.9776e-01,  1.8023e-01],
        [ 2.7590e-01,  1.4471e-01,  2.4626e-01, -2.8547e-01, -3.0765e-01,
         -8.1881e-02,  9.3031e-02,  2.2716e-01],
        [-1.0380e-01, -1.5651e-01,  2.2803e-01, -1.0835e-02,  2.3979e-02,
         -3.3733e-01, -3.2840e-02,  1.7152e-01],
        [ 3.4142e-01,  3.2942e-02,  2.2457e-01,  4.9144e-02, -2.7902e-01,
         -1.1914e-02, -1.2082e-01, -4.8013e-02],
        [-1.3752e-01,  2.6430e-01, -2.8862e-01, -2.1251e-01, -1.0978e-01,
          2.9621e-01, -7.2348e-02,  1.4427e-01],
        [ 1.7334e-01,  3.0261e-01, -8.1234e-02,  6.6046e-02, -1.7256e-01,
         -2.6874e-02, -3.0299e-01, -2.8848e-01],
        [ 9.6164e-02, -2.7097e-01,  1.8479e-01,  2.6131e-01,  1.2406e-01,
          1.3534e-01, -3.2122e-01, -1.6350e-01],
        [-2.5528e-01, -3.3525e-01,  1.5030e-01,  8.0955e-02,  3.3640e-01,
         -9.7408e-02, -2.3409e-01, -3.0435e-01],
        [ 2.1772e-02, -1.9376e-01,  6.2723e-02,  2.3387e-01,  3.0230e-01,
         -5.7662e-02, -2.2990e-01, -1.9198e-01],
        [ 2.2453e-01,  9.1495e-02,  2.2386e-02, -3.4351e-01,  1.9043e-01,
          2.2366e-01,  3.6487e-02, -6.3708e-02],
        [-1.6777e-01,  2.8877e-03,  1.7564e-02,  9.9735e-02, -1.4985e-02,
          3.3520e-01,  2.2790e-01,  7.9821e-02],
        [-3.1388e-01, -1.6881e-01,  1.3834e-01, -2.2849e-01,  9.8568e-02,
          8.6824e-02, -2.2228e-01,  7.0133e-02],
        [-4.5727e-02,  2.6334e-01, -7.8000e-02,  3.0854e-01,  3.0718e-01,
         -1.1722e-01,  5.9325e-02, -9.6647e-02],
        [ 2.8312e-01,  1.6951e-01,  9.6917e-04,  2.1381e-01, -2.8388e-01,
         -9.0414e-02,  7.2170e-02, -3.3496e-01],
        [ 3.0902e-01,  2.9047e-02,  3.1234e-01, -1.0290e-01,  2.1051e-02,
         -9.7511e-02, -1.4495e-01, -1.3101e-01],
        [ 2.4452e-01,  3.1767e-01,  1.0174e-01,  1.9742e-01,  1.5379e-01,
          4.4313e-04, -2.6316e-01,  8.8693e-02],
        [-1.2149e-01,  1.3537e-01, -2.3005e-01, -2.4031e-02, -1.3897e-01,
         -3.2707e-01, -3.2686e-01,  3.2620e-01]], device='cuda:0',
       requires_grad=True) 

model.module_1.bias torch.Size([100])
Parameter containing:
tensor([-3.8463e-04, -3.0478e-01,  5.7974e-02, -2.2189e-02,  2.9126e-01,
         3.3321e-01, -9.0874e-02, -2.1215e-01, -2.0261e-01, -9.4006e-02,
        -1.9408e-01,  3.1867e-01, -1.3514e-01,  1.8215e-01,  1.6000e-01,
         8.2664e-02,  1.7236e-01,  2.9939e-01,  1.5043e-01,  1.5557e-01,
        -2.9665e-01, -3.1333e-02,  8.1635e-03,  2.7689e-01,  1.5107e-01,
         2.7496e-01,  2.7347e-01, -1.6492e-01,  5.0157e-02,  3.3712e-01,
         1.2499e-01,  1.9990e-01,  1.4371e-01, -1.1098e-01,  8.4426e-02,
        -2.4429e-01,  3.2617e-01,  2.0229e-02,  2.7398e-01, -2.4854e-01,
        -3.2479e-01,  4.2333e-02, -4.5297e-02, -1.4301e-01,  1.8524e-01,
        -2.2999e-01,  3.0981e-01, -3.4514e-01,  7.2507e-02, -2.0672e-01,
         7.6700e-02,  3.4916e-01, -4.2436e-02,  8.2207e-02, -1.3914e-01,
        -1.8142e-01, -3.0201e-01,  2.0407e-01, -3.9265e-03,  1.2243e-01,
        -2.7192e-01, -2.9436e-01, -3.2148e-01, -2.0375e-01, -4.5971e-02,
        -5.3346e-02,  1.5546e-01, -1.6988e-01,  3.4450e-01, -1.6112e-01,
        -3.3248e-01,  2.6745e-01, -2.2722e-01,  3.3695e-02, -3.4134e-02,
        -7.3750e-02,  2.2907e-04, -3.4767e-01,  3.1793e-01, -2.2952e-01,
         2.1556e-01, -2.0906e-01, -8.7061e-02, -8.3615e-03, -1.3935e-01,
        -1.5317e-01, -2.9760e-01, -2.4283e-01, -1.6589e-02, -1.0335e-01,
        -4.9652e-02,  9.0191e-02, -4.5326e-02, -3.3469e-01, -1.3003e-01,
         1.0822e-01,  1.2724e-01,  1.7109e-01,  1.9579e-02,  2.4172e-01],
       device='cuda:0', requires_grad=True) 

model.module_3.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0684, -0.0839, -0.0267,  ...,  0.0141, -0.0744,  0.0252],
        [-0.0200, -0.0735, -0.0925,  ..., -0.0801, -0.0660, -0.0095],
        [ 0.0212,  0.0074,  0.0961,  ..., -0.0185,  0.0870, -0.0490],
        ...,
        [ 0.0836,  0.0836,  0.0262,  ..., -0.0124,  0.0937, -0.0344],
        [-0.0998, -0.0591,  0.0262,  ...,  0.0155,  0.0849,  0.0046],
        [-0.0929,  0.0576, -0.0187,  ...,  0.0516,  0.0128, -0.0501]],
       device='cuda:0', requires_grad=True) 

model.module_3.bias torch.Size([100])
Parameter containing:
tensor([-0.0779,  0.0531,  0.0296,  0.0260, -0.0370, -0.0976,  0.0137, -0.0172,
        -0.0076,  0.0095, -0.0585, -0.0623, -0.0290,  0.0388, -0.0626,  0.0932,
        -0.0984, -0.0621,  0.0287, -0.0973, -0.0555,  0.0516, -0.0678,  0.0320,
        -0.0533, -0.0473,  0.0174,  0.0097,  0.0907,  0.0208,  0.0174, -0.0519,
         0.0869, -0.0013,  0.0598, -0.0800,  0.0523,  0.0812,  0.0648,  0.0835,
        -0.0455, -0.0717,  0.0360,  0.0433, -0.0608, -0.0321, -0.0013, -0.0084,
         0.0478,  0.0710,  0.0289, -0.0396, -0.0624,  0.0864,  0.0112, -0.0523,
        -0.0746, -0.0679,  0.0934, -0.0630, -0.0974, -0.0749, -0.0475, -0.0031,
        -0.0686,  0.0440, -0.0164, -0.0416, -0.0607, -0.0317,  0.0972,  0.0050,
         0.0282, -0.0969,  0.0611,  0.0158, -0.0111,  0.0018, -0.0462, -0.0776,
        -0.0500,  0.0314,  0.0845, -0.0696,  0.0460, -0.0486,  0.0754,  0.0122,
        -0.0909, -0.0863,  0.0241,  0.0559,  0.0295,  0.0275, -0.0157, -0.0499,
         0.0172, -0.0793,  0.0499, -0.0381], device='cuda:0',
       requires_grad=True) 

model.module_5.weight torch.Size([16, 100])
Parameter containing:
tensor([[-0.0896,  0.0109,  0.0384,  ..., -0.0713, -0.0207, -0.0481],
        [ 0.0197, -0.0986,  0.0931,  ..., -0.0521,  0.0855, -0.0166],
        [ 0.0494, -0.0456, -0.0584,  ..., -0.0272,  0.0233,  0.0812],
        ...,
        [-0.0566,  0.0313, -0.0747,  ...,  0.0287,  0.0282, -0.0924],
        [-0.0077,  0.0880,  0.0084,  ..., -0.0032, -0.0096, -0.0573],
        [ 0.0477, -0.0698,  0.0825,  ..., -0.0027, -0.0697, -0.0981]],
       device='cuda:0', requires_grad=True) 

model.module_5.bias torch.Size([16])
Parameter containing:
tensor([ 0.0439,  0.0473, -0.0163, -0.0916,  0.0850,  0.0872,  0.0966,  0.0595,
         0.0851, -0.0690, -0.0973, -0.0750,  0.0988, -0.0891, -0.0270,  0.0990],
       device='cuda:0', requires_grad=True) 

model.module_7.bias torch.Size([8])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

model.module_7.lin.weight torch.Size([8, 16])
Parameter containing:
tensor([[ 0.1192, -0.2777, -0.4798,  0.0174, -0.1781,  0.4204,  0.1690, -0.2428,
          0.1147, -0.2856,  0.4617,  0.2772,  0.2475,  0.2179, -0.0493, -0.1308],
        [ 0.0461, -0.4993, -0.2613,  0.0579,  0.3661,  0.0011, -0.1715,  0.3398,
          0.1337, -0.3066,  0.2203,  0.1268, -0.4107,  0.0935, -0.3315,  0.4556],
        [-0.3147, -0.0860, -0.2084,  0.0462,  0.4359, -0.2377,  0.1602, -0.1073,
         -0.2117,  0.0166,  0.3756, -0.4518, -0.2084,  0.3795, -0.2403,  0.1155],
        [ 0.1880,  0.0414,  0.0401, -0.3345, -0.0784, -0.0963, -0.0253, -0.0552,
         -0.1170, -0.2973,  0.3562,  0.1451,  0.1668,  0.2481,  0.0103,  0.3248],
        [ 0.1555, -0.1511,  0.0070, -0.4358, -0.2591,  0.4652,  0.4950, -0.3576,
         -0.2177,  0.2751, -0.4470, -0.0555, -0.4582, -0.2366, -0.2622, -0.0237],
        [-0.1329, -0.2756,  0.2613, -0.2213, -0.4918,  0.2434,  0.3285, -0.1081,
          0.0146,  0.0639, -0.0626, -0.1016, -0.4071,  0.2189, -0.0020,  0.2652],
        [ 0.0330, -0.1985, -0.2469,  0.0650,  0.2558,  0.4974,  0.4481,  0.4101,
         -0.3787,  0.0906,  0.4555,  0.2267,  0.3331,  0.4745, -0.1509,  0.2673],
        [ 0.2962,  0.0089, -0.2939,  0.1380,  0.4162,  0.0622,  0.1569,  0.0686,
          0.3531,  0.2662, -0.1120,  0.0814, -0.2340,  0.0783, -0.4312,  0.1714]],
       device='cuda:0', requires_grad=True) 

model.module_8.weight torch.Size([100, 8])
Parameter containing:
tensor([[ 2.1422e-01, -2.9666e-01,  9.6425e-02, -4.8519e-02, -1.4018e-01,
          1.5811e-01,  1.6022e-02, -1.8636e-01],
        [ 2.4251e-01,  9.1977e-02, -2.4447e-01, -5.7527e-02, -1.9176e-01,
         -2.2249e-01,  3.3738e-01, -3.7258e-02],
        [-2.0843e-02, -4.2253e-02, -7.9461e-02, -3.0005e-01, -4.6638e-02,
         -1.4743e-01,  1.4729e-01, -9.8707e-03],
        [-3.4649e-01, -2.0978e-01, -2.6544e-01,  2.1663e-02,  2.1839e-01,
          1.6257e-01,  2.1524e-02,  2.0212e-01],
        [-3.8358e-02,  3.2604e-01, -2.9464e-01, -9.4244e-02, -4.8319e-02,
         -2.6734e-01,  1.1155e-01,  2.4226e-01],
        [ 5.8863e-02,  3.0754e-02,  3.0633e-01, -1.2609e-01, -5.5475e-02,
          1.3129e-01, -1.9344e-01, -2.6718e-01],
        [-7.1604e-02,  2.3059e-01, -1.8194e-01,  1.0159e-01,  6.4494e-03,
          3.2452e-01,  1.8644e-01, -1.8671e-01],
        [-3.4021e-01,  2.1037e-01, -3.2514e-01, -2.0726e-01,  3.4328e-01,
          1.0427e-01, -4.7838e-03, -2.6869e-01],
        [-6.6125e-02,  4.7437e-02,  2.0948e-01, -1.3813e-01, -6.2205e-02,
          7.0352e-02, -3.4768e-01, -1.0933e-01],
        [-3.2314e-01, -1.2711e-01, -2.0909e-01,  1.7330e-01, -2.4435e-01,
         -3.3290e-01, -4.0570e-02, -1.6658e-01],
        [-1.8496e-01, -8.2535e-02,  1.3175e-01, -3.1288e-01, -2.5632e-01,
          2.5772e-02,  1.5837e-01,  1.3895e-02],
        [ 3.5112e-01,  1.7579e-01, -2.3888e-01,  1.9991e-01, -1.8291e-01,
          2.6057e-01, -8.9863e-02,  2.9438e-01],
        [-8.2921e-02, -1.0282e-01, -2.5834e-01,  3.4987e-01, -2.0184e-01,
         -1.5423e-01, -1.9409e-01, -3.4952e-01],
        [-1.7446e-01,  2.9148e-01,  2.2565e-01,  9.0871e-02, -1.0385e-01,
          4.8715e-02, -6.5855e-02, -2.8962e-01],
        [ 2.4011e-01,  1.8546e-01,  3.0529e-01, -3.3025e-01,  5.5493e-02,
          1.9948e-01, -4.8918e-02,  1.6402e-01],
        [ 1.7551e-01, -1.7426e-01,  2.5996e-01,  8.9494e-02, -3.8660e-02,
          1.2790e-01,  2.6713e-01,  6.5763e-02],
        [ 1.7104e-01, -2.3991e-01, -1.6394e-01, -6.0955e-02,  2.0207e-01,
          2.0083e-01, -9.6184e-02, -5.5575e-02],
        [-4.8527e-02, -1.6383e-01,  2.9726e-01,  1.7846e-01,  2.3089e-01,
         -1.1960e-01, -8.4925e-02, -2.9440e-01],
        [ 2.6292e-01, -1.3378e-01, -2.9150e-02, -2.3481e-01,  7.2805e-02,
          1.9347e-01, -3.5145e-01,  2.7132e-01],
        [ 6.4934e-02,  1.6884e-01, -3.0896e-01,  9.0579e-02,  3.4629e-01,
          2.3299e-01, -1.5873e-01,  1.9231e-02],
        [-2.4185e-01,  1.4173e-01,  1.6772e-01,  1.5314e-01, -3.0647e-01,
          1.7185e-01,  1.3422e-02, -2.4691e-01],
        [-1.2084e-01,  3.1076e-01, -2.8404e-01,  2.0900e-01,  3.4434e-01,
         -2.5965e-01, -3.2689e-01, -2.6773e-01],
        [ 6.5414e-03, -3.3149e-01,  2.8938e-01,  3.1475e-01, -3.9611e-02,
          1.9327e-01,  2.9004e-01,  1.1300e-01],
        [-1.7404e-01, -1.1793e-02,  2.4795e-01, -1.4550e-01,  8.1375e-03,
         -4.7505e-02, -6.7571e-02, -5.9149e-02],
        [-1.8256e-01, -1.0984e-01,  3.2409e-01, -1.0875e-01, -5.0106e-02,
          3.0517e-01,  1.2523e-01, -2.4963e-01],
        [-9.9760e-02, -1.3450e-01, -1.9653e-01, -2.9363e-01,  1.7511e-01,
          2.7263e-01, -2.7976e-01,  3.5328e-01],
        [ 1.6403e-01,  3.0770e-01, -2.7869e-01,  1.0516e-01,  2.4410e-01,
          1.9696e-01, -1.0525e-01,  2.3169e-01],
        [ 1.8142e-01, -2.2475e-01,  1.8611e-01, -1.6869e-01,  2.7919e-01,
         -1.1044e-01, -2.1208e-01,  1.6012e-01],
        [-2.0372e-01, -1.4426e-01,  2.2881e-01,  3.1997e-01,  1.1372e-01,
          3.1283e-01,  1.3632e-01, -5.4247e-02],
        [-1.1804e-01, -9.2761e-02,  7.6921e-03, -4.0659e-02,  7.4398e-02,
          9.1032e-02, -2.2861e-01, -1.9980e-01],
        [ 2.9321e-01, -1.5178e-01,  1.8409e-01,  3.3318e-01, -3.2111e-01,
          5.7438e-02,  8.8541e-02, -2.1936e-01],
        [-8.8337e-02, -1.6875e-01, -3.5081e-01, -1.2262e-01,  3.2356e-01,
          3.3616e-01, -2.0833e-01, -1.1267e-01],
        [-1.8318e-01,  2.3738e-01, -2.9034e-01, -1.2031e-01, -1.1305e-01,
         -1.4265e-01,  3.0334e-01, -3.0719e-01],
        [-2.7989e-01, -2.9127e-01, -1.5981e-01,  1.9197e-01,  4.8609e-02,
         -1.6027e-02,  2.7689e-01,  2.4368e-01],
        [ 8.2535e-02,  6.7142e-02, -1.4146e-01, -3.4161e-01,  6.2700e-02,
          3.0405e-01,  2.5679e-01, -3.2966e-02],
        [-9.4640e-03,  3.4149e-01, -3.5317e-01,  3.1045e-01,  3.4562e-01,
          2.2295e-01,  1.4140e-01,  1.4580e-02],
        [ 1.2259e-01, -1.8355e-01, -5.3684e-02, -2.2696e-01,  4.2754e-02,
         -9.4468e-02,  3.1535e-01,  1.2943e-01],
        [ 1.6409e-01, -2.3555e-01, -4.0922e-03,  3.0975e-01,  1.4455e-01,
         -3.0850e-01, -1.4587e-01,  2.0325e-01],
        [ 1.8847e-01,  4.9609e-02, -9.6309e-02,  2.0632e-01,  9.7829e-02,
          3.5831e-02,  1.0897e-01, -2.0260e-01],
        [-2.4494e-01,  2.2822e-01, -1.9297e-01, -2.5686e-01, -2.8594e-01,
          2.7998e-01,  1.4451e-01,  1.5306e-01],
        [ 2.5497e-01, -3.3208e-01, -2.8602e-01,  1.3417e-01,  3.0513e-01,
          1.5952e-01,  3.2990e-02,  3.4335e-01],
        [-1.5468e-01,  3.0411e-01,  2.8896e-01, -2.7557e-01, -3.1049e-02,
          2.9334e-01,  3.2751e-01, -7.0271e-02],
        [ 3.0933e-01, -2.8677e-01,  9.5684e-02,  6.3508e-02,  1.0106e-01,
          1.9150e-01,  6.0829e-02,  1.8182e-01],
        [ 2.7793e-01,  2.0038e-01,  2.2606e-01,  3.5182e-01,  2.7732e-01,
          2.1251e-02, -2.4813e-01,  1.5395e-01],
        [ 3.5851e-02,  3.2288e-01, -1.0186e-01,  1.1558e-02, -3.3008e-01,
         -1.6931e-01,  2.5446e-01, -2.2872e-01],
        [-1.8141e-01,  1.4672e-02,  1.6340e-02,  2.5283e-01, -2.3070e-01,
          6.3871e-02, -2.2174e-01,  1.7657e-01],
        [ 1.3561e-01, -5.1875e-02,  2.5291e-01,  2.4704e-01, -2.0120e-01,
         -3.0689e-01,  1.7374e-01, -2.8963e-01],
        [ 4.4220e-02,  2.9544e-02,  1.2482e-01,  1.7673e-01, -1.8845e-01,
          2.2039e-02, -2.0815e-01,  2.4983e-01],
        [ 1.0398e-01,  3.0863e-01,  2.7907e-01,  1.5813e-01,  2.2357e-01,
          3.4177e-04, -2.6416e-01, -1.4542e-01],
        [-1.3905e-01, -1.5412e-01, -1.7883e-01, -3.4512e-01,  6.5854e-02,
         -2.2433e-01, -3.0828e-01,  1.0984e-01],
        [-3.3117e-01,  7.6654e-02, -2.0599e-02,  1.8661e-01,  2.9290e-01,
          1.7425e-01, -2.8367e-01, -3.3794e-02],
        [ 1.6144e-01, -2.7765e-01, -3.4180e-01, -3.1697e-01, -2.6354e-01,
          1.5320e-01, -1.0492e-01,  1.4333e-01],
        [-1.8829e-01, -8.9449e-02, -5.2713e-02,  3.3989e-01,  4.6724e-02,
         -2.8904e-01,  2.7283e-01,  1.9756e-02],
        [ 3.1914e-01, -3.0243e-03, -2.8622e-01,  5.8572e-02, -1.9366e-01,
         -2.4306e-01,  3.7063e-02,  1.3311e-01],
        [-1.8396e-01, -1.0110e-01, -1.3787e-01,  2.6680e-01,  8.7830e-02,
         -7.6518e-02, -1.1330e-01, -1.2855e-01],
        [-1.2146e-02,  8.5311e-02, -1.3647e-01, -1.4708e-01, -2.6149e-01,
          3.1821e-01, -1.4570e-01,  3.1112e-01],
        [-3.5525e-02, -8.0884e-02, -1.2590e-01, -4.4818e-03, -1.4813e-02,
          8.9845e-02, -1.6738e-01,  3.0448e-01],
        [ 8.1271e-02, -5.7217e-02, -2.4117e-01,  8.7072e-02, -1.9029e-02,
         -5.3339e-02, -3.2264e-01,  1.3544e-01],
        [ 4.1801e-02,  2.1473e-01, -1.9840e-01,  2.1343e-01,  2.7094e-01,
          8.0153e-02,  2.6631e-01, -3.3830e-01],
        [ 2.2964e-01, -1.1118e-01,  1.2445e-01,  2.5842e-01,  4.7427e-02,
         -5.8886e-03,  1.5550e-01,  3.3946e-01],
        [-2.5242e-01,  3.2945e-01,  5.5873e-02,  1.8655e-01, -1.1284e-02,
         -7.3096e-02, -5.5821e-02, -7.7938e-02],
        [-3.0555e-01,  2.5265e-01,  1.7590e-01, -3.5029e-01,  1.7228e-01,
         -2.6646e-01, -1.4690e-01,  3.0368e-01],
        [-3.1247e-02,  2.2572e-01,  2.0423e-01,  3.3143e-02, -3.3900e-01,
          2.4776e-01, -1.4789e-01, -2.3157e-01],
        [-1.1509e-01,  2.8464e-01, -9.6835e-02,  1.4924e-01,  3.8128e-02,
         -1.6969e-01,  5.2441e-02,  2.7847e-01],
        [ 2.8815e-01, -9.0493e-04,  3.2476e-02,  2.1229e-01, -1.2967e-01,
         -6.7788e-02,  1.8420e-01,  2.4869e-01],
        [ 4.3664e-02, -3.4852e-02, -3.0288e-01, -2.7160e-02, -2.3464e-01,
         -6.8697e-02, -5.9211e-03,  1.3539e-01],
        [ 3.0307e-01,  2.3457e-02,  5.4176e-02, -1.5820e-01, -2.5735e-01,
         -3.1578e-01,  7.5959e-02,  5.0132e-02],
        [ 3.1156e-01,  2.0371e-01,  1.2665e-02, -1.1308e-01,  2.4472e-01,
         -3.0693e-01, -1.0672e-02,  1.2441e-01],
        [-3.4619e-01,  2.7270e-01, -8.9835e-02,  3.0272e-01, -6.1860e-02,
         -2.1188e-01,  1.7217e-01, -2.2785e-01],
        [-2.4996e-01, -1.0630e-01,  2.1728e-01,  1.1666e-01,  2.7698e-01,
         -1.2035e-01, -2.8744e-05, -1.1572e-01],
        [ 3.3724e-01,  2.6508e-02, -3.2929e-01,  7.3785e-02, -2.4757e-01,
          4.7897e-02,  9.5569e-02, -1.7447e-01],
        [-3.1463e-01, -3.5294e-02, -2.4127e-01,  3.4564e-01, -1.4478e-01,
         -8.1798e-02,  2.5951e-01, -5.9335e-02],
        [ 2.3666e-03, -3.5177e-01,  1.5391e-01,  2.5112e-01, -3.4394e-01,
          3.4071e-01,  2.3718e-01,  1.7933e-01],
        [-1.1877e-02, -3.7663e-02,  3.2138e-01,  1.7294e-01, -2.0012e-01,
         -1.9374e-01,  3.1573e-01, -1.8702e-01],
        [-1.2220e-01, -2.5323e-01,  1.0893e-01, -6.9692e-02,  3.1677e-01,
         -1.5934e-01,  1.0334e-01, -2.3223e-01],
        [-2.4338e-01, -3.2774e-01,  5.0253e-03,  8.4507e-02,  1.5015e-01,
          3.4630e-01,  1.7120e-01,  5.8453e-04],
        [ 1.9614e-01, -3.2884e-01,  3.3935e-01, -2.9909e-01,  2.0491e-01,
         -2.1360e-01,  3.3754e-01,  9.8990e-02],
        [ 1.6841e-01,  1.1140e-01, -1.5901e-01,  1.7829e-02,  9.3685e-02,
          1.0849e-01,  1.0678e-01,  2.9050e-01],
        [-4.5670e-02, -2.1778e-01,  1.6751e-01,  2.6687e-01,  2.5494e-01,
         -2.4070e-01, -4.6427e-03,  8.5169e-02],
        [-7.0601e-03,  1.6232e-01, -3.2794e-01,  1.9441e-01, -1.0454e-01,
          6.4184e-02, -7.3734e-02, -3.1702e-01],
        [ 1.3948e-01,  6.3399e-03, -3.2149e-02,  2.7352e-01,  3.0241e-01,
         -1.5284e-01, -9.5041e-02, -1.0634e-01],
        [-2.5108e-01, -3.1881e-01, -1.5772e-01, -2.0099e-01, -5.3276e-02,
         -3.0820e-02,  2.5060e-01, -3.0893e-02],
        [ 1.8518e-01, -3.4056e-01, -3.3870e-02, -5.4575e-02,  1.1034e-01,
          2.4316e-01,  2.3784e-01,  6.8589e-02],
        [ 1.5176e-01,  2.5775e-01,  2.9257e-01,  1.4473e-01, -2.4413e-01,
          2.3248e-01,  1.0148e-01,  2.4619e-01],
        [ 1.1512e-01,  9.7542e-02,  2.7334e-02,  2.2856e-01,  2.8086e-01,
          3.5004e-01, -3.0178e-01,  1.7598e-01],
        [ 2.8509e-01, -1.8345e-01, -3.0940e-01,  1.8525e-01,  4.0258e-02,
          2.8964e-01,  1.4843e-01,  2.6978e-01],
        [-2.9583e-01, -1.0828e-01, -3.3590e-01,  5.4678e-02,  2.3327e-01,
         -2.4965e-01,  2.3407e-01, -3.0996e-01],
        [ 2.3846e-01, -2.9543e-01, -2.7520e-01, -1.7961e-01,  1.0040e-01,
         -3.2017e-01,  1.6729e-01, -3.3189e-01],
        [-2.8477e-02, -1.1313e-01, -6.5886e-02, -2.2734e-01,  3.4438e-01,
          3.2584e-01, -3.5274e-01, -4.9578e-02],
        [-2.7405e-01, -2.9973e-01, -1.1943e-01,  2.2385e-01, -3.2727e-01,
          3.2752e-01,  3.1156e-01,  1.4787e-01],
        [ 2.6488e-01,  5.7713e-02,  1.7455e-01,  1.8262e-01, -3.1543e-01,
          9.0601e-02, -1.2865e-02, -3.4150e-01],
        [ 2.7447e-01, -1.1147e-01,  4.8744e-02, -1.7832e-01,  2.2529e-01,
          2.2018e-02, -1.3297e-01, -1.5862e-01],
        [ 8.8634e-02, -3.0970e-01,  1.5014e-01, -2.9890e-01, -2.2227e-01,
          4.8381e-02, -1.9032e-01,  1.1446e-01],
        [-2.2747e-01, -1.1496e-01,  1.4139e-01,  1.8394e-01, -8.1498e-02,
          1.2171e-01, -2.7547e-01, -7.1140e-02],
        [ 2.2125e-01, -3.0823e-02, -3.0921e-01, -3.4435e-02, -5.2811e-02,
          1.2135e-01, -7.3337e-02, -2.4386e-01],
        [ 6.9878e-02,  2.6087e-01, -8.3848e-02,  1.0243e-01,  5.8792e-02,
          5.5866e-02, -5.3563e-02, -2.1740e-02],
        [-3.4060e-01,  2.0966e-01, -2.1200e-01, -2.7537e-01, -2.1222e-01,
          1.0111e-01, -7.1109e-02, -2.0712e-01],
        [ 1.9655e-01, -1.7380e-01, -2.4746e-01,  1.7033e-01, -1.4780e-01,
         -2.3224e-01, -1.0685e-01, -1.7318e-01],
        [ 4.1117e-03, -1.5284e-01,  1.2197e-02, -2.1839e-02,  2.4325e-01,
          2.2117e-01, -1.7195e-01,  1.3500e-01],
        [-3.1475e-01, -2.7706e-01, -2.4125e-01, -1.5143e-01, -3.3724e-01,
          2.0582e-01,  2.9673e-01, -2.7537e-01]], device='cuda:0',
       requires_grad=True) 

model.module_8.bias torch.Size([100])
Parameter containing:
tensor([-0.3233, -0.1064,  0.2763,  0.0960,  0.0200,  0.3375,  0.2820,  0.1690,
        -0.1803, -0.0894, -0.0580, -0.0629,  0.0836,  0.2220, -0.1992, -0.3439,
        -0.3088,  0.0937, -0.2286,  0.1752,  0.1115,  0.1058, -0.1345,  0.1773,
         0.2437,  0.1136,  0.0211,  0.1520,  0.0408,  0.0872,  0.1421,  0.3164,
        -0.0590,  0.1795,  0.2729, -0.2864, -0.0075, -0.2959, -0.2640,  0.2250,
        -0.2726,  0.3309,  0.3139, -0.2354, -0.3138, -0.0575, -0.3200,  0.1830,
        -0.1201,  0.0794, -0.0045, -0.0318, -0.1980,  0.0943,  0.1334,  0.0272,
        -0.0174, -0.1344, -0.1572,  0.1005,  0.1444, -0.1456, -0.1553,  0.2988,
         0.2269, -0.3357, -0.2056, -0.0105, -0.1481,  0.0335, -0.1307, -0.3535,
        -0.2557,  0.2240,  0.0614,  0.3270,  0.2945, -0.0379,  0.2006, -0.0559,
         0.1750, -0.2756, -0.1220,  0.0113,  0.0574,  0.1217,  0.3198,  0.3013,
        -0.2438, -0.0514, -0.0133,  0.1297, -0.2389,  0.1500,  0.1110,  0.2116,
        -0.1021,  0.0510,  0.1905,  0.3177], device='cuda:0',
       requires_grad=True) 

model.module_10.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0296,  0.0552, -0.0351,  ...,  0.0160, -0.0781, -0.0524],
        [-0.0995, -0.0349, -0.0464,  ..., -0.0899, -0.0671, -0.0296],
        [-0.0685,  0.0637, -0.0054,  ..., -0.0668, -0.0258, -0.0290],
        ...,
        [ 0.0103, -0.0274,  0.0294,  ..., -0.0638, -0.0698, -0.0770],
        [-0.0008, -0.0909,  0.0721,  ...,  0.0208, -0.0843, -0.0220],
        [-0.0803,  0.0688, -0.0961,  ...,  0.0578, -0.0505,  0.0378]],
       device='cuda:0', requires_grad=True) 

model.module_10.bias torch.Size([100])
Parameter containing:
tensor([-0.0157, -0.0224, -0.0229,  0.0207, -0.0374,  0.0926,  0.0133,  0.0831,
         0.0029, -0.0320, -0.0212, -0.0529, -0.0065,  0.0879, -0.0031,  0.0770,
        -0.0961, -0.0216,  0.0501,  0.0361,  0.0045, -0.0520, -0.0171, -0.0297,
        -0.0376, -0.0047, -0.0294, -0.0257, -0.0455, -0.0251, -0.0233,  0.0258,
        -0.0318,  0.0301, -0.0144, -0.0878,  0.0206, -0.0727,  0.0846, -0.0435,
         0.0437, -0.0309, -0.0363, -0.0931, -0.0916,  0.0721, -0.0163, -0.0909,
        -0.0822, -0.0290, -0.0169,  0.0342, -0.0008, -0.0222, -0.0713, -0.0855,
         0.0139, -0.0334,  0.0060, -0.0905, -0.0454, -0.0410,  0.0363,  0.0811,
        -0.0631,  0.0018, -0.0146,  0.0105,  0.0262, -0.0028, -0.0576, -0.0736,
         0.0893, -0.0082,  0.0644, -0.0822,  0.0110, -0.0620,  0.0630, -0.0574,
         0.0817,  0.0379, -0.0844,  0.0767, -0.0077,  0.0879, -0.0169,  0.0072,
         0.0043,  0.0954, -0.0448,  0.0431, -0.0213, -0.0763,  0.0595, -0.0799,
        -0.0580, -0.0708,  0.0985,  0.0679], device='cuda:0',
       requires_grad=True) 

model.module_12.weight torch.Size([16, 100])
Parameter containing:
tensor([[-0.0218, -0.0561,  0.0505,  ..., -0.0974,  0.0467,  0.0583],
        [ 0.0505,  0.0220, -0.0839,  ..., -0.0093,  0.0723, -0.0532],
        [ 0.0841,  0.0916, -0.0457,  ..., -0.0735, -0.0836, -0.0631],
        ...,
        [ 0.0542,  0.0732, -0.0270,  ...,  0.0974, -0.0376, -0.0574],
        [ 0.0276,  0.0783, -0.0911,  ..., -0.0791,  0.0565,  0.0299],
        [ 0.0878,  0.0606, -0.0867,  ..., -0.0040, -0.0184, -0.0839]],
       device='cuda:0', requires_grad=True) 

model.module_12.bias torch.Size([16])
Parameter containing:
tensor([ 0.0480, -0.0736,  0.0880,  0.0830, -0.0743,  0.0449,  0.0114, -0.0458,
        -0.0384, -0.0241,  0.0049, -0.0137, -0.0333, -0.0744,  0.0827, -0.0639],
       device='cuda:0', requires_grad=True) 

model.module_14.bias torch.Size([8])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

model.module_14.lin.weight torch.Size([8, 16])
Parameter containing:
tensor([[ 0.0494,  0.2038, -0.1644, -0.0112, -0.2707,  0.0292, -0.0987,  0.1929,
          0.4930,  0.4196,  0.0338, -0.4551,  0.4588,  0.0045, -0.1087,  0.2355],
        [ 0.1375,  0.2083, -0.1501,  0.3132,  0.0721, -0.3514,  0.3696, -0.1774,
          0.4024,  0.2012,  0.1655,  0.1564,  0.1528,  0.4309,  0.0793,  0.2903],
        [-0.1324,  0.1747,  0.1447, -0.2072,  0.2759,  0.3557,  0.3201,  0.4748,
         -0.4029, -0.1708,  0.2682, -0.0734, -0.1391,  0.1152,  0.3986,  0.2632],
        [-0.1078,  0.3439, -0.4176,  0.3692,  0.1951,  0.1936, -0.0120,  0.0766,
          0.3803,  0.0318, -0.2793,  0.1589,  0.0315, -0.0149, -0.1509,  0.3458],
        [-0.0989, -0.3875, -0.2049, -0.3751, -0.3261, -0.1306,  0.0326,  0.2354,
         -0.0279,  0.4049, -0.4470, -0.2452, -0.2032,  0.3514, -0.0391, -0.1060],
        [ 0.4132, -0.4269,  0.0677,  0.2519,  0.2465,  0.3879,  0.3470,  0.4924,
          0.3909, -0.0294,  0.0129,  0.2568, -0.2018, -0.4833,  0.0639, -0.1592],
        [-0.3602,  0.0915,  0.1613,  0.4631, -0.2037,  0.0767, -0.4252, -0.2351,
          0.1854, -0.2429, -0.0098, -0.4202,  0.1557,  0.1525, -0.2051,  0.4612],
        [-0.4724,  0.2179, -0.3803,  0.1152, -0.1198, -0.0131,  0.0358, -0.4635,
          0.3145, -0.4240,  0.2332, -0.3511, -0.0445, -0.3520,  0.1275,  0.3598]],
       device='cuda:0', requires_grad=True) 

model.module_15.weight torch.Size([100, 8])
Parameter containing:
tensor([[-2.5749e-01,  9.2783e-02,  1.7237e-02, -3.6452e-02, -1.4611e-01,
         -3.2281e-01,  2.5103e-01, -2.6306e-01],
        [ 3.2317e-01, -1.1744e-01,  1.2244e-01,  1.4035e-01, -5.4700e-02,
         -1.8851e-01, -2.1230e-01,  3.1660e-01],
        [-3.2356e-01,  3.2524e-01, -1.2912e-01,  2.2444e-01, -2.8537e-01,
         -1.8870e-02, -1.7085e-01, -1.9306e-01],
        [ 1.2990e-01,  2.3936e-01, -2.6136e-01,  1.6858e-01, -2.9432e-01,
          1.7141e-01,  1.5590e-01,  1.9144e-01],
        [ 2.6024e-01,  1.1696e-01,  3.4392e-01,  6.6399e-02,  2.9736e-01,
          6.9515e-02,  8.0094e-02, -2.2516e-01],
        [-6.3217e-02,  9.3730e-02, -1.2844e-01,  1.5198e-01,  9.7268e-02,
         -1.5849e-01, -2.1235e-01,  1.6444e-01],
        [-2.4890e-01,  1.2919e-01, -2.2004e-01, -3.0806e-01,  3.3485e-03,
         -5.5823e-02,  1.2986e-01, -1.0596e-02],
        [-2.7929e-01, -2.1154e-04, -2.1533e-01,  9.8279e-02,  2.6648e-01,
         -1.5092e-01, -1.9466e-01, -8.2416e-02],
        [-6.9002e-02,  2.6687e-02,  2.4328e-02,  1.1747e-01, -1.3049e-01,
         -1.4568e-01,  3.0466e-01,  2.0155e-01],
        [ 1.7431e-01, -2.3577e-01,  2.3694e-01,  3.3554e-01, -1.3779e-01,
         -3.3683e-01,  1.1740e-01, -1.7460e-01],
        [ 1.3173e-01, -1.1308e-01,  3.1094e-01, -1.0064e-01,  2.2950e-02,
         -6.1074e-02, -1.8092e-01,  1.2623e-01],
        [ 2.4599e-01, -3.0621e-01,  1.2400e-02,  2.2898e-01,  1.1355e-01,
         -3.3932e-01, -1.9767e-02,  1.5737e-01],
        [ 1.1133e-01, -3.5344e-01, -6.9702e-02, -2.2573e-01, -1.5751e-01,
         -6.0756e-03,  3.1733e-01,  1.8839e-01],
        [-2.2583e-01,  1.8728e-01, -1.9012e-01,  8.2666e-02, -2.9707e-01,
          3.4660e-02, -1.3638e-01,  3.4109e-01],
        [-2.5708e-01, -1.7555e-01,  1.9114e-01, -1.3664e-01,  1.0724e-01,
          3.1753e-01, -2.8795e-01, -3.2292e-01],
        [-6.2861e-03,  4.2805e-02,  1.7533e-01,  1.5398e-01, -2.6586e-01,
          2.9689e-01, -8.4860e-02,  2.1917e-01],
        [-2.2358e-01,  1.0053e-01,  2.1813e-01,  2.1323e-01, -2.3896e-01,
         -2.2006e-01,  2.9492e-02,  8.1502e-02],
        [ 2.7416e-01,  1.3839e-03,  3.4751e-01, -1.6841e-01,  1.5545e-01,
          2.2087e-01,  2.4984e-01, -2.1077e-01],
        [ 1.2919e-02,  1.3704e-01, -1.1290e-01,  5.9634e-02,  2.1738e-01,
          6.7488e-02, -1.0636e-01, -3.2899e-01],
        [-2.9780e-01, -1.4648e-01, -2.2127e-01,  1.8668e-01,  6.4377e-02,
          1.1045e-01, -3.1901e-01,  1.3630e-01],
        [ 4.8024e-03, -2.5435e-01, -2.8247e-01,  9.1066e-02,  1.7201e-02,
         -2.4917e-01, -4.8821e-02,  2.0718e-02],
        [ 1.9560e-01, -1.5709e-01, -2.7946e-01,  1.2725e-01, -1.8296e-01,
         -1.3689e-01, -3.9429e-02, -2.0927e-01],
        [-2.7985e-01, -1.7341e-01,  2.6872e-01,  9.3608e-02, -1.5542e-01,
          3.5285e-01, -1.7286e-01, -1.7710e-01],
        [ 2.3557e-01, -2.3350e-01, -2.2215e-01,  3.1105e-01, -1.9616e-01,
          2.5366e-01,  2.6346e-01, -2.4405e-01],
        [-8.4314e-02,  3.3468e-01, -2.5853e-01, -2.3854e-01,  2.8960e-01,
         -3.0474e-01,  6.0055e-02, -1.1278e-01],
        [-3.2325e-01, -2.5352e-01,  1.5129e-01,  1.3868e-01, -4.5477e-02,
         -2.4039e-01,  5.2425e-02, -6.2514e-02],
        [ 1.8490e-01, -1.2500e-01, -1.2346e-01,  2.4446e-01, -1.1186e-01,
         -2.2136e-01,  1.6139e-01,  1.1234e-01],
        [ 1.9103e-02, -1.7628e-01, -2.2637e-01,  3.7387e-02,  7.4439e-02,
         -2.5561e-01,  1.9734e-01, -1.5074e-02],
        [ 1.7044e-01,  2.5277e-01,  2.8917e-01,  3.2793e-01,  1.3728e-02,
          2.0395e-01,  2.2044e-01,  1.1786e-01],
        [-1.9170e-01, -4.4951e-02, -3.2800e-01,  6.5316e-02,  1.3737e-01,
         -1.4726e-01,  1.0796e-01,  2.2112e-01],
        [-3.4873e-01,  2.8261e-01, -2.9479e-01, -5.5377e-02, -2.0258e-01,
         -2.4526e-01,  5.3605e-02, -3.2916e-02],
        [-1.7663e-01, -1.1019e-01,  1.1719e-01,  1.7764e-01, -1.1285e-01,
          1.8941e-01, -2.5422e-01, -3.0905e-01],
        [ 3.2980e-01, -3.0513e-01,  2.6766e-01,  3.3823e-01,  1.2685e-01,
         -1.1184e-01, -1.2557e-01, -2.3544e-01],
        [-2.4913e-02,  2.0210e-01, -1.7070e-01, -1.2712e-01,  5.1715e-02,
          2.2715e-01, -2.0883e-02, -4.0445e-02],
        [-3.3929e-01, -9.8820e-02,  1.5571e-01,  1.3076e-01, -9.4213e-02,
         -1.4367e-01, -3.1491e-02, -7.3620e-02],
        [ 1.5664e-01, -1.8977e-01,  5.2995e-02,  3.1843e-01,  1.3328e-01,
         -1.5929e-01, -1.6427e-01,  9.2516e-03],
        [ 2.4695e-02,  2.7069e-01, -2.6311e-01, -3.2627e-01,  2.1626e-01,
         -1.7415e-01, -2.6630e-01,  9.0207e-02],
        [-3.4313e-01,  2.0423e-01, -1.5436e-01,  2.7768e-01, -3.3647e-01,
         -3.3702e-01, -1.4257e-01,  2.9895e-01],
        [-3.0599e-01, -2.1661e-01,  3.2155e-01,  2.7582e-01,  3.0395e-02,
         -2.9670e-01,  2.6700e-01,  1.8212e-01],
        [ 2.6413e-01,  6.9840e-02, -2.3634e-01, -3.2024e-01, -2.6243e-01,
          3.4637e-01,  8.6203e-02,  1.8141e-01],
        [-1.6448e-01,  3.0768e-01,  1.0375e-01,  2.6375e-01,  1.9672e-01,
         -2.0672e-01,  3.1171e-01, -1.6469e-01],
        [ 2.0514e-01,  3.1993e-03, -1.6631e-01,  2.2121e-01,  1.6822e-01,
          3.8028e-02, -2.6298e-01,  1.7147e-01],
        [ 2.0190e-01, -1.2417e-01,  9.5515e-02, -1.5591e-01,  2.0245e-01,
         -2.6999e-01,  1.4440e-01, -2.7236e-01],
        [ 8.1351e-02,  1.6618e-01,  1.4814e-01,  1.1630e-01,  3.4489e-01,
         -3.3382e-01, -1.4381e-01, -1.3702e-01],
        [ 3.3698e-01,  1.2523e-01, -9.6120e-02,  2.5376e-01,  3.6994e-02,
         -3.2913e-01,  4.9610e-02, -1.4869e-01],
        [-2.3980e-01,  4.1608e-02,  1.7918e-01, -3.2719e-01,  3.2329e-01,
         -2.1883e-03,  9.6458e-03, -3.3071e-01],
        [-6.3635e-03,  9.6894e-02, -2.9695e-01, -2.4985e-01,  9.2970e-02,
         -2.3335e-02,  3.4870e-01,  2.5458e-03],
        [ 3.4278e-02, -1.8142e-01, -1.1262e-01,  2.0305e-01, -3.2615e-01,
          3.4288e-02,  2.4132e-01, -1.0234e-01],
        [-3.3445e-01, -3.1320e-01, -1.8288e-01,  1.8584e-02,  2.3715e-01,
          2.5273e-01,  6.3993e-02, -1.1924e-01],
        [ 7.0622e-02,  2.5682e-02, -6.4396e-02,  9.5872e-02,  3.5412e-02,
          2.5198e-01,  1.5226e-01,  2.5616e-01],
        [ 8.8232e-02, -9.3152e-02, -3.3253e-01, -2.3671e-01, -2.2108e-01,
          1.5518e-01, -1.9188e-01,  3.0629e-01],
        [-8.5114e-02, -2.9620e-01, -1.8133e-01, -1.3152e-01, -1.7376e-01,
         -1.7821e-01,  2.1562e-01, -1.3454e-01],
        [-1.7428e-01,  3.3172e-01, -4.4741e-02, -5.1271e-02,  2.1158e-01,
          3.0244e-01,  2.9449e-02,  3.3624e-01],
        [ 6.5497e-02, -2.6754e-01,  2.0724e-01, -1.0200e-01, -1.9457e-01,
         -2.6481e-01,  3.5294e-01,  1.6113e-01],
        [ 1.1153e-02, -1.4584e-01, -2.5233e-01,  2.7942e-01,  2.6167e-01,
          4.1833e-02, -9.8205e-02,  9.3928e-02],
        [ 3.4235e-02,  7.1245e-02, -6.1575e-02, -1.3937e-01,  8.5945e-02,
          1.9917e-01, -2.3640e-01, -7.2775e-02],
        [-7.4631e-02, -1.0468e-01,  1.6028e-01, -9.8932e-02,  6.5603e-02,
          3.3700e-01, -2.6158e-01,  2.9099e-01],
        [ 5.1671e-02, -1.7019e-02,  1.5680e-01, -1.2053e-01,  1.8085e-01,
         -8.3621e-02, -5.4681e-02, -2.5340e-01],
        [ 2.9617e-01,  2.6350e-01, -2.6974e-01,  3.3459e-01, -3.7623e-02,
         -1.5474e-01, -1.6775e-01,  2.6245e-01],
        [ 4.2293e-02,  1.2244e-01,  1.3457e-01, -1.2916e-01, -5.7835e-02,
         -8.6656e-02,  8.8499e-02,  1.1876e-01],
        [-1.4525e-01, -3.4220e-01,  2.7383e-01, -4.2751e-02, -2.2668e-01,
         -8.7250e-02,  3.2574e-02, -3.4040e-01],
        [-1.6245e-01,  2.7463e-01, -6.9558e-02,  2.4382e-01, -1.5765e-01,
         -5.9532e-02, -2.4074e-01,  1.4932e-01],
        [-2.6500e-01,  2.6793e-03, -2.7560e-01, -8.3124e-02, -1.0871e-01,
          1.8446e-01, -4.4828e-02,  9.3844e-02],
        [-2.2411e-01, -1.7827e-01,  7.6591e-02,  6.6630e-02, -1.3143e-01,
         -1.9194e-01, -6.1875e-02,  3.9675e-02],
        [ 1.2300e-01,  8.5296e-02, -3.0313e-01,  1.7419e-01, -4.0929e-02,
         -1.1426e-01, -1.1985e-01, -1.0668e-01],
        [ 3.5227e-01, -1.8719e-01, -3.4323e-01,  1.3567e-01, -3.4890e-01,
          3.2543e-01,  1.6624e-01,  2.8935e-01],
        [-1.6024e-01,  3.2168e-01,  1.6361e-01,  2.8190e-01, -4.7462e-02,
         -1.1967e-01,  3.5061e-01, -1.4044e-01],
        [ 1.6802e-02,  1.5563e-01,  1.9410e-01,  6.7729e-02, -1.0323e-01,
          8.9286e-02, -1.2903e-01, -1.6830e-01],
        [ 3.6607e-02,  3.6564e-02, -3.2575e-01, -1.7506e-01, -1.3145e-01,
         -1.1831e-02,  3.1060e-01, -2.3872e-01],
        [-1.9911e-01,  3.3796e-01,  5.9013e-02, -1.4993e-01,  2.0279e-02,
         -1.7183e-01,  7.0068e-03, -1.8000e-01],
        [ 2.4789e-02,  4.1592e-02,  3.3281e-01,  1.8451e-01,  4.6386e-02,
          2.7862e-01,  3.5245e-01, -1.8860e-01],
        [-2.5743e-01,  2.5244e-03, -1.3494e-01,  1.3397e-01,  2.8819e-01,
          6.2562e-02, -4.1108e-02,  1.5620e-01],
        [-2.7585e-01,  1.8391e-01, -1.2018e-01, -2.4565e-01, -5.4250e-02,
          3.4190e-01, -1.4695e-01, -2.5227e-01],
        [ 2.2539e-01, -2.3910e-02, -1.0037e-01,  2.2443e-01,  1.5474e-01,
          1.1801e-01,  3.3976e-01, -3.0749e-01],
        [-1.2260e-01,  2.4492e-01, -2.9810e-01, -5.6906e-02,  1.1793e-01,
          2.3465e-02,  7.1297e-02, -1.9174e-01],
        [ 1.0758e-01, -2.3371e-01,  4.7793e-02, -4.7295e-02,  2.7377e-01,
         -3.2652e-01, -2.5033e-01,  3.0718e-01],
        [ 3.4768e-01, -1.1124e-02,  2.4432e-01, -5.4892e-02,  3.2325e-01,
         -1.9136e-01, -1.7273e-01,  4.8044e-02],
        [-1.5764e-01,  2.2756e-01, -1.1737e-01,  2.4200e-01, -3.0029e-01,
         -2.1160e-01, -1.6537e-01,  9.5206e-02],
        [ 3.5213e-01,  1.5380e-01, -2.8429e-01, -3.4819e-01,  1.5093e-01,
          1.9126e-01,  2.6146e-01, -2.8081e-01],
        [-2.4075e-01,  2.8782e-01,  2.8669e-01,  1.5588e-02, -3.4823e-01,
          3.4501e-01,  1.7381e-01, -1.3782e-01],
        [-8.5535e-02, -4.8400e-03,  3.0654e-01,  1.3429e-02,  2.2613e-01,
          1.6283e-01, -1.7099e-01, -3.5249e-01],
        [ 2.2692e-01, -1.9918e-01,  1.3065e-01,  2.0666e-01, -9.2928e-02,
         -2.2062e-01,  3.3986e-01, -1.9426e-01],
        [ 2.9095e-01,  2.8377e-01,  3.2595e-01,  3.2817e-01, -4.7289e-02,
          2.6992e-01, -3.1409e-01,  2.9732e-02],
        [-2.4206e-01, -2.6370e-01,  1.8729e-01, -1.8190e-01, -7.7377e-02,
         -3.2703e-01, -1.8470e-01,  1.2176e-01],
        [ 3.1968e-01,  9.0922e-02, -2.7591e-02, -1.9293e-01, -2.2406e-01,
         -2.0226e-01,  2.6852e-01, -1.5158e-01],
        [ 1.2819e-01,  1.4021e-01, -2.1678e-01, -1.9002e-01, -9.6475e-02,
         -2.4334e-01,  3.5057e-01, -1.7621e-01],
        [-3.0681e-01, -2.3733e-01,  2.7447e-03,  3.3098e-01, -3.1169e-01,
          3.6977e-02,  5.8303e-03, -1.1972e-02],
        [ 5.6004e-02, -1.3493e-01,  1.4102e-01,  7.7917e-02,  3.0392e-01,
          2.8047e-01,  6.2351e-02, -2.0567e-01],
        [ 6.1362e-04, -2.7011e-01,  1.3239e-01,  7.9381e-02, -2.7536e-03,
         -3.3280e-01, -2.0921e-01,  1.7853e-01],
        [ 2.6495e-01, -2.2131e-01, -2.3438e-01,  7.1488e-02,  1.8513e-01,
         -1.2148e-01, -3.4208e-02,  3.2869e-01],
        [-1.4154e-01,  1.5866e-01, -4.9789e-02,  2.8974e-01,  1.4782e-01,
          1.3174e-01,  2.8250e-01, -5.2410e-03],
        [-9.8590e-02, -2.9322e-01,  3.2667e-01,  2.3027e-01, -6.3693e-02,
         -3.0643e-01,  3.5247e-01,  2.7358e-01],
        [-2.9811e-01,  1.0707e-01, -1.8470e-02,  2.1355e-01, -2.0070e-02,
         -1.3234e-01, -2.2292e-02,  3.8919e-02],
        [-2.0335e-01,  2.0687e-01,  3.2705e-01,  3.4618e-01,  2.3614e-01,
         -2.0333e-01,  1.2768e-01, -1.2649e-01],
        [ 1.9415e-02, -2.1172e-01, -1.0515e-01, -2.6661e-01,  6.5684e-03,
          2.9829e-02,  3.2053e-01,  1.2863e-01],
        [ 2.0269e-01, -1.7309e-01,  1.1599e-02, -4.0672e-02,  4.2147e-02,
         -1.4919e-01,  1.8652e-01,  3.3651e-01],
        [ 1.4971e-01,  6.3657e-02, -1.0351e-02, -2.6222e-01, -2.0960e-01,
         -1.6853e-01, -1.6267e-01, -3.2744e-01],
        [ 7.4370e-02, -1.1432e-02,  5.4376e-02,  1.6363e-01, -2.2840e-01,
         -1.9278e-01, -2.6979e-01, -7.7359e-02],
        [-1.3587e-01,  2.1623e-01,  3.8394e-02, -1.3275e-01,  1.0500e-01,
         -2.5641e-02, -2.4126e-02,  2.0483e-01],
        [ 4.9866e-02,  9.6367e-02,  2.8974e-01,  2.5600e-01, -2.1267e-01,
         -8.1154e-02, -1.7673e-01,  1.5948e-01]], device='cuda:0',
       requires_grad=True) 

model.module_15.bias torch.Size([100])
Parameter containing:
tensor([-0.1256, -0.1463, -0.0371,  0.2099, -0.2806, -0.2831,  0.2623,  0.0800,
        -0.0910, -0.3468, -0.0725,  0.1986, -0.1838, -0.1025, -0.2055, -0.0533,
         0.0522,  0.1599, -0.2084, -0.2895,  0.0910, -0.2682,  0.1909, -0.1983,
        -0.2742, -0.0602,  0.1595, -0.2652, -0.0299, -0.1646, -0.1649, -0.2494,
         0.1703, -0.1796, -0.2702, -0.3162,  0.3384,  0.0154, -0.0115,  0.3208,
         0.2514, -0.0942,  0.2575, -0.0361,  0.2809, -0.2168,  0.1167, -0.2873,
        -0.1431, -0.0048, -0.2617,  0.0120, -0.0178,  0.3389,  0.0496,  0.2203,
         0.2071,  0.2117,  0.1886,  0.0969,  0.2622,  0.3097, -0.1054,  0.1882,
         0.1288,  0.2086, -0.1631,  0.0250,  0.0443,  0.1109,  0.0599,  0.2184,
        -0.1465, -0.0686, -0.3322,  0.2529, -0.3295,  0.0994, -0.2638,  0.1088,
        -0.1903,  0.2157, -0.3023,  0.2171, -0.0837, -0.3189, -0.1106, -0.1151,
         0.1158,  0.3020,  0.1154, -0.0068,  0.0322, -0.2774, -0.1727,  0.2997,
         0.2822, -0.0183,  0.1205,  0.2679], device='cuda:0',
       requires_grad=True) 

model.module_17.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0635,  0.0025, -0.0733,  ...,  0.0954,  0.0478, -0.0001],
        [ 0.0518,  0.0326,  0.0054,  ..., -0.0093,  0.0549,  0.0826],
        [-0.0021,  0.0017, -0.0694,  ..., -0.0640,  0.0869,  0.0762],
        ...,
        [-0.0434,  0.0301,  0.0465,  ...,  0.0513,  0.0850, -0.0048],
        [ 0.0991, -0.0666, -0.0832,  ..., -0.0391, -0.0708,  0.0176],
        [-0.0020,  0.0815,  0.0031,  ...,  0.0461,  0.0345, -0.0153]],
       device='cuda:0', requires_grad=True) 

model.module_17.bias torch.Size([100])
Parameter containing:
tensor([ 0.0457, -0.0635, -0.0114,  0.0399,  0.0392, -0.0495, -0.0854,  0.0495,
        -0.0500,  0.0548, -0.0947, -0.0864,  0.0930,  0.0899, -0.0329,  0.0594,
         0.0656, -0.0266,  0.0783,  0.0710,  0.0969, -0.0127, -0.0885, -0.0520,
        -0.0160, -0.0414,  0.0632,  0.0834,  0.0767,  0.0223, -0.0467, -0.0607,
        -0.0118, -0.0572,  0.0797, -0.0767, -0.0780, -0.0581, -0.0659, -0.0614,
         0.0367, -0.0414, -0.0640,  0.0729, -0.0406,  0.0895,  0.0753,  0.0857,
        -0.0897,  0.0662, -0.0661,  0.0308, -0.0640,  0.0847,  0.0931, -0.0654,
         0.0370, -0.0482, -0.0117,  0.0910,  0.0819, -0.0849,  0.0450, -0.0589,
        -0.0425,  0.0818, -0.0473,  0.0304, -0.0840, -0.0749, -0.0965,  0.0382,
        -0.0816,  0.0794,  0.0236, -0.0675,  0.0911,  0.0048, -0.0341,  0.0642,
        -0.0636, -0.0614, -0.0439, -0.0188,  0.0692,  0.0006, -0.0617, -0.0819,
        -0.0047,  0.0421, -0.0994,  0.0324,  0.0131, -0.0349,  0.0471, -0.0470,
        -0.0468, -0.0433,  0.0342,  0.0836], device='cuda:0',
       requires_grad=True) 

model.module_19.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0031,  0.0323,  0.0590,  ..., -0.0403,  0.0776, -0.0063],
        [-0.0970, -0.0234, -0.0402,  ..., -0.0428,  0.0980, -0.0627],
        [ 0.0699,  0.0922,  0.0731,  ...,  0.0071, -0.0221, -0.0443],
        ...,
        [ 0.0533, -0.0270, -0.0163,  ..., -0.0014, -0.0029, -0.0208],
        [ 0.0269,  0.0453, -0.0565,  ...,  0.0544,  0.0759,  0.0657],
        [-0.0554, -0.0462, -0.0161,  ..., -0.0488,  0.0849, -0.0990]],
       device='cuda:0', requires_grad=True) 

model.module_19.bias torch.Size([16])
Parameter containing:
tensor([ 0.0834, -0.0360, -0.0069, -0.0002, -0.0276, -0.0229,  0.0246,  0.0193,
         0.0116,  0.0982, -0.0098, -0.0619, -0.0876,  0.0758, -0.0724,  0.0505],
       device='cuda:0', requires_grad=True) 



#### FINAL PARAMETERS ####
W 256 torch.Size([16, 16])
Parameter containing:
tensor([[-4.1317e-01,  4.2671e-01,  1.0256e+00, -5.4140e-01,  4.2673e-01,
         -1.9044e+00,  6.6222e-02,  2.5172e-03,  5.2952e-01,  5.0412e-01,
          8.7831e-01,  2.0012e+00,  2.0433e-01, -4.3616e-02,  4.7875e-02,
          1.0236e+00],
        [ 7.1872e-03, -1.0613e+00, -6.8470e-01, -9.1097e-01,  1.6545e+00,
         -5.3286e-01, -5.9417e-01,  8.0325e-02, -7.6797e-01,  8.7942e-01,
         -6.1121e-01, -1.5052e+00, -6.2049e-01,  1.5895e-01,  7.9526e-01,
         -4.6898e-03],
        [ 5.3962e-01,  7.7223e-01,  7.8901e-01,  7.1249e-01, -1.6141e+00,
          4.0836e-01, -1.6632e+00, -1.5432e+00, -9.8488e-01,  1.0977e+00,
         -1.0120e+00, -1.9037e-01, -2.8250e-03,  8.6877e-02,  2.3467e-01,
          3.7227e-02],
        [-3.6489e-01, -1.1169e+00, -8.3735e-01,  2.4105e-01, -5.3148e-01,
         -1.2743e+00, -2.9817e-01,  1.5952e-02, -5.3924e-02, -1.9671e-01,
         -4.0066e-01,  1.7790e-01,  1.7472e+00, -5.6071e-01,  7.6278e-01,
         -2.4726e+00],
        [ 9.0842e-01, -7.0249e-01,  2.3954e+00,  2.8717e-01,  1.1326e+00,
          3.5186e-01,  3.6620e-01,  1.6943e-01, -1.0602e+00, -1.0519e+00,
          1.8444e+00, -7.7016e-01,  2.3126e-01,  5.6219e-01, -1.4702e-01,
          1.3839e+00],
        [-7.5106e-01, -8.5701e-01,  7.6493e-01, -8.9169e-01,  9.7164e-02,
         -6.5368e-02,  2.0252e-01, -1.3877e+00, -1.3885e-01, -2.2066e-02,
         -6.5519e-02,  1.1231e+00,  7.0764e-01,  9.8282e-02,  9.2536e-01,
          1.1903e-01],
        [ 1.0541e+00,  1.5673e-01,  1.2465e+00, -4.3649e-01,  1.2447e+00,
         -8.5138e-01, -3.8078e-01, -4.4182e-01,  1.3315e-01, -2.8974e-01,
         -9.8917e-01,  1.3841e+00, -6.2550e-01,  1.2254e+00, -1.1626e+00,
          1.2280e+00],
        [ 2.3963e-01,  2.8043e-01,  9.2702e-01, -4.8760e-01,  1.3653e-01,
         -1.0599e+00,  6.1581e-01, -1.7967e-01,  5.8115e-01,  7.8447e-01,
          1.8630e+00, -9.2880e-01,  3.0206e-01, -8.5796e-01, -3.5793e-01,
         -3.9271e-01],
        [ 6.4082e-02, -1.3043e+00, -1.0911e+00,  3.4606e-01, -1.1755e+00,
         -5.1834e-01, -5.7716e-01,  1.7630e+00, -3.0726e+00, -1.7569e+00,
         -6.5205e-01,  1.5890e+00, -2.6390e+00,  1.5130e-01, -8.1903e-02,
         -6.5142e-01],
        [ 7.8571e-01,  1.0531e+00,  9.8298e-01, -6.0382e-01,  1.5901e+00,
         -2.6750e+00, -4.7722e-01,  6.5216e-01, -1.4883e+00,  4.7829e-01,
         -2.4216e-01, -2.9700e-01, -7.7382e-01, -6.6354e-01, -5.9738e-01,
          9.9304e-02],
        [-6.0144e-01,  3.9646e-01, -2.2126e-01, -1.4982e+00,  1.3994e-01,
          3.9083e-01,  5.1334e-01,  2.8253e-01, -8.8740e-01,  2.0284e+00,
         -7.3918e-01,  1.7161e+00, -9.9581e-01, -5.5940e-01,  5.1217e-01,
          5.1972e-01],
        [-1.5811e+00, -8.9310e-01, -4.3312e-01,  2.3497e-01, -5.6037e-02,
          3.5605e-01, -6.0628e-01,  1.6170e+00, -1.0483e+00, -3.2451e-01,
          7.9069e-02,  6.2278e-01, -2.5748e-01, -5.7330e-01, -9.7879e-01,
         -1.0133e+00],
        [-2.1552e-01,  4.2660e-01,  4.2657e-01, -1.9775e+00,  1.2081e+00,
         -3.6190e-01, -2.2114e-02, -1.3830e+00,  2.9112e+00, -1.3641e+00,
          5.4461e-01, -5.6099e-01, -5.7757e-02, -1.0247e+00,  1.1684e+00,
          2.8158e-01],
        [ 1.0204e+00, -1.1897e+00,  1.0756e+00, -1.2878e+00,  8.3469e-01,
          1.8436e+00,  1.1996e+00, -1.1843e+00, -1.8179e+00,  5.9606e-01,
         -5.8594e-01, -8.6492e-01, -1.0013e+00,  3.2305e-01,  2.4984e-01,
         -1.4160e+00],
        [-8.6749e-01, -8.7535e-01, -6.5319e-01,  8.9284e-01,  3.7347e-01,
         -1.3580e+00, -6.8122e-01, -1.7359e+00, -1.1851e+00, -2.3123e-01,
          6.6760e-01,  1.1092e+00, -2.2753e+00, -1.1637e-04,  2.0859e+00,
          1.6706e+00],
        [ 1.4547e-01,  9.0048e-01,  1.5550e+00,  1.9543e+00, -2.6444e-01,
         -1.0263e+00, -4.4316e-01,  1.8513e-01, -6.8393e-01, -6.6373e-01,
         -7.7158e-01, -9.5146e-01,  5.2737e-01, -8.4518e-01, -7.3610e-01,
          1.9039e-01]], device='cuda:0', requires_grad=True) 
grad:  tensor([[ 0.0442,  0.0063,  0.0465, -0.0031, -0.0035, -0.0063, -0.0020,  0.0161,
         -0.0026,  0.0452,  0.0228,  0.0258,  0.0110,  0.0686, -0.0051,  0.0599],
        [ 0.0063,  0.0027,  0.0049, -0.0009, -0.0021, -0.0017,  0.0031,  0.0012,
         -0.0008,  0.0054,  0.0049,  0.0102,  0.0071,  0.0175, -0.0010,  0.0225],
        [ 0.0465,  0.0049,  0.0520, -0.0028, -0.0020, -0.0056, -0.0063,  0.0165,
         -0.0022,  0.0497,  0.0213,  0.0204,  0.0047,  0.0658, -0.0051,  0.0471],
        [-0.0031, -0.0009, -0.0028,  0.0003,  0.0006,  0.0006, -0.0007, -0.0010,
          0.0003, -0.0028, -0.0020, -0.0031, -0.0019, -0.0061,  0.0004, -0.0071],
        [-0.0035, -0.0021, -0.0020,  0.0006,  0.0016,  0.0011, -0.0027, -0.0006,
          0.0006, -0.0025, -0.0032, -0.0074, -0.0055, -0.0116,  0.0006, -0.0163],
        [-0.0063, -0.0017, -0.0056,  0.0006,  0.0011,  0.0012, -0.0013, -0.0022,
          0.0006, -0.0057, -0.0041, -0.0062, -0.0039, -0.0123,  0.0008, -0.0143],
        [-0.0020,  0.0031, -0.0063, -0.0007, -0.0027, -0.0013,  0.0067, -0.0013,
         -0.0008, -0.0050,  0.0027,  0.0106,  0.0105,  0.0094, -0.0003,  0.0235],
        [ 0.0161,  0.0012,  0.0165, -0.0010, -0.0006, -0.0022, -0.0013,  0.0080,
         -0.0009,  0.0159,  0.0087,  0.0062,  0.0024,  0.0192, -0.0018,  0.0172],
        [-0.0026, -0.0008, -0.0022,  0.0003,  0.0006,  0.0006, -0.0008, -0.0009,
          0.0003, -0.0022, -0.0018, -0.0029, -0.0020, -0.0055,  0.0004, -0.0068],
        [ 0.0452,  0.0054,  0.0497, -0.0028, -0.0025, -0.0057, -0.0050,  0.0159,
         -0.0022,  0.0477,  0.0211,  0.0218,  0.0063,  0.0663, -0.0050,  0.0500],
        [ 0.0228,  0.0049,  0.0213, -0.0020, -0.0032, -0.0041,  0.0027,  0.0087,
         -0.0018,  0.0211,  0.0141,  0.0184,  0.0109,  0.0399, -0.0029,  0.0437],
        [ 0.0258,  0.0102,  0.0204, -0.0031, -0.0074, -0.0062,  0.0106,  0.0062,
         -0.0029,  0.0218,  0.0184,  0.0360,  0.0243,  0.0648, -0.0039,  0.0800],
        [ 0.0110,  0.0071,  0.0047, -0.0019, -0.0055, -0.0039,  0.0105,  0.0024,
         -0.0020,  0.0063,  0.0109,  0.0243,  0.0189,  0.0368, -0.0020,  0.0550],
        [ 0.0686,  0.0175,  0.0658, -0.0061, -0.0116, -0.0123,  0.0094,  0.0192,
         -0.0055,  0.0663,  0.0399,  0.0648,  0.0368,  0.1379, -0.0089,  0.1436],
        [-0.0051, -0.0010, -0.0051,  0.0004,  0.0006,  0.0008, -0.0003, -0.0018,
          0.0004, -0.0050, -0.0029, -0.0039, -0.0020, -0.0089,  0.0006, -0.0089],
        [ 0.0599,  0.0225,  0.0471, -0.0071, -0.0163, -0.0143,  0.0235,  0.0172,
         -0.0068,  0.0500,  0.0437,  0.0800,  0.0550,  0.1436, -0.0089,  0.1807]],
       device='cuda:0') 

act.weight 1 torch.Size([1])
Parameter containing:
tensor([0.2084], device='cuda:0', requires_grad=True) 
grad:  tensor([-1.1339], device='cuda:0') 

inner_act.weight 1 torch.Size([1])
Parameter containing:
tensor([0.1532], device='cuda:0', requires_grad=True) 
grad:  tensor([-0.0116], device='cuda:0') 

out_act.weight 1 torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 
grad:  None 

encoder.module_0.weight 300 torch.Size([100, 3])
Parameter containing:
tensor([[ 4.6963e-01,  5.0743e-01, -1.1543e-01],
        [ 5.6726e-01, -8.9598e-02,  1.5852e-01],
        [-2.7884e-01,  3.4131e-01,  5.0798e-01],
        [-3.5788e-01,  5.6750e-01,  1.3814e-01],
        [ 4.7937e-01,  1.3100e-01,  3.2169e-01],
        [-7.4295e-02,  4.5229e-01,  4.5636e-02],
        [-1.5954e-01,  2.5715e-01, -1.8627e-01],
        [-1.2490e-01, -2.9170e-01,  3.6193e-01],
        [-4.2368e-01, -2.3409e-01, -1.6807e-01],
        [-3.7664e-01,  2.4997e-02, -5.7062e-01],
        [ 4.7480e-01, -5.3706e-01,  4.2650e-01],
        [ 9.2437e-02, -1.9111e-01,  3.3657e-01],
        [ 1.3976e-01,  5.1626e-01,  9.1551e-02],
        [-2.3041e-01,  1.0680e-01, -1.8110e-01],
        [ 2.1244e-01,  4.8493e-01,  3.5302e-01],
        [-3.5263e-01,  2.3306e-01,  7.4436e-02],
        [ 2.5312e-01, -3.9198e-01, -5.7921e-01],
        [-2.9797e-01, -5.1775e-01,  4.5106e-01],
        [ 2.0239e-01,  2.7524e-01,  2.1216e-01],
        [-7.6176e-03,  4.5426e-01, -4.0761e-01],
        [ 1.9964e-02, -4.1045e-01,  1.8633e-01],
        [-1.4751e-01,  2.2822e-01, -1.0462e-01],
        [ 4.8734e-01, -3.3371e-01, -3.4325e-01],
        [-4.1301e-01,  4.5064e-01,  1.5837e-01],
        [ 6.1934e-01, -4.1269e-01, -5.2567e-01],
        [-4.2957e-01, -3.6625e-01,  2.3152e-01],
        [ 2.5215e-01,  5.2514e-01, -2.8772e-01],
        [-3.0655e-01,  3.9336e-01, -1.8795e-01],
        [ 4.2247e-01, -6.4943e-02,  4.0529e-01],
        [-4.3517e-01, -2.7795e-01,  1.6839e-01],
        [ 6.2009e-02, -2.0725e-01,  3.2499e-01],
        [ 3.6106e-01, -4.5011e-01, -3.1195e-01],
        [ 5.7600e-01, -1.4747e-01, -1.8209e-01],
        [-5.8499e-01, -3.5697e-01,  1.7994e-01],
        [-1.3881e-01, -4.8169e-01, -4.9678e-04],
        [-3.9075e-01, -4.8620e-01, -2.7174e-01],
        [-5.5233e-01, -4.1465e-01,  6.2269e-01],
        [ 8.1728e-02,  1.5060e-01, -6.1508e-01],
        [-3.9444e-01, -2.0742e-01,  1.0047e-01],
        [-5.2044e-01, -2.6118e-01, -3.5132e-01],
        [-1.5483e-02, -2.3192e-01, -3.6146e-02],
        [-3.9962e-01, -4.0468e-01, -3.1701e-01],
        [-2.1954e-01, -4.7761e-01,  5.2144e-01],
        [-6.4631e-02,  5.4670e-01,  2.0839e-01],
        [-4.1485e-01,  4.7359e-01, -1.2377e-01],
        [-1.5667e-01, -4.1460e-01, -5.6066e-01],
        [ 2.9685e-02, -2.6162e-01,  1.5312e-01],
        [-3.9811e-01,  5.0434e-01, -3.7599e-01],
        [ 1.4030e-02,  2.3432e-01,  4.0687e-01],
        [ 4.9534e-01,  5.5518e-01, -4.4154e-01],
        [ 9.3284e-02, -3.0035e-01, -6.8532e-02],
        [-4.9176e-01,  4.6626e-01, -5.2088e-01],
        [ 2.8319e-01,  1.7753e-01,  1.6346e-01],
        [-3.6940e-01,  4.6753e-01,  1.0713e-01],
        [ 6.0056e-02, -5.2300e-01,  2.4600e-01],
        [-1.5728e-01, -3.3516e-01,  4.8265e-01],
        [ 7.3573e-02, -3.7458e-01, -3.1127e-01],
        [-3.5285e-02,  3.1466e-01, -1.4464e-01],
        [-3.3664e-01, -2.0493e-01, -4.0667e-01],
        [ 2.1567e-01,  4.5666e-01, -5.4256e-01],
        [ 1.5705e-01,  3.2122e-01,  1.1275e-01],
        [-1.2991e-01,  3.7704e-01,  3.6508e-01],
        [ 2.8804e-01, -2.9298e-02, -1.2228e-01],
        [ 9.4077e-02, -6.9679e-02, -1.9076e-01],
        [ 3.9298e-01,  5.2011e-01, -5.0646e-02],
        [-1.9694e-01, -5.9253e-02, -5.5146e-02],
        [ 1.6366e-01,  1.8665e-01, -5.1106e-01],
        [-1.5412e-01,  5.4515e-01,  2.4939e-01],
        [-3.3142e-02, -3.5251e-01, -3.4905e-01],
        [-5.6133e-01, -2.3235e-01,  2.5247e-01],
        [ 3.5180e-01,  2.5023e-01, -5.0534e-01],
        [-4.1045e-01, -1.5437e-01,  5.3567e-01],
        [ 1.1401e-01, -1.1902e-01,  2.6859e-01],
        [-2.5356e-01, -4.0735e-01,  4.6024e-01],
        [-1.9290e-01, -4.6114e-02, -5.5649e-01],
        [ 4.2577e-01,  4.7679e-01,  2.3290e-01],
        [-3.9767e-01, -5.6491e-01, -4.7742e-01],
        [ 4.4488e-01,  2.9153e-01,  4.7645e-01],
        [ 3.1455e-01,  1.5821e-01, -2.6464e-02],
        [-4.5193e-01, -5.0751e-01, -5.2884e-01],
        [ 1.5089e-01, -3.6891e-01, -1.4277e-01],
        [-2.9043e-01, -6.3362e-02, -4.2446e-01],
        [-4.3566e-01,  1.3310e-01, -1.8856e-01],
        [ 3.5506e-01, -1.8658e-01, -4.5786e-01],
        [-1.0144e-01, -2.7944e-01, -1.6122e-01],
        [-6.0832e-01,  2.6434e-01, -4.2598e-01],
        [ 3.2576e-01,  2.9756e-01,  4.3116e-01],
        [-3.5746e-01,  5.0063e-01, -2.3146e-01],
        [ 2.1878e-01,  5.4673e-01, -8.9140e-02],
        [-2.4569e-02, -1.5303e-01, -4.9070e-01],
        [ 2.8122e-01, -5.6900e-01,  3.6619e-01],
        [ 4.3961e-01,  5.5363e-01, -1.1904e-01],
        [-5.4770e-01,  5.6485e-02,  2.9263e-01],
        [-6.2028e-01, -1.7668e-01, -3.3132e-01],
        [-1.1076e-01, -3.4444e-01, -2.3096e-01],
        [-1.8462e-01, -5.4999e-01,  4.8393e-01],
        [ 5.5460e-01, -1.9979e-02, -3.7622e-02],
        [-2.5066e-01, -5.3641e-01, -5.8293e-01],
        [ 1.6024e-01, -3.7133e-01, -3.9648e-01],
        [-6.4825e-02, -2.1204e-01, -1.7986e-01]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[ 4.0543e-02,  4.0543e-02,  3.6170e-02],
        [ 4.9058e-02,  4.9058e-02,  3.7548e-02],
        [-2.0788e-02, -2.0788e-02, -1.0002e-02],
        [-1.8761e-03, -1.8761e-03, -2.9409e-04],
        [-3.0604e-02, -3.0604e-02, -1.2818e-02],
        [ 1.4688e-02,  1.4688e-02,  1.2334e-02],
        [-8.6071e-04, -8.6071e-04, -3.4297e-04],
        [ 1.7938e-04,  1.7938e-04, -1.1768e-02],
        [-5.6372e-03, -5.6372e-03, -3.9907e-03],
        [-6.7718e-03, -6.7718e-03, -6.2265e-03],
        [ 2.0445e-02,  2.0445e-02,  1.0330e-02],
        [ 2.6711e-02,  2.6711e-02,  1.7061e-02],
        [-1.9204e-03, -1.9204e-03,  1.2453e-04],
        [ 8.9900e-03,  8.9900e-03,  1.7344e-03],
        [ 5.2940e-02,  5.2940e-02,  3.2887e-02],
        [ 6.1532e-03,  6.1532e-03,  5.3113e-04],
        [ 6.5710e-03,  6.5710e-03, -1.3616e-03],
        [ 1.4346e-02,  1.4346e-02,  1.0219e-03],
        [ 2.2453e-02,  2.2453e-02,  2.9794e-02],
        [ 2.2911e-02,  2.2911e-02,  1.6231e-02],
        [-5.7367e-03, -5.7367e-03, -3.8596e-03],
        [-3.1471e-03, -3.1471e-03, -1.6773e-03],
        [ 4.8136e-02,  4.8136e-02,  2.9648e-02],
        [ 1.4310e-02,  1.4310e-02,  7.6887e-03],
        [-1.1345e-03, -1.1345e-03, -3.0817e-04],
        [-5.9462e-03, -5.9462e-03, -3.8687e-03],
        [-2.1429e-03, -2.1429e-03,  1.2361e-03],
        [-1.2740e-04, -1.2740e-04,  5.3239e-04],
        [-2.5197e-02, -2.5197e-02, -1.1934e-02],
        [-3.2481e-03, -3.2481e-03, -3.0084e-03],
        [ 2.8801e-02,  2.8801e-02,  1.4520e-02],
        [-3.1895e-02, -3.1895e-02, -5.2262e-02],
        [-5.6624e-03, -5.6624e-03, -2.5217e-03],
        [-3.0984e-03, -3.0984e-03, -3.2382e-03],
        [-9.2605e-03, -9.2605e-03, -2.3046e-02],
        [-1.3800e-03, -1.3800e-03, -2.0591e-03],
        [-2.8740e-02, -2.8740e-02, -5.7212e-02],
        [-6.9883e-03, -6.9883e-03, -3.7863e-03],
        [-2.6976e-03, -2.6976e-03, -2.5332e-03],
        [-1.1140e-02, -1.1140e-02, -8.0805e-03],
        [-4.2629e-03, -4.2629e-03, -3.8502e-03],
        [-3.4642e-03, -3.4642e-03, -3.3979e-03],
        [-4.3765e-03, -4.3765e-03, -5.4391e-03],
        [-4.3461e-03, -4.3461e-03, -1.5440e-03],
        [-3.0196e-03, -3.0196e-03, -1.3523e-03],
        [-5.6501e-03, -5.6501e-03, -3.7551e-03],
        [-7.9887e-03, -7.9887e-03, -7.1909e-03],
        [-3.0218e-04, -3.0218e-04,  1.7704e-04],
        [-2.3158e-02, -2.3158e-02, -1.1424e-02],
        [ 4.9031e-02,  4.9031e-02,  3.9954e-02],
        [ 8.3733e-03,  8.3733e-03, -6.9015e-03],
        [-4.0872e-03, -4.0872e-03, -3.9260e-03],
        [ 3.2837e-02,  3.2837e-02,  2.2769e-02],
        [ 1.6108e-02,  1.6108e-02,  6.6812e-03],
        [-7.3562e-03, -7.3562e-03, -5.6029e-03],
        [-1.1894e-02, -1.1894e-02, -2.3715e-02],
        [-1.4891e-03, -1.4891e-03, -9.3047e-03],
        [ 6.2053e-03,  6.2053e-03,  4.7722e-03],
        [-4.0659e-03, -4.0659e-03, -3.2622e-03],
        [ 3.5160e-02,  3.5160e-02,  2.6154e-02],
        [-3.8159e-03, -3.8159e-03,  1.8566e-03],
        [-4.1344e-02, -4.1344e-02, -2.0191e-02],
        [ 1.2536e-03,  1.2536e-03,  1.5830e-03],
        [-1.8329e-02, -1.8329e-02, -1.3282e-02],
        [ 4.1439e-02,  4.1439e-02,  3.3230e-02],
        [-6.8270e-03, -6.8270e-03, -2.0230e-02],
        [-7.1678e-04, -7.1678e-04, -3.3260e-04],
        [-7.9038e-03, -7.9038e-03, -3.6170e-03],
        [-7.0762e-03, -7.0762e-03, -4.7356e-03],
        [-3.0995e-02, -3.0995e-02, -6.3920e-02],
        [ 2.2485e-02,  2.2485e-02,  1.6476e-02],
        [ 1.7877e-02,  1.7877e-02,  3.7787e-03],
        [-4.3611e-03, -4.3611e-03, -2.4170e-03],
        [-2.0387e-02, -2.0387e-02, -4.3972e-02],
        [-4.8101e-03, -4.8101e-03, -3.0964e-03],
        [ 2.0185e-02,  2.0185e-02,  1.4888e-02],
        [-2.1500e-03, -2.1500e-03, -2.9394e-03],
        [ 4.5191e-02,  4.5191e-02,  3.3765e-02],
        [ 4.3197e-02,  4.3197e-02,  3.0994e-02],
        [-5.5112e-03, -5.5112e-03, -4.0548e-03],
        [-3.6053e-03, -3.6053e-03, -1.0449e-02],
        [-9.3534e-03, -9.3534e-03, -5.7295e-03],
        [-1.2569e-03, -1.2569e-03, -1.3331e-02],
        [ 1.8223e-02,  1.8223e-02,  1.1986e-02],
        [-2.4461e-03, -2.4461e-03, -2.5799e-03],
        [ 1.5452e-02,  1.5452e-02,  5.9317e-03],
        [-2.3138e-02, -2.3138e-02, -6.8475e-03],
        [-8.2498e-05, -8.2498e-05,  3.1174e-04],
        [ 2.2636e-02,  2.2636e-02,  1.7864e-02],
        [-9.4788e-03, -9.4788e-03, -6.6065e-03],
        [-1.0825e-02, -1.0825e-02, -9.7988e-03],
        [ 1.2869e-02,  1.2869e-02,  8.4019e-03],
        [ 1.8140e-02,  1.8140e-02,  5.6535e-03],
        [-4.7959e-02, -4.7959e-02, -8.2284e-02],
        [-3.1375e-02, -3.1375e-02, -5.8916e-02],
        [-3.6705e-03, -3.6705e-03, -3.0896e-03],
        [ 2.5997e-03,  2.5997e-03,  2.7368e-03],
        [-7.9476e-03, -7.9476e-03, -6.1012e-03],
        [-2.9668e-02, -2.9668e-02, -5.0121e-02],
        [-6.8337e-03, -6.8337e-03, -5.2784e-03]], device='cuda:0') 

encoder.module_0.bias 100 torch.Size([100])
Parameter containing:
tensor([ 0.0245, -0.0818, -0.2213, -0.2611, -0.4530,  0.4278, -0.1615,  0.1496,
        -0.1965,  0.0566,  0.5291,  0.2434, -0.4913,  0.2230,  0.5692,  0.1344,
         0.3847,  0.5602, -0.0624,  0.1075, -0.3895, -0.1111,  0.4303,  0.2773,
        -0.3421, -0.4563, -0.3893, -0.5357, -0.4142, -0.1337,  0.3816,  0.1201,
        -0.4378, -0.4263,  0.2862, -0.3663, -0.0166,  0.1835, -0.2458, -0.0621,
        -0.0361, -0.1050, -0.2630, -0.5099, -0.4439, -0.2904,  0.4980, -0.2474,
        -0.3356,  0.1431,  0.1656,  0.1934,  0.4078,  0.3197, -0.5595,  0.0525,
         0.3400, -0.0669, -0.3053,  0.5477, -0.2166, -0.3093, -0.5047,  0.0416,
         0.2514,  0.1224,  0.1115, -0.4432, -0.5309,  0.0799,  0.5198,  0.3292,
        -0.2984, -0.0245, -0.4011, -0.2480,  0.1218,  0.2988,  0.4543, -0.5124,
         0.3726, -0.4190,  0.2172,  0.4487,  0.0371,  0.5073, -0.4885, -0.1879,
         0.3182, -0.1284, -0.1168, -0.2368,  0.3861,  0.3161,  0.2065, -0.3119,
        -0.4555,  0.0493,  0.1735, -0.2499], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 9.7608e-02,  9.8992e-02, -2.6879e-02, -1.3481e-03, -3.8935e-02,
         3.2286e-02, -1.0738e-03, -2.7134e-02, -1.0983e-02, -1.7017e-02,
         3.0960e-02,  5.0997e-02, -8.8181e-04,  8.8066e-03,  9.3148e-02,
         4.1555e-03, -3.2664e-03,  6.6194e-03,  8.1459e-02,  4.4507e-02,
        -1.0076e-02, -4.9025e-03,  8.3127e-02,  2.4551e-02, -1.1064e-03,
        -1.0859e-02,  2.3385e-03,  1.2583e-03, -3.2115e-02, -7.9774e-03,
         4.2762e-02, -1.4989e-01, -7.9021e-03, -9.0700e-03, -6.0636e-02,
        -5.3483e-03, -1.5679e-01, -1.1272e-02, -6.6927e-03, -2.2679e-02,
        -1.0113e-02, -9.1541e-03, -1.2942e-02, -3.3610e-03, -4.0889e-03,
        -1.0682e-02, -1.9537e-02,  3.1720e-04, -3.0754e-02,  1.0880e-01,
        -1.3730e-02, -1.1638e-02,  6.4594e-02,  2.1116e-02, -1.5679e-02,
        -6.1101e-02, -2.4643e-02,  9.1793e-03, -9.2799e-03,  7.3646e-02,
         3.7489e-05, -5.4289e-02,  4.2542e-03, -3.6232e-02,  9.3844e-02,
        -5.4207e-02, -3.0403e-03, -8.1852e-03, -1.3093e-02, -1.7513e-01,
         4.5371e-02,  1.4993e-02, -7.3520e-03, -1.2034e-01, -8.8985e-03,
         3.3222e-02, -7.4656e-03,  9.4475e-02,  8.6563e-02, -1.0974e-02,
        -2.6785e-02, -1.6249e-02, -3.4830e-02,  3.2879e-02, -6.4598e-03,
         2.0773e-02, -2.6223e-02,  4.0972e-04,  4.9197e-02, -1.8794e-02,
        -2.5919e-02,  1.9261e-02,  1.9631e-02, -2.3103e-01, -1.6589e-01,
        -8.3703e-03,  6.2505e-03, -1.6757e-02, -1.4408e-01, -1.4533e-02],
       device='cuda:0') 

encoder.module_2.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[-0.0827,  0.0026,  0.0265,  ...,  0.1287,  0.1155, -0.0355],
        [-0.0688, -0.1112, -0.0072,  ..., -0.0504,  0.1970,  0.0160],
        [-0.1172, -0.0327, -0.0985,  ...,  0.1263,  0.0685,  0.1018],
        ...,
        [ 0.0344, -0.0445, -0.1306,  ...,  0.0167, -0.1504,  0.0654],
        [ 0.1152, -0.0068,  0.0202,  ..., -0.0107, -0.0949,  0.0897],
        [-0.0506, -0.0548, -0.0477,  ..., -0.0892, -0.0654, -0.0801]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-1.1528e-02, -5.1429e-03, -2.5934e-04,  ...,  3.3838e-03,
         -1.3402e-04,  3.3221e-03],
        [-1.3449e-03, -6.1015e-04, -8.5772e-05,  ...,  5.0465e-04,
         -1.1541e-04,  5.6945e-04],
        [-5.5737e-03, -2.4359e-03, -1.7474e-04,  ...,  1.9134e-03,
         -2.4696e-04,  2.0916e-03],
        ...,
        [-1.9488e-03, -8.4835e-04,  6.6392e-05,  ...,  4.2235e-04,
          6.7073e-05,  3.3572e-04],
        [ 7.3605e-03,  3.5949e-03,  4.8418e-04,  ..., -1.6889e-03,
         -3.1098e-04, -1.1143e-03],
        [ 1.1482e-02,  5.1789e-03, -2.0807e-05,  ..., -2.6013e-03,
         -3.5607e-04, -2.0135e-03]], device='cuda:0') 

encoder.module_2.bias 100 torch.Size([100])
Parameter containing:
tensor([ 0.0964, -0.0178,  0.0299, -0.0753, -0.0025, -0.0867,  0.0174,  0.0382,
        -0.0917,  0.0788,  0.0159, -0.0251, -0.0527,  0.0795, -0.0510,  0.0751,
         0.0011,  0.0652, -0.0555,  0.0090,  0.0087,  0.0881, -0.1087, -0.0467,
        -0.0050, -0.0650,  0.0082,  0.0604,  0.0640, -0.0492,  0.0234, -0.0708,
         0.0449, -0.0615, -0.0930,  0.0096, -0.0278, -0.0033,  0.1062,  0.0837,
         0.0712, -0.1045,  0.0060,  0.0265, -0.0752,  0.1001,  0.0748, -0.0681,
        -0.0225, -0.0503,  0.0319, -0.0143, -0.0389,  0.0687, -0.0243,  0.0250,
         0.0712, -0.0377, -0.0746,  0.0452, -0.0808, -0.0020, -0.0401,  0.0656,
        -0.0094, -0.0317, -0.0553,  0.0972, -0.0451,  0.0125,  0.0775, -0.0690,
        -0.0669,  0.0134, -0.0238, -0.0718,  0.0737, -0.0838, -0.0398, -0.0847,
         0.0421, -0.0131,  0.0190,  0.0328,  0.0027, -0.0237,  0.0853,  0.0019,
         0.0389, -0.0945, -0.0954, -0.0527, -0.0469,  0.0158, -0.0365,  0.0351,
         0.0993, -0.0237,  0.0166,  0.0045], device='cuda:0',
       requires_grad=True) 
grad:  tensor([-0.0396, -0.0073, -0.0264, -0.0256, -0.0342,  0.0712, -0.0059, -0.0018,
        -0.0511,  0.0766, -0.0558,  0.0446, -0.0022, -0.0085, -0.0210, -0.0197,
        -0.0168,  0.0163, -0.0146,  0.0016,  0.0147, -0.0163, -0.0047, -0.0270,
         0.0097,  0.0432, -0.0034, -0.0533,  0.0806, -0.0467, -0.0046,  0.0114,
        -0.0073,  0.1506, -0.0232, -0.0026, -0.0167, -0.0358,  0.0241,  0.0062,
        -0.0401, -0.0153,  0.0358, -0.0314,  0.0247,  0.0017,  0.0481, -0.0382,
        -0.0449,  0.0316, -0.0414, -0.0218, -0.0034,  0.0035,  0.0007,  0.0088,
         0.0256,  0.0424,  0.1189, -0.0210, -0.0031,  0.0066, -0.0179,  0.0079,
         0.0194,  0.0059,  0.0003,  0.0547, -0.0448, -0.0053,  0.0777, -0.0408,
         0.1283, -0.0413,  0.0762,  0.0007,  0.0140, -0.0330,  0.0191, -0.0616,
         0.0906,  0.0092, -0.0031, -0.0281, -0.0660, -0.0359, -0.0478, -0.0034,
         0.1499,  0.0196,  0.0083, -0.0370, -0.0616,  0.0092, -0.0311, -0.0011,
        -0.0156, -0.0035,  0.0097,  0.0204], device='cuda:0') 

encoder.module_4.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0837,  0.0455,  0.0435,  ..., -0.1015,  0.0961, -0.0388],
        [ 0.0373,  0.0907,  0.0635,  ..., -0.0814, -0.0766,  0.0264],
        [-0.0357,  0.0286,  0.0123,  ...,  0.0677,  0.1016,  0.0670],
        ...,
        [ 0.0035, -0.0550,  0.0742,  ...,  0.0482, -0.0434, -0.0206],
        [-0.0298,  0.0836,  0.0553,  ...,  0.0387, -0.0243,  0.0852],
        [ 0.0765, -0.0269, -0.0972,  ..., -0.1171,  0.0095, -0.0163]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 1.6985e-03,  7.8883e-04,  1.6383e-03,  ..., -3.5697e-04,
         -2.7561e-03,  1.1091e-04],
        [-2.5661e-02, -1.4018e-02, -2.4186e-02,  ..., -2.6461e-03,
          8.3891e-03,  5.8138e-03],
        [-1.4150e-02, -7.9490e-03, -1.4110e-02,  ..., -1.6086e-04,
          1.4675e-02,  1.1323e-03],
        ...,
        [-3.2897e-03, -1.8896e-03, -3.2801e-03,  ..., -2.6223e-04,
          3.1229e-03,  4.0061e-04],
        [-2.2273e-03, -1.4459e-03, -2.2419e-03,  ..., -6.3137e-04,
          4.1307e-04,  6.2933e-04],
        [-1.2467e-03, -1.0792e-03, -1.4591e-03,  ..., -9.4347e-04,
         -5.7354e-05,  5.0136e-04]], device='cuda:0') 

encoder.module_4.bias 16 torch.Size([16])
Parameter containing:
tensor([-0.0330,  0.0362, -0.0271, -0.0085, -0.0908, -0.0130,  0.0741,  0.0207,
        -0.0794,  0.0792, -0.0558, -0.0576,  0.0835, -0.0493, -0.0038,  0.0324],
       device='cuda:0', requires_grad=True) 
grad:  tensor([ 0.0056,  0.3129,  0.1012, -0.0314,  0.1135, -0.1485, -0.2785,  0.0733,
        -0.3181, -0.0531,  0.1172,  0.0341,  0.5876,  0.0338,  0.0441,  0.0458],
       device='cuda:0') 

model.module_0.bias 8 torch.Size([8])
Parameter containing:
tensor([-0.0734,  0.0588,  0.0106, -0.0335,  0.0389, -0.0169, -0.0289, -0.0061],
       device='cuda:0', requires_grad=True) 
grad:  tensor([ 0.0037, -0.5651, -1.0015,  0.9460, -0.6650,  0.7153,  0.9844, -0.0922],
       device='cuda:0') 

model.module_0.lin.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[-0.4659, -0.3677,  0.3466, -0.1717, -0.1159, -0.0183, -0.1529, -0.1599,
         -0.0542, -0.2801,  0.2899, -0.0193,  0.2170,  0.0332,  0.4151,  0.2419],
        [-0.2539, -0.1220,  0.1146, -0.1881, -0.3281,  0.4465,  0.3894, -0.2274,
          0.1742,  0.3798, -0.2226, -0.0670, -0.4303, -0.3937,  0.4000,  0.1494],
        [-0.3194, -0.0462, -0.2394, -0.0920, -0.1051,  0.1861,  0.1287, -0.3015,
          0.2979,  0.0655, -0.2033, -0.2823, -0.0242,  0.1947, -0.4357, -0.0836],
        [-0.3708, -0.4434,  0.2760, -0.1772, -0.4946, -0.1636, -0.3154,  0.2218,
         -0.1279, -0.3106, -0.3055, -0.1214,  0.4082, -0.0298, -0.4180, -0.0890],
        [ 0.4789, -0.4658, -0.2046,  0.4476, -0.1710,  0.3949, -0.2942,  0.4282,
          0.3745, -0.1083, -0.3637, -0.1546,  0.0888, -0.0723, -0.3700, -0.5104],
        [ 0.2246,  0.3797, -0.1816,  0.0189, -0.3168,  0.2663, -0.3606, -0.3383,
         -0.2415, -0.1069, -0.0322, -0.4842, -0.1671, -0.2846, -0.1282,  0.0077],
        [ 0.0204,  0.2634, -0.2806,  0.0099,  0.4731,  0.0335, -0.4230,  0.3050,
         -0.4935,  0.1729,  0.3481,  0.0672,  0.2797,  0.3627,  0.2095, -0.1611],
        [ 0.0964,  0.4082,  0.1252, -0.4010,  0.4133,  0.5360,  0.3568,  0.2579,
          0.3376, -0.2355, -0.1873,  0.2176,  0.1406,  0.1687, -0.0082, -0.4165]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 5.0281e-03,  3.9861e-03, -3.2977e-02,  6.4828e-03,  6.0475e-03,
          1.5569e-02,  2.3208e-02,  3.8581e-04,  2.6361e-02,  1.3108e-02,
         -6.8686e-04,  3.9247e-03, -4.4035e-02, -3.6469e-04,  1.0137e-04,
          1.6923e-04],
        [ 3.6857e-02, -8.5423e-02, -1.8736e-01,  5.6366e-02, -8.8772e-02,
          3.3745e-02,  5.5622e-02,  5.9474e-03,  6.9399e-02,  3.3130e-02,
          3.6561e-03, -6.4510e-02, -2.9163e-01,  5.9895e-03,  5.8631e-03,
          5.0984e-03],
        [ 7.6671e-02, -2.4185e-01, -3.6269e-01,  1.1562e-01, -8.8783e-02,
          5.9031e-02,  9.9137e-02,  1.1068e-02,  1.2369e-01,  6.1188e-02,
          6.4195e-03, -6.5562e-02, -6.0892e-01,  1.3007e-02,  1.2817e-02,
          5.6095e-03],
        [-6.0032e-02,  1.1228e-01,  3.1636e-01, -9.0772e-02,  1.4729e-01,
         -6.8291e-02, -1.0998e-01, -9.5000e-03, -1.3479e-01, -6.4367e-02,
         -4.9735e-03,  1.0721e-01,  4.7816e-01, -8.5206e-03, -8.7276e-03,
         -8.4110e-03],
        [ 4.6682e-02, -3.9856e-02, -2.6764e-01,  6.9533e-02, -1.2892e-01,
          7.3398e-02,  1.1459e-01,  7.2790e-03,  1.3730e-01,  6.5310e-02,
          2.6632e-03, -9.4076e-02, -3.7674e-01,  4.7565e-03,  5.5535e-03,
          7.8889e-03],
        [-4.9541e-02,  1.5020e-01,  2.3632e-01, -7.5344e-02,  8.1079e-02,
         -3.6444e-02, -6.1757e-02, -7.5262e-03, -7.7987e-02, -3.8037e-02,
         -4.7839e-03,  5.9225e-02,  3.9124e-01, -8.7054e-03, -8.3941e-03,
         -4.6469e-03],
        [-7.6650e-02,  2.5942e-01,  3.5517e-01, -1.1654e-01,  9.5881e-02,
         -4.9052e-02, -8.4650e-02, -1.1303e-02, -1.0762e-01, -5.3220e-02,
         -7.3391e-03,  7.0474e-02,  6.0560e-01, -1.4015e-02, -1.3443e-02,
         -5.9175e-03],
        [ 9.3400e-03, -1.4083e-01,  4.6670e-03,  1.5263e-02,  5.6929e-02,
         -3.3108e-02, -4.6200e-02,  9.3039e-04, -5.1238e-02, -2.2888e-02,
          2.3841e-03,  4.1158e-02, -6.6660e-02,  5.0876e-03,  3.9953e-03,
         -3.6183e-03]], device='cuda:0') 

model.module_1.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[ 1.4573e-01, -1.9475e-01, -2.0700e-01,  3.5046e-01,  1.6958e-01,
          2.9420e-01, -1.6865e-01,  1.1598e-01],
        [ 1.5202e-02,  2.5122e-01,  5.3243e-02,  3.0724e-01, -8.2796e-02,
          3.5273e-01,  3.3206e-01,  4.6647e-02],
        [-2.7613e-01,  1.3611e-02,  2.9049e-01, -2.7346e-01, -1.2621e-01,
          4.0459e-02,  5.6614e-02,  3.7141e-01],
        [ 2.2052e-02,  3.4759e-02,  7.9669e-02, -1.2005e-01, -2.9951e-01,
         -1.8240e-01, -3.5243e-01,  2.7137e-01],
        [ 7.3126e-02, -9.9280e-03, -7.5893e-02, -1.3183e-01, -3.0198e-01,
         -5.2587e-03,  1.7399e-01, -2.1670e-01],
        [-2.3781e-01,  2.4592e-01, -1.1314e-01,  1.6415e-01,  3.5499e-01,
          2.7293e-01, -2.9289e-01,  4.3262e-02],
        [-2.0085e-01, -5.9998e-02,  6.1479e-03, -6.1510e-02, -9.5011e-04,
         -6.9985e-02,  2.7440e-01,  6.6896e-02],
        [ 2.1679e-01,  2.6188e-01,  9.6827e-02,  3.2511e-02, -1.3856e-01,
         -2.7864e-01,  2.0181e-01,  2.5487e-01],
        [ 6.7204e-02,  2.8679e-01,  1.8338e-01,  2.5821e-01, -7.9286e-02,
          1.0533e-01, -3.0156e-01, -3.3619e-01],
        [ 1.7175e-01, -2.1123e-01,  2.9080e-01, -3.0197e-01, -3.0463e-01,
         -4.0223e-01,  2.0744e-01, -1.5771e-01],
        [-3.9557e-01,  2.3549e-01, -2.4662e-03, -4.3543e-01,  3.1823e-01,
          1.4960e-01,  1.8668e-01,  2.9252e-01],
        [-2.6666e-01, -1.6119e-01, -1.4838e-01, -3.4530e-01,  2.4616e-01,
         -1.9487e-01,  1.2313e-01, -1.6461e-01],
        [ 3.3552e-01,  2.3050e-01,  2.3150e-01,  2.1054e-01,  2.8223e-01,
          1.8320e-01,  8.2215e-02, -1.0294e-01],
        [ 2.5916e-01, -3.1520e-01,  2.6905e-01, -7.5130e-02,  1.2415e-03,
         -2.9630e-01, -1.8219e-01,  8.4151e-02],
        [-2.0861e-01,  1.6745e-01,  7.7128e-02, -3.6790e-01,  2.2204e-01,
         -2.0062e-01, -1.7488e-01, -1.1117e-01],
        [ 7.5394e-02, -2.9003e-01, -1.9859e-01,  9.6005e-02, -6.4462e-02,
          4.3880e-02, -3.6723e-01, -9.8878e-03],
        [ 1.4407e-01, -1.1221e-01,  3.0550e-02, -3.2566e-02, -2.5630e-02,
          2.4047e-01,  8.2150e-02,  6.1379e-02],
        [ 1.3515e-03, -1.8720e-02,  1.8866e-01,  5.2382e-02,  7.3231e-02,
          4.0188e-01,  2.8181e-01, -1.7568e-01],
        [-2.5918e-01,  5.6690e-02, -2.8244e-01, -3.1066e-01,  2.2113e-01,
         -2.5386e-01,  4.0022e-01, -3.3421e-01],
        [-3.5348e-01,  2.4650e-01,  6.5091e-02, -2.2227e-01,  1.6093e-01,
         -2.5810e-01, -2.4976e-01, -3.1052e-01],
        [-1.8333e-01, -2.8513e-01,  3.2678e-01, -1.4451e-01,  6.8409e-02,
         -2.4284e-01, -9.5817e-02,  3.1706e-01],
        [ 4.6949e-02,  1.8690e-01,  1.2759e-01, -3.2746e-01,  2.2827e-01,
          1.9117e-01,  8.7287e-02,  2.9319e-01],
        [-1.5672e-01, -2.4207e-01, -3.4421e-01, -4.5866e-02,  2.7751e-03,
         -2.0348e-01, -1.0693e-01, -2.0535e-01],
        [ 3.1283e-01, -8.1498e-04,  2.9973e-01, -7.4531e-03,  1.4862e-01,
          1.3917e-01, -3.5431e-01, -1.4800e-01],
        [-2.9184e-01,  3.6297e-01,  1.4908e-01, -1.8837e-01, -2.5821e-01,
          1.2674e-01,  5.9617e-02, -1.3506e-01],
        [-3.3109e-01, -1.1776e-01,  1.3608e-01, -3.8875e-01,  4.3835e-02,
          1.6668e-01,  1.2538e-01,  3.7329e-02],
        [ 5.9430e-02,  5.9661e-02,  1.3217e-01,  3.1846e-01,  6.6938e-02,
          2.7637e-01,  2.8949e-01, -2.7687e-01],
        [-2.4556e-01,  2.5385e-01,  1.0984e-01, -2.6454e-01,  1.6519e-01,
         -3.9107e-01, -2.0030e-01,  2.0201e-01],
        [-4.9997e-02, -2.0037e-01,  1.9890e-01, -3.3523e-02, -3.7779e-03,
         -3.9635e-01, -1.6540e-01,  3.1443e-02],
        [-2.4245e-01,  1.1378e-01, -2.0325e-01,  2.3237e-01,  3.4179e-01,
          3.3764e-01, -8.5382e-02, -4.5004e-01],
        [-1.2447e-01, -4.7065e-02, -3.3946e-01,  2.8272e-01,  9.4471e-02,
          2.8017e-01, -2.9967e-01, -1.7493e-01],
        [ 9.3031e-02, -1.5705e-02, -1.7606e-01,  2.9517e-01,  1.1180e-01,
          6.3494e-02,  3.6009e-01, -3.2096e-01],
        [-3.1980e-01,  7.3677e-02,  3.1004e-01,  1.8243e-01, -1.7775e-01,
          2.1738e-01,  1.7975e-01, -8.9761e-03],
        [ 2.6030e-01,  3.5190e-02, -2.6208e-02, -4.7813e-02, -2.1979e-01,
         -1.7757e-01, -6.7423e-03, -2.4347e-01],
        [ 1.9418e-02,  2.2430e-01, -2.0674e-01, -3.8748e-01,  3.3946e-01,
         -2.0826e-01, -1.3066e-01, -1.5162e-01],
        [-9.9720e-02,  2.0426e-01,  1.1521e-01,  1.6397e-01, -1.4704e-02,
         -3.8665e-01, -3.7986e-02,  2.6815e-01],
        [ 6.4140e-02,  8.8701e-02,  7.8724e-02,  2.5721e-01,  1.8894e-01,
         -1.1993e-01, -2.1225e-01,  3.0845e-01],
        [-2.2469e-01, -2.0022e-01,  1.4343e-01, -2.5588e-01, -2.7442e-01,
         -2.2425e-01,  4.4931e-02, -2.4397e-01],
        [ 2.2713e-01,  4.8669e-02, -1.6242e-01, -2.7778e-01, -1.5032e-02,
          4.2874e-01, -2.8007e-01, -4.6677e-01],
        [ 1.1251e-01,  1.1266e-01, -2.9964e-01, -1.4233e-01,  2.9526e-01,
         -1.1040e-01,  1.5643e-01, -1.8393e-01],
        [-2.6251e-01, -3.8991e-01,  2.3615e-01,  1.7874e-01,  4.2037e-02,
          1.7889e-01,  1.9070e-01,  2.3870e-01],
        [ 2.4402e-01,  2.9738e-01,  1.2691e-01,  2.0531e-02,  9.6758e-02,
         -3.5185e-01,  1.2883e-01,  9.5580e-02],
        [ 2.1108e-01, -1.3745e-01,  2.8524e-01,  1.3021e-01, -1.6026e-01,
          7.1690e-02, -7.7705e-02, -4.0305e-02],
        [ 2.5637e-01,  1.6135e-01, -2.3993e-02, -4.8260e-02,  1.2825e-01,
         -2.8454e-01, -2.4986e-01,  3.2383e-01],
        [-1.2137e-02,  1.0665e-01, -1.6775e-01, -2.7577e-01,  7.3405e-02,
          1.1719e-01, -3.4507e-01, -3.1202e-01],
        [-9.3899e-02,  2.0798e-01, -3.2740e-01,  3.2722e-01,  3.0083e-01,
         -9.1243e-03,  4.8059e-02, -3.8704e-02],
        [ 3.2387e-01,  5.7843e-02,  9.1835e-02, -1.6129e-01,  1.6446e-02,
         -2.4580e-01, -6.4168e-03, -4.9542e-02],
        [ 8.0089e-02,  5.5734e-02, -2.8978e-01,  2.7363e-01,  1.7827e-01,
          3.2014e-01,  2.7733e-01,  8.6381e-02],
        [ 2.1762e-01,  1.6148e-01,  1.9718e-01, -1.9562e-01,  1.7967e-01,
         -3.9368e-02,  1.5689e-01,  9.6256e-02],
        [-2.3475e-01, -1.8886e-01, -2.7406e-01, -5.3206e-02,  9.0735e-02,
          1.4129e-01,  3.1519e-01, -2.8100e-01],
        [ 3.4319e-02,  3.5728e-01, -2.1791e-01, -3.5502e-01,  1.3697e-01,
         -1.8428e-01,  1.0788e-02, -1.4919e-01],
        [-6.9278e-04, -2.5242e-01,  3.3906e-01, -2.5291e-01, -2.9339e-01,
         -9.4209e-02, -2.6052e-02,  3.0178e-01],
        [ 7.6652e-02, -7.8537e-02, -2.6273e-01,  1.7755e-01,  3.0963e-02,
         -4.3092e-02, -8.6708e-02,  2.7251e-02],
        [ 2.4353e-01, -2.4474e-01, -7.5821e-02,  2.2102e-01, -2.8335e-01,
          5.6414e-02,  3.2369e-01,  2.6030e-01],
        [-3.6729e-01, -8.9087e-02,  8.5558e-02,  1.2613e-01, -8.5539e-02,
         -4.5762e-01, -1.0246e-01,  2.6076e-01],
        [-2.0082e-01, -3.1242e-01,  6.0984e-02,  2.9986e-01, -2.8990e-01,
          1.9256e-01,  2.1800e-01,  9.2259e-03],
        [-2.5260e-01, -6.9221e-02, -1.6975e-01, -3.8994e-02, -9.6787e-02,
         -1.2189e-02, -1.5623e-01, -2.3066e-01],
        [ 3.2483e-01,  9.7833e-02,  1.8088e-01,  1.7367e-01,  1.5510e-01,
         -1.5210e-01, -1.3337e-01, -1.7535e-01],
        [-2.8003e-01, -3.0218e-01, -1.5163e-01,  3.7726e-01, -3.9341e-01,
         -1.8835e-01, -2.2938e-01, -2.2177e-01],
        [ 3.4503e-01, -3.2990e-01, -2.9852e-01, -1.4457e-01,  3.1125e-02,
         -5.4087e-02, -1.6958e-01,  2.7063e-01],
        [ 8.1648e-02, -2.8451e-01, -1.4915e-01,  2.6017e-01,  9.3539e-02,
         -1.6981e-01, -1.5446e-01, -1.4510e-01],
        [ 1.5798e-01, -3.0373e-01,  3.1966e-01,  7.1034e-02,  1.2386e-01,
          1.6362e-01,  2.9923e-01, -1.2816e-01],
        [-1.2237e-01, -2.4225e-01,  2.8470e-01, -6.6890e-03, -1.1431e-02,
          3.6318e-01, -8.0990e-02, -1.3147e-01],
        [-2.1025e-01,  2.7153e-01,  1.0473e-01, -2.5214e-01,  2.8361e-01,
          5.0597e-02, -1.4961e-01,  1.3698e-01],
        [-3.5314e-01, -2.1972e-01, -6.7586e-02,  1.3584e-01, -5.3355e-02,
          2.5082e-01, -3.6234e-01,  2.7980e-01],
        [-3.9833e-01, -6.5038e-02,  3.4540e-01, -1.9793e-01, -8.2035e-02,
          9.8756e-02, -2.5682e-01,  7.4050e-02],
        [-7.6327e-02,  9.5494e-02, -2.4209e-01, -1.1927e-01, -2.7892e-01,
          1.1301e-02,  4.1070e-01,  1.9276e-01],
        [-3.3119e-01,  2.2827e-01,  3.3665e-01,  2.7884e-01,  1.0665e-01,
          2.2264e-04,  2.0270e-01,  3.4901e-01],
        [-2.7286e-02, -2.8491e-02,  3.0450e-01, -1.5690e-01,  3.2168e-01,
          2.3654e-01,  6.1763e-02, -2.8618e-01],
        [ 2.6223e-01,  1.8505e-01,  1.1602e-01,  6.6160e-02,  1.6158e-01,
          1.3421e-01, -2.5829e-01, -2.0847e-01],
        [ 2.1690e-01, -1.8123e-01, -3.2340e-01,  3.4270e-01, -3.1674e-01,
         -6.0713e-02, -1.8402e-01,  3.1671e-01],
        [-7.6572e-02, -1.5583e-01,  3.1771e-01,  2.7862e-01,  2.2123e-01,
          2.2306e-01, -3.4685e-01, -3.1579e-01],
        [ 1.9835e-01, -8.7507e-02,  1.6826e-01,  3.5257e-01, -1.0579e-01,
         -1.1235e-01,  3.3968e-01, -1.5406e-01],
        [-2.5701e-01,  3.3606e-01,  1.5410e-02, -2.3954e-01,  1.7420e-01,
         -2.5867e-01, -4.6789e-02, -2.5784e-01],
        [-1.3364e-01,  3.1754e-01,  5.9351e-02, -1.1788e-01,  3.2476e-01,
          1.1506e-01,  1.4671e-01,  1.6602e-01],
        [-1.2132e-01, -3.2635e-01, -2.0732e-01, -2.0285e-01,  8.0892e-02,
          3.7212e-01,  3.4356e-01,  2.8201e-01],
        [ 3.1719e-02,  2.6969e-01,  1.0549e-01,  1.7792e-01, -2.6241e-01,
          4.5989e-01,  1.5074e-01,  4.6231e-02],
        [-1.0509e-01,  2.9778e-02, -6.1520e-02, -1.7878e-01, -2.4993e-01,
         -8.0289e-02,  1.1772e-01, -2.3720e-01],
        [ 1.8887e-01, -1.8700e-01,  2.1462e-01, -3.0825e-03,  1.8291e-02,
          1.4400e-02, -2.4533e-03,  1.6454e-01],
        [-6.5929e-02, -9.5871e-02,  6.2765e-02, -2.4236e-01,  1.5933e-01,
          4.5572e-02,  1.3404e-01, -5.4015e-02],
        [ 7.8909e-03, -1.8373e-01, -1.7376e-01,  2.8345e-02,  1.6217e-01,
         -9.0187e-02,  3.0644e-01, -1.2366e-01],
        [-5.8467e-02,  2.7167e-01, -6.6350e-02,  2.2175e-01, -4.5302e-02,
          2.7331e-01,  6.0503e-02, -1.7982e-01],
        [-2.7458e-01,  2.5353e-01,  1.0593e-01, -1.0774e-01, -1.3057e-02,
         -2.1025e-01, -2.9163e-01,  8.6806e-02],
        [-3.5864e-01,  4.6816e-02,  2.5866e-01,  8.6253e-02,  2.5344e-01,
         -4.0604e-02, -2.5944e-01,  1.7876e-01],
        [ 2.3056e-01,  1.9110e-01,  2.6104e-01, -3.5136e-01, -2.5361e-01,
         -1.7592e-01,  3.7246e-02,  2.4193e-01],
        [-1.7185e-01, -8.9894e-02,  2.7597e-01, -8.5842e-02,  7.3159e-02,
         -4.3560e-01, -1.0816e-01,  2.3540e-01],
        [ 3.8141e-01, -4.7651e-03,  2.1606e-01,  1.1337e-01, -3.4466e-01,
          4.3355e-02, -8.3839e-02, -8.0816e-03],
        [-1.1809e-01,  2.4074e-01, -3.1400e-01, -1.8442e-01, -1.2020e-01,
          3.5424e-01, -4.5786e-02,  1.1876e-01],
        [ 9.3419e-02,  3.8266e-01, -1.6226e-02, -1.9933e-02, -1.1275e-01,
         -1.1915e-01, -3.9124e-01, -2.3637e-01],
        [ 1.2063e-01, -2.9470e-01,  1.7111e-01,  3.0239e-01,  9.9446e-02,
          2.0804e-01, -2.8829e-01, -1.8650e-01],
        [-2.2771e-01, -3.6015e-01,  1.3813e-01,  1.2228e-01,  3.1379e-01,
         -3.4048e-02, -2.0639e-01, -3.1302e-01],
        [ 4.0296e-02, -1.9636e-01,  7.2296e-02,  2.6741e-01,  3.1127e-01,
          1.1097e-02, -2.2275e-01, -2.2788e-01],
        [ 2.4000e-01,  7.2982e-02,  8.6330e-03, -3.1711e-01,  1.9009e-01,
          2.8312e-01,  5.5715e-02, -8.8577e-02],
        [-1.4564e-01, -1.7150e-02,  9.1202e-03,  1.4384e-01, -3.9927e-02,
          4.0553e-01,  2.5153e-01,  6.8268e-02],
        [-3.7826e-01, -1.0517e-01,  1.8726e-01, -3.0443e-01,  1.4726e-01,
         -1.0739e-02, -2.9254e-01,  1.2247e-01],
        [-1.3222e-01,  3.1963e-01, -3.4844e-02,  2.5532e-01,  3.4854e-01,
         -4.2823e-02,  1.6556e-02, -9.5589e-02],
        [ 2.8467e-01,  1.6167e-01, -1.2933e-02,  1.9808e-01, -2.8803e-01,
         -1.3851e-01,  8.0512e-02, -3.1961e-01],
        [ 2.8253e-01,  5.4909e-02,  3.2366e-01, -1.4874e-01,  5.1173e-02,
         -1.6572e-01, -1.7163e-01, -1.2551e-01],
        [ 1.8330e-01,  3.5565e-01,  1.0148e-01,  1.2233e-01,  1.7926e-01,
         -1.0099e-01, -3.0303e-01,  1.2042e-01],
        [-1.0999e-01,  1.3048e-01, -2.4182e-01, -2.0730e-02, -1.3443e-01,
         -3.5350e-01, -3.1639e-01,  3.0157e-01]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[ 1.1987e-02, -1.6406e-02, -1.3002e-02,  1.3761e-02, -4.3209e-03,
         -1.3895e-02,  1.2335e-02, -2.2900e-03],
        [ 1.3366e-02, -2.0544e-02, -1.1344e-02,  2.0851e-02, -1.4549e-02,
         -7.9156e-03,  1.5402e-02,  1.1149e-02],
        [-7.3013e-02,  1.3680e-01,  6.5739e-02, -1.3161e-01,  1.2543e-01,
          3.9633e-02, -1.0952e-01, -1.2616e-01],
        [-2.7312e-02,  6.6986e-02,  2.4102e-02, -6.3838e-02,  8.2861e-02,
          1.0630e-02, -5.7169e-02, -1.0273e-01],
        [-8.3479e-02,  1.3295e-01,  6.8959e-02, -1.3621e-01,  1.0382e-01,
          4.3906e-02, -1.0056e-01, -8.8488e-02],
        [-9.5962e-02,  1.5347e-01,  8.1601e-02, -1.5417e-01,  1.1756e-01,
          5.6217e-02, -1.1683e-01, -1.0054e-01],
        [ 3.4934e-02, -5.7080e-02, -3.0519e-02,  5.5705e-02, -4.4075e-02,
         -2.1715e-02,  4.3944e-02,  3.8456e-02],
        [ 1.1176e-02, -1.9274e-02, -9.5672e-03,  1.8757e-02, -1.6998e-02,
         -7.0736e-03,  1.5145e-02,  1.7486e-02],
        [ 1.4220e-02, -2.4099e-02, -1.1896e-02,  2.4250e-02, -2.0702e-02,
         -7.5411e-03,  1.8661e-02,  1.9813e-02],
        [ 1.2463e-01, -1.9546e-01, -1.0608e-01,  1.9706e-01, -1.4369e-01,
         -7.3458e-02,  1.4770e-01,  1.1617e-01],
        [-3.4119e-03,  7.8304e-03,  4.1679e-03, -5.9505e-03,  7.8285e-03,
          4.9408e-03, -6.9336e-03, -1.0314e-02],
        [-1.1926e-01,  1.8795e-01,  1.0091e-01, -1.9002e-01,  1.4055e-01,
          6.9020e-02, -1.4217e-01, -1.1591e-01],
        [ 1.5314e-02, -2.4569e-02, -1.2867e-02,  2.4968e-02, -1.9132e-02,
         -8.5007e-03,  1.8673e-02,  1.6464e-02],
        [-1.2334e-01,  2.0495e-01,  1.0377e-01, -2.0655e-01,  1.6979e-01,
          6.7843e-02, -1.5779e-01, -1.5736e-01],
        [-3.7444e-03,  7.9597e-03,  7.3269e-03, -3.5594e-03,  2.9255e-03,
          1.1128e-02, -7.4368e-03, -3.1835e-03],
        [-1.2548e-02,  1.9991e-02,  8.3661e-03, -2.2533e-02,  1.8498e-02,
          1.8858e-03, -1.4688e-02, -1.6675e-02],
        [-7.4208e-02,  1.2044e-01,  6.1944e-02, -1.2215e-01,  9.6566e-02,
          4.0477e-02, -9.1899e-02, -8.5985e-02],
        [-2.9895e-02,  4.4514e-02,  2.4384e-02, -4.6374e-02,  3.0715e-02,
          1.5567e-02, -3.2744e-02, -2.1461e-02],
        [-8.7665e-02,  1.2790e-01,  8.2955e-02, -1.1939e-01,  6.8721e-02,
          7.6290e-02, -9.6254e-02, -3.9046e-02],
        [ 1.8828e-03,  6.4215e-03,  2.4772e-03, -4.6348e-04,  1.3015e-02,
          6.9942e-03, -8.3813e-03, -2.4276e-02],
        [ 1.6226e-03,  1.4606e-03, -1.2912e-03, -4.6294e-04,  7.2212e-03,
         -8.5053e-04, -2.3124e-03, -1.3271e-02],
        [-4.2648e-03, -3.2792e-03,  3.6737e-03,  1.5705e-03, -1.7446e-02,
          4.2346e-03,  5.2746e-03,  3.0933e-02],
        [-8.4555e-03,  1.2845e-02,  3.3288e-03, -1.6215e-02,  1.4581e-02,
         -3.4014e-03, -8.8614e-03, -1.3769e-02],
        [-1.1366e-01,  1.8092e-01,  9.7474e-02, -1.8107e-01,  1.3588e-01,
          6.8145e-02, -1.3761e-01, -1.1374e-01],
        [-3.1682e-02,  5.3756e-02,  3.0947e-02, -4.9950e-02,  3.9708e-02,
          2.6589e-02, -4.2510e-02, -3.6034e-02],
        [-6.0643e-02,  9.4745e-02,  5.2955e-02, -9.4141e-02,  6.7440e-02,
          3.9536e-02, -7.1844e-02, -5.4011e-02],
        [-5.9706e-02,  9.6604e-02,  4.6874e-02, -1.0148e-01,  8.1308e-02,
          2.5624e-02, -7.2964e-02, -7.3208e-02],
        [-2.2038e-03,  1.6370e-02,  4.2551e-03, -1.1154e-02,  2.8529e-02,
          5.9388e-03, -1.6660e-02, -4.5072e-02],
        [-3.5185e-02,  5.0184e-02,  3.2196e-02, -4.8794e-02,  2.6332e-02,
          2.7339e-02, -3.7072e-02, -1.2289e-02],
        [-1.9059e-02,  2.5678e-02,  1.7542e-02, -2.3902e-02,  1.1162e-02,
          1.6615e-02, -1.8740e-02, -3.0511e-03],
        [-2.8923e-02,  4.6383e-02,  2.3510e-02, -4.8056e-02,  3.7111e-02,
          1.3898e-02, -3.5040e-02, -3.1877e-02],
        [-3.7800e-02,  6.0731e-02,  2.8407e-02, -6.5248e-02,  5.2493e-02,
          1.3614e-02, -4.5501e-02, -4.7548e-02],
        [-3.0412e-02,  4.8980e-02,  2.5984e-02, -4.9308e-02,  3.7639e-02,
          1.7526e-02, -3.7337e-02, -3.2028e-02],
        [ 5.9786e-03, -1.0107e-02, -5.3535e-03,  9.8787e-03, -8.1503e-03,
         -4.0082e-03,  7.8930e-03,  7.6819e-03],
        [-7.6437e-03,  1.8177e-02,  1.0761e-02, -1.3488e-02,  1.5873e-02,
          1.1831e-02, -1.6202e-02, -1.8902e-02],
        [ 1.4658e-03, -3.4541e-04, -8.3592e-04,  1.2959e-03,  2.2068e-03,
          5.7278e-05, -4.1302e-04, -5.2030e-03],
        [-1.2181e-01,  2.0163e-01,  1.0261e-01, -2.0329e-01,  1.6541e-01,
          6.6715e-02, -1.5498e-01, -1.5119e-01],
        [ 6.5776e-03, -5.8140e-03, -4.3457e-03,  7.8966e-03,  6.8146e-04,
         -1.7252e-03,  2.8648e-03, -7.4274e-03],
        [ 3.9359e-02, -7.9396e-02, -3.0667e-02,  8.5751e-02, -8.7209e-02,
         -7.9026e-03,  6.3457e-02,  9.5405e-02],
        [ 1.9714e-02, -3.2972e-02, -1.6539e-02,  3.3225e-02, -2.7660e-02,
         -1.0655e-02,  2.5429e-02,  2.5891e-02],
        [ 9.6082e-03, -1.7497e-02, -8.9012e-03,  1.6306e-02, -1.5744e-02,
         -7.4877e-03,  1.4116e-02,  1.7159e-02],
        [-7.3348e-02,  1.1239e-01,  6.3210e-02, -1.1281e-01,  7.7483e-02,
          4.5409e-02, -8.4358e-02, -5.7618e-02],
        [ 1.1495e-02, -9.1835e-03, -1.4918e-02,  4.3234e-03,  1.3529e-02,
         -2.1612e-02,  5.7713e-03, -2.7062e-02],
        [-2.3093e-02,  4.5578e-02,  2.0643e-02, -4.2723e-02,  4.6727e-02,
          1.5591e-02, -3.7427e-02, -5.4607e-02],
        [ 1.0168e-02, -3.0029e-02, -1.4986e-03,  3.8898e-02, -5.2522e-02,
          1.6419e-02,  2.4575e-02,  6.6358e-02],
        [ 2.4124e-02, -3.9124e-02, -2.0433e-02,  3.9416e-02, -3.0877e-02,
         -1.3806e-02,  2.9903e-02,  2.7266e-02],
        [-6.7308e-02,  1.0457e-01,  5.7885e-02, -1.0496e-01,  7.4444e-02,
          4.1023e-02, -7.8848e-02, -5.7912e-02],
        [ 1.7221e-02, -2.6933e-02, -1.4971e-02,  2.6829e-02, -1.9178e-02,
         -1.0774e-02,  2.0387e-02,  1.5038e-02],
        [-5.7319e-03,  1.6325e-02,  6.9778e-03, -1.3425e-02,  1.9896e-02,
          6.6883e-03, -1.4789e-02, -2.6900e-02],
        [ 1.9325e-02, -3.2630e-02, -1.6063e-02,  3.3043e-02, -2.8065e-02,
         -1.0122e-02,  2.5218e-02,  2.6876e-02],
        [-6.8942e-03,  3.1457e-02,  1.0635e-02, -2.3483e-02,  4.7153e-02,
          1.1370e-02, -3.0538e-02, -6.9824e-02],
        [-1.0302e-02,  1.4565e-02,  8.7046e-03, -1.5105e-02,  8.5102e-03,
          6.3735e-03, -1.0557e-02, -4.5272e-03],
        [ 5.8452e-02, -9.1826e-02, -5.3039e-02,  8.9170e-02, -6.2896e-02,
         -4.1929e-02,  7.0120e-02,  4.9084e-02],
        [-1.5669e-02,  3.6399e-02,  7.3816e-03, -4.1905e-02,  5.2993e-02,
         -7.1909e-03, -2.9429e-02, -6.5494e-02],
        [ 1.2720e-02, -3.4245e-02, -9.5698e-03,  3.2980e-02, -4.8545e-02,
         -2.5474e-03,  2.9675e-02,  6.4373e-02],
        [ 1.0649e-01, -1.5792e-01, -8.9652e-02,  1.5977e-01, -1.0410e-01,
         -6.3023e-02,  1.1679e-01,  7.0300e-02],
        [ 1.9046e-02, -2.9630e-02, -1.5968e-02,  3.0269e-02, -2.1818e-02,
         -1.0768e-02,  2.2270e-02,  1.7491e-02],
        [-1.0347e-01,  1.6339e-01,  8.8628e-02, -1.6395e-01,  1.2066e-01,
          6.1433e-02, -1.2383e-01, -9.8169e-02],
        [-5.3306e-02,  8.9021e-02,  4.0924e-02, -9.4051e-02,  7.9664e-02,
          1.9102e-02, -6.7691e-02, -7.4709e-02],
        [-6.0172e-02,  9.7312e-02,  4.9593e-02, -9.9772e-02,  7.8190e-02,
          3.0795e-02, -7.3943e-02, -6.8637e-02],
        [ 1.8054e-02, -2.8775e-02, -1.5676e-02,  2.8589e-02, -2.1432e-02,
         -1.1356e-02,  2.1947e-02,  1.8027e-02],
        [ 2.2168e-02, -3.5932e-02, -1.8878e-02,  3.6072e-02, -2.8160e-02,
         -1.2891e-02,  2.7477e-02,  2.4735e-02],
        [ 1.8481e-02, -2.9634e-02, -1.5691e-02,  2.9788e-02, -2.2781e-02,
         -1.0606e-02,  2.2558e-02,  1.9409e-02],
        [-1.1443e-02,  2.4929e-02,  1.0939e-02, -2.2279e-02,  2.7526e-02,
          9.3573e-03, -2.1169e-02, -3.4626e-02],
        [-3.1050e-02,  7.8370e-02,  2.4061e-02, -7.8013e-02,  1.0320e-01,
          2.2630e-03, -6.6399e-02, -1.2733e-01],
        [-7.0975e-03,  1.7110e-02,  7.8076e-03, -1.4407e-02,  1.9013e-02,
          7.2885e-03, -1.4985e-02, -2.4447e-02],
        [-5.1875e-02,  8.5703e-02,  4.0791e-02, -8.9672e-02,  7.4520e-02,
          2.2091e-02, -6.5233e-02, -6.9677e-02],
        [-2.6017e-03,  2.4523e-04,  3.2030e-03,  3.8949e-05, -6.8983e-03,
          4.6587e-03,  6.6597e-04,  1.2289e-02],
        [-9.1973e-02,  1.4055e-01,  8.0482e-02, -1.3935e-01,  9.5144e-02,
          6.1329e-02, -1.0582e-01, -7.1229e-02],
        [ 5.1981e-03, -8.1635e-03, -4.1468e-03,  8.5759e-03, -6.3735e-03,
         -2.2938e-03,  6.0968e-03,  5.1728e-03],
        [ 1.5075e-01, -2.3519e-01, -1.2204e-01,  2.4201e-01, -1.8081e-01,
         -7.6383e-02,  1.7633e-01,  1.4977e-01],
        [-4.5494e-02,  6.6647e-02,  3.9734e-02, -6.6397e-02,  4.0985e-02,
          3.1205e-02, -4.9410e-02, -2.6266e-02],
        [ 9.0120e-02, -1.3893e-01, -7.3406e-02,  1.4277e-01, -1.0358e-01,
         -4.6749e-02,  1.0376e-01,  8.2474e-02],
        [-1.3120e-02,  3.8211e-02,  1.4406e-02, -3.2124e-02,  5.0202e-02,
          1.2827e-02, -3.4560e-02, -6.9193e-02],
        [-8.2353e-03,  2.1625e-02,  8.5825e-03, -1.8450e-02,  2.6912e-02,
          7.5132e-03, -1.9178e-02, -3.6122e-02],
        [ 6.9327e-02, -1.1651e-01, -5.8388e-02,  1.1402e-01, -9.7708e-02,
         -3.7577e-02,  9.0185e-02,  9.0973e-02],
        [-3.6603e-02,  6.7538e-02,  2.3144e-02, -7.8559e-02,  7.7035e-02,
          1.4126e-03, -5.1958e-02, -8.5079e-02],
        [ 1.5696e-02, -2.5905e-02, -1.3545e-02,  2.5706e-02, -2.0719e-02,
         -9.4710e-03,  1.9976e-02,  1.8827e-02],
        [-7.1801e-02,  1.0946e-01,  6.0619e-02, -1.1136e-01,  7.6483e-02,
          4.1741e-02, -8.1732e-02, -5.6872e-02],
        [ 1.6625e-02, -2.5742e-02, -1.4031e-02,  2.6198e-02, -1.8562e-02,
         -9.4688e-03,  1.9319e-02,  1.4387e-02],
        [-6.9059e-02,  1.1063e-01,  5.6678e-02, -1.1390e-01,  8.7932e-02,
          3.5421e-02, -8.3768e-02, -7.6310e-02],
        [ 2.3810e-02, -3.7410e-02, -2.0062e-02,  3.7983e-02, -2.7868e-02,
         -1.3454e-02,  2.8231e-02,  2.2648e-02],
        [-7.9960e-03,  2.5851e-02,  9.2168e-03, -2.0805e-02,  3.5827e-02,
          8.8897e-03, -2.3890e-02, -5.0998e-02],
        [-4.6272e-04,  6.7421e-03,  2.0802e-03, -4.1974e-03,  1.1668e-02,
          3.3232e-03, -7.1463e-03, -1.8867e-02],
        [-1.7440e-02,  2.4000e-02,  1.5867e-02, -2.3849e-02,  1.1185e-02,
          1.3249e-02, -1.7409e-02, -2.9311e-03],
        [-1.0221e-02,  1.4549e-02,  9.8325e-03, -1.3641e-02,  6.8869e-03,
          9.0255e-03, -1.0838e-02, -2.5909e-03],
        [ 8.6839e-03, -1.4101e-02, -7.9387e-03,  1.3484e-02, -1.0321e-02,
         -6.3806e-03,  1.0920e-02,  8.9254e-03],
        [ 1.8201e-02, -3.2333e-02, -1.5418e-02,  3.1905e-02, -2.9809e-02,
         -1.0430e-02,  2.5533e-02,  3.1201e-02],
        [-2.3999e-02,  4.5237e-02,  2.2230e-02, -4.2870e-02,  4.1869e-02,
          1.6475e-02, -3.6617e-02, -4.4938e-02],
        [ 1.4925e-02, -2.4755e-02, -1.3034e-02,  2.4496e-02, -1.9696e-02,
         -9.1957e-03,  1.9135e-02,  1.7839e-02],
        [ 1.9929e-02, -3.3201e-02, -1.7032e-02,  3.3268e-02, -2.7189e-02,
         -1.1431e-02,  2.5624e-02,  2.5061e-02],
        [-3.0044e-02,  4.6750e-02,  2.1675e-02, -5.1063e-02,  4.0149e-02,
          1.0156e-02, -3.4538e-02, -3.5999e-02],
        [ 1.1031e-02, -1.9195e-02, -9.0319e-03,  1.9590e-02, -1.7406e-02,
         -5.1435e-03,  1.4928e-02,  1.7218e-02],
        [ 1.9825e-02, -3.2149e-02, -1.6958e-02,  3.2086e-02, -2.5111e-02,
         -1.1730e-02,  2.4613e-02,  2.2058e-02],
        [-1.9848e-02,  3.6570e-02,  1.8268e-02, -3.4399e-02,  3.3157e-02,
          1.4205e-02, -2.9482e-02, -3.5471e-02],
        [ 1.0646e-01, -1.8506e-01, -9.0753e-02,  1.9080e-01, -1.6246e-01,
         -5.6669e-02,  1.4421e-01,  1.5901e-01],
        [-8.9949e-02,  1.4386e-01,  7.4105e-02, -1.4750e-01,  1.1363e-01,
          4.6969e-02, -1.0895e-01, -9.8226e-02],
        [-8.4894e-02,  1.3437e-01,  7.5724e-02, -1.3198e-01,  9.6604e-02,
          6.0012e-02, -1.0282e-01, -8.1256e-02],
        [-5.7049e-03,  1.3790e-02,  6.4471e-03, -1.1498e-02,  1.5056e-02,
          6.0789e-03, -1.2099e-02, -1.9218e-02],
        [-5.3921e-02,  8.6730e-02,  4.7205e-02, -8.6276e-02,  6.5181e-02,
          3.4445e-02, -6.6393e-02, -5.5735e-02]], device='cuda:0') 

model.module_1.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.0508, -0.3026,  0.0842, -0.0220,  0.2689,  0.3443, -0.0398, -0.2000,
        -0.2102, -0.0718, -0.1293,  0.3354, -0.1405,  0.1956,  0.2018,  0.0104,
         0.1475,  0.2607,  0.1784,  0.1933, -0.2424, -0.0100, -0.0128,  0.2857,
         0.1668,  0.2740,  0.2577, -0.1246,  0.0466,  0.2396,  0.1081,  0.1829,
         0.1275, -0.1121,  0.1158, -0.1659,  0.3360,  0.0073,  0.2247, -0.2624,
        -0.3159,  0.0509, -0.0427, -0.1194,  0.2635, -0.2368,  0.3073, -0.3496,
         0.0479, -0.2222,  0.0965,  0.3051, -0.0613,  0.0684, -0.1166, -0.2026,
        -0.2937,  0.2129,  0.0041,  0.1075, -0.2757, -0.3055, -0.3360, -0.1575,
        -0.0444, -0.0329,  0.1421, -0.1483,  0.3437, -0.0949, -0.3343,  0.2631,
        -0.2317,  0.0704, -0.0156, -0.1061, -0.0165, -0.3548,  0.2978, -0.2252,
         0.2133, -0.2190, -0.0609,  0.0334, -0.1132, -0.0972, -0.2801, -0.2537,
         0.0410, -0.1183, -0.0557,  0.0492, -0.0564, -0.3398, -0.0854,  0.1293,
         0.1323,  0.1723,  0.0662,  0.2214], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 0.0465,  0.0613, -0.5049, -0.3125, -0.4104, -0.4814,  0.1786,  0.0662,
         0.0809,  0.5968, -0.0391, -0.5776,  0.0779, -0.6783, -0.0494, -0.0537,
        -0.3838, -0.1215, -0.3680, -0.0749, -0.0224,  0.0529, -0.0163, -0.5650,
        -0.2003, -0.2950, -0.2992, -0.1139, -0.1386, -0.0574, -0.1436, -0.1832,
        -0.1564,  0.0360, -0.0986, -0.0083, -0.6621, -0.0071,  0.3472,  0.1094,
         0.0675, -0.3324,  0.0026, -0.1830,  0.1510,  0.1259, -0.3159,  0.0824,
        -0.0928,  0.1100, -0.2058, -0.0390,  0.2930, -0.1497,  0.1596,  0.4207,
         0.0900, -0.5025, -0.2807, -0.3074,  0.0911,  0.1155,  0.0926, -0.1112,
        -0.3525, -0.0853, -0.2743,  0.0105, -0.4197,  0.0240,  0.6776, -0.1863,
         0.3929, -0.2084, -0.1097,  0.3541, -0.2650,  0.0855, -0.3181,  0.0769,
        -0.3465,  0.1141, -0.1447, -0.0560, -0.0642, -0.0416,  0.0466,  0.1161,
        -0.1803,  0.0833,  0.1117, -0.1313,  0.0667,  0.1026, -0.1405,  0.7129,
        -0.4473, -0.4421, -0.0694, -0.2854], device='cuda:0') 

model.module_3.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[-0.1036, -0.1096,  0.0028,  ...,  0.0478, -0.0107,  0.0448],
        [-0.0183, -0.0547, -0.1333,  ..., -0.1033, -0.0838, -0.0282],
        [-0.0200, -0.0036,  0.1922,  ...,  0.0016,  0.1714, -0.0364],
        ...,
        [-0.0098,  0.0414,  0.0916,  ...,  0.0497,  0.1835, -0.0002],
        [-0.1431, -0.0803,  0.0448,  ...,  0.0468,  0.1331,  0.0195],
        [-0.0766,  0.0634, -0.0163,  ...,  0.0400, -0.0211, -0.0522]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-0.0022,  0.0034, -0.0191,  ..., -0.0047, -0.0025, -0.0231],
        [ 0.0072, -0.0033,  0.0018,  ...,  0.0035, -0.0009,  0.0182],
        [-0.0133,  0.0076, -0.0066,  ..., -0.0090,  0.0011, -0.0410],
        ...,
        [ 0.0023,  0.0006,  0.0138,  ..., -0.0019,  0.0007,  0.0062],
        [-0.0039,  0.0059, -0.0341,  ..., -0.0083, -0.0043, -0.0410],
        [-0.0085,  0.0025, -0.0092,  ..., -0.0019,  0.0004, -0.0198]],
       device='cuda:0') 

model.module_3.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.0653,  0.0349,  0.0362,  0.0160, -0.0366, -0.0749,  0.0334, -0.0033,
        -0.0129,  0.0025, -0.0798, -0.0714, -0.0260,  0.0426, -0.0635,  0.0945,
        -0.1065, -0.0457,  0.0544, -0.1126, -0.0284,  0.0440, -0.0365,  0.0469,
        -0.0212, -0.0146,  0.0320, -0.0184,  0.0871,  0.0272,  0.0026, -0.0229,
         0.0950, -0.0163,  0.0726, -0.0873,  0.0806,  0.0557,  0.0844,  0.1008,
        -0.0194, -0.0912,  0.0545,  0.0531, -0.0769, -0.0552,  0.0162, -0.0357,
         0.0398,  0.0577,  0.0087, -0.0422, -0.0857,  0.0978,  0.0126, -0.0931,
        -0.0302, -0.0660,  0.0991, -0.0308, -0.0759, -0.0881, -0.0498,  0.0135,
        -0.0865,  0.0766,  0.0087, -0.0622, -0.0438, -0.0158,  0.0769,  0.0251,
         0.0145, -0.0740,  0.0689, -0.0036,  0.0172,  0.0237, -0.0678, -0.0969,
        -0.0741,  0.0473,  0.0807, -0.0581,  0.0386, -0.0294,  0.0621,  0.0270,
        -0.0750, -0.1069,  0.0439,  0.0755,  0.0159,  0.0159, -0.0326, -0.0590,
        -0.0018, -0.0553,  0.0596, -0.0316], device='cuda:0',
       requires_grad=True) 
grad:  tensor([-0.0681,  0.0721, -0.1576,  0.0310, -0.0741, -0.0468, -0.9582, -0.0916,
        -0.0619,  0.1033,  0.0260,  0.0653,  0.0770, -0.0892,  0.0841, -0.0311,
         0.0412, -0.0336, -0.5032,  0.0733,  0.0206,  0.0404,  0.0776, -0.1433,
        -0.0014,  0.0561, -0.5933,  0.0088, -0.0741, -0.1504,  0.0109, -0.8679,
        -0.0404,  0.0945, -0.5107,  0.0559, -0.7240,  0.0040, -0.3153, -0.6147,
        -0.1866,  0.0775, -0.2371, -0.2186,  0.1233,  0.2031, -0.7077,  0.1683,
         0.1077,  0.0092,  0.1814,  0.0280,  0.1781, -0.0496,  0.1944,  0.1201,
         0.0292,  0.2092, -0.1006, -0.0455, -0.5910,  0.1114, -0.0044, -0.4261,
         0.1321, -0.0028, -0.6021,  0.1168, -0.1565, -0.0624,  0.0018, -0.7523,
         0.0082, -0.1201, -0.1501,  0.1207, -0.4741, -0.6510,  0.0526,  0.0765,
         0.1076, -0.1803, -0.0742, -0.1683, -0.0543, -1.0068, -0.0498,  0.0576,
         0.1398,  0.1552,  0.1217, -0.2352,  0.0483,  0.0017,  0.0402,  0.0032,
         0.0261,  0.0141, -0.1219, -0.0728], device='cuda:0') 

model.module_5.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[-0.1026, -0.0014,  0.0826,  ..., -0.0406,  0.0003, -0.0486],
        [ 0.0316, -0.0896,  0.0519,  ..., -0.0727,  0.0616, -0.0190],
        [ 0.0584, -0.0361, -0.0904,  ..., -0.0456, -0.0004,  0.0719],
        ...,
        [-0.0161,  0.0357, -0.0107,  ...,  0.0783,  0.0989, -0.1133],
        [ 0.0065,  0.0987, -0.0158,  ..., -0.0144, -0.0264, -0.0713],
        [ 0.0362, -0.0805,  0.1115,  ...,  0.0122, -0.0477, -0.0920]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 2.9643e-02,  2.4475e-02,  2.6350e-02,  ..., -3.8229e-02,
          2.5715e-02, -1.9463e-01],
        [-9.4641e-03, -5.8994e-03, -9.4844e-03,  ...,  5.0238e-03,
         -8.5900e-03,  4.9384e-02],
        [-6.4735e-03, -1.4184e-02, -3.7764e-04,  ...,  3.6704e-02,
         -3.5268e-03,  1.0448e-01],
        ...,
        [-7.6163e-03,  1.8963e-02, -2.1329e-02,  ..., -8.1428e-02,
         -1.2190e-02, -1.1612e-01],
        [-3.1034e-03, -8.1810e-03,  6.2875e-04,  ...,  2.2423e-02,
         -1.3893e-03,  5.9582e-02],
        [ 4.4181e-02,  6.4444e-02,  2.2535e-02,  ..., -1.4623e-01,
          3.1707e-02, -4.8409e-01]], device='cuda:0') 

model.module_5.bias 16 torch.Size([16])
Parameter containing:
tensor([ 0.0678,  0.0248, -0.0420, -0.0847,  0.1253,  0.1126,  0.1091,  0.0883,
         0.1095, -0.0936, -0.0875, -0.0751,  0.1185, -0.0857, -0.0541,  0.1247],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-1.1014,  0.2718,  0.6088, -0.2654, -3.1735, -0.9271, -0.2402, -3.2462,
        -0.4622,  0.3008, -1.0509, -0.5263, -1.2027, -0.7529,  0.3496, -2.7988],
       device='cuda:0') 

model.module_7.bias 8 torch.Size([8])
Parameter containing:
tensor([-0.0202, -0.0132, -0.0275, -0.0073,  0.0275,  0.0137, -0.0190, -0.0121],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-0.9132, -2.4725,  0.1876, -1.0736,  2.0119,  0.7229, -3.0003, -1.7572],
       device='cuda:0') 

model.module_7.lin.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[ 0.1091, -0.2557, -0.4603,  0.0178, -0.2121,  0.4459,  0.1737, -0.2630,
          0.0650, -0.2798,  0.5204,  0.3003,  0.1884,  0.2347, -0.0128, -0.1404],
        [ 0.0579, -0.4692, -0.2764,  0.0291,  0.3871,  0.0171, -0.1569,  0.3571,
          0.1594, -0.3152,  0.2263,  0.1460, -0.4094,  0.1111, -0.3337,  0.4726],
        [-0.3398, -0.0594, -0.1923,  0.0601,  0.4322, -0.2751,  0.1346, -0.1197,
         -0.1900,  0.0438,  0.3664, -0.4807, -0.1593,  0.3185, -0.2229,  0.0972],
        [ 0.2034,  0.0809,  0.0248, -0.3594, -0.0616, -0.0801, -0.0066, -0.0387,
         -0.1032, -0.3072,  0.3706,  0.1418,  0.1535,  0.2558,  0.0099,  0.3418],
        [ 0.1592, -0.1914,  0.0082, -0.4180, -0.2671,  0.4646,  0.4899, -0.3633,
         -0.2324,  0.2662, -0.4865, -0.0589, -0.4524, -0.2298, -0.2635, -0.0264],
        [-0.1212, -0.3017,  0.2645, -0.2264, -0.5241,  0.2806,  0.3372, -0.1143,
         -0.0731,  0.0489, -0.0186, -0.0686, -0.5047,  0.2722,  0.0104,  0.2703],
        [ 0.0391, -0.1588, -0.2552,  0.0413,  0.2673,  0.5174,  0.4607,  0.4201,
         -0.3655,  0.0876,  0.4811,  0.2478,  0.3206,  0.5005, -0.1501,  0.2778],
        [ 0.3121,  0.0315, -0.3114,  0.1010,  0.4356,  0.0925,  0.1904,  0.0885,
          0.3752,  0.2513, -0.0999,  0.1077, -0.2441,  0.0935, -0.4383,  0.1924]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-0.1370,  0.0027,  0.0545,  0.0111, -0.6230, -0.0065, -0.0219, -0.3722,
         -0.2503,  0.0202,  0.1409,  0.1673, -0.1711,  0.1506,  0.0312, -0.2062],
        [-0.5895,  0.0300,  0.1752,  0.0924, -1.3751, -0.5615, -0.2926, -1.0709,
         -0.5377,  0.0926, -0.0400, -0.1377, -0.3374, -0.0986,  0.0881, -0.8634],
        [-0.0092,  0.0035, -0.0053,  0.0086,  0.1590, -0.0869, -0.0259,  0.0558,
          0.0644,  0.0027, -0.1002, -0.1389,  0.0513, -0.1202, -0.0050, -0.0149],
        [-0.2229,  0.0091,  0.0725,  0.0300, -0.6613, -0.1496, -0.0897, -0.4631,
         -0.2607,  0.0342,  0.0653,  0.0560, -0.1701,  0.0564,  0.0382, -0.3267],
        [ 0.5208, -0.0280, -0.1502, -0.0858,  1.1144,  0.5360,  0.2693,  0.9066,
          0.4343, -0.0825,  0.0850,  0.1896,  0.2662,  0.1463, -0.0743,  0.7628],
        [ 0.2551, -0.0179, -0.0611, -0.0513,  0.2664,  0.3821,  0.1754,  0.3292,
          0.0979, -0.0417,  0.1897,  0.2904,  0.0460,  0.2431, -0.0266,  0.3700],
        [-0.6809,  0.0324,  0.2086,  0.1015, -1.7277, -0.5879, -0.3200, -1.2935,
         -0.6776,  0.1061,  0.0303, -0.0545, -0.4333, -0.0231,  0.1067, -0.9970],
        [-0.4189,  0.0209,  0.1246,  0.0650, -0.9810, -0.3948, -0.2112, -0.7622,
         -0.3827,  0.0655, -0.0209, -0.0847, -0.2424, -0.0588,  0.0627, -0.6110]],
       device='cuda:0') 

model.module_8.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[ 0.1711, -0.2458,  0.1269,  0.0049, -0.1860,  0.1008,  0.0640, -0.1344],
        [ 0.2435,  0.0981, -0.2117, -0.0490, -0.2210, -0.2353,  0.3523, -0.0286],
        [-0.0186, -0.0440, -0.0716, -0.3046, -0.0591, -0.1533,  0.1451, -0.0084],
        [-0.3361, -0.2129, -0.2931,  0.0237,  0.2346,  0.1743,  0.0207,  0.1977],
        [-0.0309,  0.3444, -0.2899, -0.0777, -0.0630, -0.2728,  0.1330,  0.2629],
        [ 0.0720,  0.0135,  0.2865, -0.1580, -0.0464,  0.1410, -0.2180, -0.2822],
        [-0.0486,  0.2223, -0.2041,  0.0962,  0.0260,  0.3491,  0.1839, -0.1924],
        [-0.3042,  0.2207, -0.3792, -0.1918,  0.3732,  0.1393,  0.0109, -0.2603],
        [-0.0664,  0.0351,  0.2026, -0.1439, -0.0516,  0.0777, -0.3577, -0.1222],
        [-0.3191, -0.1533, -0.2212,  0.1608, -0.2280, -0.3230, -0.0663, -0.1921],
        [-0.2176, -0.0807,  0.1819, -0.3221, -0.2895, -0.0021,  0.1498,  0.0128],
        [ 0.3470,  0.1813, -0.2237,  0.2079, -0.1911,  0.2529, -0.0818,  0.2993],
        [-0.1058, -0.0974, -0.2511,  0.3377, -0.2166, -0.1840, -0.1997, -0.3412],
        [-0.1583,  0.2971,  0.2255,  0.0973, -0.1121,  0.0503, -0.0582, -0.2823],
        [ 0.2501,  0.1967,  0.3162, -0.3277,  0.0493,  0.2206, -0.0364,  0.1747],
        [ 0.2248, -0.1480,  0.2672,  0.0954, -0.0513,  0.1901,  0.2905,  0.0920],
        [ 0.1735, -0.2545, -0.1752, -0.0670,  0.2199,  0.2142, -0.1092, -0.0729],
        [-0.0876, -0.1549,  0.3313,  0.1816,  0.2055, -0.1553, -0.0854, -0.2860],
        [ 0.2705, -0.1520, -0.0467, -0.2434,  0.0972,  0.2148, -0.3663,  0.2490],
        [ 0.0997,  0.1583, -0.3474,  0.0911,  0.3742,  0.2760, -0.1621,  0.0053],
        [-0.2855,  0.1007,  0.2001,  0.0802, -0.3280,  0.1447, -0.0474, -0.2830],
        [-0.1037,  0.3095, -0.3008,  0.1978,  0.3509, -0.2444, -0.3302, -0.2678],
        [ 0.0512, -0.3414,  0.2603,  0.3171, -0.0082,  0.2924,  0.2915,  0.1003],
        [-0.1931, -0.0327,  0.2538, -0.2056,  0.0095, -0.0527, -0.1085, -0.0817],
        [-0.2398, -0.1414,  0.3385, -0.1754, -0.0481,  0.2765,  0.0743, -0.2777],
        [-0.1428, -0.1265, -0.1681, -0.2958,  0.1439,  0.2342, -0.2807,  0.3630],
        [ 0.1836,  0.3209, -0.2868,  0.1200,  0.2403,  0.2037, -0.0856,  0.2473],
        [ 0.1808, -0.2116,  0.1845, -0.1555,  0.2699, -0.1138, -0.1993,  0.1747],
        [-0.1713, -0.1569,  0.2134,  0.3227,  0.1717,  0.3570,  0.1340, -0.0722],
        [-0.0954, -0.0845, -0.0208, -0.0208,  0.0883,  0.1100, -0.2186, -0.1932],
        [ 0.2667, -0.1540,  0.2191,  0.3101, -0.3355,  0.0436,  0.0721, -0.2210],
        [-0.0714, -0.1407, -0.3638, -0.0814,  0.3230,  0.3402, -0.1748, -0.0881],
        [-0.1684,  0.2593, -0.2928, -0.1054, -0.1170, -0.1365,  0.3243, -0.2858],
        [-0.2666, -0.2961, -0.1679,  0.1708,  0.0525, -0.0066,  0.2705,  0.2424],
        [ 0.1108,  0.0590, -0.1609, -0.3561,  0.0744,  0.3242,  0.2522, -0.0379],
        [-0.0255,  0.3280, -0.3075,  0.2410,  0.3271,  0.2217,  0.1162,  0.0078],
        [ 0.1240, -0.1819, -0.0342, -0.2292,  0.0344, -0.0943,  0.3194,  0.1301],
        [ 0.1592, -0.2028,  0.0321,  0.3536,  0.1119, -0.3247, -0.1010,  0.2365],
        [ 0.2204,  0.0498, -0.0984,  0.2235,  0.1201,  0.0869,  0.1200, -0.2064],
        [-0.2452,  0.2445, -0.1769, -0.2443, -0.3092,  0.2659,  0.1616,  0.1716],
        [ 0.2534, -0.3438, -0.3001,  0.1238,  0.3197,  0.1757,  0.0202,  0.3279],
        [-0.1481,  0.3182,  0.2922, -0.2670, -0.0424,  0.2891,  0.3429, -0.0532],
        [ 0.3484, -0.2926,  0.0586,  0.0768,  0.1376,  0.2320,  0.0699,  0.1760],
        [ 0.2556,  0.2155,  0.2637,  0.3141,  0.2670,  0.0591, -0.2536,  0.1730],
        [ 0.0289,  0.3439, -0.0912,  0.0329, -0.3388, -0.1539,  0.2792, -0.2111],
        [-0.2138,  0.0165,  0.0475,  0.2487, -0.2511,  0.0423, -0.2284,  0.1754],
        [ 0.0611, -0.0111,  0.3253,  0.2466, -0.2630, -0.3692,  0.1868, -0.2449],
        [ 0.0566,  0.0370,  0.1236,  0.1756, -0.1932,  0.0257, -0.1995,  0.2605],
        [ 0.0932,  0.3804,  0.3311,  0.2328,  0.1523, -0.0493, -0.1877, -0.0753],
        [-0.1885, -0.1421, -0.1477, -0.3323,  0.0411, -0.2653, -0.3025,  0.1214],
        [-0.3878,  0.0843,  0.0042,  0.1863,  0.2718,  0.1278, -0.2888, -0.0234],
        [ 0.1438, -0.2490, -0.3182, -0.3041, -0.2951,  0.1280, -0.0836,  0.1734],
        [-0.1716, -0.0421, -0.0253,  0.3808,  0.0080, -0.3045,  0.3217,  0.0684],
        [ 0.3279, -0.0021, -0.2887,  0.0562, -0.1965, -0.2404,  0.0390,  0.1334],
        [-0.2114, -0.1103, -0.1279,  0.2449,  0.0795, -0.0977, -0.1339, -0.1383],
        [ 0.0335,  0.0874, -0.1641, -0.1310, -0.2426,  0.3563, -0.1318,  0.3128],
        [-0.0707, -0.0719, -0.0523, -0.0188, -0.0724,  0.0388, -0.1706,  0.3161],
        [ 0.1032,  0.0084, -0.2359,  0.1430, -0.0714, -0.0713, -0.2604,  0.2046],
        [ 0.0472,  0.1808, -0.2106,  0.1961,  0.3285,  0.1331,  0.2430, -0.3791],
        [ 0.2358, -0.0925,  0.1243,  0.2695,  0.0400, -0.0092,  0.1730,  0.3591],
        [-0.2600,  0.3396,  0.0726,  0.1860, -0.0299, -0.0882, -0.0502, -0.0653],
        [-0.3460,  0.2476,  0.2315, -0.3772,  0.1464, -0.2966, -0.1619,  0.3022],
        [-0.0693,  0.2532,  0.2517,  0.0543, -0.3871,  0.2011, -0.1302, -0.2079],
        [-0.1238,  0.2948, -0.0782,  0.1504,  0.0166, -0.1891,  0.0595,  0.2910],
        [ 0.2925, -0.0058,  0.0261,  0.1933, -0.1268, -0.0647,  0.1760,  0.2481],
        [-0.0188,  0.0063, -0.2253, -0.0290, -0.3240, -0.1650,  0.0079,  0.1806],
        [ 0.2295,  0.0172,  0.1213, -0.2118, -0.2971, -0.3733,  0.0476,  0.0473],
        [ 0.3081,  0.1977,  0.0310, -0.1223,  0.2278, -0.3131, -0.0106,  0.1225],
        [-0.3409,  0.3084, -0.0786,  0.3308, -0.0846, -0.2260,  0.2070, -0.1890],
        [-0.2840, -0.0948,  0.2346,  0.1078,  0.2526, -0.1501, -0.0031, -0.1050],
        [ 0.3906,  0.0263, -0.3707,  0.0977, -0.1860,  0.1517,  0.1137, -0.1804],
        [-0.3117, -0.0147, -0.2041,  0.3573, -0.1788, -0.0939,  0.2776, -0.0342],
        [ 0.0207, -0.3619,  0.1505,  0.2532, -0.3198,  0.3838,  0.2345,  0.1620],
        [ 0.0032, -0.0599,  0.3173,  0.1497, -0.1872, -0.1725,  0.2940, -0.2107],
        [-0.1338, -0.2682,  0.1142, -0.0796,  0.3193, -0.1640,  0.0852, -0.2492],
        [-0.1922, -0.3464, -0.0477,  0.0858,  0.1952,  0.4109,  0.1677, -0.0193],
        [ 0.2146, -0.3324,  0.3247, -0.2989,  0.2118, -0.2034,  0.3386,  0.0988],
        [ 0.1685,  0.1194, -0.1463,  0.0225,  0.0856,  0.1065,  0.1189,  0.3003],
        [-0.0330, -0.2371,  0.1585,  0.2258,  0.2644, -0.2294, -0.0292,  0.0701],
        [ 0.0140,  0.1567, -0.3647,  0.1968, -0.0795,  0.1142, -0.0759, -0.3308],
        [ 0.1642, -0.0114, -0.0702,  0.2676,  0.3521, -0.1082, -0.1043, -0.1283],
        [-0.2505, -0.3233, -0.1662, -0.2042, -0.0377, -0.0179,  0.2461, -0.0386],
        [ 0.2580, -0.3149, -0.0807, -0.0046,  0.1671,  0.3546,  0.2808,  0.0871],
        [ 0.1679,  0.2750,  0.2916,  0.1604, -0.2526,  0.2361,  0.1221,  0.2640],
        [ 0.1591,  0.0834, -0.0070,  0.2399,  0.3282,  0.4383, -0.2986,  0.1574],
        [ 0.3314, -0.1889, -0.3701,  0.2005,  0.0785,  0.3303,  0.1549,  0.2667],
        [-0.3396, -0.1529, -0.3407, -0.0199,  0.2443, -0.2803,  0.1732, -0.3494],
        [ 0.1988, -0.3195, -0.2589, -0.2129,  0.1015, -0.3429,  0.1330, -0.3555],
        [ 0.0014, -0.0547, -0.0720, -0.1758,  0.3234,  0.3199, -0.2926,  0.0094],
        [-0.2460, -0.2895, -0.1052,  0.2550, -0.3401,  0.3419,  0.3334,  0.1549],
        [ 0.3203,  0.0448,  0.1114,  0.1989, -0.2416,  0.1967, -0.0052, -0.3624],
        [ 0.3221, -0.0923,  0.0109, -0.1304,  0.2462,  0.0573, -0.0975, -0.1461],
        [ 0.0887, -0.3169,  0.1386, -0.2981, -0.2069,  0.0578, -0.1961,  0.1038],
        [-0.2552, -0.1077,  0.1522,  0.1829, -0.1025,  0.0936, -0.2780, -0.0637],
        [ 0.2420, -0.0366, -0.3295, -0.0199, -0.0173,  0.1522, -0.0687, -0.2570],
        [ 0.0926,  0.2502, -0.1135,  0.0922,  0.0836,  0.0784, -0.0596, -0.0281],
        [-0.3402,  0.2070, -0.2056, -0.2700, -0.2150,  0.1051, -0.0682, -0.2092],
        [ 0.1805, -0.1710, -0.2451,  0.1694, -0.1492, -0.2434, -0.1112, -0.1734],
        [ 0.0043, -0.1640,  0.0026, -0.0157,  0.2510,  0.2194, -0.1743,  0.1221],
        [-0.3086, -0.3312, -0.2659, -0.2450, -0.3139,  0.2174,  0.2226, -0.3282]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 2.2218e-04,  6.4654e-03,  2.4795e-05,  1.8556e-03, -2.1897e-03,
         -2.3476e-03,  7.5466e-03,  5.9983e-03],
        [ 7.4088e-02, -3.9344e-01, -2.3924e-02, -6.7486e-02,  1.5779e-01,
          2.1612e-01, -3.9086e-01, -3.8478e-01],
        [ 1.1298e-03, -8.2028e-02, -1.3550e-03, -2.1492e-02,  2.9521e-02,
          3.3373e-02, -9.2226e-02, -7.6819e-02],
        [-1.2286e-02,  2.0720e-01,  6.6581e-03,  4.9850e-02, -8.0348e-02,
         -9.2811e-02,  2.2244e-01,  1.9451e-01],
        [ 3.0065e-02, -3.6440e-01, -1.1437e-02, -8.2546e-02,  1.3245e-01,
          1.6578e-01, -3.9233e-01, -3.4773e-01],
        [-5.5237e-02,  2.0155e-01,  1.7793e-02,  2.5795e-02, -9.0850e-02,
         -1.2788e-01,  1.8441e-01,  1.9987e-01],
        [ 2.5058e-02, -4.8002e-02, -7.2789e-03,  4.1113e-05,  2.5235e-02,
          4.0545e-02, -3.4645e-02, -5.0212e-02],
        [ 2.3438e-03,  9.0239e-02,  1.3201e-03,  2.5827e-02, -3.3869e-02,
         -3.4368e-02,  1.0214e-01,  8.2601e-02],
        [-2.1311e-03,  2.5513e-02,  7.7539e-04,  5.7656e-03, -9.1056e-03,
         -1.1529e-02,  2.7517e-02,  2.4383e-02],
        [-5.7341e-03,  1.8790e-02,  1.5048e-03,  2.0734e-03, -7.2864e-03,
         -1.1645e-02,  1.7316e-02,  1.9001e-02],
        [-2.0185e-02,  1.2796e-02,  4.2775e-03, -7.3232e-03, -6.6531e-03,
         -2.0540e-02,  1.3439e-03,  1.7708e-02],
        [ 3.5880e-02, -2.0768e-01, -1.0408e-02, -3.7357e-02,  7.6908e-02,
          1.0761e-01, -2.1022e-01, -2.0272e-01],
        [-1.0632e-03,  3.8768e-02,  4.2412e-04,  1.0060e-02, -1.1119e-02,
         -1.4010e-02,  4.3757e-02,  3.6449e-02],
        [ 1.0738e-02, -7.5000e-02, -4.0475e-03, -1.4632e-02,  3.1836e-02,
          3.9818e-02, -7.5823e-02, -7.2035e-02],
        [-2.7555e-03, -3.5699e-02,  5.7167e-04, -1.1022e-02,  9.7766e-03,
          1.0667e-02, -4.3649e-02, -3.3165e-02],
        [ 2.1747e-02, -1.7572e-02, -6.2664e-03,  6.5353e-03,  1.4671e-02,
          2.6498e-02, -2.1099e-03, -2.0936e-02],
        [-4.9378e-03,  4.4843e-02,  1.8968e-03,  9.5026e-03, -1.7483e-02,
         -2.1994e-02,  4.7075e-02,  4.3003e-02],
        [-2.0927e-02,  1.0983e-01,  7.0796e-03,  1.8620e-02, -4.6213e-02,
         -6.1998e-02,  1.0837e-01,  1.0736e-01],
        [ 4.2841e-03,  4.7438e-02, -6.8949e-04,  1.5003e-02, -1.4299e-02,
         -1.4362e-02,  5.7715e-02,  4.3540e-02],
        [ 7.0074e-02,  3.1452e-02, -1.9548e-02,  4.4953e-02,  1.9115e-02,
          5.3046e-02,  9.3355e-02,  1.4676e-02],
        [-6.2331e-03, -7.8699e-03,  9.5655e-04, -5.4648e-03,  3.5776e-03,
         -9.7183e-04, -1.2167e-02, -5.2155e-03],
        [-3.6681e-02,  1.7102e-01,  1.2795e-02,  2.7421e-02, -7.3867e-02,
         -9.9285e-02,  1.6387e-01,  1.6688e-01],
        [ 3.5576e-02,  1.1597e-04, -1.0024e-02,  1.8473e-02,  1.4452e-02,
          3.2437e-02,  2.9444e-02, -7.2623e-03],
        [-5.0228e-02,  1.4770e-01,  1.4011e-02,  1.3642e-02, -6.3067e-02,
         -9.8433e-02,  1.3038e-01,  1.4987e-01],
        [-3.0845e-02,  1.2901e-01,  1.0039e-02,  1.8946e-02, -5.5481e-02,
         -7.7031e-02,  1.2183e-01,  1.2692e-01],
        [-1.0870e-01,  4.0887e-01,  3.4789e-02,  5.4046e-02, -1.8078e-01,
         -2.5487e-01,  3.7721e-01,  4.0489e-01],
        [ 6.7039e-02, -2.7133e-01, -2.0244e-02, -3.8117e-02,  1.1274e-01,
          1.6233e-01, -2.5782e-01, -2.6929e-01],
        [-6.5035e-02,  3.0308e-01,  2.2299e-02,  4.8368e-02, -1.3146e-01,
         -1.7647e-01,  2.9026e-01,  2.9585e-01],
        [ 4.0448e-02,  5.1900e-02, -1.1181e-02,  3.4928e-02,  3.8963e-04,
          1.7760e-02,  9.3313e-02,  4.0485e-02],
        [-3.5647e-03,  4.8043e-02,  1.5740e-03,  1.1101e-02, -1.7971e-02,
         -2.1905e-02,  5.1808e-02,  4.5675e-02],
        [ 1.6807e-03, -9.3556e-03, -5.5375e-04, -1.6603e-03,  4.4300e-03,
          5.3086e-03, -8.7972e-03, -8.8579e-03],
        [ 1.3826e-01,  3.0610e-01, -3.6413e-02,  1.5489e-01, -4.9563e-02,
          1.0383e-02,  4.5815e-01,  2.5428e-01],
        [ 2.8570e-02, -2.6416e-01, -1.0048e-02, -5.6295e-02,  9.7307e-02,
          1.2566e-01, -2.7966e-01, -2.5387e-01],
        [ 3.1445e-02, -1.3025e-01, -1.0559e-02, -1.8667e-02,  5.8486e-02,
          8.0232e-02, -1.2275e-01, -1.2862e-01],
        [ 2.7451e-02, -5.3813e-02, -7.9967e-03, -2.0182e-04,  2.8488e-02,
          4.5344e-02, -3.9316e-02, -5.6300e-02],
        [ 3.6970e-03, -2.4791e-02, -1.0718e-03, -4.7461e-03,  8.6228e-03,
          1.2229e-02, -2.5865e-02, -2.4225e-02],
        [ 4.2881e-02, -2.0726e-01, -1.3277e-02, -3.3557e-02,  8.3039e-02,
          1.1628e-01, -2.0327e-01, -2.0363e-01],
        [ 2.5161e-03, -7.7151e-03, -8.1404e-04, -7.8900e-04,  3.7922e-03,
          5.3103e-03, -6.5998e-03, -7.6724e-03],
        [ 2.8382e-02,  3.8470e-02, -7.7744e-03,  2.5036e-02, -2.7740e-04,
          1.1603e-02,  6.8029e-02,  3.0506e-02],
        [ 1.5847e-02, -2.0100e-01, -6.3502e-03, -4.5975e-02,  7.4085e-02,
          9.1345e-02, -2.1613e-01, -1.9125e-01],
        [ 1.9221e-02,  2.1002e-02, -5.1939e-03,  1.5603e-02,  9.3901e-04,
          9.4817e-03,  4.0099e-02,  1.5814e-02],
        [ 2.6122e-02, -2.6483e-01, -1.0208e-02, -5.7665e-02,  1.0109e-01,
          1.2670e-01, -2.8108e-01, -2.5359e-01],
        [ 5.9249e-02, -2.6977e-02, -1.6605e-02,  2.3618e-02,  3.2601e-02,
          6.4429e-02,  1.7232e-02, -3.7960e-02],
        [ 4.1559e-03, -1.2762e-02, -1.0067e-03, -1.2755e-03,  4.5316e-03,
          7.8344e-03, -1.1750e-02, -1.3034e-02],
        [ 6.1902e-02, -2.9855e-01, -1.7762e-02, -4.8325e-02,  1.1252e-01,
          1.6302e-01, -2.9499e-01, -2.9410e-01],
        [-2.5742e-02,  4.6599e-02,  5.8263e-03, -1.0371e-03, -1.8817e-02,
         -3.7434e-02,  3.5575e-02,  5.0467e-02],
        [-1.2360e-03, -7.5857e-05,  4.2627e-04, -6.8365e-04, -1.0636e-03,
         -1.5031e-03, -1.2575e-03,  1.5185e-04],
        [ 2.5930e-02, -1.7212e-01, -9.2005e-03, -3.2867e-02,  6.9889e-02,
          9.0645e-02, -1.7481e-01, -1.6641e-01],
        [-9.3589e-04, -2.2238e-03,  3.4801e-04, -1.1100e-03, -2.1670e-04,
         -4.2105e-04, -3.4450e-03, -1.9027e-03],
        [-7.0384e-02,  2.2243e-01,  2.1452e-02,  2.3402e-02, -9.9976e-02,
         -1.4772e-01,  1.9799e-01,  2.2357e-01],
        [-9.5846e-03,  2.6263e-02,  2.9120e-03,  2.0888e-03, -1.2524e-02,
         -1.8748e-02,  2.2267e-02,  2.6656e-02],
        [-3.4385e-03,  1.5565e-02,  9.5272e-04,  2.4114e-03, -5.9459e-03,
         -8.6647e-03,  1.5169e-02,  1.5356e-02],
        [ 4.6946e-02, -4.3787e-01, -1.7069e-02, -9.3686e-02,  1.6305e-01,
          2.0871e-01, -4.6269e-01, -4.2008e-01],
        [ 1.3144e-02, -1.2311e-01, -4.8091e-03, -2.6325e-02,  4.6612e-02,
          5.9146e-02, -1.2987e-01, -1.1803e-01],
        [-8.1346e-02,  3.0464e-01,  2.7871e-02,  4.0099e-02, -1.4266e-01,
         -1.9545e-01,  2.7870e-01,  3.0113e-01],
        [ 7.0075e-03, -5.2352e-02, -1.3856e-03, -1.0483e-02,  1.5698e-02,
          2.3429e-02, -5.5678e-02, -5.0965e-02],
        [-1.8400e-04, -3.0596e-02, -2.0281e-03, -8.5100e-03,  1.7234e-02,
          1.5520e-02, -3.2006e-02, -2.7345e-02],
        [ 2.9778e-03, -4.0290e-03, -8.6854e-04,  4.5981e-04,  2.5506e-03,
          4.2486e-03, -2.1474e-03, -4.3872e-03],
        [ 6.1491e-02,  7.1780e-02, -1.6721e-02,  5.1101e-02,  2.1336e-03,
          2.8819e-02,  1.3384e-01,  5.5153e-02],
        [ 1.3955e-02, -1.9291e-01, -5.3676e-03, -4.4655e-02,  6.8890e-02,
          8.5873e-02, -2.0969e-01, -1.8389e-01],
        [ 1.7633e-02, -1.8358e-01, -7.2351e-03, -4.0337e-02,  7.1450e-02,
          8.7868e-02, -1.9406e-01, -1.7501e-01],
        [ 1.0983e-02, -9.3330e-02, -5.4869e-03, -1.9682e-02,  4.1317e-02,
          4.8617e-02, -9.4761e-02, -8.8410e-02],
        [-6.8228e-03,  1.0569e-02,  1.9722e-03, -7.2544e-04, -6.1675e-03,
         -1.0278e-02,  6.6534e-03,  1.1425e-02],
        [-8.0449e-03, -2.1643e-01, -6.2470e-04, -6.2437e-02,  7.2515e-02,
          7.7780e-02, -2.5306e-01, -2.0085e-01],
        [ 5.0884e-03, -8.4759e-02, -2.7707e-03, -2.0100e-02,  3.3010e-02,
          3.8957e-02, -9.2191e-02, -8.0392e-02],
        [-2.6186e-03, -2.7252e-03,  6.1869e-04, -2.1075e-03,  1.3357e-04,
         -1.1970e-03, -5.1270e-03, -1.9471e-03],
        [ 8.3090e-02, -3.3322e-01, -3.0294e-02, -4.6898e-02,  1.5790e-01,
          2.1118e-01, -3.0819e-01, -3.2776e-01],
        [ 1.5267e-02, -1.8146e-01, -6.2673e-03, -4.0913e-02,  6.7573e-02,
          8.4042e-02, -1.9499e-01, -1.7332e-01],
        [ 6.3982e-03, -4.3413e-01, -5.9226e-03, -1.1371e-01,  1.4738e-01,
          1.7143e-01, -4.9078e-01, -4.0779e-01],
        [-5.7964e-02,  1.9998e-01,  1.8077e-02,  2.3908e-02, -8.8460e-02,
         -1.2823e-01,  1.8192e-01,  1.9963e-01],
        [ 5.1380e-02,  3.9414e-02, -1.4270e-02,  3.7202e-02,  8.6293e-03,
          3.2182e-02,  8.7976e-02,  2.6576e-02],
        [-3.7992e-02, -6.3741e-02,  1.0264e-02, -3.6829e-02,  3.9047e-03,
         -1.1158e-02, -1.0533e-01, -5.2406e-02],
        [ 2.7829e-02,  3.4859e-02, -7.5125e-03,  2.3793e-02, -1.5950e-05,
          1.2105e-02,  6.3128e-02,  2.7074e-02],
        [ 2.2841e-02, -9.8532e-02, -7.0136e-03, -1.4697e-02,  4.0773e-02,
          5.7577e-02, -9.4252e-02, -9.7167e-02],
        [-8.6948e-03,  4.9076e-02,  2.9438e-03,  8.6898e-03, -2.0093e-02,
         -2.6871e-02,  4.9004e-02,  4.7823e-02],
        [ 4.8107e-02,  6.9260e-02, -1.2012e-02,  4.3794e-02, -6.6197e-03,
          1.5988e-02,  1.1699e-01,  5.4091e-02],
        [ 8.2566e-03, -1.0015e-01, -3.0483e-03, -2.2656e-02,  3.6102e-02,
          4.5441e-02, -1.0803e-01, -9.5678e-02],
        [ 3.8556e-02, -1.8069e-01, -1.1837e-02, -2.8647e-02,  7.2813e-02,
          1.0237e-01, -1.7615e-01, -1.7775e-01],
        [ 4.0460e-03, -2.2023e-02, -1.4185e-03, -3.7523e-03,  9.4023e-03,
          1.2634e-02, -2.2125e-02, -2.1680e-02],
        [ 5.2353e-02,  6.8825e-02, -1.4274e-02,  4.5592e-02,  2.7587e-04,
          2.2142e-02,  1.2329e-01,  5.4391e-02],
        [ 4.5869e-02, -1.6534e-02, -1.3192e-02,  1.9535e-02,  2.5431e-02,
          4.9539e-02,  1.8461e-02, -2.5400e-02],
        [-1.1692e-03,  2.2250e-02,  5.5281e-04,  5.3803e-03, -8.0969e-03,
         -9.6914e-03,  2.4395e-02,  2.1064e-02],
        [ 5.0764e-02,  6.6584e-02, -1.3899e-02,  4.4183e-02, -4.5760e-04,
          2.1322e-02,  1.1870e-01,  5.2240e-02],
        [ 5.1852e-02, -3.3888e-01, -1.7653e-02, -6.4309e-02,  1.3349e-01,
          1.7670e-01, -3.4548e-01, -3.2860e-01],
        [ 9.5397e-02,  1.7944e-01, -2.5826e-02,  9.7643e-02, -1.7638e-02,
          1.9960e-02,  2.8596e-01,  1.4939e-01],
        [ 6.3145e-02, -2.5519e-01, -1.7419e-02, -3.5875e-02,  9.9790e-02,
          1.4842e-01, -2.4398e-01, -2.5366e-01],
        [-2.9376e-02,  9.7340e-02,  8.5706e-03,  1.1017e-02, -4.1005e-02,
         -6.1873e-02,  8.8403e-02,  9.7690e-02],
        [-7.1376e-02,  4.5196e-01,  2.4028e-02,  8.5263e-02, -1.7856e-01,
         -2.3529e-01,  4.5631e-01,  4.3664e-01],
        [ 2.5134e-03,  1.8648e-03, -7.4109e-04,  1.8199e-03,  5.6159e-04,
          1.7423e-03,  4.1755e-03,  1.1874e-03],
        [ 8.0388e-02, -2.6143e-01, -2.3043e-02, -2.8754e-02,  1.1069e-01,
          1.6749e-01, -2.3607e-01, -2.6269e-01],
        [ 6.5618e-02,  6.6423e-02, -1.7872e-02,  5.1852e-02,  5.2629e-03,
          3.4587e-02,  1.3089e-01,  4.9067e-02],
        [ 7.0169e-02,  1.1246e-01, -1.8986e-02,  6.6646e-02, -6.5647e-03,
          2.2172e-02,  1.8790e-01,  9.1474e-02],
        [-3.8718e-03,  2.5987e-02,  1.4760e-03,  4.9950e-03, -1.0971e-02,
         -1.3891e-02,  2.6223e-02,  2.5037e-02],
        [-8.5527e-02,  3.0066e-01,  2.8829e-02,  3.6749e-02, -1.4211e-01,
         -1.9760e-01,  2.7169e-01,  2.9880e-01],
        [ 8.3953e-02,  1.3923e-01, -2.2814e-02,  8.0942e-02, -9.0898e-03,
          2.4836e-02,  2.3047e-01,  1.1397e-01],
        [-3.6585e-03, -3.2725e-02,  8.6395e-04, -1.0642e-02,  8.9923e-03,
          9.1115e-03, -4.0928e-02, -3.0161e-02],
        [-2.7960e-03,  1.5180e-02,  7.4576e-04,  2.6166e-03, -5.4152e-03,
         -7.9260e-03,  1.5428e-02,  1.4958e-02],
        [-6.9429e-03,  3.4080e-02,  2.2257e-03,  5.5545e-03, -1.4118e-02,
         -1.9363e-02,  3.3353e-02,  3.3426e-02],
        [ 8.3900e-02,  1.6879e-01, -2.1942e-02,  8.9753e-02, -2.6266e-02,
          1.2720e-02,  2.5630e-01,  1.3714e-01],
        [-1.7572e-02,  5.3588e-02,  5.0308e-03,  5.3908e-03, -2.2458e-02,
         -3.4813e-02,  4.7628e-02,  5.4056e-02]], device='cuda:0') 

model.module_8.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.2623, -0.1176,  0.2625,  0.1061,  0.0152,  0.3376,  0.2459,  0.1738,
        -0.1658, -0.0853, -0.0630, -0.0803,  0.1240,  0.2119, -0.2048, -0.3309,
        -0.3055,  0.1300, -0.2227,  0.1840,  0.0669,  0.1289, -0.1565,  0.1683,
         0.2491,  0.1480,  0.0165,  0.1890,  0.0289,  0.1179,  0.1278,  0.3721,
        -0.0636,  0.1641,  0.2500, -0.3128, -0.0329, -0.2781, -0.2447,  0.2172,
        -0.2520,  0.3268,  0.3071, -0.2220, -0.3047, -0.0433, -0.3067,  0.1753,
        -0.0909,  0.1184,  0.0254,  0.0080, -0.1773,  0.0716,  0.1489, -0.0061,
        -0.0395, -0.0550, -0.1674,  0.0954,  0.1330, -0.1576, -0.1411,  0.2852,
         0.2122, -0.3022, -0.2075, -0.0385, -0.1402,  0.0632, -0.1260, -0.3491,
        -0.2473,  0.1754,  0.0659,  0.3241,  0.2746, -0.0548,  0.1809, -0.0245,
         0.1735, -0.2657, -0.0925,  0.0047,  0.0686,  0.1037,  0.3028,  0.3128,
        -0.1364, -0.0645, -0.0147,  0.1706, -0.2281,  0.1767,  0.1212,  0.1831,
        -0.0878,  0.0733,  0.2203,  0.2750], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 1.1862e-02, -7.3685e-01, -1.5704e-01,  3.5774e-01, -6.6646e-01,
         3.8670e-01, -9.9263e-02,  1.4317e-01,  4.5840e-02,  3.3994e-02,
         5.0521e-02, -3.6976e-01,  3.9166e-02, -1.5487e-01, -5.6935e-02,
        -4.4997e-02,  8.6620e-02,  2.2316e-01,  8.0680e-02, -1.6682e-02,
        -1.2369e-02,  2.9249e-01, -2.3891e-02,  2.8425e-01,  2.3036e-01,
         7.6668e-01, -5.2952e-01,  5.5012e-01,  6.3236e-02,  8.8112e-02,
        -2.3015e-02,  4.2520e-01, -4.7987e-01, -2.7029e-01, -1.1980e-01,
        -4.2645e-02, -3.8703e-01, -1.4857e-02,  4.6973e-02, -3.6697e-01,
         2.4922e-02, -5.0760e-01, -1.0762e-01, -2.0495e-02, -5.2067e-01,
         1.0504e-01,  6.2919e-03, -3.3770e-01,  1.1463e-03,  4.3044e-01,
         5.4135e-02,  2.8118e-02, -7.8564e-01, -2.3154e-01,  5.9941e-01,
        -8.2443e-02, -5.7542e-02, -9.4750e-03,  8.7485e-02, -3.5597e-01,
        -3.4911e-01, -1.6331e-01,  2.6422e-02, -3.9037e-01, -1.7197e-01,
        -1.5959e-03, -6.4743e-01, -3.3624e-01, -7.6154e-01,  3.7480e-01,
         3.5452e-02, -7.7185e-02,  4.3298e-02, -1.8576e-01,  9.5572e-02,
         7.5382e-02, -1.8638e-01, -3.3831e-01, -5.1023e-02,  8.1963e-02,
        -8.8779e-02,  4.2265e-02,  8.5071e-02, -6.3958e-01,  2.5251e-01,
        -4.7921e-01,  1.7381e-01,  8.0020e-01,  1.4063e-04, -4.8543e-01,
         7.4228e-02,  1.4167e-01,  5.1220e-02,  6.0313e-01,  1.8364e-01,
        -6.2008e-02,  2.8256e-02,  6.7713e-02,  2.0325e-01,  8.8521e-02],
       device='cuda:0') 

model.module_10.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[-0.0363,  0.0926, -0.0327,  ...,  0.0065, -0.2072, -0.0547],
        [-0.1157, -0.1012, -0.0170,  ..., -0.0415,  0.3624,  0.0665],
        [-0.0447,  0.0477, -0.0261,  ..., -0.0609,  0.0054, -0.0539],
        ...,
        [-0.0080, -0.0995,  0.0589,  ..., -0.0218, -0.2699, -0.0125],
        [-0.0021, -0.0495,  0.0691,  ...,  0.0120, -0.2894, -0.0359],
        [-0.0877,  0.1178, -0.0934,  ...,  0.0419, -0.1598,  0.0292]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 2.0236e-02, -5.5280e-02, -7.6445e-02,  ...,  3.6520e-03,
         -1.3978e-03, -1.5801e-02],
        [ 6.6665e-03, -1.2584e-03, -2.6964e-02,  ...,  1.3639e-04,
         -3.4565e-03, -9.3464e-03],
        [-5.0239e-03,  1.7032e-02,  1.8657e-02,  ..., -1.0398e-03,
          6.4815e-04,  3.6568e-03],
        ...,
        [ 2.9466e-03, -7.3500e-03, -1.2813e-02,  ..., -8.6746e-05,
         -1.2398e-03, -6.6865e-03],
        [ 1.9800e-02, -4.4128e-02, -7.5013e-02,  ...,  3.3664e-03,
         -3.6308e-04, -1.2953e-02],
        [ 5.0982e-02, -1.1246e-01, -1.9450e-01,  ...,  8.1157e-03,
         -3.5735e-03, -3.8301e-02]], device='cuda:0') 

model.module_10.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.0160,  0.0186, -0.0410,  0.0171, -0.0188,  0.0986,  0.0135,  0.0814,
        -0.0020, -0.0525, -0.0191, -0.0206, -0.0237,  0.0992, -0.0043,  0.0586,
        -0.0924, -0.0386,  0.0505,  0.0707,  0.0020, -0.0325, -0.0160, -0.0153,
        -0.0243,  0.0114, -0.0268, -0.0264, -0.0415, -0.0373, -0.0292,  0.0264,
        -0.0261,  0.0441, -0.0149, -0.0902,  0.0276, -0.0575,  0.1000, -0.0316,
         0.0227, -0.0200, -0.0317, -0.0925, -0.0887,  0.0728, -0.0094, -0.0778,
        -0.0812, -0.0189, -0.0188,  0.0269,  0.0281,  0.0079, -0.0676, -0.0846,
        -0.0136, -0.0315,  0.0183, -0.0924, -0.0424, -0.0549,  0.0331,  0.0830,
        -0.0618, -0.0043, -0.0153,  0.0018,  0.0202,  0.0075, -0.0559, -0.0509,
         0.0928, -0.0186,  0.0701, -0.0788, -0.0010, -0.0624,  0.0730, -0.0760,
         0.0862,  0.0488, -0.0739,  0.0856, -0.0110,  0.0910, -0.0029, -0.0014,
        -0.0333,  0.1040, -0.0478,  0.0366, -0.0250, -0.0790,  0.0510, -0.0848,
        -0.0435, -0.0459,  0.0921,  0.0684], device='cuda:0',
       requires_grad=True) 
grad:  tensor([-2.3909e-01, -7.6562e-02,  6.1730e-02, -8.8055e-02,  3.1905e-02,
         9.5787e-02, -8.0073e-02, -2.3825e-01,  6.3596e-02,  8.9647e-02,
        -4.3545e-01, -3.3495e-02, -3.1917e-01,  2.3476e-01,  9.6999e-02,
        -3.8778e-01, -4.0717e-01, -3.3185e-01, -5.9521e-02, -1.7064e-01,
         1.2342e-01, -9.8610e-02, -1.0534e-02,  7.6220e-02, -3.5674e-01,
        -2.8061e-01, -1.7610e-03,  8.6901e-02, -3.4489e-01, -2.5641e-01,
         1.1255e-01, -1.5150e-01, -2.4746e-01, -1.7612e-01,  6.9719e-02,
         8.5736e-02, -6.1344e-01, -2.8459e-02, -2.8043e-01, -1.2758e-01,
        -1.1608e-01, -2.5159e-01, -1.0190e-02,  8.3206e-02, -4.2172e-01,
        -1.2524e-01, -5.9058e-01,  3.8423e-02, -1.8646e-01, -3.0432e-01,
         2.4468e-02,  1.9637e-01,  1.1929e-01, -5.5431e-02,  3.0719e-02,
        -3.4120e-01,  1.3412e-02, -2.6312e-03, -9.8926e-02,  5.6673e-02,
        -1.1990e-01,  4.1590e-02,  2.9990e-03,  6.6992e-02,  5.6061e-02,
         6.9863e-02, -1.0261e-01,  4.1076e-02, -2.5867e-01, -4.0430e-01,
         1.0015e-01, -4.5252e-02, -7.6638e-02,  1.1434e-01, -4.9989e-01,
        -1.5444e-01,  2.6715e-02,  6.5492e-05,  1.1620e-03,  1.3864e-02,
        -6.8463e-01, -2.4097e-01,  1.8435e-02, -6.1205e-01, -3.7094e-01,
        -6.1082e-02, -5.4914e-03,  2.5300e-02,  2.0361e-02,  2.5629e-01,
        -3.5620e-01,  4.6399e-02, -2.5615e-01, -5.6406e-02, -1.1365e-01,
         1.0041e-01, -3.5251e-03, -4.3073e-02, -2.2308e-01, -5.8360e-01],
       device='cuda:0') 

model.module_12.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[-0.0107, -0.0740,  0.0420,  ..., -0.1327,  0.0456,  0.0742],
        [ 0.0745,  0.0019, -0.1140,  ..., -0.0128,  0.1023, -0.0277],
        [ 0.0335,  0.1718, -0.0479,  ..., -0.0870, -0.0989, -0.0740],
        ...,
        [-0.0315,  0.1588, -0.0191,  ...,  0.1616, -0.0602, -0.1005],
        [ 0.0327,  0.0977, -0.1029,  ..., -0.0634,  0.0473,  0.0397],
        [ 0.0924,  0.0539, -0.0718,  ...,  0.0148, -0.0265, -0.1007]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-0.2483, -0.1474,  0.1322,  ..., -0.0958, -0.1846, -0.4991],
        [ 0.0885,  0.0851, -0.0519,  ...,  0.0995,  0.0592,  0.1328],
        [-0.0654, -0.1060,  0.0449,  ..., -0.0683, -0.0465, -0.1307],
        ...,
        [-0.0150, -0.0259,  0.0105,  ..., -0.0240, -0.0085, -0.0186],
        [-0.0463, -0.0495,  0.0279,  ..., -0.0177, -0.0370, -0.1123],
        [ 0.0200,  0.0216, -0.0119,  ...,  0.0328,  0.0113,  0.0161]],
       device='cuda:0') 

model.module_12.bias 16 torch.Size([16])
Parameter containing:
tensor([ 0.0474, -0.0436,  0.1123,  0.0971, -0.0577,  0.0540,  0.0145, -0.0558,
        -0.0378, -0.0355,  0.0145, -0.0014, -0.0460, -0.0451,  0.0923, -0.0758],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-1.5148,  0.5951, -0.5575, -1.2149, -1.6409, -0.5287, -1.8537, -0.2434,
        -0.8075, -0.3821, -0.4298, -2.4162,  0.0497, -0.1242, -0.3452,  0.1316],
       device='cuda:0') 

model.module_14.bias 8 torch.Size([8])
Parameter containing:
tensor([ 1.1060e-02, -2.6890e-02, -5.0344e-02, -3.2702e-02,  2.2268e-02,
        -2.5616e-02,  9.1751e-03,  8.1019e-05], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 0.7593, -2.3509, -0.3045, -0.0520,  1.8270, -2.8627,  0.5756,  2.1810],
       device='cuda:0') 

model.module_14.lin.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[ 0.0354,  0.1967, -0.2196, -0.0262, -0.2749,  0.0163, -0.1111,  0.2046,
          0.4908,  0.3625,  0.0265, -0.4673,  0.4802, -0.1665, -0.1234,  0.2651],
        [ 0.1447,  0.2167, -0.1387,  0.3130,  0.0644, -0.3534,  0.3672, -0.1834,
          0.3997,  0.2377,  0.1882,  0.1520,  0.1514,  0.4762,  0.0745,  0.2905],
        [-0.1649,  0.1928,  0.1615, -0.1896,  0.2804,  0.3497,  0.3049,  0.4347,
         -0.4547, -0.1657,  0.3058, -0.0916, -0.1303,  0.4569,  0.4072,  0.2653],
        [-0.0890,  0.4077, -0.4417,  0.3944,  0.2127,  0.2095,  0.0061,  0.0719,
          0.3980,  0.0666, -0.3139,  0.1744,  0.0127, -0.1680, -0.1391,  0.3312],
        [-0.1082, -0.4226, -0.1952, -0.3993, -0.3401, -0.1448,  0.0194,  0.2525,
         -0.0347,  0.3723, -0.4429, -0.2569, -0.1863,  0.3263, -0.0509, -0.0915],
        [ 0.4403, -0.4170,  0.0842,  0.2438,  0.2402,  0.3832,  0.3435,  0.5131,
          0.3950,  0.0278,  0.0389,  0.2518, -0.2012, -0.4537,  0.0553, -0.1513],
        [-0.4427,  0.0845,  0.1689,  0.4578, -0.1977,  0.0643, -0.4420, -0.2427,
          0.1510, -0.3536,  0.0057, -0.4373,  0.1759,  0.1886, -0.2097,  0.4703],
        [-0.4941,  0.2358, -0.4502,  0.1236, -0.1030, -0.0146,  0.0339, -0.4655,
          0.3109, -0.4653,  0.2067, -0.3567, -0.0336, -0.5535,  0.1243,  0.3740]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 3.3962e-01,  3.6608e-03,  2.7014e-01,  1.6776e-01,  1.3939e-01,
          1.8126e-01,  2.3741e-01,  1.0413e-01,  2.0197e-01,  1.7056e-01,
         -1.3427e-02,  3.2692e-01, -6.1688e-02,  2.9216e-02,  9.5531e-02,
         -3.6432e-02],
        [-5.6762e-01, -2.1211e-01, -5.4069e-01, -7.7716e-01, -5.8341e-01,
         -6.8392e-01, -7.2669e-01, -8.3707e-02, -5.1539e-01, -2.8788e-01,
         -1.4480e-02, -8.9368e-01,  1.5121e-01, -2.6407e-01, -4.3047e-01,
          7.3126e-02],
        [-2.5972e-01,  4.0871e-02, -1.6726e-01, -1.5592e-02, -2.9843e-02,
         -5.4913e-02, -1.0975e-01, -9.5316e-02, -1.2134e-01, -1.2943e-01,
          1.8031e-02, -1.7379e-01,  3.5308e-02,  5.4451e-02, -8.2619e-03,
          2.4300e-02],
        [-3.9645e-01,  7.9127e-02, -2.9943e-01,  1.6378e-02, -1.2320e-02,
         -4.9970e-02, -1.3644e-01, -1.6204e-01, -1.4772e-01, -2.0375e-01,
          2.3866e-02, -2.3509e-01,  5.2914e-02,  4.9437e-02, -4.0041e-04,
          3.7212e-02],
        [ 9.5828e-01,  2.0595e-02,  7.8067e-01,  4.8702e-01,  4.0312e-01,
          5.2369e-01,  6.7977e-01,  2.9168e-01,  5.6525e-01,  4.8634e-01,
         -2.9574e-02,  9.3409e-01, -1.7642e-01,  9.1535e-02,  2.8051e-01,
         -1.0280e-01],
        [-3.6341e-01, -3.6900e-01, -4.3015e-01, -1.0576e+00, -7.6854e-01,
         -8.6732e-01, -8.3790e-01,  4.8877e-02, -5.3675e-01, -1.8496e-01,
         -4.8405e-02, -9.6291e-01,  1.5020e-01, -3.9594e-01, -5.7744e-01,
          6.0368e-02],
        [ 2.8908e-02,  1.0697e-01,  8.1582e-02,  2.6791e-01,  1.8655e-01,
          2.0750e-01,  1.8578e-01, -3.0518e-02,  9.9773e-02,  1.5598e-02,
          1.9795e-02,  2.0087e-01, -3.0437e-02,  1.3220e-01,  1.4871e-01,
         -9.6103e-03],
        [-1.1211e-02,  3.1306e-01,  9.1098e-02,  7.6377e-01,  5.4089e-01,
          5.8363e-01,  5.0447e-01, -1.4885e-01,  2.8928e-01, -8.7869e-03,
          4.6307e-02,  5.2673e-01, -7.0239e-02,  3.0745e-01,  4.0839e-01,
         -1.7742e-02]], device='cuda:0') 

model.module_15.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[-3.9865e-01,  1.8577e-01,  1.4660e-01, -5.4964e-03, -2.1473e-01,
         -2.8280e-01,  2.4507e-01, -3.7294e-01],
        [ 2.7153e-01, -7.4350e-02,  1.4538e-01,  1.8509e-01, -1.0870e-01,
         -1.5802e-01, -2.4310e-01,  2.7241e-01],
        [-3.2453e-01,  3.3967e-01, -1.1594e-01,  2.3152e-01, -2.9448e-01,
         -1.5667e-02, -1.7187e-01, -2.0024e-01],
        [ 1.6451e-01,  2.2566e-01, -2.6965e-01,  1.9876e-01, -3.0397e-01,
          1.7844e-01,  1.5127e-01,  2.3320e-01],
        [ 3.1453e-01,  6.8213e-02,  3.2640e-01,  2.9103e-02,  3.6648e-01,
          5.4040e-02,  9.0588e-02, -2.3598e-01],
        [-4.1149e-02,  8.8231e-02, -1.4009e-01,  1.3596e-01,  1.1246e-01,
         -1.6429e-01, -2.1033e-01,  1.3234e-01],
        [-2.6906e-01,  1.4349e-01, -1.9260e-01, -2.7949e-01, -2.4672e-02,
         -3.8196e-02,  1.1605e-01,  3.5796e-02],
        [-2.9524e-01, -9.1871e-03, -2.3114e-01,  7.8576e-02,  2.7955e-01,
         -1.4257e-01, -2.1333e-01, -1.0489e-01],
        [-9.4439e-02,  3.4160e-02,  3.2279e-02,  1.1639e-01, -1.3331e-01,
         -1.1488e-01,  2.4730e-01,  1.1542e-01],
        [-2.0161e-02, -1.0229e-01,  4.4141e-01,  3.9755e-01, -2.4892e-01,
         -2.9885e-01,  1.3303e-01, -2.5446e-01],
        [ 1.3593e-01, -1.2324e-01,  3.1115e-01, -1.8505e-01,  1.0077e-01,
         -3.1472e-02, -2.1937e-01,  7.1694e-02],
        [ 2.4685e-01, -3.0476e-01, -4.7933e-03,  2.5616e-01,  9.7262e-02,
         -3.1936e-01, -5.7780e-02,  3.0751e-01],
        [ 1.1568e-01, -3.4480e-01, -1.0054e-01, -2.1157e-01, -1.5228e-01,
          2.2294e-02,  2.8090e-01,  1.3207e-01],
        [-2.2157e-01,  1.9997e-01, -1.7394e-01,  9.8668e-02, -3.0862e-01,
          4.6705e-02, -1.5001e-01,  3.1796e-01],
        [-2.2730e-01, -2.1014e-01,  1.2793e-01, -2.0574e-01,  1.7522e-01,
          3.1512e-01, -2.9999e-01, -3.6536e-01],
        [-8.6008e-03,  6.1227e-02,  1.9238e-01,  1.7417e-01, -2.8464e-01,
          3.0798e-01, -9.3752e-02,  2.1744e-01],
        [-1.9685e-01,  1.0271e-01,  2.3223e-01,  2.6614e-01, -2.6887e-01,
         -2.0958e-01,  2.5429e-02,  1.2805e-01],
        [ 2.8936e-01, -2.6757e-02,  3.2361e-01, -1.8628e-01,  1.7524e-01,
          2.0548e-01,  2.5800e-01, -1.9389e-01],
        [ 8.0513e-02,  7.7613e-02, -1.4649e-01,  3.7838e-02,  2.9577e-01,
          4.0743e-02, -8.4142e-02, -3.1993e-01],
        [-2.3149e-01, -1.8443e-01, -2.7185e-01,  1.7771e-01,  1.2670e-01,
          9.9701e-02, -3.1526e-01,  1.1115e-01],
        [-4.4222e-03, -2.2959e-01, -2.8187e-01,  1.4765e-01, -2.5940e-02,
         -2.0552e-01, -1.0679e-01,  2.0723e-01],
        [ 2.2417e-01, -1.6382e-01, -2.9853e-01,  1.0425e-01, -1.5811e-01,
         -1.4343e-01, -2.8441e-02, -2.3808e-01],
        [-2.8136e-01, -1.6104e-01,  2.7843e-01,  1.0113e-01, -1.6440e-01,
          3.5555e-01, -1.7426e-01, -1.7792e-01],
        [ 3.0283e-01, -2.7785e-01, -2.7395e-01,  2.6938e-01, -8.2354e-02,
          2.4329e-01,  2.7011e-01, -2.6214e-01],
        [-1.2192e-01,  3.7534e-01, -2.2072e-01, -2.2260e-01,  2.6702e-01,
         -2.6966e-01,  2.9998e-02, -1.6948e-01],
        [-3.7587e-01, -2.3075e-01,  2.0691e-01,  1.4891e-01, -6.6742e-02,
         -2.4252e-01,  9.8825e-02, -7.1767e-02],
        [ 1.6993e-01, -1.2124e-01, -1.0836e-01,  2.5735e-01, -1.2395e-01,
         -2.2596e-01,  1.8309e-01,  1.8998e-01],
        [ 9.9959e-03, -1.6247e-01, -2.2101e-01,  3.3204e-02,  7.4295e-02,
         -2.4372e-01,  1.7993e-01, -8.6952e-02],
        [ 1.8024e-01,  2.6154e-01,  2.9905e-01,  3.3705e-01,  7.6501e-03,
          2.0611e-01,  2.2225e-01,  1.1817e-01],
        [-1.9668e-01, -4.2803e-02, -3.4061e-01,  5.3907e-02,  1.4952e-01,
         -1.3556e-01,  9.2560e-02,  1.9183e-01],
        [-3.5487e-01,  3.0190e-01, -2.7502e-01, -6.5512e-02, -2.0341e-01,
         -2.3388e-01,  3.8348e-02, -8.5931e-02],
        [-2.2024e-01, -5.3925e-02,  1.6976e-01,  2.2997e-01, -1.6589e-01,
          2.3481e-01, -2.9744e-01, -3.5174e-01],
        [ 3.5795e-01, -3.3020e-01,  2.5033e-01,  3.5419e-01,  1.2816e-01,
         -1.1398e-01, -1.2630e-01, -1.9822e-01],
        [ 3.6174e-02,  1.7097e-01, -2.0305e-01, -1.4192e-01,  8.5748e-02,
          2.0917e-01, -7.2422e-03, -4.5193e-02],
        [-3.6286e-01, -5.7253e-02,  1.9818e-01,  1.5858e-01, -1.1811e-01,
         -1.3662e-01, -2.0980e-02, -1.0820e-01],
        [ 1.3559e-01, -1.5783e-01,  8.5557e-02,  3.3110e-01,  1.1749e-01,
         -1.4284e-01, -1.7918e-01, -4.2096e-02],
        [ 4.6427e-02,  2.3461e-01, -3.0472e-01, -3.5079e-01,  2.4146e-01,
         -2.0953e-01, -2.3306e-01,  1.3424e-01],
        [-2.9812e-01,  1.9741e-01, -1.7608e-01,  3.1415e-01, -3.4326e-01,
         -3.1258e-01, -1.7594e-01,  2.9192e-01],
        [-3.5861e-01, -1.9245e-01,  3.7488e-01,  2.9782e-01, -4.1451e-04,
         -2.8913e-01,  2.9256e-01,  1.8128e-01],
        [ 3.1436e-01,  1.6789e-02, -3.1754e-01, -3.4723e-01, -2.2484e-01,
          3.1471e-01,  9.3369e-02,  3.0752e-01],
        [-1.4743e-01,  2.7732e-01,  7.6495e-02,  2.4005e-01,  2.2129e-01,
         -2.4990e-01,  3.7173e-01, -6.3884e-02],
        [ 2.8395e-01, -1.3446e-02, -2.5441e-01,  2.5850e-01,  1.6928e-01,
          2.8597e-02, -2.4869e-01,  1.7991e-01],
        [ 1.3932e-01, -7.9775e-02,  1.4252e-01, -1.1451e-01,  1.5831e-01,
         -2.1614e-01,  9.1681e-02, -3.0897e-01],
        [ 7.8608e-02,  1.8121e-01,  1.6600e-01,  1.7769e-01,  3.0518e-01,
         -3.2596e-01, -1.3788e-01, -9.1577e-02],
        [ 3.2974e-01,  1.2138e-01, -9.2357e-02,  2.6391e-01,  2.8616e-02,
         -3.3206e-01,  5.9342e-02, -7.4643e-02],
        [-1.8372e-01, -1.2169e-02,  1.4047e-01, -3.9033e-01,  4.3244e-01,
         -1.4276e-02,  1.2053e-02, -3.6048e-01],
        [ 1.1508e-03,  1.0018e-01, -3.0307e-01, -2.2067e-01,  7.3617e-02,
         -1.2287e-02,  3.3713e-01,  1.2487e-01],
        [ 2.5006e-02, -1.4592e-01, -8.9969e-02,  2.3453e-01, -3.5205e-01,
          6.9229e-02,  2.1358e-01, -1.4717e-01],
        [-2.7502e-01, -3.4946e-01, -2.1522e-01,  1.6368e-02,  2.8724e-01,
          2.4079e-01,  7.2444e-02, -1.1798e-01],
        [ 1.1516e-01,  1.6373e-02, -8.6066e-02,  1.1902e-01,  3.3083e-02,
          2.5944e-01,  1.4135e-01,  2.6735e-01],
        [ 1.1427e-01, -8.9445e-02, -3.5954e-01, -1.9523e-01, -2.3585e-01,
          1.7365e-01, -2.1155e-01,  2.8967e-01],
        [-1.4756e-01, -2.6716e-01, -1.4904e-01, -1.7266e-01, -1.8741e-01,
         -1.5053e-01,  1.8233e-01, -1.8597e-01],
        [-1.1288e-01,  3.0342e-01, -1.0131e-01, -3.8465e-02,  2.2320e-01,
          2.7930e-01,  5.1455e-02,  4.0207e-01],
        [ 5.7276e-02, -2.7296e-01,  2.0930e-01, -9.6021e-02, -1.9963e-01,
         -2.7514e-01,  3.7641e-01,  2.4907e-01],
        [ 3.8943e-03, -1.4941e-01, -2.6997e-01,  2.8452e-01,  2.6102e-01,
          7.2302e-02, -1.4394e-01,  5.7067e-02],
        [ 3.4830e-02,  5.8121e-02, -7.7661e-02, -1.3280e-01,  8.3029e-02,
          2.0413e-01, -2.5815e-01, -2.6770e-02],
        [-4.4533e-02, -1.1201e-01,  1.3019e-01, -6.7802e-02,  5.9036e-02,
          3.5660e-01, -2.8659e-01,  2.9941e-01],
        [ 6.5055e-02, -4.3333e-02,  1.1762e-01, -1.5877e-01,  2.1177e-01,
         -8.6085e-02, -5.9531e-02, -2.4383e-01],
        [ 3.8187e-01,  2.1915e-01, -3.2483e-01,  3.2234e-01, -2.3488e-03,
         -1.5938e-01, -1.8565e-01,  2.7169e-01],
        [ 4.8950e-02,  1.0711e-01,  1.2728e-01, -1.3124e-01, -5.3003e-02,
         -1.0681e-01,  1.2551e-01,  2.5513e-01],
        [-2.7833e-02, -4.3455e-01,  1.9669e-01, -1.2541e-01, -1.2598e-01,
         -1.4434e-01,  7.5369e-02, -2.8247e-01],
        [-1.5173e-01,  2.8032e-01, -7.4225e-02,  2.5520e-01, -1.6582e-01,
         -6.4531e-02, -2.3117e-01,  1.6529e-01],
        [-2.8148e-01,  3.3595e-02, -2.5124e-01, -5.6531e-02, -1.3512e-01,
          2.1019e-01, -7.0824e-02,  6.5270e-02],
        [-2.2844e-01, -1.9727e-01,  7.0860e-02,  5.0497e-02, -1.1901e-01,
         -2.1948e-01, -2.1397e-02,  8.0430e-02],
        [ 8.2483e-02,  1.2271e-01, -2.4112e-01,  2.1430e-01, -8.9619e-02,
         -1.0268e-01, -1.2450e-01, -9.6159e-02],
        [ 5.0298e-01, -2.5340e-01, -4.5591e-01,  1.4305e-01, -3.0953e-01,
          3.0915e-01,  1.6568e-01,  3.9023e-01],
        [-9.0994e-02,  2.6246e-01,  1.0230e-01,  1.9952e-01,  2.9651e-02,
         -1.7654e-01,  3.8825e-01, -1.8828e-01],
        [ 3.1269e-02,  1.5786e-01,  1.8944e-01,  6.3354e-02, -9.9033e-02,
          9.4021e-02, -1.3839e-01, -1.8402e-01],
        [ 8.3416e-04,  4.4562e-02, -3.3171e-01, -2.0390e-01, -1.2464e-01,
         -1.7662e-02,  3.1091e-01, -2.8719e-01],
        [-2.0801e-01,  3.4980e-01,  7.2756e-02, -1.5614e-01,  1.6907e-02,
         -1.8394e-01,  2.5318e-02, -1.8373e-01],
        [-2.4334e-03,  6.7556e-02,  3.7913e-01,  1.9722e-01,  2.3326e-02,
          2.9244e-01,  3.3963e-01, -2.0366e-01],
        [-2.5298e-01, -2.5629e-02, -1.5521e-01,  1.0857e-01,  3.1009e-01,
          3.1168e-02, -8.9968e-03,  1.8314e-01],
        [-2.8129e-01,  2.0813e-01, -1.0281e-01, -2.3144e-01, -6.9246e-02,
          3.5826e-01, -1.5868e-01, -2.8859e-01],
        [ 2.6622e-01, -4.1098e-02, -1.1683e-01,  2.1926e-01,  1.8098e-01,
          1.0446e-01,  3.4822e-01, -3.3370e-01],
        [-9.0918e-02,  2.1945e-01, -2.9771e-01, -4.5414e-02,  1.4538e-01,
          1.4034e-02,  8.0874e-02, -1.8891e-01],
        [ 1.1102e-01, -2.2695e-01,  3.5332e-02, -1.0891e-02,  2.5089e-01,
         -3.0583e-01, -2.7975e-01,  4.5159e-01],
        [ 3.5507e-01, -4.8088e-03,  2.2557e-01, -5.5639e-02,  3.3079e-01,
         -1.7708e-01, -1.9222e-01,  9.9145e-03],
        [-1.9613e-01,  2.5763e-01, -5.9259e-02,  2.6879e-01, -3.3368e-01,
         -1.5773e-01, -2.2346e-01,  5.7103e-02],
        [ 3.9659e-01,  1.3444e-01, -2.9368e-01, -3.3598e-01,  2.1068e-01,
          1.9047e-01,  2.6153e-01, -2.8713e-01],
        [-2.5032e-01,  3.0391e-01,  3.1313e-01,  2.5812e-02, -3.6478e-01,
          3.4416e-01,  1.8013e-01, -1.3217e-01],
        [-4.5553e-02, -4.0199e-02,  2.4033e-01, -1.5852e-02,  2.8904e-01,
          1.6500e-01, -1.8558e-01, -3.8633e-01],
        [ 2.2377e-01, -2.0797e-01,  1.3106e-01,  2.1059e-01, -9.4945e-02,
         -2.3986e-01,  3.8308e-01, -7.1198e-02],
        [ 2.8439e-01,  3.0806e-01,  3.4907e-01,  3.4973e-01, -6.8757e-02,
          2.8619e-01, -3.2790e-01,  5.7272e-03],
        [-2.5154e-01, -2.7639e-01,  1.8624e-01, -1.9563e-01, -6.8520e-02,
         -3.3948e-01, -1.6971e-01,  1.4502e-01],
        [ 3.1442e-01,  8.7098e-02, -2.7047e-02, -1.9249e-01, -2.2335e-01,
         -1.9825e-01,  2.6510e-01, -1.5562e-01],
        [ 1.1860e-01,  1.7535e-01, -1.9850e-01, -1.5771e-01, -1.2464e-01,
         -2.0675e-01,  3.1372e-01, -2.0253e-01],
        [-3.2056e-01, -2.1933e-01,  2.7929e-02,  3.2571e-01, -3.1795e-01,
          5.4084e-02, -1.3254e-02, -5.5215e-02],
        [ 7.7149e-02, -1.5672e-01,  1.2247e-01,  3.8070e-02,  3.5959e-01,
          2.9290e-01,  3.7905e-02, -2.5299e-01],
        [-3.1483e-02, -2.4707e-01,  1.6011e-01,  1.1899e-01, -3.9734e-02,
         -3.0559e-01, -2.3665e-01,  2.8471e-01],
        [ 2.7500e-01, -2.2939e-01, -2.5971e-01,  8.9889e-02,  1.7758e-01,
         -1.1074e-01, -6.1271e-02,  4.7024e-01],
        [-1.8022e-01,  1.8895e-01,  4.8348e-03,  3.1476e-01,  1.0637e-01,
          1.6152e-01,  2.5647e-01, -1.3776e-02],
        [-9.8456e-02, -3.0466e-01,  3.2120e-01,  2.3104e-01, -6.2004e-02,
         -3.1190e-01,  3.5678e-01,  3.2152e-01],
        [-3.1335e-01,  1.1251e-01,  5.1068e-02,  1.7479e-01, -8.1158e-03,
         -1.5254e-01,  7.0556e-03,  2.1277e-02],
        [-2.1121e-01,  2.3053e-01,  3.5230e-01,  3.0703e-01,  2.5979e-01,
         -1.4957e-01,  4.8067e-02, -2.5817e-01],
        [-1.5084e-02, -1.7082e-01, -8.2795e-02, -2.5917e-01, -7.1637e-03,
          7.3076e-02,  2.7383e-01,  3.9630e-02],
        [ 2.0023e-01, -1.7850e-01,  7.5838e-03, -3.1351e-02,  3.6371e-02,
         -1.5206e-01,  1.9261e-01,  4.3845e-01],
        [ 1.5245e-01,  5.8592e-03, -6.4468e-02, -3.8715e-01, -1.3144e-01,
         -2.1721e-01, -1.2923e-01, -3.1413e-01],
        [ 7.9851e-02, -2.5919e-04,  6.1066e-02,  1.7295e-01, -2.3658e-01,
         -1.9031e-01, -2.6979e-01, -7.7387e-02],
        [-1.2593e-01,  1.9022e-01,  2.0773e-02, -1.5229e-01,  1.2422e-01,
         -6.0318e-02,  2.9053e-02,  3.0404e-01],
        [ 7.6326e-02,  4.9375e-02,  2.6327e-01,  2.1383e-01, -1.7291e-01,
         -1.4036e-01, -9.1083e-02,  2.3353e-01]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[-7.5315e-03,  1.1135e-02,  1.3799e-02,  1.5242e-02, -1.7157e-02,
         -1.1918e-03,  9.2748e-03,  1.3030e-02],
        [-8.0050e-04,  1.5163e-03, -8.7470e-04, -1.7284e-03,  3.2056e-04,
          9.0004e-03, -7.2556e-03, -1.0067e-02],
        [ 6.8439e-02, -1.0915e-01, -4.1821e-02, -6.1352e-02,  1.0291e-01,
         -2.2291e-01,  1.2355e-01,  1.5801e-01],
        [ 5.0530e-03, -1.1381e-02,  4.6206e-03, -2.9849e-03,  8.7952e-03,
         -5.0095e-02,  3.5887e-02,  3.8881e-02],
        [-1.9935e-02,  3.6472e-02, -1.8521e-03, -7.7704e-03, -1.4967e-02,
          1.4275e-01, -1.0482e-01, -1.4181e-01],
        [ 6.5352e-03, -9.6226e-03, -6.6996e-03, -9.3029e-03,  1.1725e-02,
         -8.6298e-03,  7.8769e-04,  7.1734e-04],
        [-3.2920e-02,  4.9220e-02,  3.2606e-02,  4.5995e-02, -5.8843e-02,
          5.0304e-02, -9.4484e-03, -1.0130e-02],
        [-5.3784e-02,  9.5483e-02,  6.3343e-03,  2.3340e-02, -6.9456e-02,
          2.9921e-01, -2.0182e-01, -2.5279e-01],
        [-1.1535e-02,  1.6756e-02,  1.1634e-02,  1.3404e-02, -1.8658e-02,
          1.8736e-02, -5.2508e-03, -8.1022e-03],
        [-3.4595e-02,  4.8549e-02,  3.6105e-02,  3.6167e-02, -5.2313e-02,
          5.0350e-02, -1.2779e-02, -2.5167e-02],
        [-3.0388e-02,  5.6505e-02, -5.5594e-03, -1.5629e-02, -2.0781e-02,
          2.3153e-01, -1.7182e-01, -2.3207e-01],
        [-8.1903e-02,  1.2993e-01,  6.2827e-02,  1.1371e-01, -1.4838e-01,
          1.8508e-01, -6.9266e-02, -7.1784e-02],
        [-2.4770e-03,  4.9490e-03, -1.0484e-03, -1.6844e-04, -2.6118e-03,
          2.0067e-02, -1.4558e-02, -1.8219e-02],
        [ 6.2003e-02, -9.5738e-02, -4.6450e-02, -6.9693e-02,  1.0212e-01,
         -1.6062e-01,  7.5495e-02,  9.1000e-02],
        [-2.7419e-02,  4.9784e-02, -2.2658e-03,  6.5126e-03, -3.2746e-02,
          1.7563e-01, -1.2282e-01, -1.5324e-01],
        [ 7.0067e-02, -1.1428e-01, -3.9212e-02, -6.4577e-02,  1.0817e-01,
         -2.4686e-01,  1.4026e-01,  1.7356e-01],
        [-1.4735e-02,  1.9690e-02,  1.9970e-02,  2.1050e-02, -2.4870e-02,
         -1.6171e-03,  1.4722e-02,  1.3922e-02],
        [-2.5696e-02,  4.2510e-02,  1.1406e-02,  1.7292e-02, -3.5597e-02,
          1.0584e-01, -6.5459e-02, -8.4309e-02],
        [-7.2627e-03,  1.5103e-02, -7.9042e-03, -1.3278e-02,  6.6830e-04,
          8.5168e-02, -6.7632e-02, -9.1260e-02],
        [-9.0569e-03,  1.9250e-02, -8.2962e-03, -1.4897e-02, -2.9233e-04,
          1.0332e-01, -8.1196e-02, -1.0994e-01],
        [-1.1159e-01,  1.7892e-01,  8.5249e-02,  1.6349e-01, -2.0875e-01,
          2.5160e-01, -9.0646e-02, -8.5850e-02],
        [ 2.9677e-03, -3.9614e-03, -4.8288e-03, -6.9996e-03,  6.8863e-03,
          4.9517e-03, -7.4947e-03, -1.0206e-02],
        [ 4.2575e-02, -6.8976e-02, -2.2501e-02, -3.1678e-02,  6.0124e-02,
         -1.5720e-01,  9.3409e-02,  1.2161e-01],
        [-1.4165e-02,  2.8627e-02, -8.0316e-03, -1.5230e-02, -5.1897e-03,
          1.3613e-01, -1.0451e-01, -1.4124e-01],
        [ 2.1172e-03, -2.8225e-03, -3.2359e-03, -4.0672e-03,  4.2203e-03,
          2.4304e-03, -4.2163e-03, -5.0946e-03],
        [-1.3904e-01,  1.9752e-01,  1.3963e-01,  1.4520e-01, -2.1134e-01,
          2.2300e-01, -6.7221e-02, -1.1694e-01],
        [-1.3697e-01,  2.1036e-01,  1.2151e-01,  1.8253e-01, -2.4145e-01,
          2.6931e-01, -8.8648e-02, -1.0048e-01],
        [ 6.1311e-03, -9.0137e-03, -6.6684e-03, -8.9389e-03,  1.1077e-02,
         -6.9280e-03, -2.8489e-04, -3.8888e-04],
        [ 7.8662e-02, -1.2124e-01, -6.2278e-02, -9.6755e-02,  1.3471e-01,
         -1.8530e-01,  7.8230e-02,  9.0121e-02],
        [-5.4962e-03,  9.1798e-03,  2.2501e-03,  4.1264e-03, -7.9681e-03,
          2.2954e-02, -1.4104e-02, -1.7617e-02],
        [ 2.3478e-02, -3.4586e-02, -1.9137e-02, -2.0451e-02,  3.3480e-02,
         -5.5428e-02,  2.6493e-02,  3.8712e-02],
        [ 1.1913e-01, -1.8693e-01, -8.7088e-02, -1.2767e-01,  1.9146e-01,
         -3.2388e-01,  1.5781e-01,  1.9792e-01],
        [ 1.9794e-03, -4.7333e-03,  1.6035e-03, -8.7998e-04,  3.4606e-03,
         -2.1571e-02,  1.5599e-02,  1.7292e-02],
        [-3.4648e-03,  1.1886e-02, -1.7293e-02, -2.5063e-02,  1.0794e-02,
          1.0739e-01, -9.0315e-02, -1.2086e-01],
        [ 8.3765e-03, -1.2181e-02, -5.9825e-03, -4.7190e-03,  1.0185e-02,
         -2.3739e-02,  1.3501e-02,  2.0241e-02],
        [-4.4167e-04,  1.2125e-03, -1.5586e-03, -1.7272e-03,  4.7346e-04,
          9.6912e-03, -7.9586e-03, -1.0181e-02],
        [-9.5190e-02,  1.5781e-01,  4.5547e-02,  7.6641e-02, -1.4035e-01,
          3.7113e-01, -2.2200e-01, -2.7914e-01],
        [ 7.1761e-03, -1.2375e-02, -1.8040e-03, -5.4082e-03,  1.1194e-02,
         -3.6945e-02,  2.4022e-02,  2.7800e-02],
        [-8.8055e-02,  1.2682e-01,  8.9371e-02,  9.9464e-02, -1.3989e-01,
          1.3994e-01, -3.8744e-02, -6.3359e-02],
        [-1.0199e-02,  1.5709e-02,  7.9983e-03,  1.5975e-02, -1.9584e-02,
          1.8685e-02, -4.7806e-03, -2.6577e-03],
        [-6.3906e-02,  9.7192e-02,  5.7673e-02,  8.1496e-02, -1.1021e-01,
          1.2667e-01, -4.3742e-02, -5.2373e-02],
        [-2.8152e-03,  5.3568e-03, -7.1565e-04, -5.1244e-04, -2.5493e-03,
          2.0836e-02, -1.5110e-02, -1.9701e-02],
        [-1.4559e-01,  2.3309e-01,  8.4220e-02,  1.1350e-01, -2.0840e-01,
          5.0962e-01, -2.9671e-01, -3.8720e-01],
        [-7.1622e-04,  1.2003e-03,  2.1779e-04, -7.4173e-04, -1.6152e-04,
          4.6079e-03, -3.5309e-03, -5.4003e-03],
        [-6.1564e-02,  9.3221e-02,  5.4908e-02,  7.6805e-02, -1.0450e-01,
          1.2114e-01, -4.1987e-02, -5.2106e-02],
        [-1.3421e-02,  2.7466e-02, -8.4118e-03, -1.4382e-02, -5.0904e-03,
          1.3125e-01, -1.0084e-01, -1.3541e-01],
        [-1.5949e-02,  2.4960e-02,  1.1872e-02,  1.7818e-02, -2.6031e-02,
          4.1416e-02, -1.9333e-02, -2.3999e-02],
        [ 3.2997e-03, -5.0993e-03, -2.3330e-03, -3.1080e-03,  5.0157e-03,
         -9.4689e-03,  4.9504e-03,  6.3944e-03],
        [-9.9846e-03,  2.1784e-02, -9.9700e-03, -1.5933e-02, -8.4860e-04,
          1.1654e-01, -9.1394e-02, -1.2259e-01],
        [ 4.8251e-02, -8.0963e-02, -2.8352e-02, -6.0954e-02,  8.7812e-02,
         -1.6504e-01,  8.6875e-02,  9.2483e-02],
        [-5.4738e-03,  1.0258e-02, -1.4430e-03, -3.1627e-03, -3.4744e-03,
          4.2919e-02, -3.1992e-02, -4.3186e-02],
        [-7.8063e-03,  1.2842e-02,  3.5561e-03,  4.7084e-03, -1.0451e-02,
          3.2315e-02, -2.0251e-02, -2.6481e-02],
        [ 1.0157e-02, -1.7347e-02, -4.6660e-03, -1.2603e-02,  1.8812e-02,
         -4.0389e-02,  2.2851e-02,  2.3659e-02],
        [-1.4893e-01,  2.2372e-01,  1.3710e-01,  1.8489e-01, -2.5118e-01,
          2.7801e-01, -9.0334e-02, -1.1612e-01],
        [-2.6277e-01,  4.3825e-01,  1.3634e-01,  2.7631e-01, -4.3035e-01,
          9.3227e-01, -5.1653e-01, -6.1034e-01],
        [-1.6829e-02,  2.5785e-02,  1.4828e-02,  2.3869e-02, -3.0549e-02,
          3.0956e-02, -8.7032e-03, -8.5834e-03],
        [ 1.2909e-02, -2.2526e-02, -2.2986e-03, -1.2781e-03,  1.3759e-02,
         -7.4952e-02,  5.2435e-02,  6.9291e-02],
        [-4.1029e-03,  9.5530e-03, -4.8070e-03, -3.3710e-03, -3.0330e-03,
          4.9393e-02, -3.7735e-02, -4.6877e-02],
        [ 2.0033e-02, -3.3833e-02, -1.2482e-02, -2.7759e-02,  3.8211e-02,
         -6.5480e-02,  3.2807e-02,  3.2805e-02],
        [-1.1200e-01,  1.6775e-01,  1.0318e-01,  1.3742e-01, -1.8755e-01,
          2.0845e-01, -6.8079e-02, -8.8970e-02],
        [ 1.8882e-03, -5.6822e-03,  5.7121e-03,  4.9276e-03, -3.8953e-04,
         -3.7842e-02,  3.0127e-02,  3.7879e-02],
        [ 3.7149e-02, -6.3137e-02, -9.5625e-03, -1.3284e-02,  4.4506e-02,
         -1.8720e-01,  1.2526e-01,  1.6405e-01],
        [ 1.0308e-01, -1.6174e-01, -7.4227e-02, -1.0404e-01,  1.6161e-01,
         -2.9133e-01,  1.4754e-01,  1.8879e-01],
        [-7.8546e-02,  1.1755e-01,  7.2213e-02,  9.5661e-02, -1.3135e-01,
          1.4868e-01, -5.0088e-02, -6.5041e-02],
        [ 2.1218e-02, -3.8802e-02,  1.0145e-03, -2.9949e-03,  2.3623e-02,
         -1.3617e-01,  9.5671e-02,  1.2251e-01],
        [ 1.2811e-02, -2.2234e-02, -4.0212e-03, -1.2301e-02,  2.1859e-02,
         -6.2060e-02,  3.8912e-02,  4.3045e-02],
        [ 2.7015e-02, -3.9599e-02, -2.2730e-02, -2.4427e-02,  3.8965e-02,
         -6.0181e-02,  2.7362e-02,  4.0603e-02],
        [ 5.3934e-02, -8.3571e-02, -4.2404e-02, -6.0791e-02,  8.8246e-02,
         -1.3297e-01,  5.9902e-02,  7.5001e-02],
        [ 1.7278e-01, -2.6033e-01, -1.3360e-01, -1.7756e-01,  2.6558e-01,
         -4.0452e-01,  1.8107e-01,  2.4528e-01],
        [ 3.6193e-02, -5.8024e-02, -1.8128e-02, -2.5526e-02,  4.9793e-02,
         -1.3375e-01,  8.0049e-02,  1.0502e-01],
        [ 3.2556e-02, -5.5718e-02, -1.0778e-02, -2.2150e-02,  4.6125e-02,
         -1.4850e-01,  9.3934e-02,  1.1742e-01],
        [-6.1153e-02,  9.3909e-02,  4.9613e-02,  7.3913e-02, -1.0320e-01,
          1.3899e-01, -5.7299e-02, -6.8546e-02],
        [ 1.1526e-01, -1.7586e-01, -9.5757e-02, -1.3255e-01,  1.8858e-01,
         -2.5736e-01,  1.0635e-01,  1.3614e-01],
        [ 1.9198e-03,  3.2773e-04, -1.0555e-02, -1.4276e-02,  9.6673e-03,
          4.1087e-02, -3.7454e-02, -4.9361e-02],
        [-4.1249e-03,  7.7888e-03, -1.2765e-03, -2.6314e-03, -2.5618e-03,
          3.3522e-02, -2.5134e-02, -3.3763e-02],
        [-1.0498e-01,  1.6648e-01,  7.9922e-02,  1.4446e-01, -1.8940e-01,
          2.4011e-01, -9.1558e-02, -9.5813e-02],
        [ 1.2844e-03, -6.2540e-04, -4.6619e-03, -5.0971e-03,  3.8791e-03,
          1.3963e-02, -1.3061e-02, -1.6367e-02],
        [-8.5580e-03,  3.8997e-03,  3.2131e-02,  3.4811e-02, -2.6327e-02,
         -9.6509e-02,  9.0275e-02,  1.1266e-01],
        [-1.0225e-02,  2.1440e-02, -9.1362e-03, -1.6158e-02, -7.6368e-04,
          1.1451e-01, -8.9832e-02, -1.2139e-01],
        [ 6.6639e-02, -1.1288e-01, -2.4408e-02, -4.3841e-02,  9.2706e-02,
         -2.9550e-01,  1.8624e-01,  2.3620e-01],
        [-2.1755e-02,  3.9942e-02, -7.1217e-03, -1.0580e-02, -1.5301e-02,
          1.6765e-01, -1.2498e-01, -1.6532e-01],
        [-1.0952e-01,  1.6292e-01,  1.0300e-01,  1.3376e-01, -1.8250e-01,
          1.9603e-01, -6.0868e-02, -8.1883e-02],
        [ 1.8032e-01, -2.8134e-01, -1.3182e-01, -1.8521e-01,  2.8437e-01,
         -4.9640e-01,  2.4714e-01,  3.1469e-01],
        [-1.3227e-01,  1.9948e-01,  1.1974e-01,  1.5796e-01, -2.1978e-01,
          2.6454e-01, -9.6336e-02, -1.2536e-01],
        [-5.3323e-03,  8.7008e-03,  3.0787e-03,  4.0673e-03, -7.5979e-03,
          1.9364e-02, -1.1366e-02, -1.4962e-02],
        [ 5.8285e-03, -9.0905e-03, -4.0780e-03, -5.1134e-03,  8.5565e-03,
         -1.7141e-02,  9.1344e-03,  1.2259e-02],
        [ 1.1387e-01, -1.8352e-01, -5.7238e-02, -8.5876e-02,  1.6252e-01,
         -4.2761e-01,  2.5554e-01,  3.2713e-01],
        [-2.3976e-02,  4.4733e-02, -7.2126e-03, -1.0744e-02, -1.7546e-02,
          1.8461e-01, -1.3702e-01, -1.8143e-01],
        [-8.6434e-02,  1.3335e-01,  7.7157e-02,  1.2170e-01, -1.5677e-01,
          1.6260e-01, -4.7764e-02, -4.8904e-02],
        [-1.0979e-01,  1.7621e-01,  8.5794e-02,  1.5987e-01, -2.0535e-01,
          2.4960e-01, -9.1276e-02, -8.7951e-02],
        [ 1.3289e-02, -2.7239e-02,  6.0819e-03,  7.1667e-04,  1.4360e-02,
         -1.1094e-01,  8.0599e-02,  1.0017e-01],
        [-1.5073e-02,  2.2424e-02,  1.3750e-02,  1.7418e-02, -2.4401e-02,
          2.8613e-02, -9.9861e-03, -1.3870e-02],
        [-1.0930e-02,  1.3380e-02,  1.7108e-02,  1.5686e-02, -1.8354e-02,
         -8.5596e-03,  1.6352e-02,  1.6393e-02],
        [ 3.5708e-02, -5.1571e-02, -2.3529e-02, -1.1765e-02,  3.7925e-02,
         -1.1459e-01,  7.0834e-02,  1.0812e-01],
        [ 6.6605e-05,  3.1929e-04, -9.6482e-04, -4.6976e-04,  1.4240e-04,
          3.9644e-03, -3.2675e-03, -3.6031e-03],
        [-1.0887e-01,  1.7102e-01,  9.1914e-02,  1.5165e-01, -1.9791e-01,
          2.3060e-01, -8.0501e-02, -8.3893e-02],
        [ 3.4570e-03, -3.4960e-03, -6.8566e-03, -4.8365e-03,  4.7378e-03,
          1.2036e-02, -1.2519e-02, -1.1739e-02],
        [ 8.5924e-02, -1.3880e-01, -4.7730e-02, -7.0702e-02,  1.2625e-01,
         -3.0671e-01,  1.7816e-01,  2.2757e-01],
        [-8.5375e-02,  1.2822e-01,  7.8714e-02,  1.0476e-01, -1.4322e-01,
          1.6092e-01, -5.3488e-02, -6.9533e-02],
        [-2.8021e-02,  4.1000e-02,  2.7668e-02,  3.4021e-02, -4.6155e-02,
          4.4515e-02, -1.1295e-02, -1.6972e-02]], device='cuda:0') 

model.module_15.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.0185, -0.0589, -0.0539,  0.1811, -0.2979, -0.3050,  0.2681,  0.1158,
        -0.0596, -0.2208, -0.0508,  0.2247, -0.1337, -0.1267, -0.2023, -0.0690,
         0.0354,  0.1646, -0.2491, -0.3227,  0.1394, -0.2918,  0.1729, -0.2316,
        -0.2544, -0.0264,  0.1798, -0.2695, -0.0527, -0.1392, -0.1846, -0.2165,
         0.1295, -0.2127, -0.2636, -0.2819,  0.3445, -0.0251,  0.0125,  0.3076,
         0.2459, -0.0847,  0.3271, -0.0093,  0.2929, -0.2546,  0.1395, -0.2696,
        -0.1796, -0.0378, -0.2274,  0.0754, -0.0620,  0.3548,  0.0772,  0.2323,
         0.1770,  0.2156,  0.1146,  0.1004,  0.1396,  0.2826, -0.1040,  0.1942,
         0.1226,  0.1258, -0.2308,  0.0020,  0.0713,  0.0885,  0.0426,  0.2218,
        -0.1282, -0.0940, -0.3336,  0.2830, -0.3108,  0.1128, -0.2932,  0.0883,
        -0.1922,  0.2234, -0.3147,  0.2327, -0.0613, -0.3108, -0.1223, -0.1301,
         0.1479,  0.3210,  0.1144,  0.0056, -0.0321, -0.2764, -0.1260,  0.3154,
         0.2467, -0.0409,  0.1159,  0.2338], device='cuda:0',
       requires_grad=True) 
grad:  tensor([-6.5536e-03,  3.0768e-03, -3.0381e-01, -1.8362e-02,  7.7478e-02,
        -2.9197e-02,  1.4474e-01,  2.3746e-01,  4.2569e-02,  1.2046e-01,
         1.1762e-01,  4.5430e-01,  1.3106e-02, -2.4717e-01,  1.1463e-01,
        -3.0525e-01,  7.4250e-02,  1.1237e-01,  2.9315e-02,  3.6912e-02,
         6.3280e-01, -1.5696e-02, -1.8888e-01,  6.1637e-02, -1.2811e-02,
         4.9942e-01,  6.3933e-01, -2.8092e-02, -3.2971e-01,  2.4363e-02,
        -8.9641e-02, -5.3040e-01, -1.9306e-03,  2.0348e-02, -2.8180e-02,
         1.7771e-03,  4.4023e-01, -1.3943e-02,  3.2218e-01,  5.6809e-02,
         2.6885e-01,  1.4996e-02,  6.1609e-01,  1.6939e-03,  2.7230e-01,
         6.2419e-02,  7.4346e-02, -1.2468e-02,  4.7006e-02, -1.9471e-01,
         2.3100e-02,  3.2531e-02, -3.2080e-02,  6.4622e-01,  1.3441e+00,
         8.3400e-02, -4.0940e-02,  1.8835e-02, -8.2649e-02,  4.8323e-01,
        -1.8109e-02, -1.5682e-01, -4.4535e-01,  3.2710e-01, -9.9796e-02,
        -2.6157e-02, -1.0492e-01, -2.3795e-01, -8.0832e-01, -1.6612e-01,
        -1.5177e-01,  2.6789e-01, -5.1235e-01, -8.6917e-03,  1.6560e-02,
         5.7759e-01, -3.3637e-03,  2.4383e-02,  4.1663e-02, -3.0770e-01,
         9.0656e-02,  4.6474e-01, -7.6053e-01,  5.5054e-01,  2.3553e-02,
        -2.4897e-02, -4.7771e-01,  1.0644e-01,  4.2350e-01,  5.9785e-01,
        -6.9624e-02,  6.4845e-02,  3.3522e-02, -1.1210e-01,  4.8553e-04,
         5.4074e-01, -2.8512e-02, -3.6688e-01,  3.6526e-01,  1.1788e-01],
       device='cuda:0') 

model.module_17.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[-0.1540,  0.0388, -0.1064,  ...,  0.0775,  0.0594, -0.0006],
        [ 0.0549,  0.0432, -0.0244,  ..., -0.0351,  0.0839,  0.0824],
        [ 0.0247, -0.0100, -0.0853,  ..., -0.0982,  0.1778,  0.0927],
        ...,
        [-0.0917,  0.0568,  0.0674,  ...,  0.0889,  0.0622,  0.0033],
        [ 0.0825, -0.0839, -0.0684,  ..., -0.0214, -0.0301,  0.0434],
        [-0.0156,  0.0844,  0.0187,  ...,  0.0626,  0.0148, -0.0177]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 0.0182, -0.0033,  0.0456,  ...,  0.0079,  0.0072,  0.0453],
        [ 0.0096, -0.0035,  0.0323,  ...,  0.0055,  0.0009,  0.0177],
        [ 0.0080, -0.0014,  0.0168,  ...,  0.0030,  0.0013,  0.0120],
        ...,
        [-0.0362,  0.0054, -0.0947,  ..., -0.0189, -0.0096, -0.0818],
        [ 0.0281, -0.0022,  0.0508,  ...,  0.0097,  0.0101,  0.0590],
        [-0.0181,  0.0032, -0.0423,  ..., -0.0079, -0.0036, -0.0324]],
       device='cuda:0') 

model.module_17.bias 100 torch.Size([100])
Parameter containing:
tensor([ 0.0445, -0.0619,  0.0100,  0.0478, -0.0046, -0.0636, -0.0611,  0.0586,
        -0.0561,  0.0726, -0.0863, -0.0536,  0.0924,  0.1052, -0.0128,  0.0456,
         0.0322, -0.0304,  0.0929,  0.0631,  0.1068, -0.0074, -0.1198, -0.0538,
        -0.0235, -0.0297,  0.0695,  0.0998,  0.0817,  0.0211, -0.0322, -0.0567,
         0.0085, -0.0410,  0.0775, -0.0555, -0.1232, -0.0433, -0.0571, -0.0454,
         0.0301, -0.0438, -0.0629,  0.1039, -0.0417,  0.0942,  0.0848,  0.0615,
        -0.0988,  0.0375, -0.0692,  0.0470, -0.0523,  0.0954,  0.0824, -0.0946,
         0.0451, -0.0520, -0.0039,  0.1015,  0.0771, -0.1013,  0.0494, -0.0671,
        -0.0219,  0.0791, -0.0298,  0.0363, -0.0907, -0.0755, -0.0969,  0.0250,
        -0.0874,  0.0889,  0.0253, -0.1328,  0.1075, -0.0100, -0.0216,  0.0590,
        -0.0502, -0.0619, -0.0360,  0.0007,  0.0727, -0.0037, -0.0393, -0.0596,
         0.0009, -0.0363, -0.0229,  0.0221,  0.0014, -0.0272,  0.0562, -0.0601,
        -0.0437, -0.0509,  0.0619,  0.0792], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 0.1436,  0.0708,  0.0400,  0.1900,  0.0251,  0.0786,  0.1398, -0.2723,
        -0.1831,  0.2094,  0.0217, -0.0681,  0.1228, -0.0399, -0.0389,  0.0506,
         0.0410,  0.0167,  0.2227, -0.3437,  0.0484,  0.1950,  0.0088,  0.0873,
        -0.1399,  0.0875,  0.2835, -0.1347,  0.0696, -0.0397,  0.0874,  0.0716,
         0.4073,  0.0284, -0.2898,  0.4427,  0.0189,  0.0509,  0.0143,  0.2443,
        -0.2818,  0.0596,  0.0728, -0.0101, -0.3742,  0.1602,  0.1265, -0.0585,
        -0.0260,  0.0334, -0.3364,  0.0343,  0.0898, -0.0252,  0.0495,  0.0113,
        -0.0644, -0.0660, -0.0431,  0.0779, -0.1644,  0.0368,  0.0819,  0.0403,
         0.2961, -0.1886, -0.2032, -0.0640,  0.0333,  0.0698,  0.0383, -0.0965,
        -0.1946,  0.0009,  0.3912,  0.0143,  0.4158, -0.1250,  0.4109,  0.0679,
         0.1120,  0.0781,  0.0483,  0.3774, -0.0812,  0.0298,  0.0228,  0.0230,
         0.1965,  0.0297, -0.0029, -0.1052, -0.0041,  0.3999,  0.0910, -0.1803,
        -0.2447, -0.2422,  0.1623, -0.1011], device='cuda:0') 

model.module_19.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0648,  0.0246,  0.0823,  ..., -0.1120,  0.1127, -0.0089],
        [-0.0866, -0.0328, -0.0284,  ..., -0.1144,  0.1074, -0.0271],
        [ 0.1453,  0.0830,  0.0831,  ..., -0.0658,  0.0032, -0.0384],
        ...,
        [ 0.0377, -0.0373, -0.0434,  ...,  0.0560, -0.0377,  0.0004],
        [-0.0121,  0.0464, -0.0769,  ...,  0.1649,  0.0301,  0.1176],
        [-0.0125, -0.0546, -0.0287,  ..., -0.0099,  0.0852, -0.0905]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-0.0289, -0.0308,  0.0156,  ...,  0.0158,  0.0881,  0.0244],
        [ 0.0193,  0.0086,  0.0172,  ...,  0.0048,  0.0093, -0.0052],
        [-0.0283, -0.0356,  0.0264,  ...,  0.0314,  0.1128,  0.0313],
        ...,
        [ 0.0578,  0.0376,  0.0252,  ..., -0.0151, -0.0307, -0.0317],
        [-0.0010, -0.0002, -0.0020,  ...,  0.0010, -0.0032,  0.0006],
        [ 0.0270,  0.0181,  0.0103,  ..., -0.0070, -0.0183, -0.0150]],
       device='cuda:0') 

model.module_19.bias 16 torch.Size([16])
Parameter containing:
tensor([ 0.0933, -0.0167,  0.0007, -0.0006, -0.0358, -0.0534,  0.0108,  0.0541,
         0.0037,  0.1065,  0.0191, -0.0510, -0.0721,  0.0802, -0.0964,  0.0727],
       device='cuda:0', requires_grad=True) 
grad:  tensor([ 0.9571, -0.1298,  1.1361, -0.2320,  0.2880, -0.0213,  0.3113, -0.1025,
        -0.2445,  0.5839, -0.1571, -0.9544, -0.6645, -0.8438, -0.0073, -0.4278],
       device='cuda:0') 

