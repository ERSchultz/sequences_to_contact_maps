#### INITIAL PARAMETERS ####
W torch.Size([16, 16])
Parameter containing:
tensor([[ 0.8155,  1.2841, -0.4994, -0.9522,  1.5284, -0.0693,  0.4134,  1.1722,
         -1.4326, -1.4657,  1.1519, -0.4593, -0.7880, -1.5160,  1.2319, -0.6516],
        [ 0.4039, -0.7550,  1.1492,  0.0867,  1.2933,  1.2340, -2.1650, -0.6461,
         -0.2982, -0.4242,  0.6187, -0.8215, -0.7906,  0.1406, -1.3701,  0.8481],
        [ 1.7691,  1.1397, -1.6519,  0.9508,  2.3524,  0.6921,  0.9276, -0.7980,
         -0.3040,  1.1126,  0.1078,  2.0407,  0.1301,  0.0197,  1.7417,  0.5862],
        [-0.4713,  0.0196,  0.4123,  1.2215, -0.4067,  1.0874, -0.8713,  0.6839,
          1.8173, -0.0552,  1.6135, -1.2941, -0.8123, -0.6009, -0.1199, -0.7102],
        [-0.4239,  0.0996,  0.8837, -0.7245,  0.0271, -2.4757, -0.4173, -1.7434,
         -0.3041, -1.0531,  0.4715,  0.0988, -0.5767, -0.0605,  1.1803, -0.3148],
        [ 0.4455, -1.3321, -1.1989,  0.3607, -0.1811,  0.3893, -1.2163, -0.5680,
          0.0922, -0.7489,  0.5662, -0.2896,  1.7446, -0.0670, -1.1708, -0.2247],
        [ 0.7204,  0.9585,  0.6545, -1.0235, -1.1143,  0.3367, -0.0509,  0.8461,
          1.1351,  1.0570,  1.5719, -0.7187,  2.1435,  0.2325, -0.8231, -0.3118],
        [ 0.7230, -0.2391,  2.2554, -0.4733, -1.0607,  1.0506, -1.2073, -0.7482,
          1.3284, -0.5366,  1.9497,  1.1373,  0.4085, -0.6797,  2.0249,  0.0976],
        [ 0.1202,  1.5143,  0.4494,  1.1137, -0.4201,  0.0197, -1.1887, -1.0660,
          0.3045,  0.9137, -0.0874,  0.4569,  1.3147, -0.9256,  0.7715,  0.7459],
        [-0.1180, -1.0479, -1.3755,  0.7867, -1.1050,  0.0592,  0.8749, -1.3656,
         -1.2725, -0.0189, -0.8026, -0.2668,  0.8486, -0.2308, -0.5880,  1.5124],
        [ 0.7935,  1.4433, -0.6439,  0.5406,  0.4507, -1.7446,  0.5640, -2.0243,
          1.5569,  0.3073,  0.5900,  0.0863, -0.9007,  1.3189,  1.5858,  0.5701],
        [-0.0707,  1.0579,  0.3274,  0.3569,  1.3780, -1.1759, -1.7735,  1.2009,
         -0.9657,  0.5386, -1.6630, -0.5291, -0.6799, -0.2819, -0.1830, -0.4130],
        [-0.2007, -0.6887,  0.6296, -0.6927, -2.2790, -1.9799, -2.0507,  1.5184,
         -0.4174, -0.8728, -1.2622, -0.2391,  0.0779, -0.0265, -0.5204,  0.6694],
        [ 0.6105,  2.0363, -0.8068,  1.2917, -0.8145,  0.3040,  0.0245,  0.3815,
          1.5875,  0.9890, -1.0710, -0.0714,  0.6462, -0.3358, -0.2952, -0.3684],
        [ 0.3280, -0.3663,  0.7831, -0.7242, -1.4133, -0.3707,  0.2631,  0.5066,
         -1.4863,  2.0798,  1.8890,  0.2822,  0.0370,  1.8072,  0.3590,  0.4349],
        [ 0.3960, -1.0742,  1.2011,  0.2438, -2.4870,  1.1063,  0.5106, -1.0290,
          0.5120,  2.5809, -0.7003,  0.6223, -1.0504, -1.3519,  1.0266, -0.3877]],
       device='cuda:0', requires_grad=True) 

act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

inner_act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

out_act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

encoder.module_0.weight torch.Size([100, 10])
Parameter containing:
tensor([[ 0.2418,  0.2625, -0.0741,  0.2905, -0.0693,  0.0638, -0.1540,  0.1857,
          0.2788, -0.2320],
        [ 0.2749,  0.0592,  0.2336,  0.0428,  0.1525, -0.0446,  0.2438,  0.0467,
         -0.1476,  0.0806],
        [-0.1457, -0.0371, -0.1284,  0.2098, -0.2496, -0.1458, -0.0893, -0.1901,
          0.0298, -0.3123],
        [ 0.2856, -0.2686,  0.2441,  0.0526, -0.1027,  0.1954,  0.0493,  0.2555,
          0.0346, -0.0997],
        [ 0.0850, -0.0858,  0.1331,  0.2823,  0.1828, -0.1382,  0.1825,  0.0566,
          0.1606, -0.1927],
        [-0.3130, -0.1222, -0.2426,  0.2595,  0.0911,  0.1310,  0.1000, -0.0055,
          0.2475, -0.2247],
        [ 0.0199, -0.2158,  0.0975, -0.1089,  0.0969, -0.0659,  0.2623, -0.1874,
         -0.1886, -0.1886],
        [ 0.2844,  0.1054,  0.3043, -0.2610, -0.3137, -0.2474, -0.2127,  0.1281,
          0.1132,  0.2628],
        [-0.1633, -0.2156,  0.1678, -0.1278,  0.1919, -0.0750,  0.1809, -0.2457,
         -0.1596,  0.0964],
        [ 0.0669, -0.0806,  0.1885,  0.2150, -0.2293, -0.1688,  0.2896, -0.1067,
         -0.1121, -0.3060],
        [-0.1811,  0.0790, -0.0417, -0.2295,  0.0074, -0.2160, -0.2683, -0.1741,
         -0.2768, -0.2014],
        [ 0.3161,  0.0597,  0.0974, -0.2949, -0.2077, -0.1053,  0.0494, -0.2783,
         -0.1363, -0.1893],
        [ 0.0009, -0.1177, -0.0219, -0.2143, -0.2171, -0.1845, -0.1082, -0.2496,
          0.2651, -0.0628],
        [ 0.2721,  0.0985, -0.2678,  0.2188, -0.0870, -0.1212, -0.2625, -0.3144,
          0.0905, -0.0691],
        [ 0.1231, -0.2595,  0.2348, -0.2321, -0.0546,  0.0661,  0.1633,  0.2553,
          0.2881, -0.2507],
        [ 0.0796, -0.1360, -0.0347, -0.2367,  0.2880, -0.2321,  0.1690,  0.1111,
          0.1028, -0.1710],
        [ 0.2874,  0.0695,  0.0407, -0.2787,  0.1327, -0.0474, -0.1449,  0.2716,
          0.0705, -0.1750],
        [-0.1601, -0.0151,  0.1766, -0.0808, -0.1804, -0.1083, -0.2362,  0.1128,
          0.2448, -0.2977],
        [ 0.0734,  0.1634,  0.0573, -0.1126,  0.1651,  0.1662,  0.1182, -0.0556,
         -0.0837,  0.0338],
        [-0.0559, -0.0942,  0.2021,  0.2718, -0.0313, -0.0708,  0.0046, -0.0189,
          0.0760,  0.0886],
        [-0.2872, -0.1167,  0.2663,  0.1232, -0.0157, -0.1907, -0.1935, -0.2833,
         -0.1031,  0.1068],
        [ 0.2016,  0.1460, -0.2795, -0.1902, -0.0499,  0.3059,  0.0457, -0.0819,
          0.1308, -0.1204],
        [-0.2047,  0.2308, -0.1438, -0.0634, -0.3146,  0.2116,  0.2396,  0.1152,
         -0.2205, -0.3121],
        [-0.2568,  0.2358,  0.1518,  0.2661,  0.1657,  0.0800, -0.0031, -0.2405,
         -0.2709, -0.2958],
        [ 0.1295, -0.1553, -0.0636, -0.1820, -0.0576, -0.2226, -0.2066,  0.1049,
         -0.0940,  0.1952],
        [-0.1014, -0.2320, -0.0558, -0.1533, -0.0967, -0.3010,  0.1769, -0.2202,
          0.1589,  0.1435],
        [ 0.2259, -0.2426,  0.2274, -0.1495,  0.1173,  0.2970, -0.0446, -0.0024,
         -0.0728, -0.2640],
        [ 0.1518, -0.3139,  0.1963,  0.2366,  0.2991, -0.0746, -0.2598,  0.0711,
          0.1747, -0.3147],
        [-0.0718, -0.1896, -0.0277, -0.1557, -0.1293, -0.1004, -0.3005,  0.2595,
          0.2651, -0.0496],
        [-0.0360, -0.1291, -0.2856, -0.3077,  0.1175, -0.1736, -0.2033, -0.0247,
         -0.1053, -0.1023],
        [ 0.0102, -0.0671, -0.1089, -0.1514, -0.2574,  0.2652, -0.1266,  0.0838,
         -0.1097,  0.0257],
        [ 0.2948,  0.1457, -0.2740,  0.1255,  0.3002,  0.0832,  0.2120,  0.3118,
         -0.0485,  0.0656],
        [-0.2198, -0.0652,  0.2342,  0.1621, -0.2001, -0.2536, -0.2161, -0.3121,
         -0.2440, -0.0782],
        [ 0.2134,  0.0529, -0.2405, -0.2537,  0.1573, -0.2352, -0.0389,  0.1517,
         -0.1464, -0.0345],
        [-0.0275, -0.0748, -0.1603, -0.2819, -0.2556, -0.1693,  0.3054, -0.1527,
         -0.2124,  0.0767],
        [ 0.0872,  0.1733,  0.2404,  0.1761, -0.3135,  0.0280,  0.1916, -0.0292,
         -0.1863,  0.3015],
        [-0.1183, -0.1800, -0.2851,  0.0141,  0.1401,  0.0700,  0.0625, -0.2398,
         -0.2953,  0.0056],
        [ 0.2883,  0.1824, -0.1841, -0.0410, -0.2331, -0.1526,  0.0573,  0.1722,
          0.2620, -0.2903],
        [ 0.2114, -0.2230,  0.1184,  0.2676,  0.0044,  0.2877, -0.2694, -0.1208,
          0.1844, -0.0689],
        [-0.0647, -0.1318,  0.2180,  0.1551,  0.1013, -0.1777, -0.2567,  0.0342,
          0.0937, -0.1460],
        [-0.0885,  0.2136,  0.0252,  0.0143, -0.0778, -0.2864, -0.2973, -0.1512,
         -0.1607,  0.0985],
        [-0.0921, -0.1237,  0.3015,  0.1101,  0.2254, -0.1531, -0.1292,  0.1162,
         -0.2107, -0.2067],
        [-0.0153, -0.1157, -0.2371,  0.1876,  0.2543,  0.0513, -0.0551, -0.2929,
         -0.1152,  0.0805],
        [ 0.1491, -0.0400, -0.1250,  0.1762, -0.2518,  0.1999, -0.1227,  0.0048,
         -0.0625,  0.0383],
        [-0.0956,  0.2299, -0.0082,  0.2468,  0.3040, -0.1541, -0.2307,  0.2537,
          0.2478, -0.2415],
        [-0.0244, -0.3118, -0.2589,  0.0611,  0.0841,  0.0670, -0.0861,  0.2917,
          0.0452, -0.1866],
        [-0.0179,  0.0759,  0.1107, -0.2236,  0.1185, -0.1616, -0.2628, -0.1727,
          0.3050,  0.2703],
        [ 0.2832,  0.1856,  0.2389, -0.0423, -0.1740,  0.1580, -0.1639, -0.2134,
         -0.1010,  0.0664],
        [ 0.1628, -0.1228, -0.1861,  0.0427, -0.1864, -0.2059,  0.1648, -0.0531,
          0.2890,  0.3076],
        [ 0.0946,  0.1088,  0.0728,  0.0050, -0.0230,  0.0043,  0.1181,  0.2940,
         -0.0820, -0.1337],
        [-0.0766, -0.1528,  0.0538,  0.2360,  0.2473,  0.1452, -0.2327, -0.1697,
         -0.0695, -0.0583],
        [ 0.0260, -0.2903,  0.0984, -0.2412, -0.2001, -0.2629,  0.2755, -0.2994,
          0.2386, -0.0106],
        [-0.0368,  0.1978, -0.0292,  0.1983,  0.2286, -0.2746,  0.1217,  0.0597,
          0.0680,  0.0462],
        [ 0.0865, -0.1521, -0.0405,  0.3005,  0.2125, -0.0119, -0.2974,  0.0139,
         -0.2153,  0.2572],
        [-0.1920, -0.0228, -0.0702,  0.0563,  0.2976,  0.0300,  0.1831,  0.2455,
          0.2553, -0.1092],
        [-0.0707,  0.1524, -0.0863,  0.1481, -0.0691, -0.2145,  0.1287,  0.0485,
          0.1410,  0.3142],
        [ 0.2159,  0.2998,  0.0169, -0.2720, -0.2218, -0.1964, -0.2787, -0.1585,
         -0.2911, -0.2918],
        [-0.1890, -0.3117, -0.1941,  0.1206,  0.2638, -0.0941, -0.0920,  0.1689,
         -0.1560, -0.1495],
        [ 0.1948, -0.2755,  0.0387,  0.2793,  0.0542,  0.0860, -0.1842, -0.0044,
          0.0174,  0.0776],
        [ 0.1229,  0.2748, -0.2414,  0.0095, -0.1580, -0.2502, -0.0253, -0.2784,
          0.2207,  0.0366],
        [-0.1704,  0.1653, -0.2993, -0.1223, -0.0616, -0.2687, -0.2011, -0.0516,
          0.2399,  0.3054],
        [ 0.2012, -0.1888, -0.2069,  0.2760,  0.1119,  0.0084,  0.0428, -0.2542,
         -0.1056,  0.3044],
        [-0.0780, -0.0159, -0.2626, -0.1769, -0.0065, -0.1964, -0.0392,  0.1287,
         -0.3093,  0.0939],
        [-0.2091, -0.1543,  0.1214,  0.2514, -0.0864, -0.1298, -0.2859, -0.1631,
         -0.2769, -0.0724],
        [ 0.0645, -0.2963,  0.2761,  0.1984, -0.3096, -0.1510,  0.1031, -0.0650,
         -0.0345, -0.1428],
        [ 0.2540, -0.1768,  0.2622,  0.0204,  0.0636,  0.2467, -0.0521, -0.1800,
         -0.0511,  0.2565],
        [-0.2346,  0.0718, -0.3108,  0.1658,  0.1168,  0.0134,  0.1357,  0.0004,
          0.1750, -0.2503],
        [-0.0464,  0.1403,  0.3149,  0.1611, -0.2300,  0.2432, -0.0705, -0.0675,
         -0.2874, -0.0498],
        [ 0.2237,  0.0441, -0.1842,  0.0973, -0.1014,  0.2887, -0.2745, -0.0999,
         -0.3053, -0.1245],
        [ 0.0997,  0.3044,  0.0531,  0.3100,  0.0619,  0.1826,  0.2535,  0.2643,
         -0.1770,  0.2907],
        [ 0.1916, -0.1479, -0.1509, -0.2652,  0.0794, -0.2563,  0.1336,  0.0999,
         -0.2747,  0.0862],
        [-0.0257,  0.1445,  0.1814, -0.3144,  0.2900,  0.2652,  0.1258, -0.2890,
         -0.1130, -0.0916],
        [-0.0813,  0.1783,  0.1150,  0.2505, -0.1184,  0.1064,  0.1125, -0.2633,
         -0.3067, -0.1641],
        [ 0.2165, -0.2977, -0.2753,  0.1772,  0.1706,  0.2601, -0.2387, -0.2314,
          0.1622,  0.2750],
        [ 0.1892,  0.0495,  0.1042,  0.3001, -0.2040, -0.1436,  0.2212, -0.2164,
         -0.1744,  0.2308],
        [ 0.0998,  0.1022, -0.1340, -0.0044,  0.2894, -0.1898,  0.0025,  0.1504,
         -0.2183,  0.3071],
        [-0.1580, -0.0759, -0.0856, -0.2061, -0.3103,  0.1783,  0.0840, -0.2962,
         -0.2035,  0.3125],
        [ 0.1209,  0.1269, -0.1892, -0.1386, -0.0477, -0.0578, -0.2167,  0.0261,
          0.0314, -0.0400],
        [ 0.0438, -0.1253,  0.0823,  0.1193, -0.1666, -0.3136,  0.1655,  0.0754,
         -0.1608,  0.3047],
        [-0.1430,  0.2137,  0.1604, -0.2651,  0.2039, -0.2908, -0.1752, -0.0527,
         -0.2132,  0.3089],
        [-0.0634,  0.1256, -0.2824,  0.1820, -0.0983, -0.2405,  0.0462,  0.1532,
          0.2737, -0.1931],
        [-0.1556,  0.0608,  0.0858,  0.1216,  0.1736, -0.0717,  0.1757,  0.2332,
         -0.0826,  0.2250],
        [ 0.1545,  0.2789, -0.1797, -0.1562, -0.0914,  0.0160,  0.1898, -0.1805,
          0.1583, -0.1133],
        [ 0.1910, -0.0150, -0.2770, -0.1740, -0.2289,  0.1568, -0.2120, -0.0263,
          0.0682, -0.1734],
        [ 0.0912, -0.3088, -0.2263, -0.2865, -0.0957, -0.1152,  0.0453, -0.0585,
          0.1487,  0.2899],
        [ 0.1135, -0.1246, -0.2961,  0.1145, -0.1567,  0.1609,  0.2114,  0.1220,
          0.2967,  0.3004],
        [ 0.0670, -0.2304,  0.2825, -0.1500, -0.1494,  0.2646,  0.2450,  0.0955,
          0.0198, -0.2660],
        [-0.0328,  0.3033,  0.0805,  0.0271, -0.0657, -0.1103,  0.1885,  0.0195,
          0.2057, -0.0560],
        [ 0.1382,  0.1305,  0.0504,  0.1987,  0.1982,  0.2931,  0.2431, -0.0809,
         -0.2677,  0.0578],
        [-0.0028, -0.0825, -0.0530,  0.0149,  0.2307,  0.0986, -0.1123, -0.1300,
         -0.0783, -0.1222],
        [ 0.2844,  0.1675,  0.2855,  0.0010,  0.0638,  0.1097, -0.2993,  0.0282,
         -0.0212, -0.1773],
        [-0.2454,  0.2799,  0.2571,  0.1466,  0.3018, -0.1283, -0.0546,  0.1197,
         -0.0522, -0.0621],
        [-0.2614,  0.0850, -0.1911,  0.0115,  0.3083, -0.0973, -0.0997,  0.1908,
         -0.1163, -0.0272],
        [ 0.2953, -0.1296, -0.2262, -0.1770, -0.0877, -0.1500, -0.1641,  0.1277,
          0.0537, -0.1012],
        [-0.2457, -0.0996, -0.1335, -0.1029, -0.2853,  0.0681, -0.2323, -0.2463,
         -0.2584,  0.1320],
        [-0.1904, -0.1305,  0.2479,  0.1679,  0.1813, -0.3003, -0.2268, -0.1194,
          0.2612,  0.0324],
        [-0.2365,  0.0020, -0.2456, -0.0693, -0.0870,  0.2737,  0.0979, -0.0551,
          0.0534, -0.0913],
        [ 0.1242,  0.1251,  0.0849, -0.1233,  0.2698, -0.0457, -0.1231,  0.1981,
          0.2577,  0.3147],
        [ 0.0937, -0.1078,  0.1606,  0.2713, -0.3102, -0.0392, -0.2157,  0.0589,
          0.1308, -0.0653],
        [-0.0265,  0.1423, -0.0531, -0.2656,  0.2530, -0.1592, -0.0347,  0.0298,
         -0.0190, -0.2975]], device='cuda:0', requires_grad=True) 

encoder.module_0.bias torch.Size([100])
Parameter containing:
tensor([ 1.4509e-01, -1.4364e-01, -1.6401e-01,  7.5552e-02, -1.6503e-01,
        -1.4615e-01, -1.0655e-01, -1.1880e-01, -1.3207e-01, -8.5282e-02,
         8.2180e-02, -2.5590e-01, -1.9141e-01,  4.6142e-03,  4.3977e-02,
         1.7465e-01, -2.2213e-01,  1.0094e-01,  1.7974e-01,  1.7559e-01,
        -2.9454e-01, -1.2067e-01, -2.7182e-01, -2.0011e-01,  1.7613e-01,
        -4.7219e-02,  1.3431e-01, -1.8563e-01,  4.8054e-02, -1.9127e-01,
         1.5808e-01, -1.3831e-01, -7.9297e-02, -2.7437e-01,  1.0447e-03,
         3.0025e-01,  1.5349e-01, -1.6872e-01,  4.2529e-03, -3.4674e-02,
        -2.5459e-01,  2.4795e-01,  5.0978e-03,  6.6597e-02, -1.2770e-01,
        -1.4797e-01,  5.2143e-02,  1.1691e-01,  7.0929e-02, -1.5240e-01,
         3.0702e-01, -4.6550e-02, -1.9366e-01, -1.4790e-01,  3.1130e-01,
         1.5230e-05, -4.2926e-02, -1.3160e-01, -8.2898e-02, -2.6634e-01,
        -2.5130e-01,  1.8508e-01,  2.7052e-01,  3.0178e-01, -2.2830e-01,
         1.7104e-01, -1.9573e-01,  1.8865e-01,  2.2818e-01,  2.4472e-01,
         2.2770e-01,  1.9782e-01,  6.1549e-03,  1.4530e-01, -1.1314e-01,
         1.3770e-01, -1.0164e-01, -5.3099e-03, -2.7524e-01, -8.2686e-02,
        -1.6630e-01, -1.0667e-01, -2.0194e-01, -2.8443e-01,  2.0592e-02,
         2.0523e-01,  2.8800e-01,  1.8454e-01, -1.6391e-01, -3.1275e-01,
         1.1995e-01,  1.7719e-01, -2.7149e-01,  1.1339e-01,  2.6736e-01,
         1.9156e-02, -1.9051e-01,  2.5927e-01,  1.3503e-01,  2.0941e-01],
       device='cuda:0', requires_grad=True) 

encoder.module_2.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0676,  0.0582, -0.0683,  ..., -0.0389, -0.0075, -0.0243],
        [-0.0505, -0.0318, -0.0362,  ..., -0.0803,  0.0202,  0.0546],
        [-0.0497,  0.0110, -0.0001,  ...,  0.0191, -0.0656, -0.0831],
        ...,
        [-0.0074,  0.0704, -0.0032,  ...,  0.0378, -0.0671,  0.0858],
        [-0.0659, -0.0734, -0.0759,  ..., -0.0997,  0.0442,  0.0803],
        [ 0.0599,  0.0649, -0.0803,  ...,  0.0758,  0.0459, -0.0501]],
       device='cuda:0', requires_grad=True) 

encoder.module_2.bias torch.Size([100])
Parameter containing:
tensor([ 0.0145, -0.0630,  0.0150,  0.0989, -0.0193, -0.0575, -0.0487, -0.0621,
         0.0507, -0.0590,  0.0700,  0.0584,  0.0602, -0.0048, -0.0209,  0.0362,
        -0.0149,  0.0402,  0.0223,  0.0348, -0.0427,  0.0620, -0.0192,  0.0568,
        -0.0062, -0.0983, -0.0085, -0.0319, -0.0496, -0.0039, -0.0382,  0.0078,
        -0.0295, -0.0620,  0.0367, -0.0819, -0.0774, -0.0157, -0.0087, -0.0935,
         0.0508,  0.0083,  0.0422, -0.0010, -0.0218, -0.0352, -0.0089, -0.0786,
         0.0439,  0.0284,  0.0715, -0.0934, -0.0104, -0.0392,  0.0031,  0.0153,
        -0.0149, -0.0081, -0.0165,  0.0243, -0.0547, -0.0116,  0.0494,  0.0673,
         0.0112, -0.0110,  0.0168,  0.0460,  0.0184, -0.0582, -0.0788,  0.0465,
        -0.0430,  0.0375, -0.0859,  0.0547,  0.0420, -0.0197, -0.0764, -0.0113,
         0.0566,  0.0756, -0.0037, -0.0083,  0.0820,  0.0174,  0.0955,  0.0905,
        -0.0649, -0.0705, -0.0332, -0.0153,  0.0905, -0.0752,  0.0446,  0.0767,
         0.0063, -0.0838, -0.0755,  0.0149], device='cuda:0',
       requires_grad=True) 

encoder.module_4.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0289,  0.0232,  0.0622,  ...,  0.0261,  0.0347, -0.0602],
        [ 0.0742,  0.0714,  0.0718,  ...,  0.0190,  0.0631,  0.0773],
        [-0.0054,  0.0942,  0.0529,  ...,  0.0854,  0.0579,  0.0485],
        ...,
        [ 0.0471, -0.0361,  0.0076,  ..., -0.0676,  0.0494,  0.0069],
        [-0.0143, -0.0962, -0.0361,  ...,  0.0344,  0.0385,  0.0660],
        [ 0.0767,  0.0771,  0.0321,  ..., -0.0601, -0.0242,  0.0472]],
       device='cuda:0', requires_grad=True) 

encoder.module_4.bias torch.Size([16])
Parameter containing:
tensor([-0.0685, -0.0025,  0.0810,  0.0698, -0.0802, -0.0469,  0.0161,  0.0632,
        -0.0402, -0.0908, -0.0037,  0.0627, -0.0514, -0.0921,  0.0069,  0.0831],
       device='cuda:0', requires_grad=True) 

model.module_0.bias torch.Size([8])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

model.module_0.lin.weight torch.Size([8, 16])
Parameter containing:
tensor([[ 0.2651,  0.3917, -0.4502, -0.4519,  0.2732, -0.1123,  0.2126,  0.4647,
         -0.1142, -0.2656,  0.4685, -0.2397, -0.2865,  0.4013, -0.0206, -0.2439],
        [ 0.1783, -0.2527,  0.0182, -0.3939, -0.1207,  0.3879,  0.0720, -0.0677,
          0.3792,  0.2708,  0.2806,  0.2373, -0.1711, -0.4451, -0.2961, -0.2972],
        [ 0.1392,  0.4010,  0.4622,  0.4004,  0.0709,  0.3443,  0.0251,  0.2322,
         -0.3310,  0.4816,  0.2311,  0.0007, -0.1985,  0.0876, -0.0576, -0.3236],
        [-0.3098, -0.1994,  0.1148, -0.3224,  0.2756, -0.2754,  0.3006,  0.0172,
          0.0009,  0.0675, -0.0038,  0.2471, -0.0400, -0.1765,  0.0521, -0.2928],
        [ 0.2001,  0.0503,  0.2522, -0.0877, -0.0028, -0.2381, -0.2245,  0.0124,
          0.2560, -0.1892,  0.3929, -0.1688, -0.1028,  0.4007, -0.0908,  0.2719],
        [-0.0492,  0.2972,  0.0650, -0.2356, -0.3294,  0.2968,  0.1229, -0.0777,
         -0.0955, -0.2075, -0.3463,  0.1109, -0.4251, -0.0066,  0.3573,  0.2281],
        [ 0.2701,  0.0924, -0.2797,  0.2549,  0.3902,  0.2047,  0.3483, -0.4037,
         -0.4351, -0.1158,  0.1316,  0.3213, -0.1468, -0.2213,  0.3225, -0.0153],
        [ 0.0339, -0.4771, -0.0464,  0.2426,  0.4828,  0.0466,  0.3176,  0.0695,
         -0.3946, -0.0168, -0.1709, -0.0679, -0.1945,  0.3738, -0.4082, -0.3005]],
       device='cuda:0', requires_grad=True) 

model.module_1.weight torch.Size([100, 8])
Parameter containing:
tensor([[-1.0978e-01,  2.9621e-01, -7.2348e-02,  1.4427e-01,  1.7334e-01,
          3.0261e-01, -8.1234e-02,  6.6046e-02],
        [-1.7256e-01, -2.6874e-02, -3.0299e-01, -2.8848e-01,  9.6164e-02,
         -2.7097e-01,  1.8479e-01,  2.6131e-01],
        [ 1.2406e-01,  1.3534e-01, -3.2122e-01, -1.6350e-01, -2.5528e-01,
         -3.3525e-01,  1.5030e-01,  8.0955e-02],
        [ 3.3640e-01, -9.7408e-02, -2.3409e-01, -3.0435e-01,  2.1772e-02,
         -1.9376e-01,  6.2723e-02,  2.3387e-01],
        [ 3.0230e-01, -5.7662e-02, -2.2990e-01, -1.9198e-01,  2.2453e-01,
          9.1495e-02,  2.2386e-02, -3.4351e-01],
        [ 1.9043e-01,  2.2366e-01,  3.6487e-02, -6.3708e-02, -1.6777e-01,
          2.8877e-03,  1.7564e-02,  9.9735e-02],
        [-1.4985e-02,  3.3520e-01,  2.2790e-01,  7.9821e-02, -3.1388e-01,
         -1.6881e-01,  1.3834e-01, -2.2849e-01],
        [ 9.8568e-02,  8.6824e-02, -2.2228e-01,  7.0133e-02, -4.5727e-02,
          2.6334e-01, -7.8000e-02,  3.0854e-01],
        [ 3.0718e-01, -1.1722e-01,  5.9325e-02, -9.6647e-02,  2.8312e-01,
          1.6951e-01,  9.6917e-04,  2.1381e-01],
        [-2.8388e-01, -9.0414e-02,  7.2170e-02, -3.3496e-01,  3.0902e-01,
          2.9047e-02,  3.1234e-01, -1.0290e-01],
        [ 2.1051e-02, -9.7511e-02, -1.4495e-01, -1.3101e-01,  2.4452e-01,
          3.1767e-01,  1.0174e-01,  1.9742e-01],
        [ 1.5379e-01,  4.4313e-04, -2.6316e-01,  8.8693e-02, -1.2149e-01,
          1.3537e-01, -2.3005e-01, -2.4031e-02],
        [-1.3897e-01, -3.2707e-01, -3.2686e-01,  3.2620e-01, -3.8463e-04,
         -3.0478e-01,  5.7974e-02, -2.2189e-02],
        [ 2.9126e-01,  3.3321e-01, -9.0874e-02, -2.1215e-01, -2.0261e-01,
         -9.4006e-02, -1.9408e-01,  3.1867e-01],
        [-1.3514e-01,  1.8215e-01,  1.6000e-01,  8.2664e-02,  1.7236e-01,
          2.9939e-01,  1.5043e-01,  1.5557e-01],
        [-2.9665e-01, -3.1333e-02,  8.1635e-03,  2.7689e-01,  1.5107e-01,
          2.7496e-01,  2.7347e-01, -1.6492e-01],
        [ 5.0157e-02,  3.3712e-01,  1.2499e-01,  1.9990e-01,  1.4371e-01,
         -1.1098e-01,  8.4426e-02, -2.4429e-01],
        [ 3.2617e-01,  2.0229e-02,  2.7398e-01, -2.4854e-01, -3.2479e-01,
          4.2333e-02, -4.5297e-02, -1.4301e-01],
        [ 1.8524e-01, -2.2999e-01,  3.0981e-01, -3.4514e-01,  7.2507e-02,
         -2.0672e-01,  7.6700e-02,  3.4916e-01],
        [-4.2436e-02,  8.2207e-02, -1.3914e-01, -1.8142e-01, -3.0201e-01,
          2.0407e-01, -3.9265e-03,  1.2243e-01],
        [-2.7192e-01, -2.9436e-01, -3.2148e-01, -2.0375e-01, -4.5971e-02,
         -5.3346e-02,  1.5546e-01, -1.6988e-01],
        [ 3.4450e-01, -1.6112e-01, -3.3248e-01,  2.6745e-01, -2.2722e-01,
          3.3695e-02, -3.4134e-02, -7.3750e-02],
        [ 2.2907e-04, -3.4767e-01,  3.1793e-01, -2.2952e-01,  2.1556e-01,
         -2.0906e-01, -8.7061e-02, -8.3615e-03],
        [-1.3935e-01, -1.5317e-01, -2.9760e-01, -2.4283e-01, -1.6589e-02,
         -1.0335e-01, -4.9652e-02,  9.0191e-02],
        [-4.5326e-02, -3.3469e-01, -1.3003e-01,  1.0822e-01,  1.2724e-01,
          1.7109e-01,  1.9579e-02,  2.4172e-01],
        [-2.4194e-01, -2.9670e-01, -9.4266e-02,  2.3843e-03,  2.5670e-01,
         -2.0389e-01, -2.4761e-01, -9.5649e-03],
        [ 8.9909e-02, -3.2247e-01, -1.4252e-01, -2.7773e-01,  8.2623e-02,
          3.2981e-02, -3.1440e-01, -2.3543e-01],
        [ 1.6349e-02, -9.3688e-02, -2.7346e-01, -1.0714e-01, -3.2470e-01,
         -4.0371e-02, -4.1210e-02,  1.8533e-02],
        [ 3.0029e-02, -6.1585e-02,  2.8215e-01, -1.2658e-01,  1.5978e-01,
          1.3348e-01, -4.3336e-02, -2.5910e-01],
        [-2.9791e-01,  9.7866e-02,  1.0809e-01,  2.1443e-01, -1.5650e-01,
          2.8545e-01,  3.5351e-01, -5.6234e-02],
        [-1.3778e-01, -1.1105e-01, -3.0738e-01,  2.0382e-01,  3.8531e-02,
          1.6289e-01,  2.2716e-01, -1.5015e-01],
        [ 3.2922e-03,  2.8581e-01, -2.7256e-01,  3.1085e-01,  1.8385e-01,
         -1.1104e-01, -2.8868e-01,  1.8884e-01],
        [ 1.6868e-01, -1.6011e-01,  1.6832e-01,  1.0493e-01,  3.4802e-01,
          1.8085e-01,  5.4585e-02, -3.4995e-01],
        [ 2.8774e-01,  3.0356e-01, -9.8001e-02, -2.7648e-02, -1.3774e-02,
         -2.1589e-02,  1.9220e-01,  4.7789e-02],
        [-3.0748e-01,  1.1375e-01, -2.1717e-01,  1.0094e-01,  1.5390e-01,
         -1.6882e-01,  2.3951e-01,  9.0288e-03],
        [-1.7782e-01,  3.0296e-01,  2.2592e-01,  2.5854e-01, -2.4343e-01,
         -2.6945e-01, -3.1086e-01,  2.2858e-01],
        [ 2.0620e-01, -2.1552e-01,  1.3860e-01,  7.1063e-02, -1.5050e-01,
          1.2134e-02, -2.1330e-01, -1.0351e-01],
        [ 1.3980e-01,  4.9927e-02, -2.6311e-01,  8.8973e-02, -7.0552e-02,
         -2.5973e-01, -3.2689e-01,  1.5247e-02],
        [-2.6021e-01, -2.1612e-01,  8.5194e-02,  2.1801e-02, -1.6007e-01,
          5.4810e-02,  1.7811e-01, -1.3652e-01],
        [-1.2609e-01,  6.2430e-02,  8.6483e-02,  1.2220e-01,  2.4077e-01,
         -2.3633e-02,  1.1745e-01, -2.0345e-01],
        [-4.5085e-02,  2.6190e-01, -3.4250e-01, -2.3257e-01, -3.0562e-01,
          2.9417e-01, -3.9916e-02,  3.2381e-01],
        [-1.9056e-01, -9.6141e-02,  2.2756e-01, -3.5213e-01, -3.4456e-01,
         -2.3676e-01,  6.0155e-03, -3.2526e-01],
        [ 6.5462e-02,  2.9901e-01, -7.1662e-02, -6.2251e-02, -3.1115e-01,
         -7.4736e-02,  2.9242e-02,  7.2375e-02],
        [-1.1643e-01, -2.1606e-01, -1.8523e-01,  2.4378e-01, -1.9234e-01,
          2.7487e-02, -6.2144e-02, -1.4216e-01],
        [-1.5272e-02,  2.6724e-01,  2.6770e-01, -7.3850e-02, -7.1112e-02,
         -1.9805e-01, -1.6445e-01, -6.0395e-02],
        [ 2.6235e-01,  5.0368e-02, -3.0260e-01, -9.0882e-02, -3.0543e-01,
          3.2673e-01,  3.2733e-02, -8.9736e-02],
        [ 1.4177e-01, -3.3144e-01, -1.1672e-01,  3.3166e-02,  2.5512e-01,
          2.8838e-01, -1.1818e-02, -3.5342e-01],
        [ 6.5313e-02, -1.9938e-01,  3.1888e-01, -9.5198e-02, -9.6219e-02,
         -5.2510e-02,  3.2770e-01,  1.5504e-01],
        [-2.4382e-01,  6.1957e-02,  1.1242e-01, -9.1831e-02,  1.1737e-01,
         -3.1736e-01, -1.8225e-01,  2.2586e-01],
        [ 3.2846e-01,  1.1231e-01, -2.0030e-01,  1.2885e-01, -2.0364e-01,
         -2.8329e-01, -2.3329e-01, -3.3509e-02],
        [ 7.5078e-02,  2.6324e-02,  3.3980e-01, -2.5086e-02,  3.2524e-01,
         -2.6276e-01, -1.8201e-01,  4.8474e-02],
        [ 2.1072e-01,  1.0494e-01,  3.4671e-01, -1.8846e-01,  3.3087e-01,
          1.1288e-01,  9.3351e-02, -9.0644e-03],
        [-2.5448e-01,  1.8914e-01,  7.6684e-02,  2.4372e-01,  2.6018e-01,
         -3.0028e-01,  3.2752e-01, -8.1414e-02],
        [-2.3686e-01,  3.0858e-01, -5.5915e-02,  5.8256e-02,  5.3068e-02,
         -1.9018e-01,  2.2420e-01,  1.3406e-01],
        [ 2.8478e-01, -9.8263e-02, -2.5942e-01,  6.9250e-02, -9.4996e-02,
          1.8254e-04, -2.8755e-01,  3.1708e-01],
        [-1.8594e-01, -3.1942e-02,  8.9711e-03, -1.5359e-01,  2.1006e-01,
         -2.8808e-01, -4.7558e-02, -2.2896e-01],
        [ 2.0965e-01, -2.5739e-01,  2.7992e-01, -3.0579e-01, -3.5336e-01,
          8.6224e-03, -3.4806e-01,  3.2934e-01],
        [ 3.3025e-01, -1.6145e-01,  2.6427e-01, -1.3597e-01,  8.6490e-02,
         -2.4781e-01, -2.3935e-02, -1.0795e-01],
        [ 7.9318e-02,  1.1366e-01, -3.3000e-01,  2.3890e-02,  2.7378e-01,
          2.8483e-01,  1.6008e-01,  8.1867e-03],
        [ 2.4257e-01,  1.8762e-01, -2.3256e-01, -2.0168e-02, -3.2753e-01,
          2.4894e-02,  2.6849e-02, -2.3277e-01],
        [ 8.4436e-02,  2.4450e-01, -3.0083e-01, -3.1494e-01, -1.7277e-01,
          4.5813e-02, -3.4315e-01, -7.0363e-02],
        [ 2.7146e-01, -2.9180e-01, -9.4440e-02, -7.4739e-02,  2.1368e-01,
         -1.3147e-01,  2.6840e-01, -1.7720e-01],
        [ 1.3117e-01, -6.5346e-02,  3.0777e-01, -1.7335e-01, -1.3284e-01,
          3.1888e-01, -2.8008e-01,  9.9959e-02],
        [ 1.7574e-01, -3.0706e-02,  3.1084e-01, -3.2884e-01, -5.1345e-02,
         -1.8604e-01,  1.3930e-01,  3.4569e-01],
        [-3.4608e-01, -1.5760e-01, -2.6182e-01, -1.9831e-01,  1.0689e-01,
          5.2120e-03, -2.7692e-01, -2.1680e-01],
        [-2.3156e-01,  2.6824e-02, -2.9117e-01, -2.7645e-01, -2.8327e-01,
          2.8518e-01,  2.5823e-01, -1.6729e-01],
        [ 8.2989e-02, -4.9378e-02, -1.4209e-01,  1.6486e-01, -2.3781e-01,
         -1.1667e-03,  2.6422e-01, -3.0702e-01],
        [ 2.9150e-01,  2.3354e-01,  1.5635e-01, -4.6198e-02, -1.3752e-01,
         -1.9411e-01, -2.5634e-01, -3.4464e-01],
        [-5.0716e-02,  7.0292e-02, -3.4223e-01,  3.4803e-01, -2.5262e-01,
          2.7910e-02, -1.1983e-01,  3.2177e-01],
        [-1.5391e-01,  9.2357e-02,  1.1269e-01,  1.6213e-01, -2.4786e-01,
         -1.9580e-01,  3.9397e-03, -3.4873e-01],
        [-1.3797e-01, -2.9666e-01,  1.5628e-01,  3.6636e-02, -3.3039e-01,
          3.4576e-01,  1.4494e-01, -2.0263e-01],
        [-3.5597e-02,  2.3976e-01, -2.1012e-01,  8.8422e-02,  1.1498e-01,
         -2.2729e-01, -1.8580e-01, -6.2697e-02],
        [-2.7657e-01,  3.0426e-01,  1.0095e-01, -1.1254e-01, -4.1566e-03,
          3.8640e-03,  1.1709e-01,  2.5113e-01],
        [-2.9712e-01, -1.2576e-01,  1.2748e-01, -1.9747e-01, -1.7418e-02,
         -1.0344e-01,  2.0258e-01, -1.8957e-01],
        [ 3.1860e-01,  1.6810e-01, -2.5349e-01, -7.0291e-02, -3.3165e-02,
         -3.4607e-01, -3.0301e-01,  2.9253e-01],
        [ 2.5403e-01, -2.4077e-01, -3.4799e-03,  9.4997e-02,  2.1573e-01,
          3.1317e-01,  2.2180e-01,  2.9321e-01],
        [-2.2922e-01, -8.0584e-02,  1.6917e-01, -2.7215e-01, -3.4238e-01,
          1.9928e-01,  2.5779e-01,  1.4130e-01],
        [ 2.2456e-01,  1.6542e-01,  4.7867e-02, -7.9599e-02,  4.8749e-02,
         -1.2331e-01,  2.8705e-01,  2.9863e-01],
        [-1.0831e-01,  1.5603e-01, -9.5992e-02,  2.8289e-01, -3.1805e-01,
          5.0306e-02, -2.7196e-02,  2.4140e-01],
        [ 3.7468e-02,  6.7080e-02, -3.4620e-01, -1.9451e-01,  3.3002e-01,
         -3.1686e-02,  1.5113e-01, -2.8905e-01],
        [ 1.8203e-01, -1.5382e-01, -3.6279e-02,  3.3315e-01,  2.5045e-01,
         -3.1000e-01, -1.5860e-01,  2.0861e-01],
        [-6.4968e-02,  2.7917e-01,  1.4526e-01, -3.9216e-02, -2.2043e-01,
          2.0291e-02,  2.7887e-01,  2.7170e-01],
        [-1.5258e-01, -9.7712e-02,  1.1403e-01, -3.0051e-01,  4.7237e-02,
          9.0318e-02,  3.4699e-01, -4.3776e-02],
        [ 3.4398e-01,  3.4387e-01, -1.8193e-01,  5.4965e-02,  2.0265e-01,
         -4.1058e-02, -1.9365e-01,  7.5388e-02],
        [ 1.5581e-01, -2.8647e-01, -2.8490e-01, -2.6678e-01, -2.7093e-01,
          3.0957e-01, -1.5726e-01, -4.1988e-02],
        [-9.4088e-02, -1.8173e-01,  2.9913e-01, -1.2624e-01,  2.1470e-01,
         -1.6338e-01,  3.4678e-01,  8.9356e-02],
        [-6.2403e-02,  2.4897e-03,  1.4648e-01, -1.8988e-01, -1.0486e-01,
         -2.6235e-01, -2.3712e-01,  1.7006e-01],
        [-2.9601e-02, -1.7648e-01,  1.6436e-02,  2.0173e-01,  3.2470e-01,
         -2.0697e-01,  1.4430e-01,  3.3788e-02],
        [-1.7943e-01,  7.8361e-02,  3.9725e-02,  2.0894e-01,  2.8930e-01,
          1.6606e-01,  6.6893e-02, -2.6563e-01],
        [-2.9601e-01,  1.6564e-01, -2.1690e-01,  4.8882e-03,  2.7217e-01,
          1.7746e-01, -4.4915e-02,  5.5719e-02],
        [ 1.2162e-02,  3.0517e-02,  3.0831e-01, -2.1630e-01,  3.0777e-01,
          1.6970e-02,  3.3531e-01, -1.5074e-01],
        [ 2.1734e-01, -1.9437e-01, -2.8968e-01,  2.5699e-01,  1.2221e-01,
          3.4756e-01,  1.4330e-01, -1.4916e-01],
        [-2.1027e-01,  2.8939e-01, -7.0089e-02, -2.1006e-01, -2.6113e-01,
         -2.3667e-01, -1.4851e-01, -2.8426e-01],
        [ 3.4028e-01,  4.0850e-02,  1.1664e-01, -1.7394e-01,  9.9650e-03,
          2.4099e-01, -1.1982e-01,  2.8545e-01],
        [-1.0992e-01, -1.3218e-01, -2.6023e-01, -3.5040e-01,  1.5415e-01,
         -2.2809e-01, -1.9384e-01, -1.4463e-01],
        [-2.7040e-01, -2.7177e-01, -2.3083e-01,  3.4469e-01,  2.0540e-02,
         -1.3324e-01, -2.9475e-02,  2.9555e-01],
        [-2.0565e-01,  1.4279e-01, -6.5871e-02, -3.0039e-01,  2.3384e-01,
          1.6333e-01,  2.5985e-01,  1.6187e-01],
        [ 5.7608e-02,  1.0870e-01, -2.6395e-01,  3.4071e-01, -2.2774e-01,
          2.4943e-01, -2.2386e-01, -2.5551e-01],
        [ 1.4571e-01,  2.3171e-01, -9.6297e-02,  9.9023e-02, -3.0817e-01,
         -3.9701e-02,  3.1194e-01,  3.3036e-01],
        [-1.1258e-01,  1.3063e-01,  3.2607e-01,  1.3112e-01,  6.4811e-02,
         -2.8489e-01,  1.0164e-01,  9.4391e-02]], device='cuda:0',
       requires_grad=True) 

model.module_1.bias torch.Size([100])
Parameter containing:
tensor([-0.1992,  0.1765, -0.2306,  0.3385, -0.0178,  0.2407, -0.0928, -0.1796,
         0.2572,  0.2147,  0.3472,  0.1039, -0.1484, -0.2076, -0.3374,  0.0224,
         0.3385, -0.1172, -0.0682,  0.2490,  0.3145,  0.0960,  0.0281,  0.3457,
         0.2961, -0.2250, -0.2467, -0.0811,  0.1401, -0.2164, -0.1513,  0.0293,
        -0.0893,  0.2372,  0.2239,  0.2435,  0.1881, -0.2045, -0.2721, -0.2376,
        -0.0453,  0.2779, -0.0785,  0.3253,  0.2639, -0.3356,  0.1633, -0.1491,
        -0.3373,  0.1239, -0.1215, -0.3141, -0.2488,  0.2601, -0.0847,  0.2771,
        -0.1227,  0.3454, -0.0885,  0.3346,  0.1371, -0.2657,  0.1545,  0.1485,
        -0.2968, -0.3057,  0.0205,  0.1915,  0.3012, -0.0980, -0.3311,  0.1615,
         0.0247,  0.0090,  0.2232,  0.0422,  0.3065,  0.2714,  0.0905,  0.2634,
         0.1132, -0.3355,  0.3173,  0.0108, -0.0437,  0.2914,  0.3084, -0.2798,
         0.1393, -0.1944, -0.0908,  0.0760, -0.1312, -0.1493,  0.1760, -0.0850,
         0.1335,  0.3390,  0.0858,  0.0822], device='cuda:0',
       requires_grad=True) 

model.module_3.weight torch.Size([100, 100])
Parameter containing:
tensor([[ 0.0877, -0.0376,  0.0001,  ..., -0.0924, -0.0907,  0.0484],
        [ 0.0663, -0.0634,  0.0700,  ..., -0.0131,  0.0399, -0.0855],
        [-0.0155, -0.0633, -0.0284,  ..., -0.0400, -0.0868,  0.0892],
        ...,
        [ 0.0409, -0.0376, -0.0461,  ...,  0.0028, -0.0118, -0.0273],
        [-0.0154, -0.0118, -0.0487,  ..., -0.0799,  0.0029,  0.0092],
        [ 0.0618,  0.0168,  0.0028,  ...,  0.0698,  0.0707,  0.0514]],
       device='cuda:0', requires_grad=True) 

model.module_3.bias torch.Size([100])
Parameter containing:
tensor([ 0.0151, -0.0352,  0.0715, -0.0165, -0.0343,  0.0779, -0.0243,  0.0457,
         0.0425, -0.0381,  0.0662, -0.0078,  0.0526, -0.0656,  0.0346,  0.0815,
        -0.0452,  0.0941, -0.0622,  0.0310,  0.0318,  0.0004,  0.0350,  0.0275,
        -0.0443, -0.0816, -0.0724, -0.0022,  0.0005, -0.0123, -0.0023, -0.0847,
        -0.0927, -0.0366, -0.0876,  0.0505, -0.0313, -0.0466,  0.0120,  0.0203,
         0.0521,  0.0041,  0.0344,  0.0235,  0.0865,  0.0286,  0.0375,  0.0029,
         0.0435, -0.0047, -0.0482, -0.0575,  0.0593,  0.0079,  0.0977,  0.0581,
         0.0868, -0.0117,  0.0637,  0.0134,  0.0213,  0.0293, -0.0604,  0.0897,
         0.0367, -0.0217, -0.0743, -0.0554, -0.0088,  0.0182,  0.0384,  0.0982,
         0.0717, -0.0040, -0.0188,  0.0813,  0.0020,  0.0191, -0.0051,  0.0849,
         0.0547,  0.0443,  0.0369, -0.0110,  0.0320, -0.0705, -0.0654,  0.0329,
         0.0228, -0.0655,  0.0404,  0.0443,  0.0590, -0.0459, -0.0526, -0.0017,
        -0.0054, -0.0003, -0.0706,  0.0747], device='cuda:0',
       requires_grad=True) 

model.module_5.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 9.9035e-02, -4.2346e-02,  7.5904e-02,  ...,  4.6844e-02,
          9.2413e-02,  5.7740e-02],
        [ 2.4877e-02,  6.7250e-02,  8.8722e-02,  ...,  9.0003e-02,
         -9.9207e-02,  6.3747e-02],
        [-4.1799e-02, -7.7012e-02,  2.8124e-02,  ...,  4.2493e-02,
          6.3022e-02, -4.7302e-05],
        ...,
        [ 4.8377e-02, -6.7857e-02, -4.6368e-02,  ..., -4.0804e-02,
          6.4716e-02,  9.0501e-02],
        [ 3.2165e-02,  8.8483e-02,  3.8556e-02,  ...,  4.5120e-02,
          9.3309e-03,  9.7113e-02],
        [-4.3749e-02,  8.6016e-02,  8.1729e-02,  ..., -8.5541e-04,
         -8.0956e-02,  1.6567e-02]], device='cuda:0', requires_grad=True) 

model.module_5.bias torch.Size([16])
Parameter containing:
tensor([-0.0548, -0.0687,  0.0105,  0.0376, -0.0520, -0.0286, -0.0390,  0.0755,
         0.0248, -0.0216, -0.0320, -0.0364, -0.0034,  0.0241, -0.0386, -0.0416],
       device='cuda:0', requires_grad=True) 

model.module_7.bias torch.Size([8])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

model.module_7.lin.weight torch.Size([8, 16])
Parameter containing:
tensor([[-0.2048, -0.1157,  0.3670, -0.0839,  0.0033, -0.4975,  0.2177,  0.3551,
         -0.4864,  0.4818,  0.3354,  0.2536, -0.0168, -0.0533,  0.4545,  0.2446],
        [-0.2830, -0.2740,  0.4465, -0.2645, -0.1728, -0.3581,  0.1540, -0.0986,
          0.4480, -0.2253,  0.1461, -0.3284, -0.3442, -0.4635,  0.0071,  0.1195],
        [ 0.2123,  0.4897,  0.2421,  0.0008,  0.2774, -0.4650,  0.4799, -0.4230,
          0.2898, -0.3021,  0.4774,  0.1400,  0.2382,  0.1575, -0.2249,  0.0252],
        [ 0.1325,  0.1534,  0.1510,  0.4108, -0.0646, -0.3080,  0.2369,  0.3774,
          0.3605, -0.3404, -0.0066,  0.1204, -0.0100,  0.2295, -0.4638,  0.2749],
        [-0.1478,  0.0908, -0.1043, -0.4483,  0.1973,  0.0090, -0.0455,  0.3868,
          0.4277, -0.2161, -0.1344, -0.1504, -0.3551, -0.4509, -0.2230, -0.2842],
        [-0.0753, -0.0436,  0.3544, -0.0437,  0.2619, -0.4816, -0.0479, -0.0772,
          0.1560,  0.3439,  0.3364,  0.0970,  0.2146,  0.3645,  0.4138,  0.2047],
        [-0.3452,  0.3288,  0.1435,  0.3482,  0.1628,  0.1379,  0.0387,  0.3232,
          0.3972,  0.4950, -0.4268,  0.2489,  0.4032, -0.2594, -0.4376,  0.2620],
        [ 0.0569,  0.4096,  0.2099,  0.3815, -0.4184, -0.1531, -0.4750,  0.0773,
          0.3299, -0.3531,  0.3310, -0.4383,  0.3372, -0.4178, -0.3892, -0.2540]],
       device='cuda:0', requires_grad=True) 

model.module_8.weight torch.Size([100, 8])
Parameter containing:
tensor([[ 0.1004, -0.3202,  0.1673, -0.3319, -0.0285, -0.1131, -0.0659, -0.2273],
        [ 0.3444,  0.3258, -0.3527, -0.0496, -0.2741, -0.2997, -0.1194,  0.2239],
        [-0.3273,  0.3275,  0.3116,  0.1479,  0.2649,  0.0577,  0.1746,  0.1826],
        [-0.3154,  0.0906, -0.0129, -0.3415,  0.2745, -0.1115,  0.0487, -0.1783],
        [ 0.2253,  0.0220, -0.1330, -0.1586,  0.0886, -0.3097,  0.1501, -0.2989],
        [-0.2223,  0.0484, -0.1903,  0.1145, -0.2275, -0.1150,  0.1414,  0.1839],
        [-0.0815,  0.1217, -0.2755, -0.0711,  0.2213, -0.0308, -0.3092, -0.0344],
        [-0.0528,  0.1213, -0.0733, -0.2439,  0.0699,  0.2609, -0.0838,  0.1024],
        [ 0.0588,  0.0559, -0.0536, -0.0217, -0.3406,  0.2097, -0.2120, -0.2754],
        [-0.2122,  0.1011, -0.0711, -0.2071,  0.1965, -0.1738, -0.2475,  0.1703],
        [-0.1478, -0.2322, -0.1068, -0.1732,  0.0041, -0.1528,  0.0122, -0.0218],
        [ 0.2433,  0.2212, -0.1720,  0.1350, -0.3148, -0.2771, -0.2412, -0.1514],
        [-0.3372,  0.2058,  0.2967, -0.2754, -0.3233, -0.1064,  0.2763,  0.0960],
        [ 0.0200,  0.3375,  0.2820,  0.1690, -0.1803, -0.0894, -0.0580, -0.0629],
        [ 0.0836,  0.2220, -0.1992, -0.3439, -0.3088,  0.0937, -0.2286,  0.1752],
        [ 0.1115,  0.1058, -0.1345,  0.1773,  0.2437,  0.1136,  0.0211,  0.1520],
        [ 0.0408,  0.0872,  0.1421,  0.3164, -0.0590,  0.1795,  0.2729, -0.2864],
        [-0.0075, -0.2959, -0.2640,  0.2250, -0.2726,  0.3309,  0.3139, -0.2354],
        [-0.3138, -0.0575, -0.3200,  0.1830, -0.1201,  0.0794, -0.0045, -0.0318],
        [-0.1980,  0.0943,  0.1334,  0.0272, -0.0174, -0.1344, -0.1572,  0.1005],
        [ 0.1444, -0.1456, -0.1553,  0.2988,  0.2269, -0.3357, -0.2056, -0.0105],
        [-0.1481,  0.0335, -0.1307, -0.3535, -0.2557,  0.2240,  0.0614,  0.3270],
        [ 0.2945, -0.0379,  0.2006, -0.0559,  0.1750, -0.2756, -0.1220,  0.0113],
        [ 0.0574,  0.1217,  0.3198,  0.3013, -0.2438, -0.0514, -0.0133,  0.1297],
        [-0.2389,  0.1500,  0.1110,  0.2116, -0.1021,  0.0510,  0.1905,  0.3177],
        [-0.1046,  0.1952, -0.1240,  0.1715, -0.1125,  0.0654, -0.2816,  0.1119],
        [-0.2518, -0.1930, -0.1333, -0.1180,  0.2680,  0.2716,  0.2043, -0.1912],
        [ 0.2602,  0.3305, -0.0472, -0.2030,  0.2840,  0.3239,  0.1250, -0.3468],
        [-0.2397,  0.2397, -0.3182,  0.1484,  0.2060, -0.1068, -0.3338, -0.3058],
        [ 0.2911,  0.1345,  0.1692, -0.1825, -0.1418,  0.1895, -0.2412,  0.1836],
        [-0.0149,  0.2123, -0.2020, -0.1355, -0.2644,  0.1927, -0.0718, -0.1217],
        [-0.3442,  0.2986,  0.3237, -0.2040, -0.0628, -0.1168, -0.2229, -0.2493],
        [-0.0465,  0.1654, -0.2370,  0.3507, -0.0545, -0.2453, -0.2046,  0.3521],
        [-0.0566,  0.2004,  0.0336,  0.2916, -0.2632,  0.1125,  0.1517, -0.1007],
        [-0.2119, -0.0669, -0.0342, -0.2061, -0.2890,  0.1193,  0.0435, -0.2153],
        [-0.0989, -0.0219,  0.1632,  0.1377,  0.3101,  0.0353,  0.1067, -0.2643],
        [ 0.1503, -0.1509,  0.2589,  0.0931, -0.0332, -0.1253,  0.1700,  0.1458],
        [ 0.0968,  0.0566, -0.2761, -0.1852, -0.3517, -0.1235, -0.1640, -0.0704],
        [ 0.2577,  0.0854,  0.1561,  0.1498,  0.2880,  0.2810,  0.0717,  0.3020],
        [-0.3145,  0.1909,  0.2365, -0.3351, -0.3009, -0.0567,  0.1513,  0.2984],
        [-0.3217,  0.3228, -0.0271, -0.0815, -0.0900,  0.2332,  0.1651,  0.0320],
        [-0.2962, -0.0265, -0.2856, -0.3510,  0.1219, -0.0891, -0.3382, -0.2933],
        [ 0.3394,  0.3308, -0.2493, -0.1774,  0.2128, -0.0746, -0.0287, -0.1053],
        [ 0.1710, -0.3288, -0.3213,  0.1357,  0.1761,  0.1978, -0.1049, -0.1557],
        [-0.1714, -0.1909, -0.3081,  0.1343, -0.1552, -0.3431,  0.0557,  0.2827],
        [-0.0146, -0.2879,  0.1882, -0.1931,  0.2226, -0.2432,  0.3206, -0.0856],
        [ 0.3247,  0.1670,  0.2628,  0.0643, -0.2059,  0.0370,  0.2888, -0.3073],
        [ 0.0976,  0.0521,  0.2370, -0.2427, -0.2593,  0.0954, -0.1001, -0.1214],
        [ 0.0795,  0.2800, -0.2650, -0.0182, -0.1474, -0.0435, -0.1546,  0.3368],
        [ 0.1965,  0.0766, -0.0997,  0.2188, -0.1961, -0.3179, -0.2372, -0.1045],
        [-0.2423,  0.2251, -0.0190, -0.1327, -0.2417,  0.3091,  0.3252, -0.2126],
        [ 0.2938, -0.0319, -0.1307,  0.1316, -0.2765, -0.3234, -0.0293,  0.2331],
        [ 0.2565,  0.3021,  0.1825,  0.0886,  0.0498, -0.2130,  0.2893,  0.2922],
        [-0.3046, -0.3357, -0.0856, -0.2264, -0.1241,  0.3073, -0.0697,  0.3197],
        [-0.0308,  0.0288, -0.0144, -0.1049, -0.0594, -0.1661, -0.2551,  0.0259],
        [ 0.0757,  0.0800,  0.0832, -0.1313, -0.3377,  0.1696,  0.0663, -0.3353],
        [ 0.3350, -0.0866, -0.2911, -0.2162, -0.0903, -0.2786,  0.0642, -0.1862],
        [-0.1918,  0.3091, -0.1180, -0.0111, -0.2031, -0.0414, -0.2233, -0.1970],
        [-0.2321, -0.1306,  0.0820,  0.1546,  0.2046, -0.1708, -0.2644, -0.0525],
        [ 0.3290,  0.0104,  0.3295,  0.2723,  0.2382, -0.0327,  0.0563, -0.2317],
        [ 0.0562,  0.1256, -0.2233, -0.2479, -0.1788,  0.0040, -0.0644,  0.1401],
        [-0.1770,  0.3314, -0.1698,  0.2158,  0.3147,  0.3215, -0.1720, -0.1874],
        [-0.1507, -0.2363, -0.0912, -0.1027,  0.1291,  0.3063,  0.1303,  0.0037],
        [-0.1251, -0.1042,  0.2995, -0.3049, -0.0445, -0.3420, -0.1276, -0.2615],
        [-0.3435,  0.1192, -0.1838,  0.0779,  0.3103, -0.0592,  0.1280, -0.1452],
        [ 0.2306,  0.3371, -0.1316, -0.2761,  0.2707,  0.2470,  0.1548,  0.0222],
        [ 0.1086,  0.0806,  0.0499, -0.1193,  0.0892,  0.3128, -0.1109, -0.2792],
        [-0.2532, -0.0094,  0.1306,  0.0372,  0.3255,  0.1037,  0.1564, -0.3179],
        [ 0.2081,  0.2322,  0.0739,  0.1307, -0.3280,  0.3271, -0.0262, -0.3473],
        [ 0.1236,  0.2075,  0.2278,  0.3238,  0.0577,  0.2028,  0.3452,  0.1540],
        [ 0.1356, -0.0379, -0.2613,  0.1192, -0.2571,  0.0046, -0.3316, -0.3410],
        [-0.1580, -0.3493,  0.2089,  0.0871, -0.0977,  0.3239,  0.1569,  0.2173],
        [-0.2311, -0.2980, -0.1272,  0.2307, -0.3050, -0.2444,  0.0158,  0.1286],
        [ 0.2004,  0.0649, -0.0519, -0.1360, -0.0081,  0.2227, -0.2863, -0.3265],
        [-0.0358,  0.0178,  0.1708,  0.1343,  0.3398, -0.1276,  0.1174, -0.2410],
        [-0.2491, -0.1870,  0.3076, -0.2380, -0.1272,  0.1055, -0.2327,  0.1204],
        [-0.2732,  0.2945,  0.2656,  0.1525,  0.2567,  0.1957,  0.0905,  0.1119],
        [ 0.0119, -0.1154,  0.0385, -0.2616, -0.3478,  0.0047, -0.1815, -0.1538],
        [ 0.1589, -0.1068,  0.3277, -0.1897, -0.3254,  0.1166,  0.0397,  0.0710],
        [ 0.0902, -0.1003, -0.3480,  0.2291, -0.1246,  0.2854, -0.1785,  0.2797],
        [ 0.0809, -0.0936, -0.1121,  0.3400,  0.2867, -0.3531, -0.1392, -0.0959],
        [ 0.0933, -0.2560, -0.2305,  0.0438,  0.0080, -0.2339,  0.1897,  0.3157],
        [-0.1407,  0.3512,  0.1009,  0.0472, -0.1231,  0.3059,  0.2494, -0.3088],
        [ 0.1010, -0.2357, -0.1769, -0.1877,  0.0027, -0.0979, -0.0849,  0.2498],
        [ 0.0474, -0.2625, -0.1717, -0.2894, -0.1595,  0.2013,  0.1091, -0.1059],
        [ 0.1830,  0.0153,  0.2858, -0.1459, -0.3368, -0.1276, -0.0389,  0.3208],
        [ 0.0692, -0.1515,  0.2021,  0.3166, -0.1960, -0.0586,  0.3507,  0.3164],
        [-0.0191,  0.2106,  0.2060, -0.0119, -0.1546, -0.0040,  0.0207,  0.3297],
        [ 0.1678, -0.1736,  0.3163, -0.1497, -0.1521,  0.2464,  0.1938,  0.2151],
        [ 0.0024, -0.3118,  0.3499,  0.0605,  0.1908,  0.3209,  0.1264,  0.2706],
        [ 0.0230,  0.2817,  0.3075,  0.3214,  0.1185,  0.1723, -0.0498, -0.1015],
        [-0.1897,  0.2069, -0.0960,  0.2401,  0.0311, -0.0891, -0.1567, -0.0608],
        [-0.2043, -0.0843, -0.1041, -0.2351,  0.3223, -0.1222,  0.3031,  0.3174],
        [ 0.1793,  0.3193,  0.1344, -0.3014, -0.1932,  0.0652,  0.0577,  0.0782],
        [-0.1673, -0.2121, -0.0453,  0.1727,  0.1445, -0.0369,  0.1936, -0.2692],
        [-0.2375,  0.1276,  0.3011, -0.2018, -0.2070,  0.1205,  0.0040, -0.2707],
        [-0.2819, -0.2993, -0.1205,  0.0026, -0.0743, -0.0794, -0.2687,  0.2380],
        [ 0.2809,  0.0310,  0.1053,  0.3221, -0.2272,  0.0204, -0.1284, -0.1884],
        [-0.0150, -0.1159, -0.3464,  0.3063, -0.3171,  0.2190,  0.0504,  0.1184],
        [ 0.3359,  0.2328,  0.3392,  0.1078, -0.1422,  0.0174, -0.1632, -0.2249]],
       device='cuda:0', requires_grad=True) 

model.module_8.bias torch.Size([100])
Parameter containing:
tensor([-0.0023, -0.1393,  0.0122, -0.0588, -0.1946,  0.0379, -0.2163, -0.1191,
        -0.1903,  0.2857, -0.1408, -0.2417, -0.0566,  0.1829,  0.0695,  0.3095,
        -0.0318,  0.1067, -0.2523,  0.0228,  0.1417, -0.1098, -0.0498, -0.0108,
        -0.2354, -0.1345, -0.3510, -0.1070, -0.0119, -0.0495, -0.0691, -0.0710,
        -0.0067,  0.2584, -0.0053,  0.2293, -0.1135,  0.1362,  0.0506,  0.0403,
        -0.2320,  0.1757,  0.0579, -0.2580, -0.3054, -0.1103, -0.2029, -0.3159,
        -0.0196, -0.1939, -0.2452,  0.3167,  0.1684,  0.3532,  0.2522, -0.2594,
         0.3149,  0.0660,  0.1143, -0.2904,  0.0311,  0.2409, -0.0490,  0.0560,
        -0.1861,  0.1896, -0.1501,  0.1279, -0.2437,  0.0239,  0.3534, -0.1653,
        -0.2565,  0.1862, -0.2598,  0.0553, -0.2698, -0.2520, -0.3267,  0.1073,
         0.0119, -0.2539, -0.3197,  0.0894,  0.2331, -0.1497,  0.0822,  0.3036,
         0.2704,  0.2330,  0.1344,  0.1885, -0.3380, -0.3028, -0.2130,  0.3055,
         0.3317,  0.3285, -0.1039, -0.3421], device='cuda:0',
       requires_grad=True) 

model.module_10.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0779,  0.0711,  0.0275,  ..., -0.0596,  0.0122,  0.0831],
        [-0.0721,  0.0048, -0.0073,  ..., -0.0547, -0.0395, -0.0324],
        [-0.0858, -0.0476, -0.0004,  ...,  0.0794,  0.0248,  0.0480],
        ...,
        [-0.0894,  0.0715, -0.0499,  ...,  0.0530, -0.0468,  0.0127],
        [ 0.0238,  0.0892, -0.0614,  ..., -0.0696,  0.0608,  0.0498],
        [ 0.0633,  0.0273, -0.0548,  ...,  0.0827,  0.0606,  0.0437]],
       device='cuda:0', requires_grad=True) 

model.module_10.bias torch.Size([100])
Parameter containing:
tensor([ 0.0868,  0.0048,  0.0529, -0.0460, -0.0196,  0.0055,  0.0786,  0.0649,
        -0.0566, -0.0659,  0.0542, -0.0674,  0.0973,  0.0999, -0.0860, -0.0493,
         0.0662,  0.0004, -0.0747,  0.0809, -0.0363, -0.0768,  0.0994, -0.0866,
        -0.0225,  0.0361, -0.0018, -0.0974,  0.0237,  0.0395, -0.0345,  0.0947,
         0.0808,  0.0567, -0.0671, -0.0655,  0.0835,  0.0609, -0.0222,  0.0915,
         0.0925, -0.0048,  0.0924, -0.0245,  0.0458,  0.0851,  0.0296,  0.0011,
        -0.0546, -0.0224, -0.0682, -0.0796, -0.0577,  0.0012, -0.0621, -0.0597,
        -0.0533, -0.0654, -0.0789,  0.0113,  0.0821,  0.0936,  0.0966, -0.0208,
        -0.0980, -0.0312, -0.0208, -0.0471,  0.0386,  0.0969, -0.0389,  0.0945,
        -0.0999, -0.0502,  0.0691,  0.0297,  0.0615, -0.0711, -0.0463, -0.0202,
         0.0932, -0.0992,  0.0316,  0.0676,  0.0488,  0.0594, -0.0070,  0.0208,
        -0.0002, -0.0534,  0.0628, -0.0980, -0.0138,  0.0832, -0.0740, -0.0364,
        -0.0058,  0.0989,  0.0801,  0.0565], device='cuda:0',
       requires_grad=True) 

model.module_12.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0369, -0.0126,  0.0871,  ..., -0.0856,  0.0870,  0.0573],
        [ 0.0900, -0.0628,  0.0206,  ...,  0.0875, -0.0196, -0.0094],
        [-0.0899,  0.0907,  0.0156,  ...,  0.0016,  0.0503, -0.0100],
        ...,
        [-0.0632,  0.0284,  0.0617,  ...,  0.0715,  0.0818,  0.0928],
        [ 0.0039,  0.0577,  0.0623,  ..., -0.0585,  0.0882, -0.0466],
        [ 0.0580,  0.0009, -0.0470,  ..., -0.0757,  0.0586, -0.0288]],
       device='cuda:0', requires_grad=True) 

model.module_12.bias torch.Size([16])
Parameter containing:
tensor([-0.0550, -0.0749,  0.0998,  0.0456,  0.0032, -0.0412, -0.0714,  0.0790,
         0.0740,  0.0118, -0.0278,  0.0266,  0.0097,  0.0202, -0.0174, -0.0394],
       device='cuda:0', requires_grad=True) 

model.module_14.bias torch.Size([8])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

model.module_14.lin.weight torch.Size([8, 16])
Parameter containing:
tensor([[ 0.4076,  0.0885, -0.0581,  0.2209, -0.3901,  0.2601, -0.1700, -0.3474,
         -0.0767,  0.4835, -0.2078, -0.3568,  0.3187, -0.0338, -0.1419,  0.3174],
        [ 0.2188,  0.1669,  0.4805, -0.4349, -0.1734,  0.3464, -0.4216, -0.0805,
          0.1668,  0.0332,  0.1008, -0.2712,  0.1521, -0.3305,  0.0676, -0.0669],
        [ 0.3872, -0.4618, -0.3540,  0.4344,  0.4917, -0.0157,  0.3455, -0.0776,
          0.4571, -0.2706, -0.2443,  0.0679, -0.2229,  0.3218, -0.1660,  0.3422],
        [-0.4247, -0.2992, -0.2339,  0.1346,  0.4980,  0.2175, -0.4021, -0.4924,
          0.2134,  0.2705,  0.3698, -0.3971, -0.3405,  0.4070,  0.4054,  0.0220],
        [-0.4925,  0.4879,  0.2458, -0.1949, -0.1210, -0.0068,  0.4335,  0.0190,
          0.3198,  0.2303, -0.2418, -0.4985,  0.3209, -0.2817,  0.1848,  0.2923],
        [-0.1314, -0.3120,  0.4806, -0.2747,  0.4115,  0.4013,  0.4610,  0.4641,
         -0.0669,  0.3817, -0.4442,  0.0420, -0.3423, -0.3729,  0.2649, -0.2572],
        [-0.1094, -0.4625, -0.2612,  0.1722,  0.4521,  0.1286, -0.0390, -0.2729,
         -0.3169, -0.2860,  0.3797, -0.2144,  0.1813,  0.1983, -0.3066, -0.2687],
        [-0.1364, -0.3441,  0.4958, -0.2492, -0.4339, -0.3356,  0.0039,  0.4681,
         -0.4408,  0.0523,  0.0082, -0.0169,  0.0792, -0.1908,  0.1994,  0.1102]],
       device='cuda:0', requires_grad=True) 

model.module_15.weight torch.Size([100, 8])
Parameter containing:
tensor([[ 3.0392e-01,  2.8047e-01,  6.2351e-02, -2.0567e-01,  6.1362e-04,
         -2.7011e-01,  1.3239e-01,  7.9381e-02],
        [-2.7536e-03, -3.3280e-01, -2.0921e-01,  1.7853e-01,  2.6495e-01,
         -2.2131e-01, -2.3438e-01,  7.1488e-02],
        [ 1.8513e-01, -1.2148e-01, -3.4208e-02,  3.2869e-01, -1.4154e-01,
          1.5866e-01, -4.9789e-02,  2.8974e-01],
        [ 1.4782e-01,  1.3174e-01,  2.8250e-01, -5.2410e-03, -9.8590e-02,
         -2.9322e-01,  3.2667e-01,  2.3027e-01],
        [-6.3693e-02, -3.0643e-01,  3.5247e-01,  2.7358e-01, -2.9811e-01,
          1.0707e-01, -1.8470e-02,  2.1355e-01],
        [-2.0070e-02, -1.3234e-01, -2.2292e-02,  3.8919e-02, -2.0335e-01,
          2.0687e-01,  3.2705e-01,  3.4618e-01],
        [ 2.3614e-01, -2.0333e-01,  1.2768e-01, -1.2649e-01,  1.9415e-02,
         -2.1172e-01, -1.0515e-01, -2.6661e-01],
        [ 6.5684e-03,  2.9829e-02,  3.2053e-01,  1.2863e-01,  2.0269e-01,
         -1.7309e-01,  1.1599e-02, -4.0672e-02],
        [ 4.2147e-02, -1.4919e-01,  1.8652e-01,  3.3651e-01,  1.4971e-01,
          6.3657e-02, -1.0351e-02, -2.6222e-01],
        [-2.0960e-01, -1.6853e-01, -1.6267e-01, -3.2744e-01,  7.4370e-02,
         -1.1432e-02,  5.4376e-02,  1.6363e-01],
        [-2.2840e-01, -1.9278e-01, -2.6979e-01, -7.7359e-02, -1.3587e-01,
          2.1623e-01,  3.8394e-02, -1.3275e-01],
        [ 1.0500e-01, -2.5641e-02, -2.4126e-02,  2.0483e-01,  4.9866e-02,
          9.6367e-02,  2.8974e-01,  2.5600e-01],
        [-2.1267e-01, -8.1154e-02, -1.7673e-01,  1.5948e-01, -1.2562e-01,
         -1.4635e-01, -3.7081e-02,  2.0992e-01],
        [-2.8058e-01, -2.8312e-01,  2.6233e-01,  8.0025e-02, -9.0970e-02,
         -3.4684e-01, -7.2498e-02,  1.9860e-01],
        [-1.8380e-01, -1.0247e-01, -2.0555e-01, -5.3314e-02,  5.2156e-02,
          1.5988e-01, -2.0844e-01, -2.8952e-01],
        [ 9.0998e-02, -2.6824e-01,  1.9093e-01, -1.9831e-01, -2.7425e-01,
         -6.0179e-02,  1.5950e-01, -2.6515e-01],
        [-2.9885e-02, -1.6463e-01, -1.6494e-01, -2.4938e-01,  1.7033e-01,
         -1.7963e-01, -2.7016e-01, -3.1623e-01],
        [ 3.3842e-01,  1.5360e-02, -1.1503e-02,  3.2078e-01,  2.5141e-01,
         -9.4196e-02,  2.5751e-01, -3.6147e-02],
        [ 2.8087e-01, -2.1683e-01,  1.1675e-01, -2.8727e-01, -1.4310e-01,
         -4.7722e-03, -2.6175e-01,  1.1954e-02],
        [-1.7756e-02,  3.3894e-01,  4.9623e-02,  2.2026e-01,  2.0707e-01,
          2.1170e-01,  1.8861e-01,  9.6927e-02],
        [ 2.6220e-01,  3.0969e-01, -1.0540e-01,  1.8820e-01,  1.2875e-01,
          2.0859e-01, -1.6307e-01,  2.5018e-02],
        [ 4.4299e-02,  1.1091e-01,  5.9861e-02,  2.1841e-01, -1.4652e-01,
         -6.8575e-02, -3.3216e-01,  2.5287e-01],
        [-3.2948e-01,  9.9366e-02, -2.6381e-01,  1.0876e-01, -1.9029e-01,
          2.1572e-01, -3.0231e-01,  2.1708e-01],
        [-8.3712e-02, -3.1894e-01, -1.1060e-01, -1.1508e-01,  1.1580e-01,
          3.0201e-01,  1.1540e-01, -6.7527e-03],
        [ 3.2158e-02, -2.7743e-01, -1.7272e-01,  2.9968e-01,  2.8223e-01,
         -1.8294e-02,  1.2051e-01,  2.6789e-01],
        [-2.2439e-01,  8.9328e-03, -2.5917e-01,  4.7536e-02, -6.4829e-03,
         -7.1441e-02,  3.0889e-01, -2.2644e-01],
        [ 2.2675e-01, -8.1096e-02,  3.3710e-01,  3.0495e-03, -8.8075e-02,
          5.0828e-02,  1.3858e-01, -3.0040e-03],
        [-8.1700e-02, -1.4218e-01, -1.6850e-02, -2.5847e-01, -8.2578e-02,
          5.2621e-02, -8.7183e-02,  2.4759e-01],
        [-2.4232e-01,  1.6075e-02, -3.7668e-02, -1.6857e-01,  2.5015e-01,
         -2.3386e-01,  4.1159e-02,  8.1101e-02],
        [ 2.9323e-01,  2.1326e-01,  1.8162e-01, -2.5966e-01, -6.5870e-02,
          1.4059e-01,  8.1712e-02,  2.7157e-01],
        [ 2.4016e-01,  2.0763e-01, -1.5467e-01,  1.7213e-01, -9.4721e-02,
          6.8230e-02,  2.5662e-01,  3.4032e-01],
        [-3.0092e-01,  1.5729e-01,  2.7744e-01, -2.9624e-01,  2.3151e-01,
         -2.5819e-01, -2.4556e-01,  1.4100e-01],
        [-1.2968e-01,  2.6308e-01, -1.3086e-01, -3.3593e-01, -2.3702e-01,
         -9.7528e-02, -2.9620e-01, -2.0852e-01],
        [-2.8991e-01, -1.6869e-01, -1.0064e-01,  1.7903e-01,  2.1251e-01,
         -2.9328e-01, -5.8507e-02, -1.7898e-01],
        [ 1.4105e-01, -3.1822e-01, -2.9988e-01,  1.0778e-01, -1.5434e-01,
         -2.2386e-01,  3.7327e-02, -1.1323e-01],
        [ 1.5087e-01,  3.3797e-01, -1.2504e-01,  3.5237e-01,  2.2596e-01,
          3.3113e-01,  1.7620e-01,  2.9514e-01],
        [-1.9263e-01,  2.7969e-01,  2.3679e-01,  1.9697e-01, -1.1399e-02,
         -2.1653e-01,  2.5314e-01,  2.1732e-01],
        [ 1.5660e-01,  3.3722e-01,  1.6894e-01, -4.5106e-04,  1.8301e-01,
          1.1522e-01,  1.9081e-02, -1.4142e-01],
        [ 3.1672e-01,  1.2612e-01, -8.7756e-02, -3.1913e-01,  6.7479e-02,
          1.7525e-01,  3.8408e-02,  1.6404e-01],
        [-3.3886e-01,  2.6713e-01, -1.1010e-01, -2.8455e-01, -1.5937e-01,
          2.9905e-01, -4.4652e-02, -3.1923e-01],
        [-2.2390e-01, -1.6897e-01, -1.2637e-01,  8.8117e-02, -9.6057e-02,
         -1.5154e-01, -1.0095e-01, -1.6744e-01],
        [ 9.1350e-02, -3.4654e-01, -4.4957e-02,  3.3162e-01, -4.4868e-02,
         -3.8043e-02, -5.8041e-02,  1.7129e-01],
        [ 3.2393e-01, -3.5109e-01, -2.8109e-01,  7.6415e-02, -2.7521e-01,
          3.0982e-01,  2.2678e-01,  1.8630e-01],
        [-3.2462e-01,  1.8487e-01, -2.6009e-02,  1.5396e-01, -1.5978e-01,
         -2.5023e-01,  2.9390e-01, -1.8347e-01],
        [-2.5455e-01, -1.8899e-01, -1.7386e-01, -2.8236e-01, -1.3669e-01,
         -2.2471e-01, -1.3860e-01,  1.2859e-01],
        [-4.9541e-02, -1.1182e-01,  2.9547e-01, -2.2768e-01,  1.6511e-02,
         -5.4362e-02,  2.6300e-01,  4.9903e-02],
        [-3.2492e-01,  1.5836e-01, -2.4983e-01,  1.3076e-01,  2.8135e-01,
          1.9557e-01, -1.9926e-01,  2.0093e-01],
        [-2.6975e-02,  8.7600e-02, -1.1717e-01,  2.2078e-01,  2.9564e-01,
          2.2086e-01,  6.8156e-03,  2.6411e-01],
        [-1.0792e-01,  6.2443e-02,  3.3788e-01, -2.8574e-02,  1.9638e-01,
          2.5148e-01, -1.5681e-01,  5.1387e-02],
        [ 3.7094e-02, -2.2105e-01,  2.1526e-01, -1.7381e-01, -2.1689e-02,
         -3.2967e-02,  1.9425e-01,  2.9200e-01],
        [-7.4973e-03,  5.8836e-03, -2.4554e-01, -3.1686e-02,  4.4245e-02,
          3.0376e-01, -3.0587e-01,  1.9598e-01],
        [-1.3039e-01, -8.3328e-02,  3.0655e-01,  6.0996e-02,  3.0057e-01,
         -2.2618e-01, -1.9419e-01, -2.2487e-01],
        [-2.8400e-01, -2.4972e-01,  3.1106e-01, -1.5691e-01, -3.3226e-01,
         -2.4980e-01, -7.8196e-02,  1.8492e-01],
        [ 4.3242e-03,  3.5068e-01, -1.0085e-01,  3.3476e-01,  2.4684e-01,
          6.0963e-02, -1.9963e-01, -2.0803e-01],
        [ 1.0023e-01, -9.1840e-02, -2.2736e-01, -1.2698e-01, -2.8948e-01,
         -3.0215e-01,  6.9156e-02,  3.3014e-01],
        [ 1.2475e-01,  1.8032e-01, -3.2346e-01,  1.1201e-01, -7.4971e-02,
          2.3123e-01,  1.0167e-01,  2.0660e-04],
        [-1.7012e-01,  2.2302e-01,  3.3879e-01,  2.0713e-01, -2.2282e-01,
         -2.1510e-01,  1.6912e-01,  5.4367e-02],
        [-1.0299e-01,  6.8713e-02,  3.0581e-01, -3.2434e-01,  2.2235e-01,
          2.9713e-01, -2.3441e-01, -3.0526e-01],
        [ 2.7093e-02, -2.5552e-01, -1.2062e-02,  3.3242e-03,  2.6470e-01,
          1.4071e-02,  1.8956e-01, -2.3185e-01],
        [ 4.7913e-03,  6.3315e-02,  6.8106e-02, -2.3342e-03,  1.5757e-01,
         -1.8551e-02, -8.1424e-02,  4.1167e-02],
        [ 6.3001e-03, -2.4528e-01, -5.7749e-02, -4.1804e-02, -3.0390e-01,
         -8.2584e-02, -1.0944e-02,  3.2766e-02],
        [ 3.1208e-01,  8.5960e-02, -2.7761e-01,  1.8495e-01,  3.0333e-01,
         -3.1668e-01, -1.5844e-01, -3.5229e-01],
        [ 2.6703e-01, -2.2614e-01,  3.0734e-01,  2.6939e-01,  5.7651e-02,
         -1.6101e-01, -2.1559e-03, -1.8309e-01],
        [-3.0478e-01, -2.4726e-01, -1.0622e-01,  5.1106e-02,  2.5510e-01,
         -2.0974e-02, -3.4595e-02, -1.3897e-01],
        [ 2.6930e-01,  2.3377e-02, -3.0035e-01, -3.0069e-01,  3.3242e-01,
          7.4298e-02,  3.3243e-01, -1.5842e-02],
        [ 1.0420e-01, -3.3628e-01, -2.4757e-01,  3.3498e-01, -2.2256e-01,
         -1.8682e-01,  1.2746e-02, -1.9735e-02],
        [-3.2541e-01,  2.3043e-01, -3.4887e-01, -1.6621e-01,  3.1751e-01,
          2.2273e-01,  9.3465e-02,  2.4258e-01],
        [-2.4817e-01,  3.3392e-01,  2.5868e-02,  1.0486e-01,  1.8142e-01,
          2.9928e-01, -2.7539e-01,  3.0273e-01],
        [-1.6058e-01, -2.4477e-02,  1.4108e-01,  2.8105e-01,  2.2167e-01,
          3.0392e-01, -1.0657e-01,  3.0695e-01],
        [ 5.5733e-02,  1.2158e-01,  1.9484e-01,  4.6326e-02,  2.1087e-01,
         -1.3906e-01, -3.4473e-01,  2.0240e-01],
        [ 2.9040e-01,  2.4182e-01, -3.8599e-02, -1.3295e-01, -1.4297e-01,
          2.0918e-01,  2.5064e-01,  3.7325e-03],
        [ 3.1298e-01,  2.3241e-01,  1.7057e-01, -3.1332e-01,  2.9133e-01,
          1.0211e-01, -2.4540e-01,  8.2982e-02],
        [-2.8696e-03, -2.2903e-01,  2.7906e-01, -2.4597e-01, -1.1897e-01,
         -2.5892e-01,  1.7166e-01, -2.5275e-01],
        [-1.2283e-01,  2.4674e-01, -3.3172e-02, -5.2553e-02, -2.1252e-01,
          1.4657e-01,  1.9783e-03, -1.8728e-01],
        [-1.2102e-01,  2.0407e-03, -1.6164e-01,  3.2862e-02, -1.5260e-01,
          2.9702e-01,  2.4913e-01, -1.5341e-01],
        [ 8.4207e-03,  7.1519e-02,  7.7641e-02, -1.4582e-01, -2.4994e-01,
         -3.3208e-01, -2.9411e-01, -7.8157e-02],
        [-9.7775e-02, -2.7630e-01,  2.5901e-01, -1.2538e-01,  2.5245e-01,
          2.9355e-01, -3.0531e-01, -1.9571e-01],
        [-1.9874e-01, -3.0556e-01, -3.0716e-01,  2.8694e-01,  4.2210e-02,
          2.0112e-01, -2.3709e-01, -1.5181e-01],
        [-3.1088e-01,  1.1445e-01, -2.4233e-01, -1.6116e-01, -1.0195e-01,
         -2.6605e-01,  1.9630e-01, -2.1383e-01],
        [ 2.6663e-01, -2.1224e-01, -1.4089e-01,  2.7988e-01, -8.3661e-02,
         -2.3952e-01,  6.1259e-02,  2.6165e-01],
        [ 1.7615e-02,  1.4285e-01, -1.5495e-02, -2.5694e-01,  8.6753e-02,
         -1.5321e-01,  1.7973e-01,  1.1547e-01],
        [-1.1504e-01,  6.4606e-02,  2.6740e-01, -1.6453e-01,  5.6871e-02,
          4.3964e-02,  2.9755e-01, -2.7204e-01],
        [-1.4150e-01,  4.8160e-02, -2.6376e-01, -2.6377e-01, -3.0474e-01,
         -1.6324e-01,  1.2236e-01,  1.8659e-01],
        [ 2.5907e-01, -3.3077e-01,  1.1772e-01,  3.5264e-01, -1.0383e-01,
          2.4882e-01, -3.1218e-01,  3.1036e-01],
        [ 1.6737e-01, -2.9863e-02, -1.6371e-01,  2.5386e-01, -3.1393e-01,
          2.5283e-02,  2.7626e-02, -3.1644e-01],
        [ 5.2320e-02,  1.1346e-01,  1.7580e-01,  1.8829e-01,  1.1938e-01,
          1.6462e-01, -6.0165e-03, -2.3822e-01],
        [-4.6466e-02, -2.9891e-02, -1.7250e-01,  2.9992e-01,  1.9393e-01,
          3.4355e-01,  2.8775e-01, -6.0604e-02],
        [-1.5337e-01,  8.5672e-02,  1.0331e-02, -1.0132e-01, -2.8818e-01,
         -3.1900e-01,  1.3134e-01, -2.8745e-01],
        [ 3.4009e-01, -1.5887e-03,  9.1439e-02,  3.0578e-01,  8.6663e-02,
          1.5651e-01,  1.0314e-01,  2.2245e-01],
        [ 9.9888e-02, -1.5746e-02, -2.7255e-01, -3.4349e-01, -3.4966e-01,
          3.3456e-01,  1.2855e-01, -7.1632e-03],
        [-3.0937e-01, -8.8731e-02,  1.8986e-02, -1.9696e-01, -1.8815e-01,
          2.7715e-02, -1.4368e-01, -2.9852e-01],
        [-1.7365e-01,  2.1202e-01, -3.1340e-01,  1.3999e-01,  1.8796e-01,
          1.2661e-01, -1.9770e-01,  2.5407e-01],
        [ 1.5490e-01,  2.0768e-01,  1.7016e-01,  2.3805e-02, -2.8006e-01,
          1.2980e-01, -6.4997e-02,  3.9122e-02],
        [ 2.1422e-01, -3.3422e-01, -3.4833e-01,  6.7557e-04, -8.2858e-03,
          1.6484e-01,  1.0264e-02, -6.8568e-02],
        [-5.1783e-03,  2.4145e-01, -2.9513e-01,  1.0988e-01, -2.1095e-01,
          2.0261e-01,  3.7300e-03, -3.2718e-01],
        [ 1.3845e-01, -1.7777e-01,  1.8587e-02, -1.0389e-02,  8.6695e-02,
          2.7422e-01,  2.1088e-01,  3.4386e-01],
        [-1.4347e-01, -1.0727e-01, -2.6249e-02,  1.1543e-01, -1.0176e-01,
          2.6821e-01,  3.0516e-01,  2.7758e-01],
        [ 1.7399e-01,  1.7400e-03,  3.2539e-01, -7.9496e-02,  1.7458e-01,
         -2.3786e-01,  1.3491e-01, -3.0871e-01],
        [-1.3708e-01, -1.9016e-01, -9.3707e-02, -1.8940e-01, -2.1620e-02,
          2.0520e-01,  2.5727e-01,  3.3626e-01],
        [-7.1825e-02, -7.2933e-02, -1.8860e-02,  1.3116e-01, -1.0399e-02,
         -1.2322e-01,  9.6178e-02, -2.0799e-01]], device='cuda:0',
       requires_grad=True) 

model.module_15.bias torch.Size([100])
Parameter containing:
tensor([ 0.1714,  0.0930,  0.2252, -0.2232, -0.2238, -0.3391,  0.2910, -0.2367,
         0.1227,  0.3094,  0.2701,  0.2301,  0.0100, -0.2310, -0.3362, -0.1911,
         0.0190,  0.1493, -0.2370, -0.2428,  0.2546,  0.0227, -0.1912,  0.3230,
         0.0653, -0.1672,  0.0171, -0.3368, -0.1867,  0.3024,  0.1157, -0.2217,
         0.1111, -0.1397, -0.2523, -0.3050,  0.2658,  0.1851, -0.2496, -0.2983,
         0.0734, -0.2525,  0.1440, -0.2879,  0.0842,  0.1283, -0.0675,  0.0628,
        -0.2049, -0.3002,  0.1255, -0.0629,  0.0624, -0.0205, -0.2956, -0.0197,
         0.2028, -0.0203, -0.1540, -0.2265,  0.2487, -0.3246, -0.0218, -0.2034,
         0.0886,  0.0351,  0.0403, -0.2014, -0.1292, -0.2973,  0.2926,  0.1302,
        -0.0344,  0.0607, -0.1386,  0.2430, -0.1030,  0.0923, -0.2311,  0.2953,
         0.0206, -0.0708, -0.1166, -0.0380, -0.0402, -0.1614,  0.1440,  0.3334,
         0.0274,  0.0726,  0.1025, -0.3479,  0.3322,  0.1040,  0.2019, -0.1279,
        -0.3101, -0.1972,  0.1322, -0.2087], device='cuda:0',
       requires_grad=True) 

model.module_17.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0166, -0.0063, -0.0339,  ..., -0.0080,  0.0759, -0.0562],
        [ 0.0564, -0.0397,  0.0804,  ...,  0.0870,  0.0128,  0.0209],
        [-0.0878, -0.0465,  0.0090,  ..., -0.0456,  0.0672,  0.0102],
        ...,
        [ 0.0327,  0.0953,  0.0695,  ..., -0.0304,  0.0147,  0.0329],
        [ 0.0427,  0.0745, -0.0068,  ...,  0.0948, -0.0331,  0.0310],
        [ 0.0635,  0.0427,  0.0731,  ...,  0.0208, -0.0577,  0.0261]],
       device='cuda:0', requires_grad=True) 

model.module_17.bias torch.Size([100])
Parameter containing:
tensor([ 0.0525,  0.0782, -0.0189,  0.0392,  0.0084, -0.0866, -0.0961,  0.0172,
         0.0691,  0.0244, -0.0842, -0.0392, -0.0764, -0.0832, -0.0816, -0.0582,
         0.0595, -0.0291,  0.0361,  0.0279,  0.0357,  0.0045, -0.0217,  0.0944,
         0.0743,  0.0773, -0.0046,  0.0967,  0.0896,  0.0153,  0.0815,  0.0164,
         0.0561, -0.0701, -0.0768,  0.0451, -0.0580, -0.0847,  0.0900,  0.0216,
         0.0935,  0.0117,  0.0108,  0.0227, -0.0106,  0.0287, -0.0037,  0.0970,
        -0.0653, -0.0710, -0.0447, -0.0599, -0.0225, -0.0357, -0.0414, -0.0484,
         0.0678, -0.0186, -0.0666, -0.0586,  0.0828,  0.0808,  0.0179, -0.0241,
        -0.0411, -0.0207,  0.0508, -0.0522,  0.0915, -0.0253, -0.0391,  0.0015,
         0.0285,  0.0058,  0.0433,  0.0754,  0.0309, -0.0140, -0.0853, -0.0267,
        -0.0034, -0.0303,  0.0631,  0.0006, -0.0304, -0.0872,  0.0672,  0.0287,
         0.0891, -0.0198,  0.0237, -0.0911,  0.0003, -0.0462,  0.0794,  0.0983,
        -0.0966,  0.0189, -0.0958, -0.0120], device='cuda:0',
       requires_grad=True) 

model.module_19.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0755,  0.0322,  0.0067,  ..., -0.0592,  0.0102,  0.0614],
        [-0.0510, -0.0036,  0.0401,  ...,  0.0884,  0.0334,  0.0576],
        [-0.0017,  0.0818, -0.0675,  ...,  0.0396,  0.0354, -0.0121],
        ...,
        [-0.0578,  0.0466, -0.0463,  ..., -0.0984,  0.0488, -0.0567],
        [ 0.0065, -0.0966,  0.0587,  ...,  0.0753,  0.0218, -0.0091],
        [ 0.0750,  0.0551,  0.0260,  ..., -0.0807, -0.0453,  0.0258]],
       device='cuda:0', requires_grad=True) 

model.module_19.bias torch.Size([16])
Parameter containing:
tensor([ 0.0717, -0.0616,  0.0820,  0.0949,  0.0409,  0.0510, -0.0237,  0.0065,
         0.0840,  0.0033, -0.0142,  0.0630,  0.0091,  0.0120,  0.0980, -0.0428],
       device='cuda:0', requires_grad=True) 



#### FINAL PARAMETERS ####
W 256 torch.Size([16, 16])
Parameter containing:
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0') 

act.weight 1 torch.Size([1])
Parameter containing:
tensor([nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan], device='cuda:0') 

inner_act.weight 1 torch.Size([1])
Parameter containing:
tensor([nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan], device='cuda:0') 

out_act.weight 1 torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 
grad:  None 

encoder.module_0.weight 1000 torch.Size([100, 10])
Parameter containing:
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0') 

encoder.module_0.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

encoder.module_2.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

encoder.module_2.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

encoder.module_4.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

encoder.module_4.bias 16 torch.Size([16])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0') 

model.module_0.bias 8 torch.Size([8])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0') 

model.module_0.lin.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0') 

model.module_1.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0') 

model.module_1.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

model.module_3.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

model.module_3.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

model.module_5.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

model.module_5.bias 16 torch.Size([16])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0') 

model.module_7.bias 8 torch.Size([8])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0') 

model.module_7.lin.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0') 

model.module_8.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0') 

model.module_8.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

model.module_10.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

model.module_10.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

model.module_12.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

model.module_12.bias 16 torch.Size([16])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0') 

model.module_14.bias 8 torch.Size([8])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0') 

model.module_14.lin.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0') 

model.module_15.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0') 

model.module_15.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

model.module_17.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

model.module_17.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

model.module_19.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

model.module_19.bias 16 torch.Size([16])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0') 

