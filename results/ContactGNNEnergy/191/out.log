Took 11.0 seconds to move data to scratch
#### ARCHITECTURE ####
Sequential(
  (0): Linear(3, 100, bias=True)
  (1): PReLU(num_parameters=1)
  (2): Linear(100, 100, bias=True)
  (3): PReLU(num_parameters=1)
  (4): Linear(100, 64, bias=True)
  (5): PReLU(num_parameters=1)
)
Sequential(
  (0): GATv2Conv(64, 8, heads=8)
  (1): Linear(64, 100, bias=True)
  (2): PReLU(num_parameters=1)
  (3): Linear(100, 100, bias=True)
  (4): PReLU(num_parameters=1)
  (5): Linear(100, 64, bias=True)
  (6): PReLU(num_parameters=1)
  (7): GATv2Conv(64, 8, heads=8)
  (8): Linear(64, 100, bias=True)
  (9): PReLU(num_parameters=1)
  (10): Linear(100, 100, bias=True)
  (11): PReLU(num_parameters=1)
  (12): Linear(100, 64, bias=True)
  (13): PReLU(num_parameters=1)
  (14): GATv2Conv(64, 8, heads=8)
  (15): Linear(64, 100, bias=True)
  (16): PReLU(num_parameters=1)
  (17): Linear(100, 100, bias=True)
  (18): PReLU(num_parameters=1)
  (19): Linear(100, 64, bias=True)
  (20): PReLU(num_parameters=1)
)
None 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['degree', 'ContactDistance', 'GeneticDistance', 'DiagonalParameterDistance_80'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, relabel_11_to_00=False, split_edges_for_feature_augmentation=True, data_folder='/scratch/midway2/erschultz/dataset_09_30_22', scratch='/scratch/midway2/erschultz', root_name='ContactGNNEnergy4', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='log', y_zero_diag_count=0, log_preprocessing=None, preprocessing_norm=None, min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=True, use_scratch_parallel=True, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.0001, gpus=1, milestones=[50], gamma=0.1, loss='mse', autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_sym', model_type='ContactGNNEnergy', id=191, pretrained=False, resume_training=False, k=None, m=1024, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=None, dropout_p=0.2, parameter_sharing=False, use_bias=True, message_passing='GAT', head_architecture='bilinear', head_hidden_sizes_list=None, encoder_hidden_sizes_list=[100, 100, 64], update_hidden_sizes_list=[100, 100, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=80, kernel_w_list=None, hidden_sizes_list=[8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/191', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/191/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/191/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/191/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7fa761c9b670>, channels=1, node_feature_size=3, edge_transforms=['ContactDistance', 'DiagonalParameterDistance80', 'GeneticDistance'], node_transforms=['Degree'], edge_dim=3, transforms_processed=None, pre_transforms_processed=Compose([
  Degree(norm=True, max=None, weighted=False, split_edges=True, split_val=1),
  ContactDistance(convert_to_attr=True),
  GeneticDistance(norm=True, max_value=None),
  DiagonalParameterDistance(mlp_id=80)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 54.768 minutes
Average num edges per graph:  872857.8928571428
Mean degree: [ 986.45 1021.3   776.17 ...  917.92  847.49  939.36] +- [ 42.55   2.71 106.62 ...  22.92  64.66  21.92]

#### TRAINING/VALIDATION ####
Epoch 2, loss = 10.0980
Mean test/val loss: 10.2487

Epoch 4, loss = 9.8874
Mean test/val loss: 9.9896

Epoch 6, loss = 9.5064
Mean test/val loss: 9.6238

Epoch 8, loss = 8.5640
Mean test/val loss: 8.9586

Epoch 10, loss = 7.7410
Mean test/val loss: 8.2145

Epoch 12, loss = 7.0757
Mean test/val loss: 7.3095

Epoch 14, loss = 6.7167
Mean test/val loss: 7.0338

Epoch 16, loss = 6.4575
Mean test/val loss: 6.5889

Epoch 18, loss = 6.1688
Mean test/val loss: 6.6168

Epoch 20, loss = 6.0344
Mean test/val loss: 6.4507

Epoch 22, loss = 5.7202
Mean test/val loss: 5.9836

Epoch 24, loss = 5.5652
Mean test/val loss: 6.0493

Epoch 26, loss = 5.4530
Mean test/val loss: 6.5329

Epoch 28, loss = 5.3394
Mean test/val loss: 5.4914

Epoch 30, loss = 5.2425
Mean test/val loss: 5.3824

Epoch 32, loss = 5.1454
Mean test/val loss: 6.1139

Epoch 34, loss = 5.1084
Mean test/val loss: 5.9302

Epoch 36, loss = 5.0305
Mean test/val loss: 6.3776

Epoch 38, loss = 4.8920
Mean test/val loss: 5.1857

Epoch 40, loss = 4.8970
Mean test/val loss: 5.0982

Epoch 42, loss = 4.7869
Mean test/val loss: 4.8410

Epoch 44, loss = 4.7116
Mean test/val loss: 5.2074

Epoch 46, loss = 4.6762
Mean test/val loss: 4.6400

Epoch 48, loss = 4.5622
Mean test/val loss: 4.7423

Epoch 50, loss = 4.5214
Mean test/val loss: 4.6716

Epoch 52, loss = 4.0717
Mean test/val loss: 4.3815

Epoch 54, loss = 4.0413
Mean test/val loss: 4.3433

Epoch 56, loss = 4.0216
Mean test/val loss: 4.3349

Epoch 58, loss = 3.9975
Mean test/val loss: 4.3435

Epoch 60, loss = 3.9807
Mean test/val loss: 4.2756

Epoch 62, loss = 3.9573
Mean test/val loss: 4.2812

Epoch 64, loss = 3.9469
Mean test/val loss: 4.2709

Epoch 66, loss = 3.9349
Mean test/val loss: 4.2423

Epoch 68, loss = 3.9121
Mean test/val loss: 4.2289

Epoch 70, loss = 3.8959
Mean test/val loss: 4.1721

Epoch 72, loss = 3.8790
Mean test/val loss: 4.2181

Epoch 74, loss = 3.8673
Mean test/val loss: 4.1679

Epoch 76, loss = 3.8441
Mean test/val loss: 4.1639

Epoch 78, loss = 3.8286
Mean test/val loss: 4.1753

Epoch 80, loss = 3.8181
Mean test/val loss: 4.1333

Epoch 82, loss = 3.8070
Mean test/val loss: 4.1572

Epoch 84, loss = 3.7955
Mean test/val loss: 4.1660

Epoch 86, loss = 3.7860
Mean test/val loss: 4.2223

Epoch 88, loss = 3.7694
Mean test/val loss: 4.0884

Epoch 90, loss = 3.7527
