#### ARCHITECTURE ####
Node Encoder:
 Sequential(
  (0): Linear(3, 1000, bias=True)
  (1): PReLU(num_parameters=1)
  (2): Linear(1000, 1000, bias=True)
  (3): PReLU(num_parameters=1)
  (4): Linear(1000, 64, bias=True)
  (5): PReLU(num_parameters=1)
) 

Edge Encoder:
 None 

Model:
 Sequential(
  (0): WeightedGATv2Conv(64, 8, heads=8)
  (1): Linear(64, 1000, bias=True)
  (2): PReLU(num_parameters=1)
  (3): Linear(1000, 1000, bias=True)
  (4): PReLU(num_parameters=1)
  (5): Linear(1000, 1000, bias=True)
  (6): PReLU(num_parameters=1)
  (7): Linear(1000, 1000, bias=True)
  (8): PReLU(num_parameters=1)
  (9): Linear(1000, 64, bias=True)
  (10): PReLU(num_parameters=1)
  (11): WeightedGATv2Conv(64, 8, heads=8)
  (12): Linear(64, 1000, bias=True)
  (13): PReLU(num_parameters=1)
  (14): Linear(1000, 1000, bias=True)
  (15): PReLU(num_parameters=1)
  (16): Linear(1000, 1000, bias=True)
  (17): PReLU(num_parameters=1)
  (18): Linear(1000, 1000, bias=True)
  (19): PReLU(num_parameters=1)
  (20): Linear(1000, 64, bias=True)
  (21): PReLU(num_parameters=1)
  (22): WeightedGATv2Conv(64, 8, heads=8)
  (23): Linear(64, 1000, bias=True)
  (24): PReLU(num_parameters=1)
  (25): Linear(1000, 1000, bias=True)
  (26): PReLU(num_parameters=1)
  (27): Linear(1000, 1000, bias=True)
  (28): PReLU(num_parameters=1)
  (29): Linear(1000, 1000, bias=True)
  (30): PReLU(num_parameters=1)
  (31): Linear(1000, 64, bias=True)
  (32): PReLU(num_parameters=1)
  (33): WeightedGATv2Conv(64, 8, heads=8)
  (34): Linear(64, 1000, bias=True)
  (35): PReLU(num_parameters=1)
  (36): Linear(1000, 1000, bias=True)
  (37): PReLU(num_parameters=1)
  (38): Linear(1000, 1000, bias=True)
  (39): PReLU(num_parameters=1)
  (40): Linear(1000, 1000, bias=True)
  (41): PReLU(num_parameters=1)
  (42): Linear(1000, 64, bias=True)
  (43): PReLU(num_parameters=1)
) 

Head 1:
 Bilinear 

Head 2:
 Sequential(
  (0): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=32768, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (1): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (2): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (3): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (4): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (5): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1000, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (6): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=1000, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (7): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['constant', 'degree_diag_split1', 'ContactDistance', 'GeneticDistance_norm_log'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder='/project2/depablo/erschultz/dataset_11_18_22', scratch='/scratch/midway2/erschultz', root_name='ContactGNNEnergy5', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', y_zero_diag_count=0, log_preprocessing=None, kr=False, mean_filt=None, rescale=2, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=False, use_scratch_parallel=True, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.001, gpus=1, milestones=[50], gamma=0.1, loss='mse', autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_sym_diag', model_type='ContactGNNEnergy', id=260, pretrained=False, resume_training=False, k=None, m=1024, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=None, dropout_p=0.2, parameter_sharing=False, use_bias=True, message_passing='weighted_GAT', head_architecture='bilinear', head_architecture_2='fc-fill', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000, 1024], encoder_hidden_sizes_list=[1000, 1000, 64], edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 1000, 1000, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/260', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/260/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/260/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/260/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7fc6ee8675e0>, channels=1, node_feature_size=3, input_m=512, edge_transforms=["'ContactDistance'", 'ContactDistance(norm=False)', 'GeneticDistance(norm=True, log=True)'], node_transforms=['Constant(value=1.0)', 'Degree(norm=True, split_edges=True, split_val=1.0)'], edge_dim=2, transforms_processed=None, diag=True, pre_transforms_processed=Compose([
  Constant(value=1.0),
  Degree(norm=True, split_edges=True, split_val=1.0),
  ContactDistance(norm=False),
  GeneticDistance(norm=True, log=True)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 42.178 minutes
Average num edges per graph:  219629.77916666667
Mean degree: [362.66 512.   449.47 ... 399.29 390.16 429.63] +- [70.54  0.   53.89 ... 85.38 67.92 62.93]

split sizes: train=2160, val=240, test=0, N=2400
#### TRAINING/VALIDATION ####
Epoch 2, loss = 7783688004651569427983106048.0000
Mean test/val loss: 7707234709596305450837475328.0000

Epoch 4, loss = 7313905270295358309243289600.0000
Mean test/val loss: 7246064108126508410615103488.0000

Epoch 6, loss = 6866421410549286969800654848.0000
Mean test/val loss: 6800272655573598816367017984.0000

Epoch 8, loss = 6435284233769691965154131968.0000
Mean test/val loss: 6370840513535017800874065920.0000

Epoch 10, loss = 6020395317968458900708524032.0000
Mean test/val loss: 5957933906851396425852387328.0000

Epoch 12, loss = 5620728784504060573734928384.0000
Mean test/val loss: 5559739124590183439851847680.0000

Epoch 14, loss = 5236459160345100073629122560.0000
Mean test/val loss: 5177950843303988176479059968.0000

Epoch 16, loss = 4869126605420341588870037504.0000
Mean test/val loss: 4812719751985582489412304896.0000

Epoch 18, loss = 4517167371334482666004152320.0000
Mean test/val loss: 4462873464126014272770670592.0000

Epoch 20, loss = 4181402704059228241658904576.0000
Mean test/val loss: 4129284857518757144720048128.0000

Epoch 22, loss = 3861551827684348487710801920.0000
Mean test/val loss: 3811625407334797754161430528.0000

Epoch 24, loss = 3557212912342803404386467840.0000
Mean test/val loss: 3509487029782604389340413952.0000

Epoch 26, loss = 3268689626559181004675743744.0000
Mean test/val loss: 3223305320127819852632031232.0000

Epoch 28, loss = 2995712624094201973980528640.0000
Mean test/val loss: 2952575362085247188341882880.0000

Epoch 30, loss = 2738380386170524783932866560.0000
Mean test/val loss: 2697605681753759765789409280.0000

Epoch 32, loss = 2496751977144714440501886976.0000
Mean test/val loss: 2458435251569561891241984000.0000

Epoch 34, loss = 2270542587725949289019473920.0000
Mean test/val loss: 2234694402470765295002714112.0000

Epoch 36, loss = 2060035207262944643816357888.0000
Mean test/val loss: 2026707342440826013166338048.0000

Epoch 38, loss = 1865162560582545591570006016.0000
Mean test/val loss: 1834413035200398451902775296.0000

Epoch 40, loss = 1685756915232720391579369472.0000
Mean test/val loss: 1657589837892859540048707584.0000

Epoch 42, loss = 1521976306246301632344096768.0000
Mean test/val loss: 1496486774184506617115967488.0000

Epoch 44, loss = 1373579776239926552266014720.0000
Mean test/val loss: 1350756730154876384166543360.0000

Epoch 46, loss = 1240703072394908665309560832.0000
Mean test/val loss: 1220632127708045558352445440.0000

Epoch 48, loss = 1123140029304874263602266112.0000
Mean test/val loss: 1105833811036163553204633600.0000

Epoch 50, loss = 1020846066364733964230328320.0000
Mean test/val loss: 1006326972362946418623643648.0000

Epoch 52, loss = 990563409047617359017148416.0000
Mean test/val loss: 996996374936814336329383936.0000

Epoch 54, loss = 981397947899252316190015488.0000
Mean test/val loss: 987760002864519329951514624.0000

Epoch 56, loss = 972360349213052730764951552.0000
Mean test/val loss: 978659027434159484350496768.0000

Epoch 58, loss = 963486330531392187063599104.0000
Mean test/val loss: 969731733325831202517549056.0000

Epoch 60, loss = 954775500561252093261774848.0000
Mean test/val loss: 960960390297744933008703488.0000

Epoch 62, loss = 946232379318580987966783488.0000
Mean test/val loss: 952358369626065527237509120.0000

Epoch 64, loss = 937833652066025905137385472.0000
Mean test/val loss: 943900046477431593423077376.0000

Epoch 66, loss = 929598190898834531351003136.0000
Mean test/val loss: 935607087167649273345998848.0000

Epoch 68, loss = 921519025834320856759664640.0000
Mean test/val loss: 927466974504804135930429440.0000

Epoch 70, loss = 913585465788671616178192384.0000
Mean test/val loss: 919475255444877227495260160.0000

Epoch 72, loss = 905817330336567108806115328.0000
Mean test/val loss: 911649498359478330415120384.0000

Epoch 74, loss = 898194049855297156634640384.0000
Mean test/val loss: 903969882222100243776798720.0000

Epoch 76, loss = 890745832032663644531589120.0000
Mean test/val loss: 896470306614327416037834752.0000

Epoch 78, loss = 883452470868859013186977792.0000
Mean test/val loss: 889116873799249696160481280.0000

Epoch 80, loss = 876305636036303309768753152.0000
Mean test/val loss: 881917507422061445305597952.0000

Epoch 82, loss = 869325667154137046382018560.0000
Mean test/val loss: 874883381444262180037853184.0000

Epoch 84, loss = 862487012629404734820712448.0000
Mean test/val loss: 867991645115353588207452160.0000

Epoch 86, loss = 855818604028065974860120064.0000
