#### ARCHITECTURE ####
Node Encoder:
 None 

Edge Encoder:
 None 

Model:
 Sequential(
  (0): WeightedGATv2Conv(1, 8, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (2): WeightedGATv2Conv(64, 8, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (4): WeightedGATv2Conv(64, 8, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (6): WeightedGATv2Conv(64, 8, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
) 

Head 1:
 Bilinear 

Head 2:
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=32768, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1024, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['constant', 'ContactDistance', 'GeneticDistance_norm'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project2/depablo/erschultz/dataset_11_18_22'], scratch='/scratch/midway2/erschultz', root_name='ContactGNNEnergy0', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', y_zero_diag_count=0, log_preprocessing=None, output_preprocesing='log', kr=False, mean_filt=None, rescale=2, gated=False, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=False, use_scratch_parallel=True, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.0001, weight_decay=0.0, gpus=1, milestones=[50], gamma=0.1, loss='mse', autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_SD', model_type='ContactGNNEnergy', id=296, pretrained=False, resume_training=False, k=None, m=1024, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, message_passing='weighted_GAT', head_architecture='bilinear', head_architecture_2='fc-fill', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000, 1024], encoder_hidden_sizes_list=None, inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/296', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/296/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/296/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/296/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7f6e75372940>, channels=1, node_feature_size=1, input_m=512, edge_transforms=["'ContactDistance'", 'ContactDistance(norm=False)', 'GeneticDistance(norm=True)'], node_transforms=['Constant(value=1.0)'], edge_dim=2, transforms_processed=None, diag=False, pre_transforms_processed=Compose([
  Constant(value=1.0),
  ContactDistance(norm=False),
  GeneticDistance(norm=True)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 37.308 minutes
Average num edges per graph:  219629.77916666667
Mean degree: [362.66 512.   449.47 ... 399.29 390.16 429.63] +- [70.54  0.   53.89 ... 85.38 67.92 62.93]

split sizes: train=2160, val=240, test=0, N=2400
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
#### TRAINING/VALIDATION ####
Epoch 2, loss = 0.8276
Mean test/val loss: 0.8017
[25, 50, 75] quantiles test/val loss: [0.5093 0.8078 1.0532]

Epoch 4, loss = 0.7671
Mean test/val loss: 0.7495
[25, 50, 75] quantiles test/val loss: [0.4643 0.7676 0.9865]

Epoch 6, loss = 0.7251
Mean test/val loss: 0.7167
[25, 50, 75] quantiles test/val loss: [0.4592 0.7179 0.9851]

Epoch 8, loss = 0.7061
Mean test/val loss: 0.7417
[25, 50, 75] quantiles test/val loss: [0.4285 0.7267 1.0702]

Epoch 10, loss = 0.6839
Mean test/val loss: 0.6814
[25, 50, 75] quantiles test/val loss: [0.412  0.6892 0.9579]

Epoch 12, loss = 0.6712
Mean test/val loss: 0.6552
[25, 50, 75] quantiles test/val loss: [0.406  0.6819 0.9069]

Epoch 14, loss = 0.6422
Mean test/val loss: 0.6262
[25, 50, 75] quantiles test/val loss: [0.3866 0.6327 0.8621]

Epoch 16, loss = 0.6589
Mean test/val loss: 0.6497
[25, 50, 75] quantiles test/val loss: [0.399  0.6663 0.8953]

Epoch 18, loss = 4.8100
Mean test/val loss: 0.6403
[25, 50, 75] quantiles test/val loss: [0.391  0.6326 0.8922]

Epoch 20, loss = 0.6143
Mean test/val loss: 0.6136
[25, 50, 75] quantiles test/val loss: [0.3651 0.6038 0.8451]

Epoch 22, loss = 0.6101
Mean test/val loss: 0.6090
[25, 50, 75] quantiles test/val loss: [0.358 0.605 0.832]

Epoch 24, loss = 0.6190
Mean test/val loss: 0.6093
[25, 50, 75] quantiles test/val loss: [0.3514 0.6154 0.8446]

Epoch 26, loss = 0.6093
Mean test/val loss: 0.6018
[25, 50, 75] quantiles test/val loss: [0.3476 0.6021 0.8285]

Epoch 28, loss = 0.6102
Mean test/val loss: 0.6205
[25, 50, 75] quantiles test/val loss: [0.3906 0.5962 0.8312]

Epoch 30, loss = 0.6062
Mean test/val loss: 0.5905
[25, 50, 75] quantiles test/val loss: [0.3344 0.5767 0.8329]

Epoch 32, loss = 0.5912
Mean test/val loss: 0.5937
[25, 50, 75] quantiles test/val loss: [0.3418 0.5888 0.8253]

Epoch 34, loss = 0.5824
Mean test/val loss: 0.5975
[25, 50, 75] quantiles test/val loss: [0.3232 0.5928 0.8368]

Epoch 36, loss = 0.5775
Mean test/val loss: 0.5750
[25, 50, 75] quantiles test/val loss: [0.3157 0.5723 0.81  ]

Epoch 38, loss = 0.5908
Mean test/val loss: 0.5917
[25, 50, 75] quantiles test/val loss: [0.3311 0.5845 0.8338]

Epoch 40, loss = 0.5771
Mean test/val loss: 0.5751
[25, 50, 75] quantiles test/val loss: [0.3164 0.571  0.8069]

Epoch 42, loss = 0.5692
Mean test/val loss: 0.5721
[25, 50, 75] quantiles test/val loss: [0.3183 0.5705 0.8095]

Epoch 44, loss = 0.5710
Mean test/val loss: 0.5832
[25, 50, 75] quantiles test/val loss: [0.3231 0.5712 0.8244]

Epoch 46, loss = 0.5633
Mean test/val loss: 0.5687
[25, 50, 75] quantiles test/val loss: [0.3104 0.5716 0.7956]

Epoch 48, loss = 0.5535
Mean test/val loss: 0.5655
[25, 50, 75] quantiles test/val loss: [0.3052 0.5567 0.8121]

Epoch 50, loss = 0.5483
Mean test/val loss: 0.5612
[25, 50, 75] quantiles test/val loss: [0.3026 0.542  0.7977]

Epoch 52, loss = 0.5183
Mean test/val loss: 0.5380
[25, 50, 75] quantiles test/val loss: [0.2836 0.5359 0.7738]

Epoch 54, loss = 0.5147
Mean test/val loss: 0.5356
[25, 50, 75] quantiles test/val loss: [0.2766 0.5336 0.7761]

Epoch 56, loss = 0.5119
Mean test/val loss: 0.5370
[25, 50, 75] quantiles test/val loss: [0.2762 0.5347 0.7741]

Epoch 58, loss = 0.5096
Mean test/val loss: 0.5352
[25, 50, 75] quantiles test/val loss: [0.2766 0.5274 0.7765]

Epoch 60, loss = 0.5075
Mean test/val loss: 0.5319
[25, 50, 75] quantiles test/val loss: [0.2758 0.5299 0.7615]

Epoch 62, loss = 0.5056
Mean test/val loss: 0.5302
[25, 50, 75] quantiles test/val loss: [0.2757 0.5242 0.7648]

Epoch 64, loss = 0.5039
Mean test/val loss: 0.5288
[25, 50, 75] quantiles test/val loss: [0.2771 0.5237 0.7587]

Epoch 66, loss = 0.5022
Mean test/val loss: 0.5306
[25, 50, 75] quantiles test/val loss: [0.2732 0.5258 0.7635]

Epoch 68, loss = 0.5007
Mean test/val loss: 0.5275
[25, 50, 75] quantiles test/val loss: [0.2727 0.5247 0.7594]

Epoch 70, loss = 0.4990
Mean test/val loss: 0.5261
[25, 50, 75] quantiles test/val loss: [0.27   0.5213 0.7679]

Epoch 72, loss = 0.4976
Mean test/val loss: 0.5256
[25, 50, 75] quantiles test/val loss: [0.271  0.5161 0.7605]

Epoch 74, loss = 0.4963
Mean test/val loss: 0.5259
[25, 50, 75] quantiles test/val loss: [0.2733 0.5131 0.7615]

Epoch 76, loss = 0.4948
Mean test/val loss: 0.5243
[25, 50, 75] quantiles test/val loss: [0.271  0.5185 0.7661]

Epoch 78, loss = 0.4933
Mean test/val loss: 0.5221
[25, 50, 75] quantiles test/val loss: [0.2718 0.5123 0.7591]

Epoch 80, loss = 0.4924
Mean test/val loss: 0.5218
[25, 50, 75] quantiles test/val loss: [0.2693 0.5148 0.7567]

Epoch 82, loss = 0.4912
Mean test/val loss: 0.5226
[25, 50, 75] quantiles test/val loss: [0.2634 0.5153 0.755 ]

Epoch 84, loss = 0.4900
Mean test/val loss: 0.5205
[25, 50, 75] quantiles test/val loss: [0.269  0.5136 0.7527]

Epoch 86, loss = 0.4887
Mean test/val loss: 0.5210
[25, 50, 75] quantiles test/val loss: [0.2708 0.5131 0.7639]

Epoch 88, loss = 0.4878
Mean test/val loss: 0.5198
[25, 50, 75] quantiles test/val loss: [0.2623 0.5107 0.7519]

Epoch 90, loss = 0.4866
Mean test/val loss: 0.5197
[25, 50, 75] quantiles test/val loss: [0.2636 0.5134 0.7632]

Epoch 92, loss = 0.4856
Mean test/val loss: 0.5194
[25, 50, 75] quantiles test/val loss: [0.2667 0.5081 0.7584]

Epoch 94, loss = 0.4845
Mean test/val loss: 0.5182
[25, 50, 75] quantiles test/val loss: [0.2639 0.511  0.7559]

Epoch 96, loss = 0.4835
Mean test/val loss: 0.5188
[25, 50, 75] quantiles test/val loss: [0.264  0.5082 0.7619]

Epoch 98, loss = 0.4826
Mean test/val loss: 0.5176
[25, 50, 75] quantiles test/val loss: [0.2653 0.5061 0.7552]

Epoch 100, loss = 0.4815
Mean test/val loss: 0.5168
[25, 50, 75] quantiles test/val loss: [0.2635 0.5079 0.7537]


Total parameters: 43349620
Total training + validation time: 9.0 hours, 20.0 mins, and 3.5 secs
Final val loss: 0.5167686828761362

split sizes: train=2160, val=240, test=0, N=2400
#### Plotting Script ####
Prediction Results:
dataset_11_18_22 sample1801: 0.3866291642189026
dataset_11_18_22 sample653: 1.0289738178253174
dataset_11_18_22 sample410: 0.4428877532482147
dataset_11_18_22 sample2290: 0.43887776136398315
dataset_11_18_22 sample1462: 0.26853176951408386
Loss: 0.513 +- 0.265

Downsampling (40%) Results:
dataset_11_18_22 sample1462-downsampling: 9.62880802154541
dataset_11_18_22 sample1801-downsampling: 7.252871513366699
dataset_11_18_22 sample2290-downsampling: 4.101645469665527
dataset_11_18_22 sample410-downsampling: 6.873978137969971
dataset_11_18_22 sample653-downsampling: 13.701515197753906
Loss: 8.312 +- 3.216

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy0downsample
Original sampling (100%) Results:
dataset_11_18_22 sample1462-regular: 8.384037971496582
dataset_11_18_22 sample1801-regular: 6.997666835784912
dataset_11_18_22 sample2290-regular: 4.113267421722412
dataset_11_18_22 sample410-regular: 6.331334114074707
dataset_11_18_22 sample653-regular: 13.164167404174805
Loss: 7.798 +- 3.017

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy0regsample
Upsampling (200%) Results:
dataset_11_18_22 sample1462-upsampling: 7.89244270324707
dataset_11_18_22 sample1801-upsampling: 6.988033294677734
dataset_11_18_22 sample2290-upsampling: 4.1295671463012695
dataset_11_18_22 sample410-upsampling: 7.14216423034668
dataset_11_18_22 sample653-upsampling: 12.018877029418945
Loss: 7.634 +- 2.539

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy0upsample
