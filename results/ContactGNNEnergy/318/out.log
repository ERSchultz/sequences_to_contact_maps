#### ARCHITECTURE ####
Node Encoder:
 None 

Edge Encoder:
 None 

Model:
 Sequential(
  (0): WeightedGATv2Conv(1, 8, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (2): WeightedGATv2Conv(64, 8, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (4): WeightedGATv2Conv(64, 8, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (6): WeightedGATv2Conv(64, 8, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
) 

Head 1:
 Bilinear 

Head 2:
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=32768, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1024, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['constant', 'ContactDistance', 'GeneticDistance_norm'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project2/depablo/erschultz/dataset_11_18_22', '/project2/depablo/erschultz/dataset_11_21_22'], scratch='/scratch/midway2/erschultz', root_name='ContactGNNEnergy3', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', y_zero_diag_count=0, log_preprocessing=None, output_preprocesing=None, kr=False, mean_filt=None, rescale=2, gated=False, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=False, use_scratch_parallel=True, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.0001, weight_decay=0.0, gpus=1, milestones=[50], gamma=0.1, loss='mse', w_reg=None, reg_lambda=0.1, autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_sym_diag', model_type='ContactGNNEnergy', id=318, pretrained=False, resume_training=False, k=None, m=1024, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, message_passing='weighted_GAT', head_architecture='bilinear_triu', head_architecture_2='fc-fill', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000, 1024], encoder_hidden_sizes_list=None, inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/318', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/318/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/318/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/318/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7ff5bff1aa60>, channels=1, node_feature_size=1, input_m=512, edge_transforms=["'ContactDistance'", 'ContactDistance(norm=False)', 'GeneticDistance(norm=True)'], node_transforms=['Constant(value=1.0)'], edge_dim=2, transforms_processed=None, diag=False, pre_transforms_processed=Compose([
  Constant(value=1.0),
  ContactDistance(norm=False),
  GeneticDistance(norm=True)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 78.23 minutes
Average num edges per graph:  222294.36527196653
Mean degree: [362.66 512.   449.47 ... 329.12 511.93 511.26] +- [70.54  0.   53.89 ... 80.99  0.29  1.69]

split sizes: train=4302, val=478, test=0, N=4780
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
#### TRAINING/VALIDATION ####
Epoch 2, loss = 11.3588
Mean test/val loss: 11.1282
[25, 50, 75] quantiles test/val loss: [ 6.3775  9.4072 12.8837]

Epoch 4, loss = 9.7702
Mean test/val loss: 10.0376
[25, 50, 75] quantiles test/val loss: [ 6.0084  9.1171 12.2534]

Epoch 6, loss = 9.2392
Mean test/val loss: 9.0087
[25, 50, 75] quantiles test/val loss: [ 5.163   7.5889 10.5847]

Epoch 8, loss = 8.6675
Mean test/val loss: 8.9732
[25, 50, 75] quantiles test/val loss: [ 5.2105  7.582  10.4099]

Epoch 10, loss = 8.1362
Mean test/val loss: 8.3551
[25, 50, 75] quantiles test/val loss: [ 5.0136  7.3501 10.1067]

Epoch 12, loss = 7.8944
Mean test/val loss: 9.5711
[25, 50, 75] quantiles test/val loss: [4.563  6.8033 9.7152]

Epoch 14, loss = 7.7169
Mean test/val loss: 9.7057
[25, 50, 75] quantiles test/val loss: [ 5.8236  8.3499 11.7509]

Epoch 16, loss = 7.5665
Mean test/val loss: 8.3706
[25, 50, 75] quantiles test/val loss: [5.0185 6.8458 9.756 ]

Epoch 18, loss = 7.4013
Mean test/val loss: 8.0590
[25, 50, 75] quantiles test/val loss: [4.6648 7.0624 9.8871]

Epoch 20, loss = 7.2519
Mean test/val loss: 7.4031
[25, 50, 75] quantiles test/val loss: [4.2064 6.3367 9.0592]

Epoch 22, loss = 7.1368
Mean test/val loss: 7.4914
[25, 50, 75] quantiles test/val loss: [4.5104 6.3872 9.0188]

Epoch 24, loss = 7.0477
Mean test/val loss: 7.4701
[25, 50, 75] quantiles test/val loss: [4.2636 6.5344 9.1686]

Epoch 26, loss = 7.1305
Mean test/val loss: 7.6655
[25, 50, 75] quantiles test/val loss: [4.5002 6.6411 9.1962]

Epoch 28, loss = 6.7578
Mean test/val loss: 7.4808
[25, 50, 75] quantiles test/val loss: [4.3697 6.4684 9.0782]

Epoch 30, loss = 6.8094
Mean test/val loss: 8.0407
[25, 50, 75] quantiles test/val loss: [4.4587 6.6583 9.3272]

Epoch 32, loss = 6.7275
Mean test/val loss: 6.9204
[25, 50, 75] quantiles test/val loss: [3.855  5.7952 8.5365]

Epoch 34, loss = 6.6294
Mean test/val loss: 7.4559
[25, 50, 75] quantiles test/val loss: [4.2772 6.1815 8.9584]

Epoch 36, loss = 47.3857
Mean test/val loss: 7.8917
[25, 50, 75] quantiles test/val loss: [4.7484 6.8532 9.8588]

Epoch 38, loss = 6.5993
Mean test/val loss: 7.0922
[25, 50, 75] quantiles test/val loss: [3.9983 6.033  8.4634]

Epoch 40, loss = 6.7383
Mean test/val loss: 6.9823
[25, 50, 75] quantiles test/val loss: [4.0529 5.9832 8.4526]

Epoch 42, loss = 6.5137
Mean test/val loss: 6.7975
[25, 50, 75] quantiles test/val loss: [3.7755 5.6726 8.2715]

Epoch 44, loss = 7.4125
Mean test/val loss: 7.2780
[25, 50, 75] quantiles test/val loss: [4.3277 6.2653 8.7989]

Epoch 46, loss = 6.3853
Mean test/val loss: 6.8755
[25, 50, 75] quantiles test/val loss: [3.8505 5.8584 8.4663]

Epoch 48, loss = 6.6471
Mean test/val loss: 7.0285
[25, 50, 75] quantiles test/val loss: [4.195  6.0975 8.6119]

Epoch 50, loss = 6.4424
Mean test/val loss: 6.8703
[25, 50, 75] quantiles test/val loss: [3.9409 5.9004 8.3318]

Epoch 52, loss = 5.8161
Mean test/val loss: 6.4632
[25, 50, 75] quantiles test/val loss: [3.4962 5.4109 8.0211]

Epoch 54, loss = 5.7167
Mean test/val loss: 6.3762
[25, 50, 75] quantiles test/val loss: [3.4344 5.2672 7.8374]

Epoch 56, loss = 5.6679
Mean test/val loss: 6.3247
[25, 50, 75] quantiles test/val loss: [3.3885 5.2119 7.7826]

Epoch 58, loss = 5.6297
Mean test/val loss: 6.3074
[25, 50, 75] quantiles test/val loss: [3.3983 5.2296 7.7928]

Epoch 60, loss = 5.5918
Mean test/val loss: 6.2826
[25, 50, 75] quantiles test/val loss: [3.3686 5.1712 7.6444]

Epoch 62, loss = 5.5637
Mean test/val loss: 6.2732
[25, 50, 75] quantiles test/val loss: [3.3435 5.1879 7.6725]

Epoch 64, loss = 5.5371
Mean test/val loss: 6.2505
[25, 50, 75] quantiles test/val loss: [3.289  5.1358 7.5972]

Epoch 66, loss = 5.5112
Mean test/val loss: 6.2388
[25, 50, 75] quantiles test/val loss: [3.3063 5.1248 7.5829]

Epoch 68, loss = 5.4888
Mean test/val loss: 6.2892
[25, 50, 75] quantiles test/val loss: [3.3153 5.1613 7.6568]

Epoch 70, loss = 5.4686
Mean test/val loss: 6.2230
[25, 50, 75] quantiles test/val loss: [3.2923 5.0969 7.6197]

Epoch 72, loss = 5.4497
Mean test/val loss: 6.2118
[25, 50, 75] quantiles test/val loss: [3.3411 5.0588 7.5461]

Epoch 74, loss = 5.4292
Mean test/val loss: 6.1945
[25, 50, 75] quantiles test/val loss: [3.2757 5.0564 7.5287]

Epoch 76, loss = 5.4125
Mean test/val loss: 6.1973
[25, 50, 75] quantiles test/val loss: [3.202  5.0629 7.5303]

Epoch 78, loss = 5.3929
Mean test/val loss: 6.1592
[25, 50, 75] quantiles test/val loss: [3.2447 5.0374 7.4517]

Epoch 80, loss = 5.3782
Mean test/val loss: 6.1603
[25, 50, 75] quantiles test/val loss: [3.2116 5.0077 7.4142]

Epoch 82, loss = 5.3611
Mean test/val loss: 6.1433
[25, 50, 75] quantiles test/val loss: [3.2173 5.0315 7.416 ]

Epoch 84, loss = 5.3445
Mean test/val loss: 6.1626
[25, 50, 75] quantiles test/val loss: [3.2217 4.9798 7.3965]

Epoch 86, loss = 5.3294
Mean test/val loss: 6.1546
[25, 50, 75] quantiles test/val loss: [3.1976 4.9631 7.3423]

Epoch 88, loss = 5.3162
Mean test/val loss: 6.1442
[25, 50, 75] quantiles test/val loss: [3.1949 4.9597 7.3468]

Epoch 90, loss = 5.3008
Mean test/val loss: 6.1377
[25, 50, 75] quantiles test/val loss: [3.1782 4.9256 7.4373]

Epoch 92, loss = 5.2886
Mean test/val loss: 6.1226
[25, 50, 75] quantiles test/val loss: [3.1987 4.945  7.3553]

Epoch 94, loss = 5.2730
Mean test/val loss: 6.1313
[25, 50, 75] quantiles test/val loss: [3.2117 4.9693 7.3761]

Epoch 96, loss = 5.2607
Mean test/val loss: 6.1207
[25, 50, 75] quantiles test/val loss: [3.1695 4.9205 7.3123]

Epoch 98, loss = 5.2474
Mean test/val loss: 6.1086
[25, 50, 75] quantiles test/val loss: [3.1758 4.9267 7.4407]

Epoch 100, loss = 5.2349
Mean test/val loss: 6.1302
[25, 50, 75] quantiles test/val loss: [3.1956 4.9475 7.4116]


Total parameters: 43347604
Total training + validation time: 19.0 hours, 43.0 mins, and 31.39999999999418 secs
Final val loss: 6.1301524179936955

split sizes: train=4302, val=478, test=0, N=4780
#### Plotting Script ####
Prediction Results:
dataset_11_21_22 sample939: 6.737451553344727
dataset_11_18_22 sample203: 6.553407192230225
dataset_11_21_22 sample743: 8.405644416809082
dataset_11_21_22 sample45: 2.868403911590576
dataset_11_18_22 sample559: 3.2729415893554688
Loss: 5.568 +- 2.142

Downsampling (40%) Results:
dataset_11_18_22 sample203-downsampling: 6.897390842437744
dataset_11_18_22 sample45-downsampling: 17.089462280273438
dataset_11_18_22 sample559-downsampling: 3.2729415893554688
dataset_11_18_22 sample743-downsampling: 10.689506530761719
dataset_11_18_22 sample939-downsampling: 3.5477664470672607
Loss: 6.452 +- 4.755

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy3downsample
Original sampling (100%) Results:
dataset_11_18_22 sample203-regular: 6.45280122756958
dataset_11_18_22 sample45-regular: 13.661038398742676
dataset_11_18_22 sample559-regular: 3.2387962341308594
dataset_11_18_22 sample743-regular: 9.160758018493652
dataset_11_18_22 sample939-regular: 3.2676005363464355
Loss: 5.628 +- 3.832

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy3regsample
Upsampling (200%) Results:
dataset_11_18_22 sample203-upsampling: 7.525984764099121
dataset_11_18_22 sample45-upsampling: 14.814220428466797
dataset_11_18_22 sample559-upsampling: 3.2799010276794434
dataset_11_18_22 sample743-upsampling: 9.873586654663086
dataset_11_18_22 sample939-upsampling: 3.238255262374878
Loss: 5.949 +- 4.226

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy3upsample
