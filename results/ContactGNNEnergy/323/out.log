#### ARCHITECTURE ####
Node Encoder:
 Sequential(
  (0): Linear(1, 1000, bias=True)
  (1): PReLU(num_parameters=1)
  (2): Linear(1000, 1000, bias=True)
  (3): PReLU(num_parameters=1)
  (4): Linear(1000, 64, bias=True)
  (5): PReLU(num_parameters=1)
) 

Edge Encoder:
 None 

Model:
 Sequential(
  (0): WeightedGATv2Conv(64, 8, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (2): WeightedGATv2Conv(64, 8, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (4): WeightedGATv2Conv(64, 8, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (6): WeightedGATv2Conv(64, 8, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
) 

Head 1:
 Bilinear 

Head 2:
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=32768, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1024, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['constant', 'ContactDistance', 'GeneticDistance_norm'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project2/depablo/erschultz/dataset_12_20_22'], scratch='/scratch/midway2/erschultz', root_name='ContactGNNEnergy11', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', y_zero_diag_count=0, log_preprocessing=None, output_preprocesing=None, kr=False, mean_filt=None, rescale=2, gated=False, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=False, use_scratch_parallel=True, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.0001, weight_decay=0.0, gpus=1, milestones=[50], gamma=0.1, loss='mse', w_reg=None, reg_lambda=0.1, autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_sym_diag', model_type='ContactGNNEnergy', id=323, pretrained=False, resume_training=False, k=None, m=1024, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, message_passing='weighted_GAT', head_architecture='bilinear_triu', head_architecture_2='fc-fill', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000, 1024], encoder_hidden_sizes_list=[1000, 1000, 64], inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/323', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/323/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/323/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/323/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7f5a3c33b9d0>, channels=1, node_feature_size=1, input_m=512, edge_transforms=["'ContactDistance'", 'ContactDistance(norm=False)', 'GeneticDistance(norm=True)'], node_transforms=['Constant(value=1.0)'], edge_dim=2, transforms_processed=None, diag=False, pre_transforms_processed=Compose([
  Constant(value=1.0),
  ContactDistance(norm=False),
  GeneticDistance(norm=True)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 76.84 minutes
Average num edges per graph:  248549.4796
Mean degree: [507.27 508.81 506.38 ... 511.81 440.   510.31] +- [ 5.29  4.55  9.05 ...  0.67 60.66  3.19]

split sizes: train=4500, val=500, test=0, N=5000
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
#### TRAINING/VALIDATION ####
Epoch 2, loss = 6.9588
Mean test/val loss: 6.4230
[25, 50, 75] quantiles test/val loss: [4.1965 5.622  7.7574]

Epoch 4, loss = 5.9305
Mean test/val loss: 6.1087
[25, 50, 75] quantiles test/val loss: [3.9849 5.6123 7.54  ]

Epoch 6, loss = 5.3158
Mean test/val loss: 6.4916
[25, 50, 75] quantiles test/val loss: [4.4986 6.0673 8.1254]

Epoch 8, loss = 4.7622
Mean test/val loss: 4.6573
[25, 50, 75] quantiles test/val loss: [2.8567 3.9871 5.6406]

Epoch 10, loss = 4.8202
Mean test/val loss: 4.3721
[25, 50, 75] quantiles test/val loss: [2.8536 3.8596 5.1077]

Epoch 12, loss = 4.2553
Mean test/val loss: 3.9895
[25, 50, 75] quantiles test/val loss: [2.4907 3.399  4.8516]

Epoch 14, loss = 4.0345
Mean test/val loss: 4.0564
[25, 50, 75] quantiles test/val loss: [2.1892 3.2978 5.0504]

Epoch 16, loss = 3.8047
Mean test/val loss: 3.5910
[25, 50, 75] quantiles test/val loss: [1.9676 2.9686 4.6146]

Epoch 18, loss = 3.7168
Mean test/val loss: 3.5174
[25, 50, 75] quantiles test/val loss: [1.9594 2.8998 4.368 ]

Epoch 20, loss = 3.5446
Mean test/val loss: 3.4184
[25, 50, 75] quantiles test/val loss: [2.0989 2.9267 4.175 ]

Epoch 22, loss = 3.5029
Mean test/val loss: 3.2552
[25, 50, 75] quantiles test/val loss: [1.816  2.6568 3.9896]

Epoch 24, loss = 3.3565
Mean test/val loss: 3.3246
[25, 50, 75] quantiles test/val loss: [2.0553 2.8252 4.016 ]

Epoch 26, loss = 3.4437
Mean test/val loss: 3.2184
[25, 50, 75] quantiles test/val loss: [1.9464 2.8246 4.0023]

Epoch 28, loss = 3.2372
Mean test/val loss: 3.0452
[25, 50, 75] quantiles test/val loss: [1.7182 2.498  3.7014]

Epoch 30, loss = 375320.8553
Mean test/val loss: 5.8908
[25, 50, 75] quantiles test/val loss: [3.7527 5.1037 6.8526]

Epoch 32, loss = 5.3171
Mean test/val loss: 4.9606
[25, 50, 75] quantiles test/val loss: [3.2012 4.272  5.9134]

Epoch 34, loss = 4.2378
Mean test/val loss: 4.0647
[25, 50, 75] quantiles test/val loss: [2.2793 3.2803 4.9926]

Epoch 36, loss = 3.2504
Mean test/val loss: 3.0914
[25, 50, 75] quantiles test/val loss: [1.7756 2.5857 3.7981]

Epoch 38, loss = 3.1132
Mean test/val loss: 3.1722
[25, 50, 75] quantiles test/val loss: [1.9411 2.6971 3.8371]

Epoch 40, loss = 3.0820
Mean test/val loss: 2.9445
[25, 50, 75] quantiles test/val loss: [1.7178 2.4994 3.6653]

Epoch 42, loss = 3.0073
Mean test/val loss: 38.5824
[25, 50, 75] quantiles test/val loss: [1.8402 2.7014 4.1124]

Epoch 44, loss = 4.9100
Mean test/val loss: 3.4384
[25, 50, 75] quantiles test/val loss: [1.9273 2.8917 4.1642]

Epoch 46, loss = 3.0302
Mean test/val loss: 2.9817
[25, 50, 75] quantiles test/val loss: [1.7186 2.4497 3.7358]

Epoch 48, loss = 2.9741
Mean test/val loss: 3.4282
[25, 50, 75] quantiles test/val loss: [2.069  2.9408 4.2617]

Epoch 50, loss = 3.0032
Mean test/val loss: 3.6752
[25, 50, 75] quantiles test/val loss: [2.1811 3.1409 4.6489]

Epoch 52, loss = 2.6683
Mean test/val loss: 2.7838
[25, 50, 75] quantiles test/val loss: [1.5632 2.2712 3.5209]

Epoch 54, loss = 2.4904
Mean test/val loss: 2.6965
[25, 50, 75] quantiles test/val loss: [1.5449 2.1763 3.4345]

Epoch 56, loss = 2.5033
Mean test/val loss: 2.6991
[25, 50, 75] quantiles test/val loss: [1.5509 2.1898 3.4366]

Epoch 58, loss = 2.4487
Mean test/val loss: 2.6622
[25, 50, 75] quantiles test/val loss: [1.5313 2.1489 3.4227]

Epoch 60, loss = 2.4231
Mean test/val loss: 2.6408
[25, 50, 75] quantiles test/val loss: [1.5136 2.1362 3.3943]

Epoch 62, loss = 2.3927
Mean test/val loss: 2.6179
[25, 50, 75] quantiles test/val loss: [1.5071 2.1196 3.3273]

Epoch 64, loss = 2.3686
Mean test/val loss: 2.6080
[25, 50, 75] quantiles test/val loss: [1.4988 2.106  3.3169]

Epoch 66, loss = 2.3469
Mean test/val loss: 2.5892
[25, 50, 75] quantiles test/val loss: [1.5009 2.1099 3.2875]

Epoch 68, loss = 2.3281
Mean test/val loss: 2.5819
[25, 50, 75] quantiles test/val loss: [1.474  2.0763 3.2641]

Epoch 70, loss = 2.3100
Mean test/val loss: 2.5839
[25, 50, 75] quantiles test/val loss: [1.4628 2.0588 3.3304]

Epoch 72, loss = 2.2933
Mean test/val loss: 2.5987
[25, 50, 75] quantiles test/val loss: [1.4805 2.0965 3.2981]

Epoch 74, loss = 2.2786
Mean test/val loss: 2.5626
[25, 50, 75] quantiles test/val loss: [1.461  2.0504 3.2471]

Epoch 76, loss = 2.2606
Mean test/val loss: 2.5374
[25, 50, 75] quantiles test/val loss: [1.4458 2.0332 3.2526]

Epoch 78, loss = 2.2464
Mean test/val loss: 2.5576
[25, 50, 75] quantiles test/val loss: [1.4414 2.0411 3.2509]

Epoch 80, loss = 2.2350
Mean test/val loss: 2.5509
[25, 50, 75] quantiles test/val loss: [1.459  2.0443 3.211 ]

Epoch 82, loss = 2.2205
Mean test/val loss: 2.5403
[25, 50, 75] quantiles test/val loss: [1.4521 2.0156 3.2273]

Epoch 84, loss = 2.2090
Mean test/val loss: 2.5212
[25, 50, 75] quantiles test/val loss: [1.4432 2.034  3.2309]

Epoch 86, loss = 2.1948
Mean test/val loss: 2.5409
[25, 50, 75] quantiles test/val loss: [1.459  2.0379 3.1929]

Epoch 88, loss = 2.1860
Mean test/val loss: 2.5391
[25, 50, 75] quantiles test/val loss: [1.4483 2.0219 3.1824]

Epoch 90, loss = 2.1733
Mean test/val loss: 2.5137
[25, 50, 75] quantiles test/val loss: [1.4335 2.0197 3.1616]

Epoch 92, loss = 2.1614
Mean test/val loss: 2.5234
[25, 50, 75] quantiles test/val loss: [1.4259 2.0136 3.1832]

Epoch 94, loss = 2.1507
Mean test/val loss: 2.5101
[25, 50, 75] quantiles test/val loss: [1.4377 1.9918 3.173 ]

Epoch 96, loss = 2.1398
Mean test/val loss: 2.5045
[25, 50, 75] quantiles test/val loss: [1.4268 2.0085 3.1903]

Epoch 98, loss = 2.1309
Mean test/val loss: 2.5258
[25, 50, 75] quantiles test/val loss: [1.4331 2.0258 3.1307]

Epoch 100, loss = 2.1206
Mean test/val loss: 2.5105
[25, 50, 75] quantiles test/val loss: [1.4051 1.9818 3.1833]


Total parameters: 44422732
Total training + validation time: 22.0 hours, 6.0 mins, and 18.39999999999418 secs
Final val loss: 2.510509380578995

split sizes: train=4500, val=500, test=0, N=5000
#### Plotting Script ####
Prediction Results:
dataset_12_20_22 sample981: 2.6391587257385254
dataset_12_20_22 sample324: 3.536193370819092
dataset_12_20_22 sample3464: 1.6147534847259521
dataset_12_20_22 sample2834: 3.2242836952209473
dataset_12_20_22 sample1936: 3.627127170562744
Loss: 2.928 +- 0.742

Downsampling (40%) Results:
dataset_12_20_22 sample1936-downsampling: 3.627126693725586
dataset_12_20_22 sample2834-downsampling: 2.8401007652282715
dataset_12_20_22 sample324-downsampling: 3.581663131713867
dataset_12_20_22 sample3464-downsampling: 1.9491043090820312
dataset_12_20_22 sample981-downsampling: 2.7571651935577393
Loss: 2.951 +- 0.618

Removing /project2/depablo/erschultz/dataset_12_20_22/ContactGNNEnergy11downsample
Original sampling (100%) Results:
dataset_12_20_22 sample1936-regular: 3.690669536590576
dataset_12_20_22 sample2834-regular: 3.528102397918701
dataset_12_20_22 sample324-regular: 3.6539254188537598
dataset_12_20_22 sample3464-regular: 1.6147528886795044
dataset_12_20_22 sample981-regular: 2.628969669342041
Loss: 3.023 +- 0.805

Removing /project2/depablo/erschultz/dataset_12_20_22/ContactGNNEnergy11regsample
Upsampling (200%) Results:
