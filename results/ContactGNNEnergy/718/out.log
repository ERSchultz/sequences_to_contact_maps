#### ARCHITECTURE ####
Node Encoder:
 None 

Linear:
 Linear(in_features=10, out_features=128, bias=True) 

Edge Encoder:
 None 

Model:
 Sequential(
  (0): WeightedGATv2Conv(128, 16, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=128, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (3): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (4): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
  )
)
  (2): WeightedGATv2Conv(128, 16, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=128, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (3): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (4): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
  )
)
  (4): WeightedGATv2Conv(128, 16, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=128, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (3): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (4): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
  )
)
  (6): WeightedGATv2Conv(128, 16, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=128, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (3): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (4): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
  )
)
) 

Head L:
 None 
 Bilinear 

Head D:
 None 
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=32768, out_features=1000, bias=True)
          (1): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=512, bias=True)
          (1): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['ContactDistance', 'MeanContactDistance', 'AdjPCs_10'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project2/depablo/erschultz/dataset_12_06_23_max_ent_other_exp'], scratch='/scratch/midway3/erschultz', root_name='ContactGNNEnergy13', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='log_inf', sweep_choices=None, y_zero_diag_count=0, log_preprocessing=None, output_preprocesing=None, kr=False, mean_filt=None, rescale=2, gated=False, preprocessing_norm='mean_fill', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, move_data_to_scratch=False, use_scratch_parallel=False, plaid_score_cutoff=None, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, max_sample=None, start_epoch=1, n_epochs=20, save_mod=5, print_mod=2, lr=0.0001, min_lr=1e-06, weight_decay=0.0, gpus=1, scheduler='MultiStepLR', milestones=[20], gamma=0.1, patience=10, loss='mse_log', loss_k=2, lambda1=1.0, lambda2=1.0, lambda3=1, grad_clip=None, w_reg=None, reg_lambda=0.1, autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_sym_diag', save_early_stop=False, model_type='ContactGNNEnergy', id=718, pretrain_id=690, resume_training=False, k=10, m=512, seed=42, act='leaky', inner_act='leaky', out_act='leaky', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, input_L_to_D=False, input_L_to_D_mode='meandist', output_clip=None, use_sign_net=False, use_sign_plus=True, message_passing='weighted_GAT', head_architecture='bilinear', head_architecture_2='fc-fill_512', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000], encoder_hidden_sizes_list=None, inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 1000, 1000, 128], head_act='leaky', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, bonded_path='optimize_grid_b_200_v_8_spheroid_1.5', kernel_w_list=None, hidden_sizes_list=[16, 16, 16, 16], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/718', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/718/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/718/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/718/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, node_feature_size=0, input_m=256, edge_transforms=['ContactDistance(norm=False)', 'MeanContactDistance(norm=False)'], node_transforms=['AdjPCs(k=10, normalize=False, sign_net=True)'], edge_dim=2, transforms_processed=None, diag=True, corr=False, pre_transforms_processed=Compose([
  ContactDistance(norm=False),
  MeanContactDistance(norm=False),
  AdjPCs(k=10, normalize=False, sign_net=True)
]), eig=False, criterion=<function mse_log at 0x7f1d21c8c4c0>, cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 0.436 minutes
Number of samples: 160
Average num edges per graph:  64496.9875
Mean degree: [253.73 254.72 254.27 253.62 251.82 252.6  254.62 254.52 254.09 250.7
 253.17 253.05 252.16 249.36 254.16 249.72 253.5  252.55 253.21 252.92
 254.12 248.59 254.68 251.94 253.63 248.46 251.72 250.67 254.23 254.19
 254.85 245.24 254.5  253.77 254.48 250.25 253.25 249.97 250.13 253.93
 253.07 244.54 238.76 248.68 247.69 243.68 239.15 252.33 242.4  249.32
 234.68 251.   254.8  254.89 250.43 254.99 254.8  254.99 251.16 254.69
 253.66 254.87 254.54 254.84 250.62 254.92 254.63 254.8  253.52 254.66
 251.05 252.94 254.25 252.02 251.62 254.21 254.41 253.86 252.05 254.26
 252.59 252.88 253.88 254.69 254.75 250.8  253.69 253.7  254.62 250.88
 254.61 254.03 253.02 254.63 248.42 253.88 254.31 254.77 253.16 254.83
 250.65 252.21 254.55 254.2  253.12 251.42 254.37 254.34 252.68 250.21
 254.68 251.11 252.98 253.25 250.84 254.15 243.84 253.77 253.67 253.25
 244.91 254.77 252.16 253.79 251.94 254.22 244.73 254.79 253.05 253.17
 248.35 254.19 248.29 251.34 254.54 253.19 248.77 244.52 250.53 253.04
 249.68 240.59 249.8  242.12 250.29 244.29 249.92 254.5  254.47 250.93
 253.95 254.65 254.69 252.1  253.57 254.59 253.17 253.98 249.34 253.39] +- [ 1.94  0.71  1.71  2.39 13.73  5.14  0.81  1.03  1.97  9.81  2.87  6.67
  3.08 10.13  1.52 15.01  2.03  5.37  8.76  2.61  1.37 16.36  0.71  3.82
  1.63  7.4   3.75  5.51  3.29  1.74  0.56 25.53  0.94  1.66  1.1   7.61
  2.73 15.12  8.32  2.97  2.21 14.02 21.14  5.72 11.7   8.82 15.47  3.59
 18.2   7.25 17.43 10.63  0.59  0.35 13.81  0.09  1.01  0.09  5.92  0.62
  3.25  0.43  1.13  0.53 12.56  0.28  0.67  0.55  2.64  0.91 15.11  4.89
  1.39  5.01  9.99  1.34  2.13  1.34  5.27  1.27  7.6   4.4   6.51  0.72
  0.56 13.12  1.73  2.84  0.73  4.59  0.75  2.22  2.6   0.82 15.96  1.48
  1.08  0.51  3.11  0.48 15.79  5.66  1.66  1.29  3.4   6.76  1.18  2.96
  2.3   8.98  0.75 10.8   3.85  7.55  4.2   1.48 17.27  1.24  3.56  2.27
  8.8   0.66  3.55  1.75  3.63  1.61 20.48  0.49  2.43  2.91  8.27  1.31
 16.36  7.88  1.41  2.31  8.8  15.23  5.28  4.03  5.56 15.28  5.59 18.92
  5.19  9.79 11.84  1.25  0.98 14.44  1.3   1.26  0.62  4.04  1.83  0.99
  2.84  1.65 16.19  2.06]

split sizes: train=144, val=16, test=0, N=160
First 100 val samples: [608, 620, 101, 460, 435, 469, 476, 274, 569, 515, 574, 614, 573, 450, 631, 234]
Pre-trained model is loaded.
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f1d142f4610>
#### TRAINING/VALIDATION ####
Epoch 2, loss = 0.2886
Mean test/val loss: 0.2766
[25, 50, 75] percentiles test/val loss: [0.2383 0.2587 0.3096]

Epoch 4, loss = 0.2794
Mean test/val loss: 0.2447
[25, 50, 75] percentiles test/val loss: [0.2288 0.2439 0.277 ]

Epoch 6, loss = 0.2526
Mean test/val loss: 0.2430
[25, 50, 75] percentiles test/val loss: [0.2105 0.2295 0.2849]

Epoch 8, loss = 0.2459
Mean test/val loss: 0.2447
[25, 50, 75] percentiles test/val loss: [0.2132 0.2266 0.2625]

Epoch 10, loss = 0.2415
Mean test/val loss: 0.2341
[25, 50, 75] percentiles test/val loss: [0.2128 0.2432 0.2592]

Epoch 12, loss = 0.2280
Mean test/val loss: 0.2322
[25, 50, 75] percentiles test/val loss: [0.2023 0.2214 0.2592]

Epoch 14, loss = 0.2230
Mean test/val loss: 0.2517
[25, 50, 75] percentiles test/val loss: [0.2212 0.2408 0.2842]

Epoch 16, loss = 0.2130
Mean test/val loss: 0.2350
[25, 50, 75] percentiles test/val loss: [0.2053 0.23   0.258 ]

Epoch 18, loss = 0.2128
Mean test/val loss: 0.2381
[25, 50, 75] percentiles test/val loss: [0.2113 0.2276 0.2701]

Epoch 20, loss = 0.2032
Mean test/val loss: 0.2292
[25, 50, 75] percentiles test/val loss: [0.2025 0.22   0.2605]

New lr: 1e-05

Total parameters: 51478960
Total training + validation time: 0.0 hours, 15.0 mins, and 59.200000000000045 secs
Final val loss: 0.2292146710678935

split sizes: train=144, val=16, test=0, N=160
#### Plotting Script ####
Prediction Results:
dataset_12_06_23_max_ent_other_exp sample234: 0.2266463041305542
dataset_12_06_23_max_ent_other_exp sample460: 0.20481818914413452
dataset_12_06_23_max_ent_other_exp sample101: 0.3000141978263855
dataset_12_06_23_max_ent_other_exp sample608: 0.201693594455719
dataset_12_06_23_max_ent_other_exp sample450: 0.2574222683906555
MSE_log: 0.238 +- 0.037

Downsampling (200k) Results:
Original sampling (400k) Results:
