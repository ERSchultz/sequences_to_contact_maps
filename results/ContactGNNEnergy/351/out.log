#### ARCHITECTURE ####
Node Encoder:
 Sequential(
  (0): Linear(1, 64, bias=True)
  (1): PReLU(num_parameters=1)
) 

Edge Encoder:
 None 

Linear:
 Linear(in_features=72, out_features=64, bias=True) 

Model:
 Sequential(
  (0): WeightedGATv2Conv(64, 8, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (2): WeightedGATv2Conv(64, 8, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (4): WeightedGATv2Conv(64, 8, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (6): WeightedGATv2Conv(64, 8, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
) 

Head L:
 Bilinear 

Head D:
 None 
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=16384, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1024, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['constant', 'ContactDistance', 'GeneticDistance_norm', 'AdjPCs_8'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project/depablo/erschultz/dataset_11_18_22', '/project/depablo/erschultz/dataset_11_21_22'], scratch='/scratch/midway2/erschultz', root_name='ContactGNNEnergy3', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', y_zero_diag_count=0, log_preprocessing=None, output_preprocesing='log', kr=False, mean_filt=None, rescale=4, gated=False, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=False, use_scratch_parallel=True, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.0001, min_lr=1e-06, weight_decay=0.0, gpus=1, scheduler='ReduceLROnPlateau', milestones=None, gamma=0.1, patience=10, loss='mse', w_reg=None, reg_lambda=0.1, autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_sym_diag', model_type='ContactGNNEnergy', id=351, pretrained=False, resume_training=False, k=8, m=1024, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, use_sign_net=False, use_sign_plus=True, message_passing='weighted_GAT', head_architecture='bilinear_triu', head_architecture_2='fc-fill', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000, 1024], encoder_hidden_sizes_list=[64], inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/351', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/351/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/351/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/351/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7f0d535ff3a0>, channels=1, node_feature_size=1, input_m=256, edge_transforms=["'ContactDistance'", 'ContactDistance(norm=False)', 'GeneticDistance(norm=True)'], node_transforms=['AdjPCs(k=8, normalize=False, sign_net=True)', 'Constant(value=1.0)'], edge_dim=2, transforms_processed=None, diag=True, pre_transforms_processed=Compose([
  Constant(value=1.0),
  ContactDistance(norm=False),
  GeneticDistance(norm=True),
  AdjPCs(k=8, normalize=False, sign_net=True)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 21.066 minutes
Average num edges per graph:  59772.228870292885
Mean degree: [215.03 256.   245.64 ... 198.8  256.   256.  ] +- [29.37  0.   13.17 ... 35.7   0.    0.  ]

split sizes: train=4302, val=478, test=0, N=4780
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f0d199ea2b0>
#### TRAINING/VALIDATION ####
Epoch 2, loss = 0.7779
Mean test/val loss: 0.7119
[25, 50, 75] quantiles test/val loss: [0.336  0.6951 1.0323]

Epoch 4, loss = 0.7163
Mean test/val loss: 0.7110
[25, 50, 75] quantiles test/val loss: [0.3265 0.6908 1.0581]

Epoch 6, loss = 0.6950
Mean test/val loss: 0.7071
[25, 50, 75] quantiles test/val loss: [0.3351 0.7051 1.0208]

Epoch 8, loss = 0.6810
Mean test/val loss: 0.6775
[25, 50, 75] quantiles test/val loss: [0.3282 0.6482 0.9981]

Epoch 10, loss = 0.6674
Mean test/val loss: 0.6321
[25, 50, 75] quantiles test/val loss: [0.2837 0.6176 0.9419]

Epoch 12, loss = 0.6458
Mean test/val loss: 0.6160
[25, 50, 75] quantiles test/val loss: [0.2828 0.6125 0.9005]

Epoch 14, loss = 0.6643
Mean test/val loss: 0.5983
[25, 50, 75] quantiles test/val loss: [0.2693 0.5673 0.8951]

Epoch 16, loss = 0.6251
Mean test/val loss: 0.5908
[25, 50, 75] quantiles test/val loss: [0.2705 0.5578 0.8777]

Epoch 18, loss = 0.6106
Mean test/val loss: 0.6058
[25, 50, 75] quantiles test/val loss: [0.2624 0.5705 0.9075]

Epoch 20, loss = 0.6016
Mean test/val loss: 0.5784
[25, 50, 75] quantiles test/val loss: [0.2541 0.5555 0.8758]

Epoch 22, loss = 0.5961
Mean test/val loss: 0.5805
[25, 50, 75] quantiles test/val loss: [0.2449 0.5615 0.865 ]

Epoch 24, loss = 0.5859
Mean test/val loss: 0.5586
[25, 50, 75] quantiles test/val loss: [0.2368 0.5383 0.8413]

Epoch 26, loss = 0.5779
Mean test/val loss: 12.1261
[25, 50, 75] quantiles test/val loss: [0.2306 0.5313 0.8478]

Epoch 28, loss = 0.5751
Mean test/val loss: 0.6226
[25, 50, 75] quantiles test/val loss: [0.2616 0.5964 0.928 ]

Epoch 30, loss = 0.5679
Mean test/val loss: 0.5498
[25, 50, 75] quantiles test/val loss: [0.2356 0.5145 0.828 ]

Epoch 32, loss = 0.5653
Mean test/val loss: 0.5448
[25, 50, 75] quantiles test/val loss: [0.2239 0.507  0.8235]

Epoch 34, loss = 0.5665
Mean test/val loss: 0.5438
[25, 50, 75] quantiles test/val loss: [0.2245 0.512  0.827 ]

Epoch 36, loss = 0.5559
Mean test/val loss: 0.5447
[25, 50, 75] quantiles test/val loss: [0.2237 0.499  0.8254]

Epoch 38, loss = 0.5472
Mean test/val loss: 0.5377
[25, 50, 75] quantiles test/val loss: [0.2224 0.5089 0.8179]

Epoch 40, loss = 0.5440
Mean test/val loss: 0.5404
[25, 50, 75] quantiles test/val loss: [0.2204 0.5079 0.8347]

Epoch 42, loss = 0.5661
Mean test/val loss: 0.5567
[25, 50, 75] quantiles test/val loss: [0.2299 0.5263 0.8457]

Epoch 44, loss = 0.5536
Mean test/val loss: 0.5333
[25, 50, 75] quantiles test/val loss: [0.2155 0.4927 0.8102]

Epoch 46, loss = 0.5591
Mean test/val loss: 0.5429
[25, 50, 75] quantiles test/val loss: [0.2121 0.503  0.8252]

Epoch 48, loss = 0.5342
Mean test/val loss: 0.5251
[25, 50, 75] quantiles test/val loss: [0.2107 0.4966 0.8043]

Epoch 50, loss = 0.5324
Mean test/val loss: 0.5415
[25, 50, 75] quantiles test/val loss: [0.243  0.5063 0.8067]

Epoch 52, loss = 0.5701
Mean test/val loss: 0.5448
[25, 50, 75] quantiles test/val loss: [0.2166 0.5161 0.8229]

Epoch 54, loss = 0.5278
Mean test/val loss: 0.5243
[25, 50, 75] quantiles test/val loss: [0.2109 0.5005 0.8002]

Epoch 56, loss = 0.5251
Mean test/val loss: 0.5271
[25, 50, 75] quantiles test/val loss: [0.21   0.4945 0.8001]

Epoch 58, loss = 0.5202
Mean test/val loss: 0.5230
[25, 50, 75] quantiles test/val loss: [0.2118 0.4954 0.7992]

Epoch 60, loss = 0.5174
Mean test/val loss: 0.5194
[25, 50, 75] quantiles test/val loss: [0.2038 0.4861 0.7987]

Epoch 62, loss = 0.5138
Mean test/val loss: 0.5164
[25, 50, 75] quantiles test/val loss: [0.201  0.4792 0.7911]

Epoch 64, loss = 0.5108
Mean test/val loss: 0.5171
[25, 50, 75] quantiles test/val loss: [0.2068 0.4856 0.7887]

Epoch 66, loss = 0.5067
Mean test/val loss: 0.5173
[25, 50, 75] quantiles test/val loss: [0.2062 0.4919 0.7913]

Epoch 68, loss = 0.5080
Mean test/val loss: 0.5682
[25, 50, 75] quantiles test/val loss: [0.2537 0.5459 0.8477]

Epoch 70, loss = 0.5015
Mean test/val loss: 0.5184
[25, 50, 75] quantiles test/val loss: [0.2058 0.4833 0.7908]

Epoch 72, loss = 0.5024
Mean test/val loss: 0.5095
[25, 50, 75] quantiles test/val loss: [0.2007 0.4759 0.7688]

Epoch 74, loss = 0.4993
Mean test/val loss: 0.5161
[25, 50, 75] quantiles test/val loss: [0.2077 0.476  0.7855]

Epoch 76, loss = 0.4957
Mean test/val loss: 0.5110
[25, 50, 75] quantiles test/val loss: [0.2051 0.4715 0.7864]

Epoch 78, loss = 0.4936
Mean test/val loss: 0.5196
[25, 50, 75] quantiles test/val loss: [0.2219 0.4818 0.7824]

Epoch 80, loss = 0.5259
Mean test/val loss: 0.5150
[25, 50, 75] quantiles test/val loss: [0.2048 0.4787 0.7959]

Epoch 82, loss = 0.4944
Mean test/val loss: 0.5151
[25, 50, 75] quantiles test/val loss: [0.1998 0.4802 0.7936]

New lr: 1e-05
Epoch 84, loss = 0.4983
Mean test/val loss: 0.5066
[25, 50, 75] quantiles test/val loss: [0.1982 0.4738 0.7774]

Epoch 86, loss = 0.4855
Mean test/val loss: 0.5045
[25, 50, 75] quantiles test/val loss: [0.1963 0.472  0.7767]

Epoch 88, loss = 0.4776
Mean test/val loss: 0.5027
[25, 50, 75] quantiles test/val loss: [0.1959 0.4686 0.7703]

Epoch 90, loss = 0.4740
Mean test/val loss: 0.5026
[25, 50, 75] quantiles test/val loss: [0.1962 0.4664 0.7755]

Epoch 92, loss = 0.4719
Mean test/val loss: 0.5027
[25, 50, 75] quantiles test/val loss: [0.1968 0.4679 0.7758]

Epoch 94, loss = 0.4703
Mean test/val loss: 0.5026
[25, 50, 75] quantiles test/val loss: [0.1952 0.468  0.7749]

Epoch 96, loss = 0.4690
Mean test/val loss: 0.5028
[25, 50, 75] quantiles test/val loss: [0.1963 0.4678 0.7786]

Epoch 98, loss = 0.4679
Mean test/val loss: 0.5028
[25, 50, 75] quantiles test/val loss: [0.1936 0.4654 0.7758]

Epoch 100, loss = 0.4668
Mean test/val loss: 0.5024
[25, 50, 75] quantiles test/val loss: [0.1958 0.4657 0.7754]


Total parameters: 26976468
Total training + validation time: 16.0 hours, 17.0 mins, and 27.900000000001455 secs
Final val loss: 0.5023925820084009

split sizes: train=4302, val=478, test=0, N=4780
#### Plotting Script ####
Prediction Results:
dataset_11_21_22 sample939: 0.5180076956748962
dataset_11_18_22 sample203: 0.9044971466064453
dataset_11_21_22 sample743: 0.8995165228843689
dataset_11_21_22 sample45: 0.19278842210769653
dataset_11_18_22 sample559: 0.4276512861251831
Loss: 0.588 +- 0.277

Downsampling (40%) Results:
dataset_11_18_22 sample203-downsampling: 7.741990566253662
dataset_11_18_22 sample45-downsampling: 22.003314971923828
dataset_11_18_22 sample559-downsampling: 3.834627628326416
dataset_11_18_22 sample743-downsampling: 14.355544090270996
dataset_11_18_22 sample939-downsampling: 3.4455127716064453
Loss: 7.753 +- 6.383

Removing /project/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy3downsample
Original sampling (100%) Results:
dataset_11_18_22 sample203-regular: 7.804327487945557
dataset_11_18_22 sample45-regular: 17.616445541381836
dataset_11_18_22 sample559-regular: 3.6231956481933594
dataset_11_18_22 sample743-regular: 13.585113525390625
dataset_11_18_22 sample939-regular: 3.2331743240356445
Loss: 7.15 +- 5.468

Removing /project/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy3regsample
Upsampling (200%) Results:
dataset_11_18_22 sample203-upsampling: 7.666696548461914
dataset_11_18_22 sample45-upsampling: 20.36030387878418
dataset_11_18_22 sample559-upsampling: 3.947251319885254
dataset_11_18_22 sample743-upsampling: 14.353219985961914
dataset_11_18_22 sample939-upsampling: 3.1051692962646484
Loss: 7.457 +- 6.088

Removing /project/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy3upsample
