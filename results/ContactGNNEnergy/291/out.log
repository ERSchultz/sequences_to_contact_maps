#### ARCHITECTURE ####
Node Encoder:
 None 

Edge Encoder:
 None 

Model:
 Sequential(
  (0): WeightedGATv2Conv(1, 8, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (2): WeightedGATv2Conv(64, 8, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (4): WeightedGATv2Conv(64, 8, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (6): WeightedGATv2Conv(64, 8, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
) 

Head 1:
 Bilinear 

Head 2:
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=32768, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1024, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['constant', 'ContactDistance', 'GeneticDistance_norm'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project2/depablo/erschultz/dataset_11_18_22'], scratch='/scratch/midway2/erschultz', root_name='ContactGNNEnergy1', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', y_zero_diag_count=0, log_preprocessing=None, output_preprocesing='log', kr=True, mean_filt=None, rescale=2, gated=False, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=False, use_scratch_parallel=True, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.0001, weight_decay=0.0, gpus=1, milestones=[50], gamma=0.1, loss='mse', autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_SD', model_type='ContactGNNEnergy', id=291, pretrained=False, resume_training=False, k=None, m=1024, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, message_passing='weighted_GAT', head_architecture='bilinear', head_architecture_2='fc-fill', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000, 1024], encoder_hidden_sizes_list=None, inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/291', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/291/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/291/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/291/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7f511c956940>, channels=1, node_feature_size=1, input_m=512, edge_transforms=["'ContactDistance'", 'ContactDistance(norm=False)', 'GeneticDistance(norm=True)'], node_transforms=['Constant(value=1.0)'], edge_dim=2, transforms_processed=None, diag=False, pre_transforms_processed=Compose([
  Constant(value=1.0),
  ContactDistance(norm=False),
  GeneticDistance(norm=True)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 37.313 minutes
Average num edges per graph:  219629.77916666667
Mean degree: [362.66 512.   449.47 ... 399.29 390.16 429.63] +- [70.54  0.   53.89 ... 85.38 67.92 62.93]

split sizes: train=2160, val=240, test=0, N=2400
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
#### TRAINING/VALIDATION ####
Epoch 2, loss = 0.9585
Mean test/val loss: 0.8551
[25, 50, 75] quantiles test/val loss: [0.5712 0.8761 1.1087]

Epoch 4, loss = 0.9665
Mean test/val loss: 0.8826
[25, 50, 75] quantiles test/val loss: [0.6144 0.9114 1.1528]

Epoch 6, loss = 0.8536
Mean test/val loss: 0.8326
[25, 50, 75] quantiles test/val loss: [0.5266 0.863  1.1333]

Epoch 8, loss = 0.8438
Mean test/val loss: 0.9643
[25, 50, 75] quantiles test/val loss: [0.5766 0.9195 1.3603]

Epoch 10, loss = 0.8121
Mean test/val loss: 0.8031
[25, 50, 75] quantiles test/val loss: [0.5348 0.832  1.0846]

Epoch 12, loss = 0.8069
Mean test/val loss: 0.7740
[25, 50, 75] quantiles test/val loss: [0.5181 0.8016 0.9904]

Epoch 14, loss = 0.7896
Mean test/val loss: 0.8184
[25, 50, 75] quantiles test/val loss: [0.535  0.8246 1.046 ]

Epoch 16, loss = 0.7740
Mean test/val loss: 0.8026
[25, 50, 75] quantiles test/val loss: [0.547  0.8266 1.0184]

Epoch 18, loss = 0.8054
Mean test/val loss: 0.8074
[25, 50, 75] quantiles test/val loss: [0.5312 0.8669 1.0892]

Epoch 20, loss = 0.8431
Mean test/val loss: 0.7938
[25, 50, 75] quantiles test/val loss: [0.5557 0.8512 1.0267]

Epoch 22, loss = 0.7633
Mean test/val loss: 0.7624
[25, 50, 75] quantiles test/val loss: [0.5098 0.7713 0.9821]

Epoch 24, loss = 0.7638
Mean test/val loss: 0.8334
[25, 50, 75] quantiles test/val loss: [0.5326 0.8517 1.1109]

Epoch 26, loss = 0.7427
Mean test/val loss: 0.7334
[25, 50, 75] quantiles test/val loss: [0.476  0.7875 0.9935]

Epoch 28, loss = 0.7826
Mean test/val loss: 0.7498
[25, 50, 75] quantiles test/val loss: [0.5011 0.7722 0.9856]

Epoch 30, loss = 0.7311
Mean test/val loss: 0.7487
[25, 50, 75] quantiles test/val loss: [0.487  0.8262 0.9915]

Epoch 32, loss = 0.7328
Mean test/val loss: 0.7196
[25, 50, 75] quantiles test/val loss: [0.4846 0.7455 0.9457]

Epoch 34, loss = 4.0235
Mean test/val loss: 2.0072
[25, 50, 75] quantiles test/val loss: [1.0733 1.6608 2.6178]

Epoch 36, loss = 1.3249
Mean test/val loss: 1.0339
[25, 50, 75] quantiles test/val loss: [0.666  0.9697 1.3848]

Epoch 38, loss = 1.0644
Mean test/val loss: 0.9276
[25, 50, 75] quantiles test/val loss: [0.5988 0.9227 1.2455]

Epoch 40, loss = 0.9304
Mean test/val loss: 1.0397
[25, 50, 75] quantiles test/val loss: [0.7386 1.0501 1.3686]

Epoch 42, loss = 0.8435
Mean test/val loss: 0.8484
[25, 50, 75] quantiles test/val loss: [0.5435 0.8352 1.1088]

Epoch 44, loss = 0.7973
Mean test/val loss: 0.7891
[25, 50, 75] quantiles test/val loss: [0.5092 0.8439 1.0708]

Epoch 46, loss = 0.7491
Mean test/val loss: 0.7119
[25, 50, 75] quantiles test/val loss: [0.4647 0.7453 0.9235]

Epoch 48, loss = 0.7814
Mean test/val loss: 0.7342
[25, 50, 75] quantiles test/val loss: [0.469  0.7568 0.971 ]

Epoch 50, loss = 0.7761
Mean test/val loss: 0.7593
[25, 50, 75] quantiles test/val loss: [0.4699 0.8175 1.0315]

Epoch 52, loss = 0.6995
Mean test/val loss: 0.6940
[25, 50, 75] quantiles test/val loss: [0.4348 0.7118 0.9514]

Epoch 54, loss = 0.6812
Mean test/val loss: 0.6779
[25, 50, 75] quantiles test/val loss: [0.4225 0.6915 0.942 ]

Epoch 56, loss = 0.6709
Mean test/val loss: 0.6778
[25, 50, 75] quantiles test/val loss: [0.4181 0.6849 0.9481]

Epoch 58, loss = 0.6633
Mean test/val loss: 0.6635
[25, 50, 75] quantiles test/val loss: [0.406  0.6796 0.9181]

Epoch 60, loss = 0.6573
Mean test/val loss: 0.6570
[25, 50, 75] quantiles test/val loss: [0.4018 0.667  0.9099]

Epoch 62, loss = 0.6533
Mean test/val loss: 0.6537
[25, 50, 75] quantiles test/val loss: [0.3998 0.6603 0.8913]

Epoch 64, loss = 0.6494
Mean test/val loss: 0.6510
[25, 50, 75] quantiles test/val loss: [0.3955 0.6577 0.9006]

Epoch 66, loss = 0.6456
Mean test/val loss: 0.6472
[25, 50, 75] quantiles test/val loss: [0.3909 0.6577 0.8831]

Epoch 68, loss = 0.6423
Mean test/val loss: 0.6455
[25, 50, 75] quantiles test/val loss: [0.3891 0.6526 0.883 ]

Epoch 70, loss = 0.6384
Mean test/val loss: 0.6409
[25, 50, 75] quantiles test/val loss: [0.384  0.6499 0.8811]

Epoch 72, loss = 0.6363
Mean test/val loss: 0.6446
[25, 50, 75] quantiles test/val loss: [0.3848 0.6445 0.889 ]

Epoch 74, loss = 0.6332
Mean test/val loss: 0.6355
[25, 50, 75] quantiles test/val loss: [0.3803 0.6373 0.8709]

Epoch 76, loss = 0.6294
Mean test/val loss: 0.6371
[25, 50, 75] quantiles test/val loss: [0.3846 0.6416 0.878 ]

Epoch 78, loss = 0.6259
Mean test/val loss: 0.6328
[25, 50, 75] quantiles test/val loss: [0.3806 0.6373 0.8781]

Epoch 80, loss = 0.6225
Mean test/val loss: 0.6483
[25, 50, 75] quantiles test/val loss: [0.4057 0.6546 0.8757]

Epoch 82, loss = 0.6208
Mean test/val loss: 0.6300
[25, 50, 75] quantiles test/val loss: [0.3651 0.6394 0.8722]

Epoch 84, loss = 0.6164
Mean test/val loss: 0.6318
[25, 50, 75] quantiles test/val loss: [0.3769 0.643  0.8621]

Epoch 86, loss = 0.6128
Mean test/val loss: 0.6276
[25, 50, 75] quantiles test/val loss: [0.3697 0.6327 0.8637]

Epoch 88, loss = 0.6108
Mean test/val loss: 0.6346
[25, 50, 75] quantiles test/val loss: [0.37   0.629  0.8755]

Epoch 90, loss = 0.6085
Mean test/val loss: 0.6278
[25, 50, 75] quantiles test/val loss: [0.3761 0.6363 0.877 ]

Epoch 92, loss = 0.6055
Mean test/val loss: 0.6265
[25, 50, 75] quantiles test/val loss: [0.3641 0.628  0.8691]

Epoch 94, loss = 0.6037
Mean test/val loss: 0.6238
[25, 50, 75] quantiles test/val loss: [0.3534 0.6409 0.8627]

Epoch 96, loss = 0.5994
Mean test/val loss: 0.6199
[25, 50, 75] quantiles test/val loss: [0.3504 0.6252 0.8667]

Epoch 98, loss = 0.5980
Mean test/val loss: 0.6209
[25, 50, 75] quantiles test/val loss: [0.3464 0.6232 0.858 ]

Epoch 100, loss = 0.5952
Mean test/val loss: 0.6185
[25, 50, 75] quantiles test/val loss: [0.3585 0.6197 0.859 ]


Total parameters: 43349620
Total training + validation time: 9.0 hours, 26.0 mins, and 50.0 secs
Final val loss: 0.6184715357841923

split sizes: train=2160, val=240, test=0, N=2400
#### Plotting Script ####
Prediction Results:
dataset_11_18_22 sample1801: 0.48323071002960205
dataset_11_18_22 sample653: 1.1119117736816406
dataset_11_18_22 sample410: 0.5273110270500183
dataset_11_18_22 sample2290: 0.5153759121894836
dataset_11_18_22 sample1462: 0.38273537158966064
Loss: 0.604 +- 0.259

Downsampling (40%) Results:
dataset_11_18_22 sample1462-downsampling: 16.691986083984375
dataset_11_18_22 sample1801-downsampling: 9.264748573303223
dataset_11_18_22 sample2290-downsampling: 4.951412200927734
dataset_11_18_22 sample410-downsampling: 8.266798973083496
dataset_11_18_22 sample653-downsampling: 14.16330337524414
Loss: 10.668 +- 4.217

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy1downsample
Original sampling (100%) Results:
dataset_11_18_22 sample1462-regular: 15.529454231262207
dataset_11_18_22 sample1801-regular: 9.136744499206543
dataset_11_18_22 sample2290-regular: 5.242964267730713
dataset_11_18_22 sample410-regular: 7.743869781494141
dataset_11_18_22 sample653-regular: 14.584744453430176
Loss: 10.448 +- 3.976

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy1regsample
Upsampling (200%) Results:
dataset_11_18_22 sample1462-upsampling: 15.299921989440918
dataset_11_18_22 sample1801-upsampling: 9.068299293518066
dataset_11_18_22 sample2290-upsampling: 6.399894714355469
dataset_11_18_22 sample410-upsampling: 10.063102722167969
dataset_11_18_22 sample653-upsampling: 14.91611099243164
Loss: 11.149 +- 3.449

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy1upsample
