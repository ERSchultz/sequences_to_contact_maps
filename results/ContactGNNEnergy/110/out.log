Took 248.0 seconds to move data to scratch
#### ARCHITECTURE ####
Sequential(
  (0): Linear(13, 100, bias=True)
  (1): PReLU(num_parameters=1)
  (2): Linear(100, 100, bias=True)
  (3): PReLU(num_parameters=1)
  (4): Linear(100, 16, bias=True)
  (5): PReLU(num_parameters=1)
)
Sequential(
  (0): WeightedSignedConv(16, 8, first_aggr=True)
  (1): Linear(16, 100, bias=True)
  (2): PReLU(num_parameters=1)
  (3): Linear(100, 100, bias=True)
  (4): PReLU(num_parameters=1)
  (5): Linear(100, 16, bias=True)
  (6): PReLU(num_parameters=1)
  (7): WeightedSignedConv(8, 8, first_aggr=False)
  (8): Linear(16, 100, bias=True)
  (9): PReLU(num_parameters=1)
  (10): Linear(100, 100, bias=True)
  (11): PReLU(num_parameters=1)
  (12): Linear(100, 16, bias=True)
  (13): PReLU(num_parameters=1)
  (14): WeightedSignedConv(8, 8, first_aggr=False)
  (15): Linear(16, 100, bias=True)
  (16): PReLU(num_parameters=1)
  (17): Linear(100, 100, bias=True)
  (18): PReLU(num_parameters=1)
  (19): Linear(100, 16, bias=True)
  (20): PReLU(num_parameters=1)
)
None 

Namespace(GNN_mode=True, act='prelu', autoencoder_mode=False, batch_size=2, bottleneck=None, channels=1, classes=10, criterion=<function mse_loss at 0x7fb3820504c0>, crop=None, cuda=True, data_folder='/scratch/midway2/erschultz/dataset_01_17_22', delete_root=False, device=device(type='cuda'), dilation_list=None, dilation_list_head=None, dilation_list_trunk=None, down_sampling=None, encoder_hidden_sizes_list=[100, 100, 16], gamma=0.1, gpus=1, head_act='prelu', head_architecture='bilinear', head_hidden_sizes_list=None, hidden_sizes_list=[8, 8, 8], id=110, inner_act='prelu', k=None, kernel_w_list=None, log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/110/out.log' mode='a' encoding='UTF-8'>, log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/110/out.log', loss='mse', lr=0.001, m=1024, message_passing='SignedConv', milestones=None, min_subtraction=True, model_type='ContactGNNEnergy', n_epochs=100, nf=None, node_feature_size=13, num_workers=4, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/110', out_act='prelu', output_mode='energy', param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/110/params.log' mode='a' encoding='UTF-8'>, parameter_sharing=False, plot=True, plot_predictions=True, pre_transforms=['AdjPCA', 'degree'], pre_transforms_processed=Compose([
    <utils.pyg_fns.AdjPCATransform object at 0x7fb356cad250>,
    <utils.pyg_fns.Degree object at 0x7fb356cad310>,
]), pretrained=False, print_mod=2, print_params=True, random_split=False, relabel_11_to_00=False, resume_training=False, root_name='ContactGNNEnergy6', save_mod=5, scratch='/scratch/midway2/erschultz', seed=42, shuffle=True, sparsify_threshold=0.176, sparsify_threshold_upper=None, split_edges_for_feature_augmentation=True, split_neg_pos_edges=True, split_percents=None, split_sizes=[4000, 200, 0], start_epoch=1, top_k=None, toxx=False, toxx_mode='mean', training_norm=None, transform_k=10, transforms=None, transforms_processed=None, update_hidden_sizes_list=[100, 100, 16], use_bias=True, use_edge_weights=True, use_node_features=False, use_parallel=False, use_scratch=True, use_scratch_parallel=False, verbose=False, x_reshape=True, y_log_transform=True, y_norm=None, y_preprocessing='diag', y_reshape=True, ydtype=torch.float32)

Dataset construction time: 44.752 minutes
Mean degree: [790.61 345.01 627.84 ... 178.61 161.1  806.37] +- [132.49  95.2  140.36 ...  96.5   84.01 148.96]

#### TRAINING/VALIDATION ####
Epoch 2, loss = 1.6931
Mean test/val loss: 1.5414

Epoch 4, loss = 1.4286
Mean test/val loss: 1.3393

Epoch 6, loss = 1.3381
Mean test/val loss: 1.2660

Epoch 8, loss = 1.3036
Mean test/val loss: 1.2407

Epoch 10, loss = 1.2664
Mean test/val loss: 1.2534

Epoch 12, loss = 1.2366
Mean test/val loss: 1.2323

Epoch 14, loss = 1.2203
Mean test/val loss: 1.3337

Epoch 16, loss = 1.1920
Mean test/val loss: 1.1758

Epoch 18, loss = 1.1820
Mean test/val loss: 1.1583

Epoch 20, loss = 1.1715
Mean test/val loss: 1.1641

Epoch 22, loss = 1.1662
Mean test/val loss: 1.1442

Epoch 24, loss = 1.1686
Mean test/val loss: 1.1263

Epoch 26, loss = 1.1495
Mean test/val loss: 1.1165

Epoch 28, loss = 1.1462
Mean test/val loss: 1.1068

Epoch 30, loss = 1.1352
Mean test/val loss: 1.1239

Epoch 32, loss = 1.2808
Mean test/val loss: 1.2213

Epoch 34, loss = 1.1962
Mean test/val loss: 1.1590

Epoch 36, loss = 1.1617
Mean test/val loss: 1.1552

Epoch 38, loss = 1.1400
Mean test/val loss: 1.1220

Epoch 40, loss = 1.1347
Mean test/val loss: 1.1007

Epoch 42, loss = 1.1298
Mean test/val loss: 1.1504

Epoch 44, loss = 1.1353
Mean test/val loss: 1.1165

Epoch 46, loss = 1.1271
Mean test/val loss: 1.0981

Epoch 48, loss = 1.1269
Mean test/val loss: 1.1124

Epoch 50, loss = 1.1193
Mean test/val loss: 1.0863

Epoch 52, loss = 1.1149
Mean test/val loss: 1.0906

Epoch 54, loss = 1.1199
Mean test/val loss: 1.1003

Epoch 56, loss = 1.1072
Mean test/val loss: 1.0905

Epoch 58, loss = 1.1069
Mean test/val loss: 1.1008

Epoch 60, loss = 1.1079
Mean test/val loss: 1.0933

Epoch 62, loss = 3.2865
Mean test/val loss: 1.1800

Epoch 64, loss = 1.1590
Mean test/val loss: 1.1255

Epoch 66, loss = 1.1227
Mean test/val loss: 1.1015

Epoch 68, loss = 1.1111
Mean test/val loss: 1.0798

Epoch 70, loss = 1.1063
Mean test/val loss: 1.0841

Epoch 72, loss = 24.3544
Mean test/val loss: 1.5686

Epoch 74, loss = 1.3968
Mean test/val loss: 1.2877

Epoch 76, loss = 1.2660
Mean test/val loss: 1.2750

Epoch 78, loss = 1.2024
