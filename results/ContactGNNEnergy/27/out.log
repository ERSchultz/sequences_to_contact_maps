Took 25.0 seconds to move data to scratch
#### ARCHITECTURE ####
Sequential(
  (0): GCNConv(1, 16)
  (1): ReLU(inplace=True)
  (2): GCNConv(16, 4)
)
Sequential(
  (0): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=16, out_features=1, bias=True)
      (1): Identity()
    )
  )
) 

Namespace(GNN_mode=True, act='relu', autoencoder_mode=False, batch_size=4, bottleneck=None, channels=1, classes=10, criterion=<function mse_loss at 0x7efc394b6040>, crop=None, cuda=True, data_folder='/scratch/midway2/erschultz/dataset_04_18_21', degree=True, delete_root=False, device=device(type='cuda'), dilation_list=None, dilation_list_head=None, dilation_list_trunk=None, down_sampling=None, gamma=0.1, gpus=1, head_act=None, head_architecture='outer', head_hidden_sizes_list=[1], hidden_sizes_list=[16, 4], id=27, ifile=None, ifile_folder=None, inner_act='sigmoid', k=2, kernel_w_list=None, log_file=<_io.TextIOWrapper name='results/ContactGNNEnergy/27/out.log' mode='a' encoding='UTF-8'>, loss='mse', lr=0.001, m=1024, message_passing='GCN', milestones=None, min_subtraction=True, model_type='ContactGNNEnergy', n_epochs=100, nf=None, node_feature_size=1, num_workers=4, ofile_folder='results/ContactGNNEnergy/27', out_act=None, output_mode='energy', parameter_sharing=False, plot=True, plot_predictions=True, pre_transforms=['degree'], pre_transforms_processed=None, pretrained=False, print_mod=2, print_params=True, relabel_11_to_00=False, resume_training=False, root_name='ContactGNNEnergy', save_mod=5, seed=42, shuffle=True, sparsify_threshold=1.0, sparsify_threshold_upper=None, split=[0.8, 0.1, 0.1], split_neg_pos_edges=False, split_neg_pos_edges_for_feature_augmentation=False, start_epoch=1, top_k=None, toxx=False, toxx_mode='mean', training_norm=None, transforms=None, transforms_processed=None, use_bias=True, use_edge_weights=True, use_node_features=False, use_parallel=False, use_scratch=True, verbose=False, weighted_LDP=False, weighted_degree=False, x_reshape=True, y_log_transform=False, y_norm=None, y_preprocessing='diag', y_reshape=True, ydtype=torch.float32)

#### INITIAL PARAMETERS ####
model.nns.0.weight torch.Size([1, 16])
Parameter containing:
tensor([[ 0.4542,  0.4931, -0.1392,  0.5457, -0.1302,  0.1199, -0.2892,  0.3489,
          0.5237, -0.4358,  0.5164,  0.1112,  0.4389,  0.0805,  0.2865, -0.0839]],
       device='cuda:0', requires_grad=True) 

model.nns.0.bias torch.Size([16])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True) 

model.nns.2.weight torch.Size([16, 4])
Parameter containing:
tensor([[ 0.4222,  0.0810, -0.2557,  0.1396],
        [-0.2524, -0.0642, -0.2225,  0.3633],
        [-0.4324, -0.2525, -0.1547, -0.3293],
        [ 0.0517, -0.5410,  0.4947, -0.4653],
        [ 0.4229,  0.0912, -0.1778,  0.3385],
        [ 0.0854,  0.4425,  0.0599, -0.1727],
        [ 0.1472, -0.1485,  0.2305,  0.4890],
        [ 0.3166, -0.2394,  0.3162,  0.0980],
        [ 0.2782, -0.3338, -0.5422, -0.2116],
        [-0.4201,  0.4494,  0.1578,  0.2269],
        [ 0.1732, -0.0095,  0.4287, -0.3892],
        [ 0.0345, -0.3738,  0.1689, -0.1886],
        [ 0.1678, -0.1141,  0.4543, -0.3246],
        [-0.3267, -0.3267,  0.4926,  0.1825],
        [ 0.5270, -0.4520, -0.5433, -0.4285],
        [-0.3684,  0.2218,  0.1961,  0.4551]], device='cuda:0',
       requires_grad=True) 

model.nns.2.bias torch.Size([4])
Parameter containing:
tensor([0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

head.0.model.0.weight torch.Size([1, 16])
Parameter containing:
tensor([[-0.1291, -0.1704,  0.1326, -0.1011,  0.1517, -0.0593,  0.1430, -0.1942,
         -0.1262,  0.0762,  0.0529, -0.0637,  0.1490,  0.1700, -0.1813, -0.1335]],
       device='cuda:0', requires_grad=True) 

head.0.model.0.bias torch.Size([1])
Parameter containing:
tensor([0.2289], device='cuda:0', requires_grad=True) 



#### TRAINING/VALIDATION ####
Epoch 2, loss = 0.2479
Mean test/val loss: 0.2358

Epoch 4, loss = 0.2027
Mean test/val loss: 0.1934

Epoch 6, loss = 0.1824
Mean test/val loss: 0.1792

Epoch 8, loss = 0.1756
Mean test/val loss: 0.1732

Epoch 10, loss = 0.1720
Mean test/val loss: 0.1701

Epoch 12, loss = 0.1702
Mean test/val loss: 0.1685

Epoch 14, loss = 0.1691
Mean test/val loss: 0.1677

Epoch 16, loss = 0.1683
Mean test/val loss: 0.1669

Epoch 18, loss = 0.1677
Mean test/val loss: 0.1666

Epoch 20, loss = 0.1672
Mean test/val loss: 0.1659

Epoch 22, loss = 0.1668
Mean test/val loss: 0.1655

Epoch 24, loss = 0.1664
Mean test/val loss: 0.1653

Epoch 26, loss = 0.1660
Mean test/val loss: 0.1656

Epoch 28, loss = 0.1658
Mean test/val loss: 0.1647

Epoch 30, loss = 0.1655
Mean test/val loss: 0.1646

Epoch 32, loss = 0.1652
Mean test/val loss: 0.1642

Epoch 34, loss = 0.1651
Mean test/val loss: 0.1641

Epoch 36, loss = 0.1648
Mean test/val loss: 0.1637

Epoch 38, loss = 0.1646
Mean test/val loss: 0.1639

Epoch 40, loss = 0.1645
Mean test/val loss: 0.1637

Epoch 42, loss = 0.1642
Mean test/val loss: 0.1633

Epoch 44, loss = 0.1640
Mean test/val loss: 0.1631

Epoch 46, loss = 0.1638
Mean test/val loss: 0.1628

Epoch 48, loss = 0.1637
Mean test/val loss: 0.1631

Epoch 50, loss = 0.1635
Mean test/val loss: 0.1625

Epoch 52, loss = 0.1633
Mean test/val loss: 0.1628

Epoch 54, loss = 0.1632
Mean test/val loss: 0.1622

Epoch 56, loss = 0.1630
Mean test/val loss: 0.1620

Epoch 58, loss = 0.1628
Mean test/val loss: 0.1618

Epoch 60, loss = 0.1626
Mean test/val loss: 0.1617

Epoch 62, loss = 0.1624
Mean test/val loss: 0.1613

Epoch 64, loss = 0.1621
Mean test/val loss: 0.1612

Epoch 66, loss = 0.1619
Mean test/val loss: 0.1611

Epoch 68, loss = 0.1616
Mean test/val loss: 0.1607

Epoch 70, loss = 0.1613
Mean test/val loss: 0.1603

Epoch 72, loss = 0.1611
Mean test/val loss: 0.1600

Epoch 74, loss = 0.1606
Mean test/val loss: 0.1595

Epoch 76, loss = 0.1602
Mean test/val loss: 0.1592

Epoch 78, loss = 0.1597
Mean test/val loss: 0.1586

Epoch 80, loss = 0.1592
Mean test/val loss: 0.1581

Epoch 82, loss = 0.1585
Mean test/val loss: 0.1579

Epoch 84, loss = 0.1578
Mean test/val loss: 0.1566

Epoch 86, loss = 0.1569
Mean test/val loss: 0.1557

Epoch 88, loss = 0.1559
Mean test/val loss: 0.1555

Epoch 90, loss = 0.1549
Mean test/val loss: 0.1548

Epoch 92, loss = 0.1538
Mean test/val loss: 0.1531

Epoch 94, loss = 0.1526
Mean test/val loss: 0.1517

Epoch 96, loss = 0.1515
Mean test/val loss: 0.1509

Epoch 98, loss = 0.1503
Mean test/val loss: 0.1495

Epoch 100, loss = 0.1494
Mean test/val loss: 0.1485

#### FINAL PARAMETERS ####
model.nns.0.weight 16 torch.Size([1, 16])
Parameter containing:
tensor([[ 1.0286,  1.1697, -0.1392,  1.2811, -0.1302,  1.3133, -0.2892,  0.9810,
          0.5902, -0.4358,  1.6648,  0.5461,  1.4985,  0.0342,  0.3112, -0.0839]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-0.0088,  0.0099,  0.0000,  0.0109,  0.0000, -0.0367,  0.0000, -0.0063,
         -0.0238,  0.0000,  0.0210, -0.0084,  0.0166,  0.0000, -0.0376,  0.0000]],
       device='cuda:0') 

model.nns.0.bias 16 torch.Size([16])
Parameter containing:
tensor([-0.1607, -0.0551,  0.0000, -0.1532,  0.0000, -0.7039,  0.0000, -0.0176,
         0.2214,  0.0000, -0.1953,  0.1454, -0.1800, -0.0465,  0.2470,  0.0000],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-0.0138,  0.0149,  0.0000,  0.0167,  0.0000, -0.0452,  0.0000, -0.0122,
        -0.0412,  0.0000,  0.0330, -0.0154,  0.0258,  0.0000, -0.0641,  0.0000],
       device='cuda:0') 

model.nns.2.weight 64 torch.Size([16, 4])
Parameter containing:
tensor([[ 6.8671e-01,  1.7354e-02,  9.8653e-01,  7.9584e-01],
        [ 2.0219e-03, -1.7677e-01,  1.0688e+00,  1.0198e+00],
        [-4.3236e-01, -2.5251e-01, -1.5466e-01, -3.2933e-01],
        [ 3.8768e-01, -6.7212e-01,  1.4445e+00,  1.3159e-01],
        [ 4.2286e-01,  9.1152e-02, -1.7785e-01,  3.3847e-01],
        [-1.0240e+00,  2.6437e+00, -6.5381e+00, -4.0200e+00],
        [ 1.4716e-01, -1.4853e-01,  2.3051e-01,  4.8902e-01],
        [ 5.5298e-01, -3.4242e-01,  1.0232e+00,  7.3409e-01],
        [ 5.0049e-01, -4.4233e-01,  1.4743e-02,  5.3435e-01],
        [-4.2012e-01,  4.4943e-01,  1.5776e-01,  2.2687e-01],
        [ 4.6885e-01, -1.3269e-01,  1.9550e+00,  3.1172e-01],
        [ 2.7034e-01, -5.0687e-01,  4.3698e-01,  4.9415e-01],
        [ 4.6908e-01, -2.4845e-01,  1.7837e+00,  3.2355e-01],
        [-2.9425e-01, -3.6250e-01,  4.6126e-01,  1.9924e-01],
        [ 7.4664e-01, -5.7849e-01, -3.3367e-01,  3.5353e-01],
        [-3.6845e-01,  2.2185e-01,  1.9613e-01,  4.5512e-01]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[-0.0236,  0.0058,  0.0157, -0.0077],
        [-0.0329,  0.0083,  0.0219, -0.0109],
        [ 0.0000,  0.0000,  0.0000,  0.0000],
        [-0.0316,  0.0079,  0.0210, -0.0103],
        [ 0.0000,  0.0000,  0.0000,  0.0000],
        [-0.0101,  0.0022,  0.0067, -0.0029],
        [ 0.0000,  0.0000,  0.0000,  0.0000],
        [-0.0291,  0.0074,  0.0193, -0.0097],
        [-0.0294,  0.0077,  0.0194, -0.0100],
        [ 0.0000,  0.0000,  0.0000,  0.0000],
        [-0.0412,  0.0103,  0.0274, -0.0135],
        [-0.0242,  0.0063,  0.0160, -0.0082],
        [-0.0369,  0.0092,  0.0245, -0.0121],
        [ 0.0000,  0.0000,  0.0000,  0.0000],
        [-0.0222,  0.0059,  0.0146, -0.0076],
        [ 0.0000,  0.0000,  0.0000,  0.0000]], device='cuda:0') 

model.nns.2.bias 4 torch.Size([4])
Parameter containing:
tensor([-1.6350,  2.2808, -3.8322, -2.5078], device='cuda:0',
       requires_grad=True) 
grad:  tensor([-0.0763,  0.0180,  0.0490, -0.0227], device='cuda:0') 

head.0.model.0.weight 16 torch.Size([1, 16])
Parameter containing:
tensor([[-2.4657,  0.0412, -0.3731, -1.9428,  0.2977, -0.6533,  1.7662,  1.0200,
         -0.5862,  1.8352,  1.3812, -0.2700, -1.8203,  1.2752, -0.5231, -1.8235]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[0.0234, 0.0375, 0.0165, 0.0136, 0.0382, 0.0547, 0.0307, 0.0218, 0.0163,
         0.0300, 0.0091, 0.0096, 0.0136, 0.0216, 0.0097, 0.0080]],
       device='cuda:0') 

head.0.model.0.bias 1 torch.Size([1])
Parameter containing:
tensor([0.2311], device='cuda:0', requires_grad=True) 
grad:  tensor([0.0918], device='cuda:0') 


Total parameters: 117
Total time: 25215.3739631176
Final val loss: 0.14846056550741196

#### Plotting Script ####
Prediction Results:
results/ContactGNNEnergy/27/sample1230
results/ContactGNNEnergy/27/sample1761
results/ContactGNNEnergy/27/sample40
results/ContactGNNEnergy/27/sample1751
results/ContactGNNEnergy/27/sample1718
Loss: 0.14114039540290832 +- 0.013722157879516975

