#### ARCHITECTURE ####
Node Encoder:
 Sequential(
  (0): Linear(2, 64, bias=True)
  (1): PReLU(num_parameters=1)
) 

Edge Encoder:
 None 

Linear:
 Linear(in_features=72, out_features=64, bias=True) 

Model:
 Sequential(
  (0): WeightedGATv2Conv(64, 8, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (2): WeightedGATv2Conv(64, 8, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (4): WeightedGATv2Conv(64, 8, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (6): WeightedGATv2Conv(64, 8, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
) 

Head L:
 None 
 Bilinear 

Head D:
 None 
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=16384, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=512, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['GridSize', 'constant', 'ContactDistance', 'GeneticDistance_norm', 'AdjPCs_8'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project2/depablo/erschultz/dataset_03_22_23'], scratch='/scratch/midway3/erschultz', root_name='ContactGNNEnergy5', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', y_zero_diag_count=0, log_preprocessing=None, output_preprocesing=None, kr=False, mean_filt=None, rescale=2, gated=False, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, move_data_to_scratch=False, use_scratch_parallel=False, plaid_score_cutoff=None, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.0001, min_lr=1e-06, weight_decay=0.0, gpus=1, scheduler='MultiStepLR', milestones=[50], gamma=0.1, patience=10, loss='mse', w_reg=None, reg_lambda=0.1, autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_sym_diag', model_type='ContactGNNEnergy', id=391, pretrain_id=None, resume_training=False, k=8, m=512, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, use_sign_net=False, use_sign_plus=True, message_passing='weighted_GAT', head_architecture='bilinear', head_architecture_2='fc-fill_512', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000], encoder_hidden_sizes_list=[64], inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/391', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/391/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/391/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/391/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7f9f768b33a0>, channels=1, node_feature_size=2, input_m=256, edge_transforms=["'ContactDistance'", 'ContactDistance(norm=False)', 'GeneticDistance(norm=True)'], node_transforms=['AdjPCs(k=8, normalize=False, sign_net=True)', 'Constant(value=1.0)', 'GridSize'], edge_dim=2, transforms_processed=None, diag=True, pre_transforms_processed=Compose([
  GridSize,
  Constant(value=1.0),
  ContactDistance(norm=False),
  GeneticDistance(norm=True),
  AdjPCs(k=8, normalize=False, sign_net=True)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 17.851 minutes
Number of samples: 5000
Average num edges per graph:  56654.6962
Mean degree: [214.81 251.84 255.85 ... 229.03 251.71 254.87] +- [18.68  5.89  0.47 ... 20.82  4.38  1.61]

split sizes: train=4500, val=500, test=0, N=5000
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f9f382f63a0>
#### TRAINING/VALIDATION ####
Epoch 2, loss = 8.5587
Mean test/val loss: 8.5743
[25, 50, 75] percentiles test/val loss: [3.175  5.0949 8.9512]

Epoch 4, loss = 7.6616
Mean test/val loss: 6.9165
[25, 50, 75] percentiles test/val loss: [2.8789 4.9335 8.3266]

Epoch 6, loss = 7.1746
Mean test/val loss: 7.5753
[25, 50, 75] percentiles test/val loss: [3.2754 5.227  9.3945]

Epoch 8, loss = 6.8266
Mean test/val loss: 6.8895
[25, 50, 75] percentiles test/val loss: [2.6798 4.4264 7.4754]

Epoch 10, loss = 6.5508
Mean test/val loss: 6.2617
[25, 50, 75] percentiles test/val loss: [2.4984 4.2162 7.0263]

Epoch 12, loss = 6.1989
Mean test/val loss: 5.5062
[25, 50, 75] percentiles test/val loss: [2.4877 4.0559 6.3424]

Epoch 14, loss = 5.6360
Mean test/val loss: 5.2607
[25, 50, 75] percentiles test/val loss: [2.3396 3.7782 6.1349]

Epoch 16, loss = 5.2972
Mean test/val loss: 7.9143
[25, 50, 75] percentiles test/val loss: [2.4754 4.4279 7.3905]

Epoch 18, loss = 5.0346
Mean test/val loss: 4.5537
[25, 50, 75] percentiles test/val loss: [2.3795 3.5518 5.1941]

Epoch 20, loss = 5.0981
Mean test/val loss: 5.1023
[25, 50, 75] percentiles test/val loss: [2.2701 3.6458 6.0889]

Epoch 22, loss = 4.7349
Mean test/val loss: 4.4991
[25, 50, 75] percentiles test/val loss: [2.0977 3.2268 5.1322]

Epoch 24, loss = 4.5996
Mean test/val loss: 5.1743
[25, 50, 75] percentiles test/val loss: [1.9772 3.4344 5.7859]

Epoch 26, loss = 4.6120
Mean test/val loss: 5.0303
[25, 50, 75] percentiles test/val loss: [2.6448 3.8139 5.7309]

Epoch 28, loss = 4.3970
Mean test/val loss: 4.2899
[25, 50, 75] percentiles test/val loss: [1.8306 3.1563 5.0947]

Epoch 30, loss = 4.3933
Mean test/val loss: 4.5752
[25, 50, 75] percentiles test/val loss: [2.0494 3.2772 5.204 ]

Epoch 32, loss = 4.1831
Mean test/val loss: 4.0918
[25, 50, 75] percentiles test/val loss: [1.8039 2.9418 4.7763]

Epoch 34, loss = 4.0207
Mean test/val loss: 3.9482
[25, 50, 75] percentiles test/val loss: [1.7881 2.8848 4.631 ]

Epoch 36, loss = 4.6119
Mean test/val loss: 4.4214
[25, 50, 75] percentiles test/val loss: [1.896  3.1054 5.135 ]

Epoch 38, loss = 3.7268
Mean test/val loss: 4.6493
[25, 50, 75] percentiles test/val loss: [2.1453 3.2231 5.162 ]

Epoch 40, loss = 3.9984
Mean test/val loss: 4.0617
[25, 50, 75] percentiles test/val loss: [1.8742 2.926  4.5529]

Epoch 42, loss = 3.7996
Mean test/val loss: 4.0307
[25, 50, 75] percentiles test/val loss: [1.8016 2.8521 4.4611]

Epoch 44, loss = 3.7512
Mean test/val loss: 4.1047
[25, 50, 75] percentiles test/val loss: [1.8561 2.979  4.6629]

Epoch 46, loss = 3.6967
Mean test/val loss: 4.0727
[25, 50, 75] percentiles test/val loss: [1.7378 2.9235 4.8343]

Epoch 48, loss = 53.2824
Mean test/val loss: 4.9521
[25, 50, 75] percentiles test/val loss: [2.3881 3.8249 5.7811]

Epoch 50, loss = 3.4326
Mean test/val loss: 3.6483
[25, 50, 75] percentiles test/val loss: [1.6497 2.6405 4.361 ]

New lr: 1e-05
Epoch 52, loss = 3.0382
Mean test/val loss: 3.5103
[25, 50, 75] percentiles test/val loss: [1.5421 2.5514 4.2041]

Epoch 54, loss = 2.9720
Mean test/val loss: 3.4943
[25, 50, 75] percentiles test/val loss: [1.5068 2.5166 4.2008]

Epoch 56, loss = 2.9300
Mean test/val loss: 3.4357
[25, 50, 75] percentiles test/val loss: [1.5116 2.5055 4.1453]

Epoch 58, loss = 2.8892
Mean test/val loss: 3.3900
[25, 50, 75] percentiles test/val loss: [1.4944 2.468  4.1109]

Epoch 60, loss = 2.8570
Mean test/val loss: 3.4126
[25, 50, 75] percentiles test/val loss: [1.4587 2.4809 4.1865]

Epoch 62, loss = 2.8255
Mean test/val loss: 3.4281
[25, 50, 75] percentiles test/val loss: [1.4616 2.4584 4.0788]

Epoch 64, loss = 2.8005
Mean test/val loss: 3.3483
[25, 50, 75] percentiles test/val loss: [1.4349 2.4348 4.0106]

Epoch 66, loss = 2.7771
Mean test/val loss: 3.4774
[25, 50, 75] percentiles test/val loss: [1.487  2.409  4.2262]

Epoch 68, loss = 2.7523
Mean test/val loss: 3.3123
[25, 50, 75] percentiles test/val loss: [1.4429 2.4042 4.0235]

Epoch 70, loss = 2.7293
Mean test/val loss: 3.3409
[25, 50, 75] percentiles test/val loss: [1.4462 2.4329 4.0237]

Epoch 72, loss = 2.7079
Mean test/val loss: 3.2795
[25, 50, 75] percentiles test/val loss: [1.4551 2.3875 4.0532]

Epoch 74, loss = 2.6895
Mean test/val loss: 3.3037
[25, 50, 75] percentiles test/val loss: [1.4402 2.3715 4.0044]

Epoch 76, loss = 2.6687
Mean test/val loss: 3.2695
[25, 50, 75] percentiles test/val loss: [1.4335 2.3533 3.9784]

Epoch 78, loss = 2.6509
Mean test/val loss: 3.2964
[25, 50, 75] percentiles test/val loss: [1.4335 2.3782 4.0002]

Epoch 80, loss = 2.6329
Mean test/val loss: 3.2490
[25, 50, 75] percentiles test/val loss: [1.4239 2.3462 3.9366]

Epoch 82, loss = 2.6151
Mean test/val loss: 3.2523
[25, 50, 75] percentiles test/val loss: [1.4088 2.3554 3.917 ]

Epoch 84, loss = 2.5973
Mean test/val loss: 3.2258
[25, 50, 75] percentiles test/val loss: [1.4089 2.3366 3.9254]

Epoch 86, loss = 2.5822
Mean test/val loss: 3.2501
[25, 50, 75] percentiles test/val loss: [1.4178 2.3293 3.9619]

Epoch 88, loss = 2.5647
Mean test/val loss: 3.2265
[25, 50, 75] percentiles test/val loss: [1.4109 2.3409 3.933 ]

Epoch 90, loss = 2.5602
Mean test/val loss: 3.2152
[25, 50, 75] percentiles test/val loss: [1.3876 2.3042 3.8822]

Epoch 92, loss = 2.5369
Mean test/val loss: 3.2059
[25, 50, 75] percentiles test/val loss: [1.3999 2.3165 3.8983]

Epoch 94, loss = 2.5215
Mean test/val loss: 3.2152
[25, 50, 75] percentiles test/val loss: [1.3785 2.3155 3.8866]

Epoch 96, loss = 2.5076
Mean test/val loss: 3.2371
[25, 50, 75] percentiles test/val loss: [1.4128 2.3412 3.8244]

Epoch 98, loss = 2.4928
Mean test/val loss: 3.2308
[25, 50, 75] percentiles test/val loss: [1.3997 2.2575 3.9289]

Epoch 100, loss = 2.4789
Mean test/val loss: 3.1953
[25, 50, 75] percentiles test/val loss: [1.3613 2.2633 3.8966]


Total parameters: 26466036
Total training + validation time: 8.0 hours, 32.0 mins, and 17.0 secs
Final val loss: 3.1952968074679373

split sizes: train=4500, val=500, test=0, N=5000
#### Plotting Script ####
Prediction Results:
dataset_03_22_23 sample981: 2.291551113128662
dataset_03_22_23 sample324: 1.172670602798462
dataset_03_22_23 sample3464: 4.588746070861816
dataset_03_22_23 sample2834: 7.866463661193848
dataset_03_22_23 sample1936: 1.213958501815796
Loss: 3.427 +- 2.543

Downsampling (40%) Results:
dataset_03_22_23 sample1936-downsampling: 1.213958501815796
dataset_03_22_23 sample2834-downsampling: 8.996274948120117
dataset_03_22_23 sample324-downsampling: 1.199027180671692
dataset_03_22_23 sample3464-downsampling: 5.527665138244629
dataset_03_22_23 sample981-downsampling: 3.93704891204834
Loss: 4.175 +- 2.924

Removing /scratch/midway3/erschultz/ContactGNNEnergy5downsample
Original sampling (100%) Results:
dataset_03_22_23 sample1936-regular: 1.1080145835876465
dataset_03_22_23 sample2834-regular: 7.86114501953125
dataset_03_22_23 sample324-regular: 1.1130481958389282
dataset_03_22_23 sample3464-regular: 4.5887451171875
dataset_03_22_23 sample981-regular: 2.401911973953247
Loss: 3.415 +- 2.561

Removing /scratch/midway3/erschultz/ContactGNNEnergy5regsample
Upsampling (200%) Results:
