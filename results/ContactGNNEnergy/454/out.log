#### ARCHITECTURE ####
Node Encoder:
 None 

Linear:
 None 

Edge Encoder:
 None 

Model:
 Sequential(
  (0): WeightedGATv2Conv(8, 8, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
  )
)
  (2): WeightedGATv2Conv(64, 8, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
  )
)
  (4): WeightedGATv2Conv(64, 8, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
  )
)
  (6): WeightedGATv2Conv(64, 8, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
  )
)
) 

Head L:
 None 
 Bilinear 

Head D:
 None 
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=16384, out_features=1000, bias=True)
          (1): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=512, bias=True)
          (1): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['ContactDistance', 'MeanContactDistance', 'MeanContactDistance_bonded', 'AdjPCs_8'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project2/depablo/erschultz/dataset_08_25_23'], scratch='/scratch/midway3/erschultz', root_name='ContactGNNEnergy3', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', sweep_choices=[2, 3, 4, 5], y_zero_diag_count=0, log_preprocessing=None, output_preprocesing='log', kr=False, mean_filt=None, rescale=2, gated=False, preprocessing_norm='mean_fill', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, move_data_to_scratch=False, use_scratch_parallel=False, plaid_score_cutoff=None, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=80, save_mod=5, print_mod=2, lr=0.0001, min_lr=1e-06, weight_decay=0.0, gpus=1, scheduler='MultiStepLR', milestones=[40], gamma=0.1, patience=10, loss='mse', w_reg=None, reg_lambda=0.1, autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_sym_diag', model_type='ContactGNNEnergy', id=454, pretrain_id=None, resume_training=False, k=8, m=512, seed=42, act='leaky', inner_act='leaky', out_act='leaky', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, use_sign_net=False, use_sign_plus=False, message_passing='weighted_GAT', head_architecture='bilinear', head_architecture_2='fc-fill_512', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000], encoder_hidden_sizes_list=None, inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 64], head_act='leaky', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, bonded_path=None, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/454', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/454/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/454/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/454/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7f19478a8310>, channels=1, node_feature_size=8, input_m=256, edge_transforms=['ContactDistance(norm=False)', 'MeanContactDistance(norm=False)', 'MeanContactDistance(norm=False, bonded=True)'], node_transforms=['AdjPCs(k=8, normalize=False)'], edge_dim=3, transforms_processed=None, diag=True, pre_transforms_processed=Compose([
  ContactDistance(norm=False),
  MeanContactDistance(norm=False),
  MeanContactDistance(norm=False, bonded=True),
  AdjPCs(k=8, normalize=False)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 17.759 minutes
Number of samples: 5000
Average num edges per graph:  64713.4272
Mean degree: [252.9  254.92 254.73 ... 254.88 254.63 254.43] +- [3.31 0.33 0.66 ... 0.35 0.82 1.18]

split sizes: train=4500, val=500, test=0, N=5000
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f19027df5e0>
#### TRAINING/VALIDATION ####
Epoch 2, loss = 1.2197
Mean test/val loss: 1.2654
[25, 50, 75] percentiles test/val loss: [0.4265 0.8148 1.8618]

Epoch 4, loss = 1.0827
Mean test/val loss: 1.0206
[25, 50, 75] percentiles test/val loss: [0.2461 0.6376 1.5821]

Epoch 6, loss = 1.0379
Mean test/val loss: 0.9471
[25, 50, 75] percentiles test/val loss: [0.232  0.5977 1.4625]

Epoch 8, loss = 0.9503
Mean test/val loss: 0.9077
[25, 50, 75] percentiles test/val loss: [0.2202 0.5496 1.4171]

Epoch 10, loss = 0.9107
Mean test/val loss: 0.9258
[25, 50, 75] percentiles test/val loss: [0.2244 0.5734 1.4631]

Epoch 12, loss = 0.8668
Mean test/val loss: 0.8533
[25, 50, 75] percentiles test/val loss: [0.2056 0.5209 1.3469]

Epoch 14, loss = 0.8391
Mean test/val loss: 0.8418
[25, 50, 75] percentiles test/val loss: [0.2058 0.5205 1.327 ]

Epoch 16, loss = 0.8149
Mean test/val loss: 0.8346
[25, 50, 75] percentiles test/val loss: [0.2112 0.5395 1.3021]

Epoch 18, loss = 0.7970
Mean test/val loss: 0.8028
[25, 50, 75] percentiles test/val loss: [0.1992 0.4947 1.2884]

Epoch 20, loss = 0.7776
Mean test/val loss: 0.8157
[25, 50, 75] percentiles test/val loss: [0.2529 0.5297 1.2497]

Epoch 22, loss = 0.7606
Mean test/val loss: 0.7755
[25, 50, 75] percentiles test/val loss: [0.1989 0.5149 1.2343]

Epoch 24, loss = 0.7489
Mean test/val loss: 0.7831
[25, 50, 75] percentiles test/val loss: [0.1968 0.5004 1.2377]

Epoch 26, loss = 0.7351
Mean test/val loss: 0.7856
[25, 50, 75] percentiles test/val loss: [0.2184 0.5015 1.2189]

Epoch 28, loss = 0.7226
Mean test/val loss: 0.7685
[25, 50, 75] percentiles test/val loss: [0.1966 0.4803 1.1904]

Epoch 30, loss = 0.7138
Mean test/val loss: 0.7383
[25, 50, 75] percentiles test/val loss: [0.183  0.4648 1.1475]

Epoch 32, loss = 0.7059
Mean test/val loss: 0.7159
[25, 50, 75] percentiles test/val loss: [0.1747 0.4479 1.1299]

Epoch 34, loss = 0.6975
Mean test/val loss: 0.7212
[25, 50, 75] percentiles test/val loss: [0.1751 0.4516 1.1355]

Epoch 36, loss = 0.6859
Mean test/val loss: 0.7407
[25, 50, 75] percentiles test/val loss: [0.2135 0.4728 1.139 ]

Epoch 38, loss = 0.6862
Mean test/val loss: 0.7123
[25, 50, 75] percentiles test/val loss: [0.1742 0.4465 1.1366]

Epoch 40, loss = 0.6802
Mean test/val loss: 0.7221
[25, 50, 75] percentiles test/val loss: [0.1708 0.4528 1.1326]

New lr: 1e-05
Epoch 42, loss = 0.6396
Mean test/val loss: 0.6761
[25, 50, 75] percentiles test/val loss: [0.163  0.4288 1.0718]

Epoch 44, loss = 0.6342
Mean test/val loss: 0.6723
[25, 50, 75] percentiles test/val loss: [0.1607 0.4256 1.0653]

Epoch 46, loss = 0.6306
Mean test/val loss: 0.6705
[25, 50, 75] percentiles test/val loss: [0.1605 0.4242 1.056 ]

Epoch 48, loss = 0.6279
Mean test/val loss: 0.6690
[25, 50, 75] percentiles test/val loss: [0.1606 0.4227 1.065 ]

Epoch 50, loss = 0.6255
Mean test/val loss: 0.6659
[25, 50, 75] percentiles test/val loss: [0.1607 0.4192 1.0589]

Epoch 52, loss = 0.6231
Mean test/val loss: 0.6654
[25, 50, 75] percentiles test/val loss: [0.1585 0.4183 1.0579]

Epoch 54, loss = 0.6211
Mean test/val loss: 0.6640
[25, 50, 75] percentiles test/val loss: [0.1591 0.4209 1.0627]

Epoch 56, loss = 0.6191
Mean test/val loss: 0.6631
[25, 50, 75] percentiles test/val loss: [0.1587 0.419  1.061 ]

Epoch 58, loss = 0.6174
Mean test/val loss: 0.6606
[25, 50, 75] percentiles test/val loss: [0.157  0.415  1.0592]

Epoch 60, loss = 0.6158
Mean test/val loss: 0.6601
[25, 50, 75] percentiles test/val loss: [0.1593 0.4142 1.0471]

Epoch 62, loss = 0.6142
Mean test/val loss: 0.6589
[25, 50, 75] percentiles test/val loss: [0.1555 0.4167 1.0464]

Epoch 64, loss = 0.6127
Mean test/val loss: 0.6588
[25, 50, 75] percentiles test/val loss: [0.1548 0.4125 1.0484]

Epoch 66, loss = 0.6114
Mean test/val loss: 0.6572
[25, 50, 75] percentiles test/val loss: [0.1552 0.4101 1.0481]

Epoch 68, loss = 0.6100
Mean test/val loss: 0.6575
[25, 50, 75] percentiles test/val loss: [0.1567 0.4118 1.0542]

Epoch 70, loss = 0.6086
Mean test/val loss: 0.6563
[25, 50, 75] percentiles test/val loss: [0.1544 0.4086 1.0467]

Epoch 72, loss = 0.6075
Mean test/val loss: 0.6558
[25, 50, 75] percentiles test/val loss: [0.1546 0.4089 1.0444]

Epoch 74, loss = 0.6062
Mean test/val loss: 0.6555
[25, 50, 75] percentiles test/val loss: [0.1557 0.4113 1.0471]

Epoch 76, loss = 0.6052
Mean test/val loss: 0.6536
[25, 50, 75] percentiles test/val loss: [0.154  0.4112 1.0478]

Epoch 78, loss = 0.6040
Mean test/val loss: 0.6550
[25, 50, 75] percentiles test/val loss: [0.1548 0.4079 1.0385]

Epoch 80, loss = 0.6030
Mean test/val loss: 0.6529
[25, 50, 75] percentiles test/val loss: [0.1545 0.4069 1.0373]


Total parameters: 26454256
Total training + validation time: 3.0 hours, 57.0 mins, and 15.399999999999636 secs
Final val loss: 0.652853230971843

split sizes: train=4500, val=500, test=0, N=5000
#### Plotting Script ####
Prediction Results:
dataset_08_25_23 sample981: 1.6814649105072021
dataset_08_25_23 sample324: 0.19530577957630157
dataset_08_25_23 sample3464: 0.16307367384433746
dataset_08_25_23 sample2834: 0.08750630915164948
dataset_08_25_23 sample1936: 0.2602485120296478
Loss: 0.478 +- 0.605

Downsampling (40%) Results:
dataset_08_25_23 sample1936-downsampling: 529.8215942382812
dataset_08_25_23 sample2834-downsampling: 1104.1304931640625
dataset_08_25_23 sample324-downsampling: 625.8071899414062
dataset_08_25_23 sample3464-downsampling: 949.8295288085938
dataset_08_25_23 sample981-downsampling: 9171.623046875
Loss: 2476.242 +- 3354.204

Removing /scratch/midway3/erschultz/ContactGNNEnergy3downsample
Original sampling (100%) Results:
dataset_08_25_23 sample1936-regular: 492.86260986328125
dataset_08_25_23 sample2834-regular: 1033.7835693359375
dataset_08_25_23 sample324-regular: 548.3380126953125
dataset_08_25_23 sample3464-regular: 909.9822998046875
dataset_08_25_23 sample981-regular: 8918.6376953125
Loss: 2380.721 +- 3275.463

Removing /scratch/midway3/erschultz/ContactGNNEnergy3regsample
