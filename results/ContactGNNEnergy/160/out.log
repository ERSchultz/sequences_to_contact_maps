Took 39.0 seconds to move data to scratch
#### ARCHITECTURE ####
Sequential(
  (0): Linear(3, 100, bias=True)
  (1): PReLU(num_parameters=1)
  (2): Linear(100, 100, bias=True)
  (3): PReLU(num_parameters=1)
  (4): Linear(100, 64, bias=True)
  (5): PReLU(num_parameters=1)
)
Sequential(
  (0): WeightedSignedConv(64, 32, first_aggr=True,edge_dim=2)
  (1): Linear(64, 100, bias=True)
  (2): PReLU(num_parameters=1)
  (3): Linear(100, 100, bias=True)
  (4): PReLU(num_parameters=1)
  (5): Linear(100, 64, bias=True)
  (6): PReLU(num_parameters=1)
  (7): WeightedSignedConv(32, 32, first_aggr=False,edge_dim=2)
  (8): Linear(64, 100, bias=True)
  (9): PReLU(num_parameters=1)
  (10): Linear(100, 100, bias=True)
  (11): PReLU(num_parameters=1)
  (12): Linear(100, 64, bias=True)
  (13): PReLU(num_parameters=1)
  (14): WeightedSignedConv(32, 32, first_aggr=False,edge_dim=2)
  (15): Linear(64, 100, bias=True)
  (16): PReLU(num_parameters=1)
  (17): Linear(100, 100, bias=True)
  (18): PReLU(num_parameters=1)
  (19): Linear(100, 64, bias=True)
  (20): PReLU(num_parameters=1)
)
None 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['degree', 'ContactDistance', 'GeneticDistance'], sparsify_threshold=0.176, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, relabel_11_to_00=False, split_edges_for_feature_augmentation=True, data_folder='/scratch/midway2/erschultz/dataset_05_12_22', scratch='/scratch/midway2/erschultz', root_name='ContactGNNEnergy2', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='diag', y_log_transform='10', y_norm=None, min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=True, use_scratch_parallel=False, split_percents=None, split_sizes=[-1, 200, 0], random_split=False, shuffle=True, batch_size=2, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.001, gpus=1, milestones=[50], gamma=0.1, loss='mse', autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_sym', model_type='ContactGNNEnergy', id=160, pretrained=False, resume_training=False, k=None, m=1024, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, parameter_sharing=False, use_bias=True, message_passing='SignedConv', head_architecture='bilinear', head_hidden_sizes_list=None, encoder_hidden_sizes_list=[100, 100, 64], update_hidden_sizes_list=[100, 100, 64], head_act='prelu', num_heads=1, concat_heads=True, kernel_w_list=None, hidden_sizes_list=[32, 32, 32], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/160', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/160/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/160/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/160/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=True, criterion=<function mse_loss at 0x7f216128a670>, channels=1, node_feature_size=3, edge_transforms=['ContactDistance', 'GeneticDistance'], node_transforms=['Degree'], edge_dim=2, transforms_processed=None, pre_transforms_processed=Compose([
  Degree (norm=True, max=None, weighted=False, split_edges=True, split_val=0),
  ContactDistance, (True),
  GeneticDistance(norm=True, max_value=None)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 25.797 minutes
Mean degree: [390.08 519.04 418.04 ... 821.2  327.6  369.17] +- [ 97.63  99.8   42.07 ... 100.14  68.89  99.13]

#### TRAINING/VALIDATION ####
Epoch 2, loss = 1.5683
Mean test/val loss: 1.7157

Epoch 4, loss = 1.5705
Mean test/val loss: 1.7188

Epoch 6, loss = 1.5390
Mean test/val loss: 1.7200

Epoch 8, loss = 1.5322
Mean test/val loss: 1.7143

Epoch 10, loss = 1.4996
Mean test/val loss: 1.7133

Epoch 12, loss = 1.4794
Mean test/val loss: 1.7142

Epoch 14, loss = 1.4665
Mean test/val loss: 1.7105

Epoch 16, loss = 1.5131
Mean test/val loss: 1.7182

Epoch 18, loss = 1.4495
Mean test/val loss: 1.7099

Epoch 20, loss = 1.4416
Mean test/val loss: 1.7091

Epoch 22, loss = 1.4275
Mean test/val loss: 1.7082

Epoch 24, loss = 1.4187
Mean test/val loss: 1.7258

Epoch 26, loss = 1.4046
Mean test/val loss: 1.7107

Epoch 28, loss = 1.4085
Mean test/val loss: 1.7093

Epoch 30, loss = 1.4023
Mean test/val loss: 1.7097

Epoch 32, loss = 1.4034
Mean test/val loss: 1.7131

Epoch 34, loss = 1.3915
Mean test/val loss: 1.7166

Epoch 36, loss = 1.3925
Mean test/val loss: 1.7095

Epoch 38, loss = 1.3880
Mean test/val loss: 1.7086

Epoch 40, loss = 1.3898
Mean test/val loss: 1.7195

Epoch 42, loss = 1.3841
Mean test/val loss: 1.7084

Epoch 44, loss = 1.3870
Mean test/val loss: 1.7074

Epoch 46, loss = 1.3841
Mean test/val loss: 1.7082

Epoch 48, loss = 1.3823
Mean test/val loss: 1.7051

Epoch 50, loss = 1.3795
Mean test/val loss: 1.7078

Epoch 52, loss = 1.3656
Mean test/val loss: 1.7043

Epoch 54, loss = 1.3627
Mean test/val loss: 1.7107

Epoch 56, loss = 1.3601
Mean test/val loss: 1.7066

Epoch 58, loss = 1.3612
Mean test/val loss: 1.6999

Epoch 60, loss = 1.3605
Mean test/val loss: 1.6986

Epoch 62, loss = 1.3594
Mean test/val loss: 1.6991

Epoch 64, loss = 1.3579
Mean test/val loss: 1.6995

Epoch 66, loss = 1.3577
Mean test/val loss: 1.6979

Epoch 68, loss = 1.3572
Mean test/val loss: 1.7000

Epoch 70, loss = 1.3572
Mean test/val loss: 1.6967

Epoch 72, loss = 1.3555
Mean test/val loss: 1.6977

Epoch 74, loss = 1.3549
Mean test/val loss: 1.6952

Epoch 76, loss = 1.3542
Mean test/val loss: 1.7012

Epoch 78, loss = 1.3543
Mean test/val loss: 1.6951

Epoch 80, loss = 1.3534
Mean test/val loss: 1.6922

Epoch 82, loss = 1.3526
Mean test/val loss: 1.7006

Epoch 84, loss = 1.3513
Mean test/val loss: 1.6990

Epoch 86, loss = 1.3511
Mean test/val loss: 1.6943

Epoch 88, loss = 1.3507
Mean test/val loss: 1.6992

Epoch 90, loss = 1.3495
Mean test/val loss: 1.6945

Epoch 92, loss = 1.3503
Mean test/val loss: 1.6915

Epoch 94, loss = 1.3500
Mean test/val loss: 1.6897

Epoch 96, loss = 1.3489
Mean test/val loss: 1.6893

Epoch 98, loss = 1.3479
Mean test/val loss: 1.6991

Epoch 100, loss = 1.3468
Mean test/val loss: 1.6949


Total parameters: 111,567
Total training + validation time: 18.0 hours
Final val loss: 1.6948938059806824

#### Plotting Script ####
Prediction Results:
/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/160/sample1: 0.7552172541618347
/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/160/sample2: 0.6221317648887634
/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/160/sample3: 1.5284757614135742
/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/160/sample4: 1.673414945602417
/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/160/sample5: 1.6966242790222168
Loss: 1.2551728010177612 +- 0.4680164333344481

