#### ARCHITECTURE ####
Node Encoder:
 Sequential(
  (0): Linear(2, 64, bias=True)
  (1): PReLU(num_parameters=1)
) 

Edge Encoder:
 None 

Linear:
 Linear(in_features=72, out_features=64, bias=True) 

Model:
 Sequential(
  (0): WeightedGATv2Conv(64, 8, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (2): WeightedGATv2Conv(64, 8, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (4): WeightedGATv2Conv(64, 8, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (6): WeightedGATv2Conv(64, 8, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
) 

Head L:
 None 
 Bilinear 

Head D:
 None 
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=32768, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1024, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['GridSize', 'constant', 'ContactDistance', 'GeneticDistance_norm', 'AdjPCs_8'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project2/depablo/erschultz/dataset_05_28_23'], scratch='/scratch/midway3/erschultz', root_name='ContactGNNEnergy6', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', sweep_choices=[1, 2, 3], y_zero_diag_count=0, log_preprocessing=None, output_preprocesing='log', kr=False, mean_filt=None, rescale=2, gated=False, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, move_data_to_scratch=False, use_scratch_parallel=False, plaid_score_cutoff=None, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=80, save_mod=5, print_mod=2, lr=0.0001, min_lr=1e-06, weight_decay=0.0, gpus=1, scheduler='MultiStepLR', milestones=[50], gamma=0.1, patience=10, loss='mse', w_reg=None, reg_lambda=0.1, autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_sym_diag', model_type='ContactGNNEnergy', id=411, pretrain_id=None, resume_training=False, k=8, m=1024, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, use_sign_net=False, use_sign_plus=True, message_passing='weighted_GAT', head_architecture='bilinear', head_architecture_2='fc-fill_1024', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000], encoder_hidden_sizes_list=[64], inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, grid_path=None, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/411', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/411/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/411/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/411/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7f07f6319310>, channels=1, node_feature_size=2, input_m=512, edge_transforms=["'ContactDistance'", 'ContactDistance(norm=False)', 'GeneticDistance(norm=True)'], node_transforms=['AdjPCs(k=8, normalize=False, sign_net=True)', 'Constant(value=1.0)', 'GridSize'], edge_dim=2, transforms_processed=None, diag=True, pre_transforms_processed=Compose([
  GridSize,
  Constant(value=1.0),
  ContactDistance(norm=False),
  GeneticDistance(norm=True),
  AdjPCs(k=8, normalize=False, sign_net=True)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 34.093 minutes
Number of samples: 5000
Average num edges per graph:  211303.4792
Mean degree: [367.61 462.48 490.11 ... 400.13 215.69 404.94] +- [72.63 33.28 19.86 ... 74.8  75.24 57.87]

split sizes: train=4500, val=500, test=0, N=5000
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f07b42a0190>
#### TRAINING/VALIDATION ####
Epoch 2, loss = 0.5635
Mean test/val loss: 0.5523
[25, 50, 75] percentiles test/val loss: [0.3819 0.524  0.6922]

Epoch 4, loss = 0.4737
Mean test/val loss: 0.4955
[25, 50, 75] percentiles test/val loss: [0.3039 0.4266 0.6354]

Epoch 6, loss = 0.4297
Mean test/val loss: 0.4276
[25, 50, 75] percentiles test/val loss: [0.2592 0.3627 0.5293]

Epoch 8, loss = 0.4003
Mean test/val loss: 0.4310
[25, 50, 75] percentiles test/val loss: [0.2833 0.3846 0.524 ]

Epoch 10, loss = 0.3824
Mean test/val loss: 0.3919
[25, 50, 75] percentiles test/val loss: [0.246  0.3276 0.4774]

Epoch 12, loss = 0.3692
Mean test/val loss: 0.3887
[25, 50, 75] percentiles test/val loss: [0.2479 0.3383 0.4647]

Epoch 14, loss = 0.3512
Mean test/val loss: 0.3764
[25, 50, 75] percentiles test/val loss: [0.2377 0.3204 0.4679]

Epoch 16, loss = 0.3303
Mean test/val loss: 0.3666
[25, 50, 75] percentiles test/val loss: [0.2294 0.3078 0.4467]

Epoch 18, loss = 0.3191
Mean test/val loss: 0.3398
[25, 50, 75] percentiles test/val loss: [0.2071 0.2896 0.4101]

Epoch 20, loss = 522.7530
Mean test/val loss: 0.4947
[25, 50, 75] percentiles test/val loss: [0.3134 0.4177 0.6196]

Epoch 22, loss = 0.4113
Mean test/val loss: 0.4299
[25, 50, 75] percentiles test/val loss: [0.2765 0.3677 0.5355]

Epoch 24, loss = 0.3348
Mean test/val loss: 0.3363
[25, 50, 75] percentiles test/val loss: [0.2038 0.2882 0.4087]

Epoch 26, loss = 0.2999
Mean test/val loss: 0.3267
[25, 50, 75] percentiles test/val loss: [0.2083 0.2787 0.3994]

Epoch 28, loss = 0.2931
Mean test/val loss: 0.3292
[25, 50, 75] percentiles test/val loss: [0.2086 0.2786 0.3989]

Epoch 30, loss = 0.2813
Mean test/val loss: 0.3025
[25, 50, 75] percentiles test/val loss: [0.187  0.2535 0.3691]

Epoch 32, loss = 0.2906
Mean test/val loss: 0.3150
[25, 50, 75] percentiles test/val loss: [0.1964 0.2661 0.3782]

Epoch 34, loss = 0.2727
Mean test/val loss: 0.3039
[25, 50, 75] percentiles test/val loss: [0.1854 0.2532 0.3735]

Epoch 36, loss = 104059.5505
Mean test/val loss: 1.5338
[25, 50, 75] percentiles test/val loss: [0.6651 1.0293 1.7601]

Epoch 38, loss = 0.6725
Mean test/val loss: 0.6157
[25, 50, 75] percentiles test/val loss: [0.3806 0.5213 0.7419]

Epoch 40, loss = 0.4917
Mean test/val loss: 0.5198
[25, 50, 75] percentiles test/val loss: [0.3553 0.4766 0.6479]

Epoch 42, loss = 0.2910
Mean test/val loss: 0.2975
[25, 50, 75] percentiles test/val loss: [0.183  0.2512 0.3657]

Epoch 44, loss = 0.2571
Mean test/val loss: 0.2875
[25, 50, 75] percentiles test/val loss: [0.1754 0.2449 0.3466]

Epoch 46, loss = 0.2581
Mean test/val loss: 0.2944
[25, 50, 75] percentiles test/val loss: [0.1831 0.2479 0.3577]

Epoch 48, loss = 0.2537
Mean test/val loss: 0.2856
[25, 50, 75] percentiles test/val loss: [0.1715 0.2356 0.3506]

Epoch 50, loss = 0.2476
Mean test/val loss: 0.2836
[25, 50, 75] percentiles test/val loss: [0.1754 0.2354 0.3383]

New lr: 1e-05
Epoch 52, loss = 0.2270
Mean test/val loss: 0.2635
[25, 50, 75] percentiles test/val loss: [0.1587 0.2187 0.325 ]

Epoch 54, loss = 0.2241
Mean test/val loss: 0.2622
[25, 50, 75] percentiles test/val loss: [0.1573 0.216  0.3236]

Epoch 56, loss = 0.2219
Mean test/val loss: 0.2615
[25, 50, 75] percentiles test/val loss: [0.1555 0.2162 0.3216]

Epoch 58, loss = 0.2202
Mean test/val loss: 0.2600
[25, 50, 75] percentiles test/val loss: [0.1549 0.2146 0.3175]

Epoch 60, loss = 0.2186
Mean test/val loss: 0.2596
[25, 50, 75] percentiles test/val loss: [0.1541 0.2141 0.319 ]

Epoch 62, loss = 0.2171
Mean test/val loss: 0.2583
[25, 50, 75] percentiles test/val loss: [0.1533 0.2111 0.3174]

Epoch 64, loss = 0.2159
Mean test/val loss: 0.2579
[25, 50, 75] percentiles test/val loss: [0.1526 0.2104 0.3152]

Epoch 66, loss = 0.2146
Mean test/val loss: 0.2573
[25, 50, 75] percentiles test/val loss: [0.1513 0.2109 0.3155]

Epoch 68, loss = 0.2133
Mean test/val loss: 0.2570
[25, 50, 75] percentiles test/val loss: [0.1509 0.2103 0.3158]

Epoch 70, loss = 0.2121
Mean test/val loss: 0.2567
[25, 50, 75] percentiles test/val loss: [0.1495 0.2111 0.3142]

Epoch 72, loss = 0.2110
Mean test/val loss: 0.2558
[25, 50, 75] percentiles test/val loss: [0.149  0.2084 0.3142]

Epoch 74, loss = 0.2098
Mean test/val loss: 0.2552
[25, 50, 75] percentiles test/val loss: [0.1487 0.2098 0.3111]

Epoch 76, loss = 0.2087
Mean test/val loss: 0.2553
[25, 50, 75] percentiles test/val loss: [0.1476 0.2077 0.3109]

Epoch 78, loss = 0.2077
Mean test/val loss: 0.2551
[25, 50, 75] percentiles test/val loss: [0.1481 0.2075 0.3113]

Epoch 80, loss = 0.2067
Mean test/val loss: 0.2549
[25, 50, 75] percentiles test/val loss: [0.1471 0.2068 0.3124]


Total parameters: 43362548
Total training + validation time: 13.0 hours, 56.0 mins, and 33.900000000001455 secs
Final val loss: 0.2548960841950029

split sizes: train=4500, val=500, test=0, N=5000
#### Plotting Script ####
Prediction Results:
dataset_05_28_23 sample981: 0.3163633346557617
dataset_05_28_23 sample324: 0.15004566311836243
dataset_05_28_23 sample3464: 0.16228371858596802
dataset_05_28_23 sample2834: 0.26649409532546997
dataset_05_28_23 sample1936: 0.6818519830703735
Loss: 0.315 +- 0.194

Downsampling (40%) Results:
dataset_05_28_23 sample1936-downsampling: 4.469302177429199
dataset_05_28_23 sample2834-downsampling: 2.48197078704834
dataset_05_28_23 sample324-downsampling: 1.7755805253982544
dataset_05_28_23 sample3464-downsampling: 3.7998762130737305
dataset_05_28_23 sample981-downsampling: 4.221673011779785
Loss: 3.35 +- 1.044

Removing /scratch/midway3/erschultz/ContactGNNEnergy6downsample
Original sampling (100%) Results:
dataset_05_28_23 sample1936-regular: 3.972142219543457
dataset_05_28_23 sample2834-regular: 2.8232085704803467
dataset_05_28_23 sample324-regular: 1.788877248764038
dataset_05_28_23 sample3464-regular: 4.21516227722168
dataset_05_28_23 sample981-regular: 4.045288562774658
Loss: 3.369 +- 0.931

Removing /scratch/midway3/erschultz/ContactGNNEnergy6regsample
