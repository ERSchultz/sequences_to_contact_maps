#### ARCHITECTURE ####
Node Encoder:
 Sequential(
  (0): Linear(2, 64, bias=True)
  (1): PReLU(num_parameters=1)
) 

Edge Encoder:
 None 

Linear:
 Linear(in_features=72, out_features=64, bias=True) 

Model:
 Sequential(
  (0): WeightedGATv2Conv(64, 8, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (2): WeightedGATv2Conv(64, 8, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (4): WeightedGATv2Conv(64, 8, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (6): WeightedGATv2Conv(64, 8, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
) 

Head L:
 None 
 Bilinear 

Head D:
 None 
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=16384, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=512, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['GridSize', 'constant', 'ContactDistance', 'GeneticDistance_norm', 'AdjPCs_8'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project2/depablo/erschultz/dataset_04_28_23'], scratch='/scratch/midway3/erschultz', root_name='ContactGNNEnergy5', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', y_zero_diag_count=0, log_preprocessing=None, output_preprocesing='log', kr=False, mean_filt=None, rescale=2, gated=False, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, move_data_to_scratch=False, use_scratch_parallel=False, plaid_score_cutoff=None, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.0001, min_lr=1e-06, weight_decay=0.0, gpus=1, scheduler='MultiStepLR', milestones=[50], gamma=0.1, patience=10, loss='mse', w_reg=None, reg_lambda=0.1, autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_sym_diag', model_type='ContactGNNEnergy', id=401, pretrain_id=None, resume_training=False, k=8, m=512, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, use_sign_net=False, use_sign_plus=True, message_passing='weighted_GAT', head_architecture='bilinear', head_architecture_2='fc-fill_512', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000], encoder_hidden_sizes_list=[64], inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/401', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/401/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/401/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/401/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7fef869b53a0>, channels=1, node_feature_size=2, input_m=256, edge_transforms=["'ContactDistance'", 'ContactDistance(norm=False)', 'GeneticDistance(norm=True)'], node_transforms=['AdjPCs(k=8, normalize=False, sign_net=True)', 'Constant(value=1.0)', 'GridSize'], edge_dim=2, transforms_processed=None, diag=True, pre_transforms_processed=Compose([
  GridSize,
  Constant(value=1.0),
  ContactDistance(norm=False),
  GeneticDistance(norm=True),
  AdjPCs(k=8, normalize=False, sign_net=True)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 17.787 minutes
Number of samples: 5000
Average num edges per graph:  61883.9736
Mean degree: [246.68 255.88 220.23 ... 252.09 216.5  256.  ] +- [ 9.13  0.37 26.94 ...  4.77 29.22  0.  ]

split sizes: train=4500, val=500, test=0, N=5000
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fef282e3f40>
#### TRAINING/VALIDATION ####
Epoch 2, loss = 0.6828
Mean test/val loss: 0.6750
[25, 50, 75] percentiles test/val loss: [0.3471 0.5814 0.8349]

Epoch 4, loss = 0.6117
Mean test/val loss: 0.6099
[25, 50, 75] percentiles test/val loss: [0.3038 0.4908 0.7517]

Epoch 6, loss = 0.5675
Mean test/val loss: 0.5517
[25, 50, 75] percentiles test/val loss: [0.2837 0.4552 0.6786]

Epoch 8, loss = 0.5305
Mean test/val loss: 0.5427
[25, 50, 75] percentiles test/val loss: [0.2867 0.4679 0.6727]

Epoch 10, loss = 0.5081
Mean test/val loss: 0.4935
[25, 50, 75] percentiles test/val loss: [0.2518 0.4142 0.612 ]

Epoch 12, loss = 0.4777
Mean test/val loss: 0.4683
[25, 50, 75] percentiles test/val loss: [0.2344 0.3907 0.5806]

Epoch 14, loss = 0.4551
Mean test/val loss: 0.4960
[25, 50, 75] percentiles test/val loss: [0.2544 0.4096 0.607 ]

Epoch 16, loss = 0.4424
Mean test/val loss: 0.4684
[25, 50, 75] percentiles test/val loss: [0.2352 0.386  0.6058]

Epoch 18, loss = 0.4172
Mean test/val loss: 0.4254
[25, 50, 75] percentiles test/val loss: [0.2115 0.3476 0.5   ]

Epoch 20, loss = 0.4014
Mean test/val loss: 0.4136
[25, 50, 75] percentiles test/val loss: [0.2058 0.343  0.5052]

Epoch 22, loss = 0.3935
Mean test/val loss: 0.4031
[25, 50, 75] percentiles test/val loss: [0.2108 0.3273 0.4818]

Epoch 24, loss = 0.3837
Mean test/val loss: 0.3856
[25, 50, 75] percentiles test/val loss: [0.1949 0.3082 0.4596]

Epoch 26, loss = 0.3782
Mean test/val loss: 0.4911
[25, 50, 75] percentiles test/val loss: [0.2392 0.4054 0.6121]

Epoch 28, loss = 0.4285
Mean test/val loss: 0.4567
[25, 50, 75] percentiles test/val loss: [0.2272 0.3754 0.5665]

Epoch 30, loss = 0.3551
Mean test/val loss: 0.3877
[25, 50, 75] percentiles test/val loss: [0.1969 0.3156 0.4648]

Epoch 32, loss = 1.8104
Mean test/val loss: 1.0790
[25, 50, 75] percentiles test/val loss: [0.6503 0.928  1.3326]

Epoch 34, loss = 0.6430
Mean test/val loss: 0.6169
[25, 50, 75] percentiles test/val loss: [0.3249 0.5305 0.7691]

Epoch 36, loss = 0.5475
Mean test/val loss: 0.5397
[25, 50, 75] percentiles test/val loss: [0.2777 0.4517 0.6704]

Epoch 38, loss = 0.4592
Mean test/val loss: 0.4576
[25, 50, 75] percentiles test/val loss: [0.2239 0.3726 0.5555]

Epoch 40, loss = 0.3587
Mean test/val loss: 0.3724
[25, 50, 75] percentiles test/val loss: [0.1807 0.2913 0.4597]

Epoch 42, loss = 0.3434
Mean test/val loss: 0.3746
[25, 50, 75] percentiles test/val loss: [0.1859 0.2994 0.4456]

Epoch 44, loss = 0.3437
Mean test/val loss: 0.3756
[25, 50, 75] percentiles test/val loss: [0.1802 0.2932 0.4462]

Epoch 46, loss = 0.3345
Mean test/val loss: 0.3824
[25, 50, 75] percentiles test/val loss: [0.1908 0.3039 0.4524]

Epoch 48, loss = 0.3327
Mean test/val loss: 0.3619
[25, 50, 75] percentiles test/val loss: [0.1768 0.2801 0.4269]

Epoch 50, loss = 0.3216
Mean test/val loss: 0.3492
[25, 50, 75] percentiles test/val loss: [0.1757 0.2709 0.4182]

New lr: 1e-05
Epoch 52, loss = 0.2914
Mean test/val loss: 0.3366
[25, 50, 75] percentiles test/val loss: [0.163  0.2604 0.4076]

Epoch 54, loss = 0.2873
Mean test/val loss: 0.3354
[25, 50, 75] percentiles test/val loss: [0.1606 0.2583 0.4033]

Epoch 56, loss = 0.2844
Mean test/val loss: 0.3361
[25, 50, 75] percentiles test/val loss: [0.1612 0.2586 0.4073]

Epoch 58, loss = 0.2820
Mean test/val loss: 0.3342
[25, 50, 75] percentiles test/val loss: [0.1579 0.2548 0.4   ]

Epoch 60, loss = 0.2799
Mean test/val loss: 0.3336
[25, 50, 75] percentiles test/val loss: [0.1569 0.2576 0.4031]

Epoch 62, loss = 0.2779
Mean test/val loss: 0.3333
[25, 50, 75] percentiles test/val loss: [0.158  0.2552 0.4019]

Epoch 64, loss = 0.2761
Mean test/val loss: 0.3329
[25, 50, 75] percentiles test/val loss: [0.1546 0.2546 0.3984]

Epoch 66, loss = 0.2744
Mean test/val loss: 0.3320
[25, 50, 75] percentiles test/val loss: [0.1532 0.2533 0.3955]

Epoch 68, loss = 0.2727
Mean test/val loss: 0.3311
[25, 50, 75] percentiles test/val loss: [0.1533 0.2531 0.3956]

Epoch 70, loss = 0.2711
Mean test/val loss: 0.3315
[25, 50, 75] percentiles test/val loss: [0.1532 0.2528 0.3918]

Epoch 72, loss = 0.2697
Mean test/val loss: 0.3310
[25, 50, 75] percentiles test/val loss: [0.1526 0.2516 0.394 ]

Epoch 74, loss = 0.2682
Mean test/val loss: 0.3303
[25, 50, 75] percentiles test/val loss: [0.1506 0.2532 0.3946]

Epoch 76, loss = 0.2668
Mean test/val loss: 0.3300
[25, 50, 75] percentiles test/val loss: [0.1506 0.2524 0.3904]

Epoch 78, loss = 0.2655
Mean test/val loss: 0.3302
[25, 50, 75] percentiles test/val loss: [0.1506 0.2514 0.39  ]

Epoch 80, loss = 0.2642
Mean test/val loss: 0.3305
[25, 50, 75] percentiles test/val loss: [0.1523 0.2515 0.3889]

Epoch 82, loss = 0.2630
Mean test/val loss: 0.3306
[25, 50, 75] percentiles test/val loss: [0.1529 0.2496 0.39  ]

Epoch 84, loss = 0.2618
Mean test/val loss: 0.3296
[25, 50, 75] percentiles test/val loss: [0.1512 0.2502 0.3876]

Epoch 86, loss = 0.2606
Mean test/val loss: 0.3294
[25, 50, 75] percentiles test/val loss: [0.153  0.2496 0.3866]

Epoch 88, loss = 0.2595
Mean test/val loss: 0.3301
[25, 50, 75] percentiles test/val loss: [0.152  0.2474 0.3951]

Epoch 90, loss = 0.2584
Mean test/val loss: 0.3300
[25, 50, 75] percentiles test/val loss: [0.1502 0.2502 0.3845]

Epoch 92, loss = 0.2574
Mean test/val loss: 0.3292
[25, 50, 75] percentiles test/val loss: [0.1514 0.2493 0.388 ]

Epoch 94, loss = 0.2563
Mean test/val loss: 0.3286
[25, 50, 75] percentiles test/val loss: [0.1508 0.2499 0.3853]

Epoch 96, loss = 0.2554
Mean test/val loss: 0.3283
[25, 50, 75] percentiles test/val loss: [0.1504 0.2476 0.3873]

Epoch 98, loss = 0.2543
Mean test/val loss: 0.3281
[25, 50, 75] percentiles test/val loss: [0.1499 0.2478 0.3839]

Epoch 100, loss = 0.2534
Mean test/val loss: 0.3290
[25, 50, 75] percentiles test/val loss: [0.1512 0.249  0.3862]


Total parameters: 26466036
Total training + validation time: 8.0 hours, 38.0 mins, and 0.7000000000007276 secs
Final val loss: 0.32901343252137305

split sizes: train=4500, val=500, test=0, N=5000
#### Plotting Script ####
Prediction Results:
dataset_04_28_23 sample981: 0.8465313911437988
dataset_04_28_23 sample324: 0.7013691663742065
dataset_04_28_23 sample3464: 0.5200546979904175
dataset_04_28_23 sample2834: 0.4777352213859558
dataset_04_28_23 sample1936: 0.24238468706607819
Loss: 0.558 +- 0.206

Downsampling (40%) Results:
dataset_04_28_23 sample1936-downsampling: 7.359447956085205
dataset_04_28_23 sample2834-downsampling: 8.20914077758789
dataset_04_28_23 sample324-downsampling: 16.500770568847656
dataset_04_28_23 sample3464-downsampling: 9.699183464050293
dataset_04_28_23 sample981-downsampling: 16.845083236694336
Loss: 11.723 +- 4.112

Removing /scratch/midway3/erschultz/ContactGNNEnergy5downsample
Original sampling (100%) Results:
dataset_04_28_23 sample1936-regular: 7.715908527374268
dataset_04_28_23 sample2834-regular: 8.605826377868652
dataset_04_28_23 sample324-regular: 13.928860664367676
dataset_04_28_23 sample3464-regular: 9.324799537658691
dataset_04_28_23 sample981-regular: 28.254512786865234
Loss: 13.566 +- 7.651

Removing /scratch/midway3/erschultz/ContactGNNEnergy5regsample
Upsampling (200%) Results:
