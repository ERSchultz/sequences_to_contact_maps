#### ARCHITECTURE ####
Node Encoder:
 Sequential(
  (0): Linear(1, 1000, bias=True)
  (1): PReLU(num_parameters=1)
  (2): Linear(1000, 1000, bias=True)
  (3): PReLU(num_parameters=1)
  (4): Linear(1000, 64, bias=True)
  (5): PReLU(num_parameters=1)
) 

Edge Encoder:
 None 

Model:
 Sequential(
  (0): WeightedGATv2Conv(64, 8, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (2): WeightedGATv2Conv(64, 8, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (4): WeightedGATv2Conv(64, 8, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (6): WeightedGATv2Conv(64, 8, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
) 

Head 1:
 Bilinear 

Head 2:
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=32768, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1024, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['constant', 'ContactDistance', 'GeneticDistance_norm'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project2/depablo/erschultz/dataset_11_18_22', '/project2/depablo/erschultz/dataset_11_21_22', '/project2/depablo/erschultz/dataset_12_05_22'], scratch='/scratch/midway2/erschultz', root_name='ContactGNNEnergy6', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', y_zero_diag_count=0, log_preprocessing=None, output_preprocesing='none', kr=False, mean_filt=None, rescale=2, gated=False, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=False, use_scratch_parallel=True, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.0001, weight_decay=0.0, gpus=1, milestones=[50], gamma=0.1, loss='mse', autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_SD', model_type='ContactGNNEnergy', id=284, pretrained=False, resume_training=False, k=None, m=1024, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, message_passing='weighted_GAT', head_architecture='bilinear', head_architecture_2='fc-fill', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000, 1024], encoder_hidden_sizes_list=[1000, 1000, 64], inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/284', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/284/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/284/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/284/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7f71f047c940>, channels=1, node_feature_size=1, input_m=512, edge_transforms=["'ContactDistance'", 'ContactDistance(norm=False)', 'GeneticDistance(norm=True)'], node_transforms=['Constant(value=1.0)'], edge_dim=2, transforms_processed=None, diag=False, pre_transforms_processed=Compose([
  Constant(value=1.0),
  ContactDistance(norm=False),
  GeneticDistance(norm=True)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 233.984 minutes
Average num edges per graph:  223985.86407307172
Mean degree: [362.66 512.   449.47 ... 331.03 456.7  501.52] +- [70.54  0.   53.89 ... 86.6  48.23  8.56]

split sizes: train=13302, val=1478, test=0, N=14780
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
#### TRAINING/VALIDATION ####
Epoch 2, loss = 9.0556
Mean test/val loss: 8.2902
[25, 50, 75] quantiles test/val loss: [5.4715 7.4286 9.8814]

Epoch 4, loss = 7.7079
Mean test/val loss: 6.9866
[25, 50, 75] quantiles test/val loss: [4.3392 6.4763 8.7775]

Epoch 6, loss = 7.1053
Mean test/val loss: 7.2237
[25, 50, 75] quantiles test/val loss: [4.3727 6.6625 9.133 ]

Epoch 8, loss = 7.6806
Mean test/val loss: 6.7810
[25, 50, 75] quantiles test/val loss: [4.3287 6.2709 8.5731]

Epoch 10, loss = 6.7396
Mean test/val loss: 7.6586
[25, 50, 75] quantiles test/val loss: [4.8184 6.9571 9.3896]

Epoch 12, loss = 6.7036
Mean test/val loss: 6.5640
[25, 50, 75] quantiles test/val loss: [4.0292 5.914  8.1372]

Epoch 14, loss = 6.6388
Mean test/val loss: 6.2265
[25, 50, 75] quantiles test/val loss: [3.9291 5.7026 7.8405]

Epoch 16, loss = 15.5610
Mean test/val loss: 6.7358
[25, 50, 75] quantiles test/val loss: [4.3235 6.3006 8.5433]

Epoch 18, loss = 6.4724
Mean test/val loss: 8.5908
[25, 50, 75] quantiles test/val loss: [ 5.5821  7.999  10.8683]

Epoch 20, loss = 6.6842
Mean test/val loss: 6.2795
[25, 50, 75] quantiles test/val loss: [3.9352 5.8675 7.9694]

Epoch 22, loss = 9.1060
Mean test/val loss: 6.2475
[25, 50, 75] quantiles test/val loss: [3.9352 5.8173 7.8505]

Epoch 24, loss = 6.2474
Mean test/val loss: 6.1954
[25, 50, 75] quantiles test/val loss: [3.8328 5.6466 7.8156]

Epoch 26, loss = 6.1206
Mean test/val loss: 5.8753
[25, 50, 75] quantiles test/val loss: [3.6312 5.368  7.4689]

Epoch 28, loss = 6.0064
Mean test/val loss: 5.9173
[25, 50, 75] quantiles test/val loss: [3.6164 5.4114 7.4515]

Epoch 30, loss = 8.2205
Mean test/val loss: 7.3033
[25, 50, 75] quantiles test/val loss: [4.534  6.8187 9.3955]

Epoch 32, loss = 7.3709
Mean test/val loss: 6.5108
[25, 50, 75] quantiles test/val loss: [4.0931 6.0489 8.2076]

Epoch 34, loss = 5.8361
Mean test/val loss: 5.6814
[25, 50, 75] quantiles test/val loss: [3.495  5.2073 7.1836]

Epoch 36, loss = 277.1937
Mean test/val loss: 6.3310
[25, 50, 75] quantiles test/val loss: [4.0503 5.9227 7.9412]

Epoch 38, loss = 5.9429
Mean test/val loss: 6.3273
[25, 50, 75] quantiles test/val loss: [3.806  5.8064 7.9444]

Epoch 40, loss = 5.7239
Mean test/val loss: 5.6361
[25, 50, 75] quantiles test/val loss: [3.4397 5.1158 7.13  ]

Epoch 42, loss = 5.9165
Mean test/val loss: 5.7928
[25, 50, 75] quantiles test/val loss: [3.4733 5.2494 7.3229]

Epoch 44, loss = 221.2754
Mean test/val loss: 23.8201
[25, 50, 75] quantiles test/val loss: [14.9476 21.1416 29.3799]

Epoch 46, loss = 509.4313
Mean test/val loss: 13.5173
[25, 50, 75] quantiles test/val loss: [ 7.4799 12.1385 16.7413]

Epoch 48, loss = 6.0039
Mean test/val loss: 5.7163
[25, 50, 75] quantiles test/val loss: [3.4928 5.2333 7.2064]

Epoch 50, loss = 5.7079
Mean test/val loss: 5.6365
[25, 50, 75] quantiles test/val loss: [3.3911 4.9928 7.1535]

Epoch 52, loss = 5.1788
Mean test/val loss: 5.3334
[25, 50, 75] quantiles test/val loss: [3.2157 4.7743 6.8042]

Epoch 54, loss = 5.1256
Mean test/val loss: 5.2917
[25, 50, 75] quantiles test/val loss: [3.1697 4.7425 6.743 ]

Epoch 56, loss = 5.0892
Mean test/val loss: 2330.9843
[25, 50, 75] quantiles test/val loss: [3.1501 4.7346 6.7458]

Epoch 58, loss = 5.0627
Mean test/val loss: 5.2499
[25, 50, 75] quantiles test/val loss: [3.139  4.6874 6.7386]

Epoch 60, loss = 5.0382
Mean test/val loss: 5.2297
[25, 50, 75] quantiles test/val loss: [3.1178 4.6864 6.6936]

Epoch 62, loss = 5.0112
Mean test/val loss: 5.2322
[25, 50, 75] quantiles test/val loss: [3.1496 4.674  6.6773]

Epoch 64, loss = 4.9859
Mean test/val loss: 5.1898
[25, 50, 75] quantiles test/val loss: [3.1063 4.6546 6.6397]

Epoch 66, loss = 24.9211
Mean test/val loss: 5.3023
[25, 50, 75] quantiles test/val loss: [3.1969 4.7186 6.79  ]

Epoch 68, loss = 4.9563
