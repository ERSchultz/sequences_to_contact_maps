#### INITIAL PARAMETERS ####
W torch.Size([16, 16])
Parameter containing:
tensor([[-1.1229e+00,  3.2853e-01, -2.0609e-02,  8.3717e-01, -2.8069e-01,
          2.7020e-01,  6.2136e-01, -1.3241e+00,  2.1599e+00,  2.3087e-01,
         -8.1522e-01, -3.0488e-01, -5.3192e-01,  4.4767e-01, -5.0646e-02,
         -2.8375e-01],
        [-1.0689e+00,  1.0466e+00, -1.1908e+00, -7.4924e-01,  5.8012e-01,
          3.7053e-01,  3.8798e-01, -8.6162e-01,  4.3882e-01, -6.7957e-01,
          2.0481e+00,  1.1281e-01,  1.9896e-01, -1.4618e+00,  2.8895e-01,
         -6.3447e-02],
        [-3.8986e-01,  3.6169e-02, -1.1902e+00, -1.0703e+00, -6.4381e-01,
         -3.7349e-01, -5.2412e-01, -8.1931e-02,  1.2839e+00, -9.3788e-01,
          7.2690e-01,  7.0801e-01, -2.3549e-01,  1.9672e-01, -2.6053e+00,
          2.8732e-01],
        [-1.1139e+00,  5.8154e-02,  8.7057e-01, -1.3635e+00,  3.7904e-01,
         -5.9439e-01, -5.4368e-01,  1.5546e+00,  8.4901e-01, -2.3068e-01,
         -5.8793e-01,  1.5145e+00, -1.5976e+00, -1.0106e+00,  1.2066e+00,
          1.8997e+00],
        [ 4.1682e-01, -1.7437e+00,  5.2692e-01, -1.9785e+00, -2.7663e-01,
         -2.3531e-01,  9.5234e-02,  6.8242e-02, -8.5636e-01,  1.3333e+00,
          1.6485e+00,  6.1842e-01,  4.4338e-01, -2.2085e-02, -9.6139e-01,
          3.3756e-01],
        [ 1.3580e+00, -1.1890e+00, -1.7711e+00,  1.2186e+00,  1.3397e+00,
         -4.0160e-01, -1.1891e+00,  1.5666e-01, -6.5406e-01, -2.7633e-01,
         -1.8364e-01, -4.3282e-01,  9.8941e-01,  6.8589e-02, -1.2540e+00,
          1.9135e+00],
        [-2.2998e+00, -1.9898e+00, -2.0576e+00,  1.5164e+00,  1.5780e-01,
          1.2733e+00, -1.5518e+00, -1.1596e+00,  1.0298e-01, -1.7550e-02,
         -4.7992e-01,  7.1419e-01, -1.5059e+00, -6.5887e-01, -1.0112e+00,
         -4.6797e-01],
        [-8.1640e-01,  3.0440e-01,  3.5460e-02,  3.7664e-01, -2.7760e-01,
          2.8219e-01,  1.0285e+00, -1.9978e-01,  6.6918e-01, -3.2720e-01,
         -2.7388e-01, -3.4850e-01, -6.0576e-01, -2.3101e-01, -9.9756e-01,
          3.0791e+00],
        [-1.3969e+00, -3.4042e-01,  2.3228e-01,  5.0699e-01,  6.9967e-01,
          8.2613e-01, -4.4572e-01,  3.5512e-01,  5.3487e-02,  1.8266e+00,
          3.8156e-01,  4.5703e-01,  1.6046e+00, -7.2225e-02, -4.2368e-01,
          1.0794e+00],
        [-2.4887e+00,  1.1065e+00,  4.9829e-01, -1.0289e+00, -3.0085e-01,
          8.7048e-01,  5.2788e-01, -4.0420e-02, -1.0310e+00, -1.3436e+00,
          1.0604e+00, -3.4652e-01, -4.7216e-01, -2.5938e-02,  2.1782e+00,
          6.8597e-01],
        [ 5.7593e-01, -2.7632e-01, -1.1657e+00, -7.1889e-01,  6.5353e-01,
         -2.3828e+00,  4.9330e-01,  1.4596e+00, -1.2872e+00,  1.4961e+00,
          2.1167e+00, -1.4281e+00, -2.1851e+00, -1.5309e+00,  8.5097e-01,
          9.6835e-01],
        [ 1.0762e+00,  4.6656e-01,  1.1997e+00,  3.6904e-01, -2.3628e+00,
          6.0813e-01,  2.4885e+00,  1.7333e+00,  1.0821e+00, -4.2347e-01,
         -6.3570e-01, -1.1350e+00,  3.8672e-01,  1.8823e+00,  8.2395e-01,
         -7.7045e-01],
        [ 1.4023e+00,  4.2739e-01, -1.8372e+00, -2.2986e+00, -8.0393e-01,
         -1.7540e+00,  8.1104e-04,  5.3921e-01,  2.7166e-01,  1.0232e-01,
         -4.5379e-01,  9.0858e-01,  1.0808e+00, -2.3232e-01, -1.0556e-01,
         -4.3018e-01],
        [-7.5267e-01, -1.4585e+00, -6.3624e-01,  1.0686e+00,  6.8076e-01,
          1.8949e-01,  1.2949e+00,  9.0989e-02, -9.2803e-02,  1.0459e+00,
          6.4278e-01,  1.3243e+00, -1.5177e-01,  5.0397e-01, -1.6221e-01,
          1.0540e+00],
        [-1.4656e+00, -1.4488e-02, -2.4256e+00,  2.1429e+00,  3.0045e+00,
          2.3031e+00,  3.0452e+00, -4.6803e-01,  1.1399e+00, -4.3792e-01,
         -1.4360e-02,  1.6313e+00,  1.6522e+00, -5.5385e-02, -1.8391e-01,
         -2.9449e-01],
        [-1.2085e+00, -1.4642e+00,  4.7749e-01,  2.3290e-01,  2.1346e+00,
          9.0028e-01, -2.0975e-02,  1.1720e-01, -1.1936e+00,  2.3780e+00,
          2.1968e-01,  4.9713e-01,  6.0143e-01, -2.9420e+00,  6.4157e-01,
         -6.2332e-02]], device='cuda:0', requires_grad=True) 

act.weight torch.Size([1])
Parameter containing:
tensor([0.2318], device='cuda:0', requires_grad=True) 

inner_act.weight torch.Size([1])
Parameter containing:
tensor([0.2033], device='cuda:0', requires_grad=True) 

out_act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

encoder.module_0.weight torch.Size([100, 11])
Parameter containing:
tensor([[ 0.2404,  0.2707, -0.1174,  ...,  0.3151, -0.1656,  0.2731],
        [ 0.0201,  0.2352,  0.0965,  ..., -0.0304, -0.0445, -0.0336],
        [-0.0619,  0.2651, -0.3156,  ...,  0.2229, -0.2815,  0.2505],
        ...,
        [ 0.2093,  0.2196,  0.2987,  ...,  0.1349, -0.0386,  0.0079],
        [-0.1761, -0.1022, -0.1503,  ...,  0.2990,  0.2277, -0.1745],
        [-0.3039,  0.0985,  0.1305,  ...,  0.1615,  0.0798,  0.1948]],
       device='cuda:0', requires_grad=True) 

encoder.module_0.bias torch.Size([100])
Parameter containing:
tensor([-0.1990,  0.1746, -0.2030,  0.2822, -0.1179,  0.1716,  0.0657,  0.0798,
        -0.1282,  0.1328, -0.1204, -0.2998, -0.0937,  0.2304, -0.0734,  0.0781,
        -0.1246,  0.2249,  0.1728,  0.1068, -0.1416, -0.2436, -0.0005, -0.1627,
         0.2555, -0.3157,  0.1169,  0.3136,  0.1096,  0.0767, -0.3567,  0.2937,
        -0.0372, -0.2841,  0.2773, -0.1018, -0.0141,  0.2663, -0.2187, -0.3346,
         0.0439, -0.0483,  0.0705, -0.2622, -0.0178, -0.1484, -0.1448, -0.2851,
         0.1316,  0.0350, -0.2515,  0.2586,  0.0670,  0.0472, -0.1838,  0.0384,
         0.2759,  0.2123, -0.2450,  0.2663,  0.0073,  0.1451,  0.2246,  0.2567,
        -0.2344,  0.2420, -0.1989,  0.0069, -0.2203, -0.0546, -0.0201, -0.0509,
        -0.0744,  0.0329,  0.2885,  0.1703,  0.1594,  0.1132,  0.2193, -0.0117,
         0.0336,  0.0633, -0.2591, -0.2313,  0.0472, -0.1200,  0.0069, -0.0916,
         0.0503,  0.1624, -0.1062,  0.2457,  0.2414, -0.2513, -0.2273, -0.2528,
        -0.1581, -0.1087, -0.0596, -0.0867], device='cuda:0',
       requires_grad=True) 

encoder.module_2.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0597, -0.0293, -0.0411,  ..., -0.0713,  0.0234,  0.0700],
        [-0.0594,  0.0177, -0.0353,  ...,  0.0232, -0.0665, -0.0693],
        [-0.0445, -0.0882, -0.0204,  ...,  0.0133,  0.0627,  0.1059],
        ...,
        [-0.0829, -0.0974, -0.0473,  ..., -0.1244,  0.0603,  0.0800],
        [ 0.0102,  0.0337, -0.1048,  ...,  0.0347,  0.0619, -0.0553],
        [-0.0272, -0.0584,  0.0300,  ..., -0.1092, -0.0602,  0.0336]],
       device='cuda:0', requires_grad=True) 

encoder.module_2.bias torch.Size([100])
Parameter containing:
tensor([ 0.0255,  0.0255,  0.0628,  0.0648, -0.0897,  0.0472,  0.0689, -0.0514,
        -0.0762, -0.0935, -0.0716,  0.0535,  0.0269, -0.0552, -0.0804, -0.0968,
         0.0374,  0.0336,  0.0209, -0.0115,  0.0460,  0.0128,  0.0526,  0.0106,
        -0.0561, -0.0775,  0.0370,  0.0459,  0.0659, -0.0775,  0.0518, -0.0900,
         0.0199, -0.0578, -0.0440, -0.0275,  0.0927,  0.0980, -0.0397, -0.0088,
        -0.0822, -0.1309, -0.0549, -0.0057, -0.0803, -0.0186,  0.0319,  0.0098,
        -0.0029,  0.0337,  0.0916, -0.0871, -0.0633,  0.0431,  0.0342,  0.0737,
         0.0801, -0.1036,  0.0015, -0.0988,  0.0364,  0.0599, -0.0948, -0.0623,
         0.0462,  0.0268, -0.0603,  0.0072, -0.0530,  0.0345,  0.0142,  0.0446,
        -0.0179,  0.0088, -0.0654,  0.0855,  0.0032, -0.0012,  0.0090, -0.0899,
         0.0186,  0.0835,  0.0698,  0.0219,  0.0276,  0.0383, -0.0030,  0.0433,
         0.0405, -0.0122, -0.0580, -0.0241,  0.0673,  0.0622, -0.0597,  0.0225,
        -0.0502,  0.0402,  0.0189, -0.0529], device='cuda:0',
       requires_grad=True) 

encoder.module_4.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0945,  0.0656,  0.0551,  ...,  0.0568,  0.0723,  0.1156],
        [ 0.0059,  0.0779,  0.0379,  ...,  0.1368,  0.0460,  0.0845],
        [-0.0274, -0.0852, -0.0052,  ...,  0.0533,  0.1064,  0.1103],
        ...,
        [-0.0131, -0.0972, -0.0465,  ...,  0.0798, -0.0280,  0.0754],
        [ 0.0885,  0.0771,  0.0360,  ..., -0.0804, -0.0222,  0.0472],
        [-0.0605, -0.0106,  0.0494,  ...,  0.0447, -0.0250,  0.0276]],
       device='cuda:0', requires_grad=True) 

encoder.module_4.bias torch.Size([16])
Parameter containing:
tensor([-0.0485,  0.0296, -0.0525, -0.0579, -0.0644, -0.0088,  0.1040,  0.0664,
        -0.0575,  0.0786,  0.0910,  0.1038,  0.0197,  0.0293,  0.0771,  0.0893],
       device='cuda:0', requires_grad=True) 

model.module_0.bias torch.Size([8])
Parameter containing:
tensor([ 0.0081, -0.0029, -0.0032,  0.0004, -0.0494,  0.0234, -0.0215, -0.0248],
       device='cuda:0', requires_grad=True) 

model.module_0.lin.weight torch.Size([8, 16])
Parameter containing:
tensor([[ 0.3966,  0.1971,  0.3548, -0.4514, -0.4705, -0.1177,  0.1347,  0.3253,
         -0.1436, -0.2243,  0.3299, -0.0411,  0.0382, -0.5085, -0.0453,  0.2938],
        [ 0.4863,  0.0645,  0.3166,  0.0844, -0.3737, -0.0233, -0.1724, -0.0678,
         -0.1812,  0.3686, -0.4108, -0.2617, -0.1782,  0.4190, -0.0994,  0.1927],
        [ 0.2487,  0.4513, -0.1181,  0.1190, -0.2226, -0.0441, -0.4307, -0.4114,
          0.1507, -0.3949,  0.2580,  0.4212,  0.1611,  0.1980, -0.4523, -0.2502],
        [-0.3665, -0.4652,  0.2078,  0.1514,  0.5062, -0.1427, -0.3349, -0.4347,
          0.0316, -0.2770,  0.0832,  0.3572,  0.4228, -0.0760, -0.3242, -0.2972],
        [ 0.3128,  0.1188,  0.0147, -0.4558,  0.2381,  0.3077,  0.0358, -0.1112,
         -0.2486, -0.0230,  0.0085,  0.1394,  0.0109,  0.5043,  0.3089,  0.0687],
        [-0.4910, -0.2888,  0.2016, -0.3390,  0.1325,  0.1396, -0.3093,  0.1086,
         -0.1117,  0.4179, -0.1102,  0.3674,  0.4436, -0.1733,  0.0815, -0.1203],
        [ 0.4224,  0.2659,  0.0110,  0.3024, -0.4118, -0.1640,  0.0877, -0.4858,
          0.4682, -0.0503,  0.4462, -0.1268,  0.0395, -0.1262, -0.2122, -0.0989],
        [ 0.3417,  0.4699,  0.1372,  0.3454,  0.2349, -0.0052, -0.3824,  0.1147,
         -0.1631,  0.1850, -0.3406,  0.0278, -0.2114, -0.4443, -0.4717,  0.4256]],
       device='cuda:0', requires_grad=True) 

model.module_1.weight torch.Size([100, 8])
Parameter containing:
tensor([[-2.4001e-02, -2.9794e-01,  6.0944e-02, -6.9113e-04,  2.6499e-01,
          3.6923e-01, -1.1372e-01, -2.0942e-01],
        [-2.1094e-01, -9.3715e-02, -2.0267e-01,  3.0760e-01, -1.2693e-01,
          1.8391e-01,  1.5492e-01,  9.0246e-02],
        [ 1.4960e-01,  2.8775e-01,  1.5824e-01,  1.7413e-01, -3.1256e-01,
         -1.2320e-02, -1.0242e-02,  2.8238e-01],
        [ 1.2496e-01,  2.2845e-01,  2.6455e-01, -1.4450e-01,  3.0942e-02,
          3.6445e-01,  9.0285e-02,  1.7621e-01],
        [ 1.4066e-01, -1.1510e-01,  7.2117e-02, -2.4762e-01,  3.2727e-01,
          3.6549e-02,  2.3521e-01, -2.6178e-01],
        [-3.3391e-01,  4.0473e-02, -1.0249e-02, -1.2617e-01,  1.8120e-01,
         -2.6006e-01,  3.6633e-01, -3.3258e-01],
        [ 5.0290e-02, -2.1812e-01,  7.9314e-02,  3.6498e-01, -5.3340e-02,
          1.1959e-01, -1.5556e-01, -1.8825e-01],
        [-3.2284e-01,  1.8310e-01, -1.6857e-02,  1.3066e-01, -2.8044e-01,
         -2.5787e-01, -3.7066e-01, -2.1209e-01],
        [-5.8078e-02, -4.6253e-02,  1.7316e-01, -1.6174e-01,  3.3962e-01,
         -1.6581e-01, -3.1341e-01,  2.8515e-01],
        [-2.1497e-01,  1.5827e-02, -4.3316e-02, -8.5756e-02,  1.0375e-02,
         -3.5903e-01,  3.2725e-01, -2.5152e-01],
        [ 2.1312e-01, -1.9573e-01, -9.1374e-02, -7.5887e-03, -1.4473e-01,
         -1.2999e-01, -3.1822e-01, -2.4223e-01],
        [-1.8554e-02, -1.2861e-01, -5.4340e-02,  9.0118e-02, -4.2103e-02,
         -3.2363e-01, -1.4000e-01,  1.0154e-01],
        [ 1.1797e-01,  1.6346e-01,  3.0270e-02,  2.4911e-01, -2.4536e-01,
         -2.9805e-01, -7.9312e-02,  9.0802e-03],
        [ 2.5974e-01, -2.0113e-01, -2.5115e-01, -6.3705e-03,  8.3165e-02,
         -3.1155e-01, -1.5343e-01, -2.8298e-01],
        [ 8.4590e-02,  6.9044e-02, -2.9100e-01, -2.2992e-01,  1.1847e-02,
         -1.4091e-01, -2.1417e-01, -9.1788e-02],
        [-3.3492e-01, -7.4509e-02, -4.6655e-02,  2.7401e-02,  2.5650e-02,
         -5.1562e-02,  2.6212e-01, -1.4326e-01],
        [ 1.5439e-01,  1.7051e-01, -2.9010e-02, -2.4632e-01, -3.1127e-01,
          1.0041e-01,  1.0709e-01,  2.2633e-01],
        [-1.5915e-01,  2.6359e-01,  3.4884e-01, -5.6254e-02, -1.3316e-01,
         -1.1560e-01, -3.0329e-01,  1.9621e-01],
        [ 2.1243e-02,  1.5444e-01,  2.2160e-01, -1.4813e-01,  5.7302e-04,
          3.0476e-01, -2.9185e-01,  3.1297e-01],
        [ 1.8710e-01, -1.0578e-01, -2.9426e-01,  1.8840e-01,  1.6540e-01,
         -1.5083e-01,  1.5914e-01,  1.0105e-01],
        [ 3.4697e-01,  1.9629e-01,  5.2615e-02, -3.4684e-01,  2.7765e-01,
          3.2106e-01, -1.1363e-01, -2.5523e-02],
        [-6.6617e-03, -3.0253e-02,  1.9486e-01,  3.7838e-02, -2.9113e-01,
          8.8270e-02, -1.9290e-01,  1.0114e-01],
        [ 1.3227e-01, -1.9142e-01,  2.4056e-01,  2.3925e-02, -1.8790e-01,
          3.2790e-01,  2.0013e-01,  2.5362e-01],
        [-2.4363e-01, -2.6820e-01, -3.1428e-01,  2.3144e-01,  1.9825e-01,
         -2.0127e-01,  1.2635e-01,  6.7179e-02],
        [-1.5353e-01,  3.4657e-02, -2.1287e-01, -1.0102e-01,  1.2901e-01,
          6.2683e-02, -2.7051e-01,  9.4590e-02],
        [-6.1338e-02, -2.5014e-01, -3.2624e-01,  1.1261e-02, -2.5503e-01,
         -2.3466e-01,  9.1022e-02,  1.9215e-02],
        [-1.4291e-01,  4.0472e-02,  1.5398e-01, -1.6213e-01, -1.1381e-01,
          6.7503e-02,  7.2179e-02,  1.1618e-01],
        [ 2.4079e-01, -1.1185e-02,  1.1452e-01, -2.0324e-01, -5.1825e-02,
          2.8455e-01, -3.5896e-01, -2.3087e-01],
        [-3.1220e-01,  2.7783e-01, -3.9290e-02,  3.2740e-01, -1.9249e-01,
         -8.9701e-02,  2.1453e-01, -3.5155e-01],
        [-3.9558e-01, -1.9336e-01,  5.3602e-02, -2.7555e-01,  2.1785e-02,
          2.9687e-01, -3.9060e-02, -1.3160e-02],
        [-3.3016e-01, -9.6008e-02,  1.5213e-02,  7.5915e-02, -1.1881e-01,
         -1.8104e-01, -2.2793e-01,  2.2569e-01],
        [-2.1327e-01,  3.5937e-02, -6.4473e-02, -1.4105e-01, -2.4395e-02,
          2.8951e-01,  2.5411e-01, -5.0351e-02],
        [-9.0077e-02, -1.8286e-01, -1.5172e-01, -3.7678e-02,  2.3704e-01,
          8.2746e-02, -3.1123e-01, -7.6709e-02],
        [-2.8422e-01,  3.1976e-01,  2.1503e-02, -1.1825e-01,  1.6716e-01,
         -3.3992e-01, -1.0400e-01,  2.4643e-02],
        [ 2.5798e-01,  2.8310e-01, -3.7271e-02, -3.5784e-01,  6.5702e-02,
         -1.8759e-01,  2.7729e-01, -1.0990e-01],
        [-1.0265e-01, -5.6925e-02,  3.3764e-01,  1.5957e-01, -2.4425e-01,
          5.5156e-02,  1.3118e-01, -8.4357e-02],
        [ 1.0226e-01, -2.8405e-01, -1.5986e-01,  2.4946e-01,  2.9987e-01,
          1.2678e-01, -1.9740e-01,  1.5397e-01],
        [-1.9915e-01, -2.8276e-01, -2.4050e-01, -5.4692e-02,  9.8656e-02,
          2.1094e-02,  3.4117e-01, -3.8318e-02],
        [ 3.2079e-01, -2.5569e-01, -1.8143e-01,  5.1550e-02,  2.0794e-01,
          1.1242e-01,  3.4152e-01, -1.8863e-01],
        [ 3.2586e-01,  1.6793e-01,  1.5099e-01,  7.8387e-03, -2.6922e-01,
          1.7328e-01,  1.0112e-01,  2.8844e-01],
        [ 2.7798e-01, -2.7012e-01,  3.4119e-01, -8.9028e-02, -2.3099e-01,
          2.9466e-01, -3.8236e-02,  5.8642e-02],
        [ 4.4548e-02, -2.0107e-01,  2.3093e-01,  1.4156e-01,  2.8476e-01,
         -1.1104e-01, -2.4054e-01,  6.4366e-02],
        [-8.3620e-02, -2.2081e-02, -3.1769e-01,  2.8581e-01, -1.6139e-01,
         -1.7395e-02, -2.4896e-02, -1.6850e-01],
        [ 2.1092e-01, -3.0468e-01, -7.6436e-02, -2.3840e-01,  2.1434e-01,
         -2.1646e-01,  2.2392e-01, -3.2461e-01],
        [-3.7986e-01,  5.7249e-03, -3.3344e-01,  3.5355e-01,  3.0605e-01,
         -1.3410e-01,  2.6123e-01, -1.2537e-01],
        [ 9.8959e-02, -2.3470e-01, -2.8201e-02, -1.2060e-01,  8.7099e-02,
          9.9154e-02, -3.3386e-01,  2.7035e-02],
        [ 2.4590e-01,  2.8145e-01,  1.4763e-01, -4.3531e-04,  2.4521e-01,
          2.1231e-01, -2.4634e-01, -1.1647e-02],
        [-3.2124e-01,  2.9977e-02,  2.0981e-02, -2.3497e-01,  8.1974e-02,
          2.5369e-01, -3.0857e-01, -3.1864e-01],
        [-1.3974e-01,  5.6884e-02, -3.4471e-01, -8.5996e-02,  2.8710e-01,
         -3.0835e-01, -9.6063e-02, -7.6321e-02],
        [ 2.1625e-01, -1.0866e-01,  3.0653e-01, -1.6696e-01,  1.2593e-01,
         -9.1936e-02,  3.4048e-01, -1.6651e-01],
        [-1.1489e-01,  3.1739e-01, -2.8522e-01,  7.7023e-02,  2.0466e-01,
         -5.1406e-02,  3.2226e-01, -3.4310e-01],
        [-3.9787e-02, -2.0620e-01,  1.3544e-01,  3.3586e-01, -3.3033e-01,
         -1.7821e-01, -2.3345e-01, -2.0979e-01],
        [ 1.1158e-01,  6.8796e-03, -2.8668e-01, -2.2136e-01, -2.3095e-01,
          4.5749e-02, -3.1001e-01, -2.8629e-01],
        [-2.9411e-01,  2.7438e-01,  2.6318e-01, -1.5955e-01,  7.8491e-02,
         -3.9825e-02, -1.5079e-01,  1.6474e-01],
        [-2.2997e-01, -1.1358e-02,  2.7619e-01, -3.1192e-01,  3.1233e-01,
          2.1167e-01,  1.8470e-01, -4.7897e-02],
        [-1.3641e-01, -1.8915e-01, -2.6403e-01, -3.4499e-01, -5.5335e-02,
          9.8873e-02, -3.6826e-01,  3.4121e-01],
        [-2.5079e-01,  2.9685e-02, -1.1999e-01,  3.1447e-01, -1.4587e-01,
          9.2615e-02,  1.1690e-01,  1.7332e-01],
        [-2.5421e-01, -2.0146e-01,  2.0081e-02, -3.3887e-01, -1.4460e-01,
         -3.1838e-01,  1.8185e-01,  3.8261e-02],
        [-3.6234e-01,  3.4501e-01,  1.4803e-01, -1.8614e-01, -5.2470e-02,
          2.5425e-01, -2.2130e-01,  1.0245e-01],
        [ 1.2840e-01, -2.2592e-01, -1.9733e-01, -7.3155e-02, -2.7344e-01,
          3.1600e-01,  8.2539e-02, -1.2297e-01],
        [-1.8976e-03, -4.9248e-03,  1.2304e-01,  2.4899e-01, -2.9059e-01,
         -1.4002e-01,  1.4737e-01, -1.9454e-01],
        [-3.6202e-04, -9.6739e-02,  1.9676e-01, -2.0082e-01,  3.2612e-01,
          1.4865e-01, -2.5222e-01, -7.8906e-02],
        [-5.3581e-02, -3.3510e-01, -2.9996e-01,  2.9218e-01,  2.5019e-01,
         -2.1868e-01, -6.3658e-03,  1.1571e-01],
        [ 2.4077e-01,  3.4320e-01,  2.6162e-01,  2.8026e-01, -2.1602e-01,
         -1.1293e-01,  2.0812e-01, -2.5538e-01],
        [-3.3392e-01,  1.9087e-01,  2.5801e-01,  1.3107e-01,  2.3892e-01,
          1.3742e-01,  6.2630e-02, -8.2221e-02],
        [ 3.7425e-02, -1.3334e-01,  2.8972e-01,  3.0643e-01, -1.1232e-01,
          1.6125e-01, -1.1633e-01,  2.8545e-01],
        [-3.2919e-01,  2.3631e-02, -4.8118e-02,  2.3728e-01,  4.0602e-02,
          1.0460e-01, -3.9557e-01, -2.1307e-01],
        [ 3.3626e-01, -5.4974e-02,  1.2258e-01, -2.9938e-01,  1.9051e-01,
         -1.4896e-01, -8.1072e-02,  3.0050e-01],
        [ 2.4301e-01, -3.0383e-01, -1.5705e-01,  2.1879e-01, -7.6918e-02,
          2.9126e-01,  1.3310e-01, -4.0783e-02],
        [-2.2708e-01,  1.6757e-02,  2.8514e-01,  2.7577e-01, -1.5349e-01,
         -1.0198e-01,  1.1379e-01, -2.9323e-01],
        [ 3.4089e-02,  7.4121e-02,  3.3702e-01, -4.4875e-02,  3.4446e-01,
          3.6503e-01, -2.0148e-01,  5.1868e-02],
        [ 2.0055e-01, -3.2226e-02, -1.9932e-01,  7.7576e-02,  1.4757e-01,
         -2.6254e-01, -3.0572e-01, -2.7032e-01],
        [-2.7749e-01,  3.1452e-01, -1.4216e-01, -2.4856e-02, -1.0667e-01,
         -1.9105e-01,  3.1107e-01, -1.2431e-01],
        [ 2.1552e-01, -1.6016e-01,  3.5948e-01,  9.7655e-02, -6.8302e-02,
         -3.8059e-03,  1.8102e-01, -1.9901e-01],
        [-1.0943e-01, -2.5271e-01, -2.4026e-01,  1.7430e-01, -4.0675e-02,
         -1.4883e-01, -5.3304e-03,  2.0472e-01],
        [ 3.3489e-01, -1.7200e-01,  1.7057e-01,  3.3382e-02, -1.8190e-01,
          6.7458e-02,  5.5041e-02,  2.2713e-01],
        [ 2.9384e-01,  1.7620e-01,  6.0363e-02, -2.6790e-01, -3.0013e-01,
          1.7878e-01, -2.3521e-01,  2.8836e-03],
        [ 2.7686e-01,  1.9176e-01, -5.0951e-02,  5.3696e-02,  7.9007e-03,
          3.5634e-02,  2.9248e-01, -2.1260e-01],
        [ 3.1332e-01,  1.8408e-02,  3.4730e-01, -1.4931e-01,  2.1611e-01,
         -2.1156e-01, -2.5692e-01,  2.4926e-01],
        [ 1.3383e-01,  3.4162e-01,  1.2655e-01, -1.5964e-01, -2.0540e-01,
          3.0008e-01, -9.1413e-02, -2.2154e-01],
        [-2.5191e-01, -2.3126e-01, -1.5875e-01, -2.9169e-01,  3.4126e-01,
          5.3112e-02,  1.0155e-01, -1.7959e-01],
        [ 5.3458e-02,  2.2202e-01, -1.4413e-01,  2.5346e-01, -7.9762e-02,
         -1.5063e-01, -2.6896e-01, -3.8383e-01],
        [ 1.3340e-01, -2.2447e-01, -1.6978e-01, -1.2435e-01, -2.8459e-01,
         -2.6604e-01, -2.1688e-01,  3.6355e-01],
        [ 5.5068e-02, -1.5393e-01, -5.0341e-02,  2.7313e-01, -1.8681e-01,
          1.3121e-01, -7.6689e-02, -3.2742e-01],
        [ 2.3237e-01,  1.5813e-01,  2.6299e-01,  1.6146e-01,  5.8956e-02,
          9.9026e-02, -2.4765e-01,  3.4869e-01],
        [-2.7898e-01,  3.2144e-01, -1.7854e-01, -2.0628e-01,  8.6774e-02,
          2.9091e-01, -7.1822e-02,  1.5484e-01],
        [-3.1212e-01, -4.7065e-02,  3.1512e-01,  3.3085e-01, -1.1165e-01,
          1.3509e-01,  3.2767e-01,  1.3688e-01],
        [ 5.3073e-02, -2.9950e-01,  7.4338e-02,  7.6367e-02, -1.9092e-01,
          2.0703e-01, -2.6828e-01,  3.3003e-01],
        [-7.2577e-02,  2.7634e-01, -2.8857e-02, -1.1083e-01,  1.9859e-01,
          1.9886e-01,  4.1093e-01,  1.4493e-01],
        [-1.7221e-01, -1.7226e-01, -3.0598e-01,  4.6195e-02,  3.1722e-01,
         -1.2398e-01, -3.6833e-02,  2.9223e-01],
        [ 2.9508e-01,  1.0256e-01,  5.1331e-02,  3.7387e-01,  2.7071e-01,
         -2.1825e-01, -2.2209e-01, -7.1083e-02],
        [ 1.4962e-01, -2.1141e-01, -1.5568e-01,  2.3865e-02, -8.8959e-02,
          2.3460e-01,  2.1949e-01,  2.4504e-01],
        [ 1.8554e-01, -1.8499e-01, -2.7421e-01, -2.3301e-01, -5.6238e-02,
          2.9232e-01, -1.0369e-01,  3.3085e-01],
        [ 2.4391e-01, -2.9555e-01,  1.9245e-01, -1.2044e-01, -3.7364e-01,
          1.4962e-01, -1.2055e-01, -2.7248e-01],
        [-2.5229e-01,  2.5910e-01, -9.2234e-02,  2.7301e-01, -1.2212e-01,
          3.5150e-01, -1.0901e-01,  3.4086e-01],
        [ 1.8615e-01, -2.2698e-01,  2.1022e-01,  1.2170e-01, -2.5658e-01,
         -3.7670e-01,  8.9600e-02,  2.0764e-01],
        [ 2.9887e-01, -9.4873e-02, -3.4204e-01,  1.5676e-01,  2.5892e-02,
          3.1444e-02,  1.9525e-01,  3.1781e-02],
        [ 3.4295e-01,  3.0862e-01,  1.3896e-01,  2.5225e-01,  1.4146e-01,
         -3.9894e-01,  3.6189e-01,  3.4308e-02],
        [-6.4983e-02,  2.8646e-01,  3.2691e-01, -2.4870e-01,  1.0836e-01,
         -1.8364e-01, -9.3635e-02,  9.0135e-02],
        [-1.6120e-01, -1.5460e-01,  1.8223e-01, -6.3388e-02,  1.1572e-01,
          3.6820e-01,  6.4751e-02,  8.6161e-02]], device='cuda:0',
       requires_grad=True) 

model.module_1.bias torch.Size([100])
Parameter containing:
tensor([ 0.3233, -0.1403, -0.0147, -0.3409, -0.1538, -0.0359,  0.3327,  0.2123,
        -0.1107, -0.0850,  0.0862, -0.1593, -0.0659,  0.1112, -0.1359,  0.2682,
         0.1534, -0.0410, -0.0646,  0.0372,  0.1855,  0.0860, -0.1086,  0.1413,
        -0.0107, -0.2577, -0.2440,  0.0057,  0.3133, -0.1900,  0.2260, -0.1886,
         0.2066, -0.1255, -0.1305,  0.0919,  0.1945, -0.2745, -0.0253,  0.0690,
         0.0874,  0.3424, -0.3174,  0.3113,  0.1743, -0.3386, -0.1774,  0.1538,
        -0.2566,  0.3248, -0.1422,  0.1459,  0.0768, -0.1411, -0.3398,  0.0399,
        -0.3081, -0.1048,  0.0595, -0.1082,  0.2008, -0.3091, -0.3398,  0.2197,
        -0.1885,  0.2838, -0.0471, -0.0483,  0.3504, -0.0419, -0.2904, -0.1440,
         0.1147,  0.2370,  0.3026, -0.1148,  0.0603,  0.2603, -0.1386,  0.0422,
        -0.1595,  0.0934,  0.3255,  0.3597, -0.2428,  0.1416,  0.3295, -0.0214,
         0.0659, -0.3657,  0.2018, -0.0617,  0.3272,  0.2129, -0.2068, -0.1171,
        -0.2797, -0.2948, -0.3272,  0.1610], device='cuda:0',
       requires_grad=True) 

model.module_3.weight torch.Size([100, 100])
Parameter containing:
tensor([[ 0.0698, -0.0583,  0.0796,  ..., -0.0757,  0.0108, -0.0319],
        [-0.0026, -0.0777, -0.0373,  ..., -0.0710, -0.1025,  0.0704],
        [ 0.0935,  0.0003, -0.0415,  ..., -0.0128, -0.0743,  0.0229],
        ...,
        [-0.0247, -0.0024, -0.0447,  ..., -0.0916, -0.0053,  0.0187],
        [ 0.0642,  0.0327,  0.0105,  ...,  0.0291,  0.0422,  0.1066],
        [ 0.0140, -0.0335,  0.0839,  ...,  0.0118, -0.0566,  0.0836]],
       device='cuda:0', requires_grad=True) 

model.module_3.bias torch.Size([100])
Parameter containing:
tensor([ 0.1206, -0.0279,  0.0876,  0.0417,  0.0406,  0.0130,  0.1068, -0.0313,
         0.0321,  0.0009,  0.0174, -0.0290, -0.0780,  0.0864, -0.1031, -0.0524,
         0.1237, -0.0454, -0.0301, -0.0718, -0.0129, -0.0468,  0.0183,  0.1007,
         0.0168, -0.0076,  0.0880,  0.0540, -0.0537, -0.0682, -0.0046,  0.0941,
        -0.0210, -0.0389,  0.0483, -0.0793,  0.0640,  0.0199, -0.0117, -0.0064,
         0.0251,  0.0156,  0.0936,  0.1207,  0.0374, -0.0179,  0.0018, -0.0723,
         0.0551, -0.0172, -0.0853, -0.0515, -0.0576, -0.0577,  0.0120,  0.0735,
        -0.0590, -0.0548,  0.0003,  0.0304,  0.0629,  0.0494, -0.0477,  0.0633,
        -0.1136, -0.0844,  0.0387,  0.1124,  0.0471, -0.0142, -0.0766,  0.1144,
        -0.0817,  0.1210, -0.0862, -0.0990,  0.0216,  0.0383, -0.1056, -0.0379,
         0.0188, -0.0168, -0.0294,  0.0896, -0.0633,  0.0582,  0.0332, -0.0304,
         0.0613, -0.0988, -0.0730,  0.0639, -0.0238,  0.0510, -0.0870,  0.0343,
        -0.0825,  0.0309,  0.0943,  0.0600], device='cuda:0',
       requires_grad=True) 

model.module_5.weight torch.Size([16, 100])
Parameter containing:
tensor([[-0.0120,  0.0666,  0.0816,  ...,  0.0866, -0.1911,  0.0625],
        [-0.0128, -0.0621,  0.0313,  ...,  0.0361,  0.0786,  0.0097],
        [ 0.1182,  0.0341, -0.0694,  ...,  0.0050,  0.2077,  0.0845],
        ...,
        [ 0.0256,  0.0713,  0.0337,  ...,  0.0468,  0.0142,  0.0918],
        [-0.0325,  0.0951,  0.0897,  ..., -0.0107, -0.1330,  0.0247],
        [-0.0396, -0.0621,  0.0117,  ..., -0.0225, -0.0192,  0.0415]],
       device='cuda:0', requires_grad=True) 

model.module_5.bias torch.Size([16])
Parameter containing:
tensor([ 0.0344,  0.0250,  0.0256, -0.0278, -0.0585, -0.1055,  0.0836,  0.0366,
         0.0942,  0.0945,  0.0068, -0.0638,  0.1025, -0.0865,  0.0114,  0.0475],
       device='cuda:0', requires_grad=True) 

model.module_7.bias torch.Size([8])
Parameter containing:
tensor([-0.0062,  0.0093,  0.0163, -0.0152,  0.0042, -0.0137,  0.0069,  0.0153],
       device='cuda:0', requires_grad=True) 

model.module_7.lin.weight torch.Size([8, 16])
Parameter containing:
tensor([[ 0.1711,  0.1370, -0.0388,  0.3204,  0.3995,  0.5294, -0.4251,  0.2409,
          0.4067, -0.2609, -0.4658,  0.2663,  0.0540,  0.4362,  0.2134,  0.3779],
        [-0.3733, -0.1346, -0.5655,  0.0993,  0.3468, -0.3419,  0.3499, -0.4756,
          0.3709, -0.4053, -0.4400, -0.2661,  0.1609, -0.4523,  0.2514, -0.4526],
        [-0.0039, -0.1547, -0.1826, -0.3141,  0.4937,  0.4882, -0.4904, -0.0710,
         -0.3729, -0.4188, -0.2114,  0.3105, -0.4571,  0.4926,  0.4496,  0.2156],
        [ 0.3651,  0.0788,  0.2796,  0.2604, -0.4461,  0.1011, -0.0272, -0.4668,
          0.3820, -0.1573,  0.0826, -0.2469,  0.3121,  0.0219, -0.1931, -0.2232],
        [ 0.1144, -0.4479,  0.2485, -0.4294, -0.3243,  0.0508, -0.2853,  0.1863,
         -0.3353, -0.1734,  0.2155,  0.2661, -0.1279,  0.1729, -0.4009, -0.1055],
        [ 0.3118, -0.0454, -0.4946, -0.0455, -0.0749,  0.1720, -0.1116, -0.3305,
          0.0985,  0.3723, -0.1373,  0.1485,  0.0771,  0.1169, -0.0835, -0.0245],
        [-0.4966,  0.2952, -0.2733, -0.3923, -0.3033,  0.1281, -0.1104, -0.2682,
          0.2689, -0.2535, -0.3445,  0.2432, -0.2171, -0.3255, -0.1560, -0.2436],
        [ 0.0032, -0.2239,  0.0196, -0.0379,  0.3368,  0.3219, -0.2596,  0.2159,
         -0.4564, -0.4078, -0.3400, -0.2102, -0.4898,  0.3254,  0.4113, -0.3897]],
       device='cuda:0', requires_grad=True) 

model.module_8.weight torch.Size([100, 8])
Parameter containing:
tensor([[-0.3258, -0.0963,  0.2717,  0.0980,  0.0144,  0.3287,  0.2793,  0.1609],
        [-0.1818, -0.0864, -0.0651, -0.0625,  0.0763,  0.2264, -0.2035, -0.3802],
        [-0.3170,  0.0896, -0.2354,  0.1735,  0.1177,  0.0765, -0.1320,  0.1707],
        [ 0.2592,  0.1181,  0.0359,  0.1561,  0.0297,  0.1493,  0.1334,  0.3443],
        [-0.0591,  0.1713,  0.2803, -0.2780, -0.0013, -0.2606, -0.2601,  0.2454],
        [-0.2622,  0.3354,  0.3193, -0.2344, -0.3241, -0.0249, -0.3274,  0.2050],
        [-0.1087,  0.0915, -0.0254, -0.0331, -0.2066,  0.0853,  0.1227, -0.0238],
        [-0.0324, -0.1297, -0.1803,  0.1042,  0.1499, -0.1848, -0.1494,  0.2685],
        [ 0.2436, -0.3338, -0.1951, -0.0083, -0.1586,  0.0957, -0.1405, -0.3436],
        [-0.2644,  0.2180,  0.0547,  0.3289,  0.3037, -0.0614,  0.2063, -0.0701],
        [ 0.1689, -0.2852, -0.1231,  0.0069,  0.0676,  0.0882,  0.3230,  0.2852],
        [-0.2482, -0.0477, -0.0313,  0.1316, -0.2430,  0.1345,  0.1064,  0.1475],
        [-0.0930,  0.0587,  0.1818,  0.3179, -0.1132,  0.1898, -0.1331,  0.1292],
        [-0.1041,  0.0639, -0.2800,  0.1169, -0.2615, -0.1695, -0.1436, -0.1425],
        [ 0.2953,  0.2973,  0.1802, -0.1806,  0.2316,  0.3456, -0.0754, -0.2514],
        [ 0.2727,  0.3095,  0.1193, -0.3276, -0.2242,  0.2828, -0.3021,  0.1721],
        [ 0.2154, -0.1010, -0.3148, -0.3387,  0.2836,  0.1129,  0.1652, -0.2025],
        [-0.1415,  0.1939, -0.2661,  0.1851, -0.0148,  0.1959, -0.2043, -0.1870],
        [-0.2771,  0.1774, -0.0633, -0.1207, -0.3284,  0.2919,  0.3374, -0.2065],
        [-0.0514, -0.0988, -0.2738, -0.2375, -0.0596,  0.1567, -0.2525,  0.2632],
        [-0.0080, -0.2411, -0.1864,  0.3287, -0.0827,  0.2142,  0.0021,  0.2963],
        [-0.2694,  0.1121,  0.1146, -0.0931, -0.2084, -0.0653, -0.0317, -0.2853],
        [-0.2660,  0.1441,  0.0431, -0.2215, -0.1253, -0.0344,  0.1362,  0.1278],
        [ 0.2885,  0.0121,  0.1276, -0.2592,  0.1758, -0.1522,  0.2905,  0.1495],
        [-0.0181, -0.1137,  0.1773,  0.1488,  0.0849,  0.0634, -0.2932, -0.1748],
        [-0.3610, -0.1244, -0.1724, -0.0709,  0.2639,  0.0458,  0.1598,  0.1445],
        [ 0.2999,  0.2896,  0.0682,  0.3021, -0.3274,  0.2278,  0.2274, -0.3407],
        [-0.2928, -0.0581,  0.1272,  0.3115, -0.3227,  0.3462, -0.0273, -0.0802],
        [-0.0804,  0.2387,  0.1664,  0.0313, -0.3064,  0.0042, -0.2925, -0.3429],
        [ 0.1094, -0.0936, -0.3221, -0.2982,  0.3468,  0.3384, -0.2371, -0.1400],
        [ 0.2214, -0.0851, -0.0076, -0.0989,  0.1716, -0.2727, -0.3216,  0.1735],
        [ 0.1462,  0.1721, -0.0774, -0.1390, -0.1441, -0.1720, -0.2805,  0.1992],
        [-0.1465, -0.3259,  0.0434,  0.2774, -0.0275, -0.3006,  0.1756, -0.2342],
        [ 0.2236, -0.2453,  0.3273, -0.1021,  0.3316,  0.1399,  0.2670,  0.0559],
        [-0.2110,  0.0349,  0.2881, -0.3070,  0.1018,  0.0336,  0.2410, -0.2387],
        [-0.2883,  0.0792, -0.1120, -0.1103,  0.1004,  0.2557, -0.2477, -0.0287],
        [-0.1577, -0.0478, -0.1579,  0.3362,  0.2077,  0.0431, -0.0915,  0.2033],
        [-0.1996, -0.3206, -0.2288, -0.1018, -0.2456,  0.2296, -0.0207, -0.1454],
        [-0.2375,  0.3507,  0.3145, -0.2394,  0.2734, -0.0810, -0.1435,  0.0944],
        [-0.2699, -0.3138, -0.0365,  0.2288,  0.2516,  0.2818,  0.1748,  0.0587],
        [ 0.0604, -0.2066,  0.2896,  0.2930, -0.3155, -0.3045, -0.0936, -0.2263],
        [-0.1340,  0.2958, -0.0890,  0.3299, -0.0192,  0.0250, -0.0032, -0.1246],
        [-0.0562, -0.1684, -0.2567,  0.0300,  0.0759,  0.0783,  0.0808, -0.1418],
        [-0.3152,  0.1822,  0.1185, -0.3661,  0.3181, -0.0979, -0.3082, -0.1406],
        [-0.1014, -0.2837,  0.0257, -0.1679, -0.1825,  0.3006, -0.1108, -0.0752],
        [-0.1780, -0.0276, -0.2348, -0.2015, -0.2521, -0.1218,  0.0622,  0.2010],
        [ 0.2114, -0.1572, -0.2501, -0.0508,  0.3161,  0.0242,  0.3242,  0.2989],
        [ 0.2461, -0.0303,  0.0819, -0.2351,  0.0565,  0.1674, -0.2219, -0.2063],
        [-0.1689,  0.0072, -0.0914,  0.1446, -0.1828,  0.3398, -0.1742,  0.1963],
        [ 0.3253,  0.3281, -0.1816, -0.1847, -0.1614, -0.2073, -0.1007, -0.1342],
        [ 0.1521,  0.3058,  0.1363,  0.0110, -0.1367, -0.0469,  0.2867, -0.3019],
        [-0.0330, -0.3412, -0.1078, -0.2613, -0.3500,  0.1694, -0.1872,  0.1179],
        [ 0.2917, -0.0781,  0.1443, -0.1293,  0.2535,  0.3765, -0.1075, -0.2086],
        [ 0.2454,  0.2088,  0.1265,  0.0564,  0.1435,  0.1146,  0.0812, -0.1391],
        [ 0.1080,  0.3260, -0.1030, -0.2854, -0.2712,  0.0260,  0.1158,  0.0481],
        [ 0.2972,  0.0592,  0.1845, -0.2910,  0.2537,  0.2679,  0.1189,  0.1885],
        [-0.3210,  0.3300,  0.0108, -0.3710,  0.1244,  0.1657,  0.2255,  0.3726],
        [ 0.0634,  0.2041,  0.3373,  0.1639,  0.1291,  0.0035, -0.2663,  0.1058],
        [-0.2628,  0.0006, -0.3511, -0.3346, -0.1574, -0.3650,  0.2029,  0.0613],
        [-0.0870,  0.3271,  0.1685,  0.2158, -0.2404, -0.2684, -0.1341,  0.2537],
        [-0.3007, -0.2419,  0.0302,  0.1230,  0.1978,  0.0574, -0.0548, -0.1065],
        [-0.0057,  0.2248, -0.2526, -0.3424, -0.0357,  0.0183,  0.1785,  0.1848],
        [ 0.3646, -0.1105,  0.1319, -0.2528, -0.2746, -0.1518,  0.2853, -0.2205],
        [-0.1368,  0.0975, -0.2605,  0.1324, -0.2613,  0.2850,  0.2750,  0.1178],
        [ 0.2241,  0.1748,  0.0756,  0.1269,  0.0419, -0.1343,  0.0704, -0.2640],
        [-0.3529,  0.0023, -0.1843, -0.1544,  0.1658, -0.1316,  0.3304, -0.2085],
        [-0.3242,  0.1276,  0.0167,  0.0714,  0.0851, -0.1246, -0.3561,  0.1809],
        [-0.1301,  0.2865, -0.1796,  0.2697,  0.0851, -0.1162, -0.1086,  0.3324],
        [ 0.2337, -0.4049, -0.1519, -0.0517,  0.1532, -0.2261, -0.1695,  0.0760],
        [ 0.0272, -0.2201,  0.1754,  0.3254, -0.1563,  0.3657,  0.0831,  0.0175],
        [-0.1200,  0.3159,  0.2159, -0.2758,  0.0923, -0.2132, -0.1895, -0.2602],
        [-0.0199, -0.1098, -0.0977,  0.2499,  0.0599, -0.3124, -0.1625, -0.3041],
        [-0.1530,  0.2037,  0.1037, -0.1113,  0.1748, -0.0137,  0.2758, -0.1599],
        [-0.3436, -0.1319, -0.0336,  0.3163,  0.0766, -0.1924,  0.2050,  0.3224],
        [-0.1926, -0.0701,  0.3753,  0.2963, -0.0110,  0.1815,  0.2115,  0.0239],
        [-0.1534, -0.0019,  0.0209,  0.3263,  0.1681, -0.1904,  0.3157, -0.1607],
        [-0.1450,  0.2506,  0.2145,  0.1973,  0.0005, -0.3569,  0.3449,  0.0696],
        [ 0.1886,  0.3095,  0.1385,  0.2670,  0.0319,  0.2726,  0.3162,  0.3329],
        [ 0.1274,  0.1714, -0.0352, -0.1007, -0.1956,  0.2437, -0.0991,  0.2729],
        [ 0.0454, -0.0855, -0.1447, -0.0624, -0.2154, -0.0463, -0.1136, -0.2174],
        [ 0.3238, -0.1472,  0.3075,  0.3217,  0.1877,  0.3223,  0.1346, -0.2821],
        [-0.2198,  0.0458,  0.0241,  0.1082, -0.1445, -0.1993, -0.0258,  0.1340],
        [ 0.1479, -0.0316,  0.1964, -0.2652, -0.2395,  0.1622,  0.3012, -0.1760],
        [-0.2021,  0.1198,  0.0111, -0.2668, -0.2819, -0.2709, -0.1210,  0.0231],
        [-0.0615, -0.0674, -0.2767,  0.2288,  0.2714,  0.0046,  0.0906,  0.2919],
        [-0.2231,  0.0313, -0.1532, -0.1740, -0.0289, -0.0947, -0.3584,  0.2788],
        [-0.3280,  0.2175,  0.0296,  0.1189,  0.3422,  0.1884,  0.3411,  0.0671],
        [-0.1421,  0.0195, -0.1827, -0.2226, -0.0016, -0.1577,  0.0082, -0.1010],
        [-0.2054,  0.0254, -0.2315, -0.0988, -0.1781,  0.3288, -0.1294, -0.2422],
        [-0.0355,  0.1949,  0.0643,  0.3104, -0.0495,  0.1194, -0.2685,  0.0399],
        [ 0.1484, -0.1047, -0.0555, -0.0082, -0.2443, -0.1109, -0.3575, -0.1077],
        [ 0.0283, -0.0524,  0.0311, -0.0994, -0.0215,  0.3014, -0.0233,  0.3529],
        [-0.0839,  0.1560,  0.0745,  0.0169, -0.2520,  0.2075,  0.0461, -0.2341],
        [-0.3232, -0.1317, -0.1828, -0.3150,  0.0044, -0.2356, -0.2258,  0.3587],
        [ 0.2087,  0.3494,  0.3367, -0.3103,  0.2962,  0.0731,  0.0918, -0.1698],
        [ 0.0277,  0.2180, -0.0199,  0.0648, -0.1707,  0.2380, -0.1326,  0.1797],
        [-0.2384,  0.0271,  0.3433, -0.1560, -0.2650,  0.2135, -0.2660,  0.0503],
        [-0.2574, -0.2556, -0.3140,  0.1063,  0.0080, -0.2523, -0.3281,  0.1161],
        [ 0.2256, -0.1699,  0.0856,  0.3080,  0.2857,  0.2239,  0.1443,  0.1911],
        [-0.3229, -0.2899, -0.2092,  0.2984,  0.3147,  0.3086, -0.1257, -0.3179]],
       device='cuda:0', requires_grad=True) 

model.module_8.bias torch.Size([100])
Parameter containing:
tensor([-0.2550,  0.2608,  0.1046,  0.3366,  0.1149, -0.1381, -0.3720, -0.1056,
         0.1431,  0.0367, -0.1829,  0.0264, -0.2367,  0.0800, -0.2861, -0.0718,
         0.1001, -0.2439, -0.0819, -0.2929, -0.0544,  0.0809, -0.1597,  0.2147,
        -0.2133,  0.2044,  0.1728, -0.2020,  0.1927,  0.2742, -0.1289,  0.0697,
         0.4225,  0.3559,  0.0030,  0.2396,  0.2209,  0.2056,  0.0434, -0.3411,
         0.1480, -0.0216, -0.1824, -0.2986, -0.2894, -0.2059, -0.0595, -0.1819,
        -0.2508, -0.0902, -0.0246,  0.1003,  0.2515,  0.1397, -0.1835,  0.1784,
         0.2713,  0.3054,  0.0884,  0.3205,  0.1512, -0.0391, -0.3199, -0.1273,
         0.0928,  0.2032, -0.2093,  0.0057,  0.2876, -0.2862,  0.1872,  0.0773,
         0.0563,  0.1932,  0.2711, -0.1706,  0.1964, -0.2902,  0.1631,  0.0506,
        -0.0008,  0.2529,  0.1729, -0.0603, -0.0715,  0.2388,  0.1899, -0.1136,
         0.1019, -0.3194,  0.3030, -0.1131, -0.2398,  0.2766, -0.0583,  0.2717,
         0.2164, -0.2264,  0.0527,  0.3102], device='cuda:0',
       requires_grad=True) 

model.module_10.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0516,  0.0087,  0.0187,  ..., -0.0526, -0.0152, -0.0122],
        [-0.0793, -0.0468, -0.0108,  ...,  0.0657,  0.0220,  0.0378],
        [ 0.0817, -0.0730,  0.0885,  ..., -0.0661, -0.0217,  0.0265],
        ...,
        [ 0.0148,  0.0996, -0.0667,  ..., -0.0871,  0.0502,  0.0425],
        [ 0.0565,  0.0507, -0.0485,  ...,  0.0832,  0.0759,  0.0527],
        [ 0.0683,  0.0503,  0.0811,  ...,  0.0830,  0.0553,  0.0719]],
       device='cuda:0', requires_grad=True) 

model.module_10.bias torch.Size([100])
Parameter containing:
tensor([ 0.0368, -0.0058,  0.0764, -0.0155,  0.0516, -0.0781,  0.0037, -0.0237,
         0.1011, -0.0469, -0.1000,  0.0554,  0.0054,  0.0364, -0.0096,  0.0759,
         0.0325,  0.1081,  0.0394,  0.0123,  0.0495,  0.0492,  0.0472, -0.0723,
         0.0280, -0.1109, -0.0279, -0.0021, -0.0565,  0.0707, -0.0278,  0.0101,
        -0.0454, -0.1068, -0.0824, -0.1052,  0.0782, -0.0621,  0.0705,  0.0092,
        -0.0364, -0.0475,  0.0333, -0.0811, -0.0196, -0.0264,  0.0620, -0.0216,
        -0.0373, -0.1101,  0.0388, -0.0034, -0.0358,  0.0470, -0.0042,  0.1114,
        -0.0394, -0.0549, -0.0170, -0.0857,  0.0694, -0.0069,  0.0515, -0.1067,
         0.0655,  0.0974, -0.0809,  0.0471, -0.0463, -0.0390, -0.1212, -0.1597,
         0.0352,  0.0424, -0.0546,  0.0621,  0.0593, -0.0864, -0.0765,  0.0620,
         0.0476, -0.0714, -0.0827, -0.0493, -0.0147, -0.0709, -0.0606,  0.0793,
         0.0344,  0.0113, -0.0489, -0.0478,  0.0178,  0.0269,  0.0847, -0.0857,
        -0.0798, -0.0690,  0.1006,  0.0930], device='cuda:0',
       requires_grad=True) 

model.module_12.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0888, -0.0466,  0.0263,  ...,  0.0879, -0.0102, -0.0072],
        [-0.0856,  0.0905,  0.0440,  ...,  0.0080,  0.0588, -0.0117],
        [-0.0142, -0.1140, -0.0210,  ...,  0.0517,  0.0430,  0.0958],
        ...,
        [-0.0029,  0.0586,  0.0561,  ..., -0.0625,  0.0761, -0.0838],
        [ 0.0672,  0.0172, -0.0467,  ..., -0.0903,  0.0703, -0.0093],
        [-0.0422, -0.0666,  0.1078,  ...,  0.0938,  0.0677,  0.1244]],
       device='cuda:0', requires_grad=True) 

model.module_12.bias torch.Size([16])
Parameter containing:
tensor([-0.0285,  0.0996,  0.0365,  0.1004, -0.0053, -0.0292,  0.1286, -0.0280,
         0.0006,  0.0169,  0.0681,  0.0378, -0.0314,  0.0321, -0.0142, -0.0125],
       device='cuda:0', requires_grad=True) 

model.module_14.bias torch.Size([8])
Parameter containing:
tensor([ 0.0215,  0.0165,  0.0373, -0.0133, -0.0196,  0.0160,  0.0170, -0.0089],
       device='cuda:0', requires_grad=True) 

model.module_14.lin.weight torch.Size([8, 16])
Parameter containing:
tensor([[ 0.4358,  0.1289, -0.0520, -0.2750, -0.3242, -0.2830,  0.3866, -0.2151,
          0.1753,  0.1846, -0.3013, -0.2724, -0.1271, -0.3652,  0.5041, -0.2506],
        [-0.5245, -0.3472, -0.0057,  0.4668, -0.4602,  0.0267,  0.0255, -0.0271,
          0.0924, -0.2583,  0.1960,  0.1058,  0.4857,  0.3579,  0.1218, -0.2958],
        [-0.1069, -0.3755,  0.2072,  0.1304,  0.0041, -0.4685, -0.2738,  0.2661,
          0.3623, -0.3711, -0.3176,  0.1213,  0.2883, -0.2048, -0.0380,  0.4805],
        [-0.2022,  0.2305, -0.0647,  0.4244,  0.2151,  0.1869,  0.4336, -0.0017,
         -0.1349, -0.4216,  0.4662,  0.3351, -0.0908, -0.4306,  0.4925,  0.3870],
        [-0.4275,  0.1455, -0.0291,  0.3044, -0.0323, -0.2015, -0.0146,  0.0475,
         -0.2720,  0.2812,  0.4553,  0.4859,  0.3463, -0.2878,  0.1867, -0.1769],
        [ 0.0042, -0.3048, -0.1603, -0.3844, -0.0036,  0.0397,  0.4547,  0.1737,
          0.2860, -0.2760,  0.0143, -0.0660,  0.0761, -0.2260,  0.2758,  0.4690],
        [ 0.1845,  0.0878, -0.0129, -0.3751, -0.2962, -0.2335, -0.2420, -0.4600,
          0.0970, -0.0138,  0.0762,  0.2308, -0.3210, -0.2853, -0.3767, -0.1069],
        [-0.1834,  0.3118,  0.0660, -0.1777,  0.1572, -0.0414, -0.0226,  0.2937,
          0.0742,  0.1393,  0.4132,  0.3707, -0.3057, -0.1149, -0.2581,  0.2319]],
       device='cuda:0', requires_grad=True) 

model.module_15.weight torch.Size([100, 8])
Parameter containing:
tensor([[-0.1186, -0.1336, -0.0221,  0.2110, -0.2805, -0.2804,  0.2662,  0.0761],
        [-0.0963, -0.3330, -0.0668,  0.2113, -0.1746, -0.1058, -0.2157, -0.0492],
        [ 0.0703,  0.1452, -0.2115, -0.2899,  0.0753, -0.2531,  0.2075, -0.2128],
        [-0.2777, -0.0374,  0.1504, -0.2460, -0.0200, -0.1690, -0.1782, -0.2432],
        [ 0.1825, -0.1718, -0.2390, -0.3280,  0.3246,  0.0364,  0.0030,  0.3061],
        [ 0.2440, -0.0465,  0.3123, -0.0275,  0.2868, -0.1937,  0.1094, -0.2865],
        [-0.1186,  0.0398, -0.2372, -0.0054, -0.0383,  0.3719,  0.0711,  0.1963],
        [ 0.2117,  0.2510,  0.2322,  0.0921,  0.2550,  0.3304, -0.1001,  0.1767],
        [ 0.1167,  0.2247, -0.1724,  0.0545,  0.0613,  0.1110,  0.0375,  0.2288],
        [-0.1647, -0.0299, -0.3032,  0.2821, -0.3035,  0.0951, -0.2892,  0.1245],
        [-0.1944,  0.2293, -0.2939,  0.2220, -0.0762, -0.3237, -0.1164, -0.1129],
        [ 0.1466,  0.3725,  0.1745, -0.0279,  0.0079, -0.2338, -0.1461,  0.2669],
        [ 0.2736, -0.0541,  0.0846,  0.2804, -0.2117, -0.0112, -0.2706,  0.0650],
        [-0.0269, -0.0079,  0.3921, -0.2024,  0.2504, -0.0717,  0.3166,  0.0181],
        [-0.1064, -0.0071,  0.1234,  0.0035, -0.0683, -0.1785, -0.0300, -0.2409],
        [-0.0765,  0.0673, -0.0971,  0.2440, -0.2490,  0.0243, -0.0333, -0.1730],
        [ 0.2504, -0.2300,  0.0328,  0.0846,  0.2938,  0.2170,  0.1801, -0.2580],
        [-0.0683,  0.1634,  0.0875,  0.2843,  0.2474,  0.2097, -0.1635,  0.1742],
        [-0.0859,  0.0940,  0.2990,  0.3286, -0.3132,  0.1870,  0.2889, -0.3119],
        [ 0.2375, -0.2163, -0.2494,  0.1488, -0.1304,  0.2722, -0.1322, -0.3331],
        [-0.2073, -0.0775, -0.2957, -0.2353, -0.3249, -0.1572, -0.0725,  0.1558],
        [ 0.2032, -0.3193, -0.0732, -0.1805,  0.1435, -0.3286, -0.3025,  0.1144],
        [-0.1295, -0.2029,  0.0194, -0.1281,  0.1258,  0.3640, -0.1055,  0.3335],
        [ 0.2328,  0.3384,  0.1377,  0.2971, -0.1967,  0.2855,  0.2377,  0.1970],
        [-0.0057, -0.1735,  0.2641,  0.2202,  0.1544,  0.3496,  0.1697, -0.0079],
        [ 0.1902,  0.1145,  0.0155, -0.1472,  0.3090,  0.1337, -0.0801, -0.3235],
        [ 0.0378,  0.1649,  0.0345,  0.1959, -0.3024,  0.2371, -0.1457, -0.2536],
        [-0.1723,  0.2734, -0.0622, -0.3142, -0.2163, -0.1851, -0.1370,  0.1016],
        [-0.0942, -0.1542, -0.0977, -0.1648,  0.0902, -0.3377, -0.0419,  0.3287],
        [-0.0574, -0.0183, -0.0514,  0.1859,  0.3391, -0.3623, -0.2953,  0.0868],
        [-0.3055,  0.3387,  0.2234,  0.2048, -0.2972,  0.1702, -0.0539,  0.1712],
        [-0.1746, -0.2215,  0.3053, -0.1688, -0.2428, -0.1860, -0.1861, -0.2713],
        [-0.1333, -0.2067, -0.1240,  0.1253, -0.0564, -0.1042,  0.2994, -0.2324],
        [-0.0057, -0.0776,  0.2527,  0.0658, -0.3042,  0.1286, -0.2707,  0.1524],
        [ 0.2549,  0.2180, -0.1803,  0.2529,  0.0100,  0.0836, -0.1541,  0.2431],
        [ 0.2946,  0.2682,  0.0493,  0.2674, -0.1048,  0.0773,  0.3371, -0.0296],
        [ 0.1682,  0.2006, -0.1595,  0.0684,  0.0634, -0.2528,  0.1929, -0.1512],
        [-0.0226, -0.0017,  0.1979,  0.2965, -0.0072,  0.0141, -0.2484, -0.0335],
        [ 0.0413,  0.3218, -0.2995,  0.1969, -0.1316, -0.0784,  0.3047,  0.0616],
        [ 0.3163, -0.2495, -0.2066, -0.2211, -0.2956, -0.2397,  0.3225, -0.1667],
        [-0.3228, -0.2620, -0.0674,  0.1720, -0.0042,  0.3527, -0.0899,  0.3223],
        [ 0.2562,  0.0423, -0.2096, -0.2038,  0.0912, -0.0868, -0.2193, -0.1281],
        [-0.2555, -0.2970,  0.0771,  0.2976,  0.0935,  0.2067, -0.2907,  0.0793],
        [-0.0549,  0.3243,  0.1742, -0.0117, -0.1849,  0.2731,  0.3556,  0.1845],
        [-0.2408, -0.2366,  0.1716,  0.0531, -0.0913,  0.0524,  0.2983, -0.3105],
        [ 0.2354,  0.2869, -0.2477, -0.3032,  0.0169, -0.2470,  0.0013, -0.0007],
        [ 0.2639,  0.0804,  0.2278, -0.2229,  0.0107,  0.0877,  0.0633, -0.0023],
        [ 0.1816, -0.0103, -0.0824,  0.0148, -0.0168, -0.2232, -0.0321, -0.0647],
        [-0.3098, -0.0576, -0.0062,  0.0424,  0.3246,  0.0760, -0.2869,  0.1917],
        [ 0.2953, -0.3577, -0.1886, -0.3433,  0.2731, -0.2400,  0.3000,  0.2836],
        [ 0.0776, -0.1586,  0.0022, -0.1635, -0.3111, -0.2247, -0.0919,  0.0386],
        [ 0.2707,  0.0522,  0.0258, -0.1476,  0.2587,  0.0640, -0.2882, -0.3183],
        [ 0.3428,  0.1150,  0.3643, -0.0258,  0.0947, -0.3177, -0.2389,  0.3196],
        [-0.2380, -0.2119,  0.0305, -0.0041, -0.3088,  0.2228, -0.3625, -0.1542],
        [ 0.3166,  0.2653,  0.1455,  0.2454, -0.2453,  0.3477,  0.0252,  0.1037],
        [ 0.1769,  0.3435, -0.2395,  0.3172, -0.1461, -0.0180,  0.1310,  0.2840],
        [ 0.2078,  0.3219, -0.1050,  0.3364,  0.0747,  0.1166,  0.1715,  0.0589],
        [ 0.2188, -0.0910, -0.3336,  0.2032,  0.2869,  0.2597, -0.0362, -0.1412],
        [-0.1768,  0.1718,  0.2408,  0.0272,  0.3452,  0.1962,  0.1369, -0.2809],
        [ 0.2749,  0.0790, -0.2349,  0.0895,  0.0126, -0.2304,  0.2672, -0.2443],
        [-0.1104, -0.2774,  0.1535, -0.2593, -0.1356,  0.2476, -0.0214, -0.0535],
        [-0.2006,  0.1456,  0.0021, -0.1996, -0.1334,  0.0150, -0.1465,  0.0233],
        [-0.1568,  0.3977,  0.3275, -0.1479,  0.0107,  0.1103,  0.0731, -0.1517],
        [-0.2472, -0.3282, -0.2928, -0.0770, -0.1002, -0.2743,  0.2592, -0.1338],
        [ 0.2517,  0.3395, -0.2826, -0.1904, -0.1976, -0.2914, -0.3095,  0.2852],
        [ 0.0318,  0.1630, -0.2756, -0.1529, -0.3118,  0.0903, -0.2506, -0.1406],
        [-0.1073, -0.2447,  0.2116, -0.2046,  0.2737, -0.2135, -0.1492,  0.2817],
        [-0.0983, -0.2759,  0.0334,  0.2683,  0.0283,  0.1257, -0.0269, -0.2422],
        [ 0.0888, -0.0744,  0.2230,  0.1215, -0.1118,  0.0932,  0.2656, -0.1682],
        [ 0.0646,  0.1262,  0.3541, -0.2699, -0.1429,  0.0886, -0.2609, -0.2737],
        [-0.3081, -0.1421,  0.1258,  0.1924,  0.2656, -0.3342,  0.1117,  0.3542],
        [-0.1064,  0.2655, -0.3062,  0.3190,  0.1752, -0.0321, -0.1706,  0.2563],
        [-0.3210,  0.0532,  0.0524, -0.3073,  0.0609,  0.1186,  0.1702,  0.1942],
        [ 0.1332,  0.1346, -0.0190, -0.2575, -0.0669, -0.0224, -0.1535,  0.2894],
        [ 0.1408,  0.4250,  0.3546, -0.0016, -0.0971,  0.0626, -0.0447, -0.0511],
        [-0.2496, -0.2936,  0.1282, -0.3071,  0.3084,  0.0199,  0.1267,  0.2776],
        [ 0.0633,  0.1381,  0.0836,  0.2430,  0.1228, -0.0362, -0.2947, -0.3213],
        [-0.3269,  0.4119,  0.2021, -0.0245, -0.3286, -0.0413,  0.0401, -0.2228],
        [-0.1720,  0.0572, -0.1268, -0.3111, -0.1875,  0.2391, -0.2970,  0.1255],
        [ 0.2064,  0.1874, -0.2022,  0.2524,  0.1425,  0.2507,  0.1794,  0.0056],
        [-0.2617,  0.1520, -0.0546,  0.0229,  0.1982, -0.3178, -0.3321, -0.0192],
        [-0.0117,  0.2169,  0.1108, -0.0648,  0.0007,  0.2538, -0.2980,  0.1057],
        [-0.2110,  0.1750, -0.0119, -0.3326,  0.1381, -0.1848,  0.0213, -0.0061],
        [ 0.0664,  0.2512,  0.1751,  0.3726, -0.1191, -0.1294, -0.0530,  0.1410],
        [-0.0984,  0.3247,  0.3825,  0.2843,  0.1762,  0.0187,  0.3238, -0.0862],
        [ 0.2101, -0.2145,  0.1484, -0.3188, -0.1726, -0.1638, -0.0608, -0.2104],
        [-0.0312,  0.2133,  0.2481,  0.3484, -0.0614, -0.0814, -0.0315,  0.1394],
        [-0.0373, -0.1750,  0.0613, -0.1938,  0.1924,  0.0537,  0.2049, -0.1966],
        [-0.2420, -0.3273,  0.3596, -0.2248,  0.1383,  0.2998,  0.2564,  0.2428],
        [-0.0264, -0.2907, -0.3614, -0.1359,  0.0549,  0.1127, -0.2744, -0.1981],
        [ 0.2836,  0.0326, -0.1914,  0.2984,  0.0361, -0.1310,  0.0445, -0.3646],
        [-0.1786,  0.4038,  0.2167, -0.2234,  0.1074, -0.0972, -0.2471, -0.3185],
        [ 0.2620,  0.1613, -0.2611, -0.2717,  0.0752, -0.2590,  0.1320, -0.2772],
        [ 0.0751,  0.1544, -0.0568,  0.0778, -0.1970, -0.2965,  0.1110, -0.0525],
        [ 0.1048,  0.0006, -0.2912, -0.0452,  0.1635,  0.0158, -0.1199, -0.2584],
        [ 0.2339, -0.2972,  0.0110, -0.1649,  0.1192,  0.0418,  0.0181, -0.2019],
        [-0.1514, -0.2702,  0.3008,  0.1562, -0.0086,  0.0386, -0.1640,  0.2672],
        [-0.0875,  0.1128, -0.2304,  0.2861,  0.0095, -0.0639, -0.1045, -0.0492],
        [-0.0055, -0.1273,  0.1748,  0.3013, -0.0083,  0.1203,  0.1337, -0.3914],
        [ 0.3039,  0.0989,  0.1923, -0.0885, -0.2704, -0.2245,  0.0954, -0.1760]],
       device='cuda:0', requires_grad=True) 

model.module_15.bias torch.Size([100])
Parameter containing:
tensor([-0.0397, -0.0313, -0.1339, -0.2560,  0.2302,  0.1323,  0.3527,  0.2781,
        -0.0143, -0.2099,  0.0634, -0.0321, -0.3370,  0.1457, -0.3667,  0.3622,
        -0.0195, -0.0664,  0.1553,  0.1561, -0.0617, -0.1547,  0.2271, -0.1150,
        -0.0312,  0.0496, -0.2878, -0.3386, -0.3067, -0.2842, -0.2689,  0.3145,
         0.1578, -0.3487, -0.1791,  0.1190,  0.0523,  0.3037,  0.2178, -0.1456,
        -0.1472, -0.1988, -0.3081,  0.2113, -0.1262, -0.0389,  0.3100, -0.1256,
        -0.2770,  0.0155, -0.1604,  0.2026,  0.0182, -0.1521,  0.1036, -0.1141,
         0.0096,  0.3207, -0.0631, -0.3044, -0.0553,  0.1873,  0.2187, -0.2875,
         0.1396, -0.2160,  0.2647, -0.3312,  0.1644,  0.3689, -0.2470, -0.1333,
         0.0722,  0.1357,  0.1707,  0.0773, -0.1818,  0.2663,  0.3163,  0.2959,
         0.2155,  0.0408, -0.3405, -0.1893,  0.0705,  0.0319, -0.1736, -0.2972,
        -0.0368, -0.1492,  0.3038,  0.2024, -0.0304,  0.0312,  0.0676, -0.1741,
        -0.2348, -0.0574,  0.1952, -0.1628], device='cuda:0',
       requires_grad=True) 

model.module_17.weight torch.Size([100, 100])
Parameter containing:
tensor([[ 0.0531, -0.0473,  0.0813,  ...,  0.0826,  0.0195,  0.0242],
        [-0.1088, -0.0679,  0.0146,  ..., -0.0594,  0.0717,  0.0189],
        [ 0.0059,  0.0567,  0.0921,  ...,  0.0711,  0.0650, -0.0723],
        ...,
        [ 0.0287,  0.0741, -0.0200,  ...,  0.1188, -0.0103,  0.0244],
        [ 0.0645,  0.0484,  0.0669,  ...,  0.0380, -0.0516,  0.0204],
        [ 0.0297,  0.0696, -0.0316,  ...,  0.0208, -0.0667, -0.0233]],
       device='cuda:0', requires_grad=True) 

model.module_17.bias torch.Size([100])
Parameter containing:
tensor([ 0.0856,  0.0334,  0.0211, -0.0715,  0.0303,  0.0539,  0.0055, -0.0626,
         0.0238,  0.0285, -0.0167,  0.0199,  0.0265, -0.0400, -0.0004,  0.0054,
        -0.1059,  0.0344, -0.0618,  0.0007,  0.0110,  0.0244, -0.0679,  0.0319,
         0.0964, -0.0742,  0.0766, -0.1006,  0.0650,  0.0372, -0.0497, -0.0196,
         0.0797,  0.0198,  0.0641,  0.0575, -0.0705, -0.0220,  0.0798,  0.0251,
        -0.1009,  0.1113, -0.0112, -0.0161,  0.0203, -0.0659,  0.0046,  0.0651,
        -0.0531, -0.0799, -0.0800, -0.0678,  0.0534, -0.0588, -0.0640, -0.0677,
         0.0232,  0.0686, -0.0876,  0.1085, -0.0036,  0.0079,  0.0618, -0.0199,
         0.0195, -0.0882, -0.0402, -0.0366,  0.0122, -0.0377, -0.0085,  0.1125,
         0.0106,  0.0296, -0.0216,  0.0685,  0.0984, -0.0339, -0.0317, -0.0261,
        -0.0041, -0.0069,  0.0129,  0.0174, -0.0139,  0.0846,  0.0342, -0.0169,
        -0.0331,  0.0645, -0.0203, -0.0161,  0.0643, -0.0738, -0.0337, -0.0225,
         0.0741, -0.0506,  0.0096,  0.0879], device='cuda:0',
       requires_grad=True) 

model.module_19.weight torch.Size([16, 100])
Parameter containing:
tensor([[-0.0406, -0.0296,  0.0007,  ...,  0.0875,  0.0366,  0.0288],
        [-0.0043,  0.0937, -0.0693,  ...,  0.0546,  0.0449, -0.0321],
        [-0.0705, -0.0988,  0.0210,  ...,  0.0466, -0.0820,  0.0245],
        ...,
        [ 0.0130, -0.0896,  0.0395,  ...,  0.0799,  0.0298, -0.0173],
        [ 0.0736,  0.1100,  0.0635,  ..., -0.0708, -0.0344,  0.0499],
        [ 0.0805,  0.0249,  0.1253,  ...,  0.0270,  0.0131, -0.0480]],
       device='cuda:0', requires_grad=True) 

model.module_19.bias torch.Size([16])
Parameter containing:
tensor([ 5.3162e-02, -8.7544e-02,  4.0386e-02, -4.6350e-02, -8.1858e-02,
         2.0768e-02, -1.0954e-05,  8.5925e-02, -3.0151e-02,  9.6147e-02,
         4.1068e-02,  2.7487e-02, -1.4913e-04,  5.5371e-02,  7.4819e-02,
         2.0645e-02], device='cuda:0', requires_grad=True) 



#### FINAL PARAMETERS ####
W 256 torch.Size([16, 16])
Parameter containing:
tensor([[-1.1197e+00,  3.3111e-01, -4.6465e-04,  8.3217e-01, -3.0408e-01,
          2.4728e-01,  6.0696e-01, -1.3235e+00,  2.1685e+00,  2.2764e-01,
         -8.1837e-01, -3.1415e-01, -5.3559e-01,  4.4598e-01, -5.2070e-02,
         -2.9647e-01],
        [-1.0663e+00,  1.0491e+00, -1.1685e+00, -7.5340e-01,  5.6349e-01,
          3.5077e-01,  3.8102e-01, -8.6233e-01,  4.3844e-01, -6.8427e-01,
          2.0490e+00,  1.0669e-01,  1.9626e-01, -1.4712e+00,  2.7936e-01,
         -7.8307e-02],
        [-3.6971e-01,  5.8514e-02, -1.1473e+00, -1.0475e+00, -6.2375e-01,
         -4.3390e-01, -4.7588e-01, -8.9397e-02,  1.2613e+00, -9.1936e-01,
          7.2764e-01,  7.1839e-01, -2.3908e-01,  1.6404e-01, -2.6290e+00,
          2.6654e-01],
        [-1.1189e+00,  5.3992e-02,  8.9336e-01, -1.3742e+00,  3.7178e-01,
         -5.8412e-01, -5.5423e-01,  1.5457e+00,  8.3777e-01, -2.3708e-01,
         -5.8660e-01,  1.5150e+00, -1.5927e+00, -1.0127e+00,  1.2048e+00,
          1.9036e+00],
        [ 3.9342e-01, -1.7603e+00,  5.4698e-01, -1.9858e+00, -2.5907e-01,
         -2.3718e-01,  7.6397e-02,  4.9119e-02, -8.5461e-01,  1.3250e+00,
          1.6734e+00,  6.3780e-01,  4.4952e-01, -3.1190e-02, -9.5861e-01,
          3.7679e-01],
        [ 1.3351e+00, -1.2088e+00, -1.8315e+00,  1.2289e+00,  1.3378e+00,
         -3.7293e-01, -1.1675e+00,  1.6340e-01, -5.8903e-01, -2.6910e-01,
         -2.0556e-01, -4.9592e-01,  9.8824e-01,  8.0459e-02, -1.2391e+00,
          1.8911e+00],
        [-2.3142e+00, -1.9968e+00, -2.0094e+00,  1.5059e+00,  1.3896e-01,
          1.2950e+00, -1.5734e+00, -1.1736e+00,  9.8168e-02, -2.7511e-02,
         -4.7150e-01,  7.1810e-01, -1.5029e+00, -6.6031e-01, -1.0114e+00,
         -4.5498e-01],
        [-8.1585e-01,  3.0369e-01,  2.7994e-02,  3.6768e-01, -2.9673e-01,
          2.8893e-01,  1.0145e+00, -1.9017e-01,  6.8545e-01, -3.3242e-01,
         -2.7717e-01, -3.6124e-01, -6.1469e-01, -2.1956e-01, -9.8892e-01,
          3.0727e+00],
        [-1.3883e+00, -3.4080e-01,  2.0975e-01,  4.9576e-01,  7.0143e-01,
          8.9116e-01, -4.5052e-01,  3.7139e-01,  3.8480e-02,  1.8228e+00,
          3.7316e-01,  4.5478e-01,  1.6043e+00, -5.7891e-02, -4.2171e-01,
          1.0748e+00],
        [-2.4919e+00,  1.1018e+00,  5.1680e-01, -1.0353e+00, -3.0924e-01,
          8.7772e-01,  5.1793e-01, -4.5640e-02, -1.0348e+00, -1.3482e+00,
          1.0683e+00, -3.3650e-01, -4.7297e-01, -2.2024e-02,  2.1821e+00,
          6.9932e-01],
        [ 5.7278e-01, -2.7539e-01, -1.1650e+00, -7.1756e-01,  6.7844e-01,
         -2.4047e+00,  5.0172e-01,  1.4563e+00, -1.2956e+00,  1.5040e+00,
          2.1199e+00, -1.4359e+00, -2.1793e+00, -1.5335e+00,  8.5180e-01,
          9.7360e-01],
        [ 1.0669e+00,  4.6044e-01,  1.2101e+00,  3.6956e-01, -2.3434e+00,
          5.4504e-01,  2.4924e+00,  1.7206e+00,  1.0799e+00, -4.1345e-01,
         -6.4356e-01, -1.1663e+00,  4.0013e-01,  1.8757e+00,  8.2461e-01,
         -7.8070e-01],
        [ 1.3986e+00,  4.2469e-01, -1.8407e+00, -2.2938e+00, -7.9779e-01,
         -1.7552e+00,  3.8532e-03,  5.3028e-01,  2.7136e-01,  1.0151e-01,
         -4.4801e-01,  9.2198e-01,  1.0823e+00, -2.4278e-01, -1.1180e-01,
         -4.2280e-01],
        [-7.5437e-01, -1.4679e+00, -6.6893e-01,  1.0666e+00,  6.7165e-01,
          2.0136e-01,  1.2935e+00,  1.0244e-01, -7.8469e-02,  1.0498e+00,
          6.4014e-01,  1.3177e+00, -1.6223e-01,  5.1884e-01, -1.5240e-01,
          1.0504e+00],
        [-1.4671e+00, -2.4082e-02, -2.4493e+00,  2.1410e+00,  3.0073e+00,
          2.3180e+00,  3.0449e+00, -4.5939e-01,  1.1419e+00, -4.3396e-01,
         -1.3529e-02,  1.6320e+00,  1.6459e+00, -4.5577e-02, -1.7993e-01,
         -2.9311e-01],
        [-1.2212e+00, -1.4791e+00,  4.5671e-01,  2.3683e-01,  2.1738e+00,
          8.7787e-01, -7.9815e-03,  1.1085e-01, -1.1982e+00,  2.3913e+00,
          2.2493e-01,  4.8689e-01,  6.0881e-01, -2.9457e+00,  6.4295e-01,
         -5.2687e-02]], device='cuda:0', requires_grad=True) 
grad:  tensor([[ 0.0200,  0.0061, -0.0031,  0.0175,  0.0049, -0.0018,  0.0194,  0.0218,
          0.0121,  0.0235,  0.0227,  0.0184, -0.0049,  0.0249,  0.0331,  0.0086],
        [ 0.0061,  0.0020, -0.0009,  0.0052,  0.0014, -0.0006,  0.0060,  0.0064,
          0.0034,  0.0072,  0.0062,  0.0051, -0.0014,  0.0070,  0.0094,  0.0021],
        [-0.0031, -0.0009,  0.0006, -0.0030, -0.0009,  0.0002, -0.0031, -0.0037,
         -0.0022, -0.0040, -0.0046, -0.0036,  0.0009, -0.0045, -0.0060, -0.0020],
        [ 0.0175,  0.0052, -0.0030,  0.0163,  0.0049, -0.0016,  0.0174,  0.0198,
          0.0115,  0.0217,  0.0227,  0.0178, -0.0046,  0.0235,  0.0314,  0.0094],
        [ 0.0049,  0.0014, -0.0009,  0.0049,  0.0016, -0.0004,  0.0050,  0.0058,
          0.0035,  0.0065,  0.0074,  0.0057, -0.0014,  0.0071,  0.0096,  0.0034],
        [-0.0018, -0.0006,  0.0002, -0.0016, -0.0004,  0.0002, -0.0018, -0.0019,
         -0.0010, -0.0021, -0.0018, -0.0015,  0.0004, -0.0021, -0.0029, -0.0006],
        [ 0.0194,  0.0060, -0.0031,  0.0174,  0.0050, -0.0018,  0.0192,  0.0213,
          0.0120,  0.0234,  0.0230,  0.0184, -0.0049,  0.0246,  0.0328,  0.0089],
        [ 0.0218,  0.0064, -0.0037,  0.0198,  0.0058, -0.0019,  0.0213,  0.0245,
          0.0141,  0.0263,  0.0271,  0.0215, -0.0056,  0.0288,  0.0383,  0.0109],
        [ 0.0121,  0.0034, -0.0022,  0.0115,  0.0035, -0.0010,  0.0120,  0.0141,
          0.0084,  0.0151,  0.0166,  0.0129, -0.0033,  0.0170,  0.0227,  0.0071],
        [ 0.0235,  0.0072, -0.0040,  0.0217,  0.0065, -0.0021,  0.0234,  0.0263,
          0.0151,  0.0290,  0.0297,  0.0235, -0.0061,  0.0309,  0.0414,  0.0121],
        [ 0.0227,  0.0062, -0.0046,  0.0227,  0.0074, -0.0018,  0.0230,  0.0271,
          0.0166,  0.0297,  0.0352,  0.0269, -0.0067,  0.0337,  0.0452,  0.0161],
        [ 0.0184,  0.0051, -0.0036,  0.0178,  0.0057, -0.0015,  0.0184,  0.0215,
          0.0129,  0.0235,  0.0269,  0.0210, -0.0052,  0.0263,  0.0352,  0.0120],
        [-0.0049, -0.0014,  0.0009, -0.0046, -0.0014,  0.0004, -0.0049, -0.0056,
         -0.0033, -0.0061, -0.0067, -0.0052,  0.0013, -0.0068, -0.0091, -0.0029],
        [ 0.0249,  0.0070, -0.0045,  0.0235,  0.0071, -0.0021,  0.0246,  0.0288,
          0.0170,  0.0309,  0.0337,  0.0263, -0.0068,  0.0347,  0.0463,  0.0143],
        [ 0.0331,  0.0094, -0.0060,  0.0314,  0.0096, -0.0029,  0.0328,  0.0383,
          0.0227,  0.0414,  0.0452,  0.0352, -0.0091,  0.0463,  0.0617,  0.0193],
        [ 0.0086,  0.0021, -0.0020,  0.0094,  0.0034, -0.0006,  0.0089,  0.0109,
          0.0071,  0.0121,  0.0161,  0.0120, -0.0029,  0.0143,  0.0193,  0.0080]],
       device='cuda:0') 

act.weight 1 torch.Size([1])
Parameter containing:
tensor([0.2060], device='cuda:0', requires_grad=True) 
grad:  tensor([-13.4195], device='cuda:0') 

inner_act.weight 1 torch.Size([1])
Parameter containing:
tensor([0.1526], device='cuda:0', requires_grad=True) 
grad:  tensor([0.2491], device='cuda:0') 

out_act.weight 1 torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 
grad:  None 

encoder.module_0.weight 1100 torch.Size([100, 11])
Parameter containing:
tensor([[ 0.2260,  0.2622, -0.0971,  ...,  0.3026, -0.1199,  0.2768],
        [ 0.0092,  0.2256,  0.0891,  ..., -0.0303, -0.0744, -0.0340],
        [-0.0657,  0.2751, -0.2966,  ...,  0.2418, -0.3042,  0.2418],
        ...,
        [ 0.1760,  0.1997,  0.3336,  ...,  0.1597,  0.0348, -0.0057],
        [-0.1559, -0.1108, -0.1616,  ...,  0.3246,  0.1393, -0.2069],
        [-0.2926,  0.1080,  0.1478,  ...,  0.1751,  0.0736,  0.1818]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-0.2205, -0.1423, -0.0015,  ..., -0.0025,  0.0053, -0.0189],
        [-0.0601, -0.1686, -0.0344,  ...,  0.0009,  0.0015, -0.0342],
        [ 0.1690,  0.1237,  0.0604,  ..., -0.0019, -0.0040, -0.0029],
        ...,
        [ 0.1126, -0.0211, -0.0496,  ...,  0.0035, -0.0011,  0.0103],
        [ 0.0251,  0.0112,  0.0126,  ...,  0.0016,  0.0023,  0.0015],
        [-0.0697, -0.1258,  0.0125,  ..., -0.0038, -0.0020, -0.0022]],
       device='cuda:0') 

encoder.module_0.bias 100 torch.Size([100])
Parameter containing:
tensor([-1.9921e-01,  1.6951e-01, -2.2272e-01,  2.7475e-01, -1.3086e-01,
         1.6866e-01,  6.1822e-02,  7.7465e-02, -1.2768e-01,  1.2645e-01,
        -1.2987e-01, -3.0537e-01, -9.8445e-02,  2.1149e-01, -8.2229e-02,
         6.8275e-02, -1.2922e-01,  2.2481e-01,  1.7007e-01,  9.6260e-02,
        -1.4832e-01, -2.5040e-01, -3.6228e-03, -1.6119e-01,  2.6237e-01,
        -3.2013e-01,  1.0849e-01,  3.3126e-01,  9.1591e-02,  7.0708e-02,
        -3.7318e-01,  3.0001e-01, -3.9543e-02, -2.9616e-01,  2.8772e-01,
        -1.0079e-01, -2.1862e-02,  2.6265e-01, -2.0893e-01, -3.2286e-01,
         3.5124e-02, -5.2565e-02,  6.8920e-02, -2.7025e-01, -3.4625e-02,
        -1.5788e-01, -1.4539e-01, -2.8707e-01,  1.2842e-01,  1.0610e-02,
        -2.5200e-01,  2.5146e-01,  3.0417e-02,  3.7231e-02, -1.8570e-01,
         2.1887e-02,  2.5916e-01,  2.0907e-01, -2.5712e-01,  2.6820e-01,
        -2.1802e-04,  1.3708e-01,  2.0717e-01,  2.5721e-01, -2.7415e-01,
         2.3340e-01, -2.0082e-01, -4.2071e-03, -2.2271e-01, -5.0529e-02,
        -2.7877e-02, -8.0381e-02, -1.0157e-01,  3.5346e-02,  2.7836e-01,
         1.6847e-01,  1.5884e-01,  1.0429e-01,  2.0442e-01, -3.0951e-02,
         3.2566e-02,  5.8758e-02, -2.6396e-01, -2.2487e-01,  4.6298e-02,
        -1.2169e-01,  1.2951e-02, -1.0260e-01,  4.9231e-02,  1.5973e-01,
        -1.0667e-01,  2.3761e-01,  2.4233e-01, -2.6035e-01, -2.3002e-01,
        -2.6216e-01, -1.5863e-01, -1.2321e-01, -1.0619e-01, -9.2060e-02],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-2.9305e-02, -6.2225e-02, -1.1809e-02, -9.6374e-02, -2.7121e-03,
         2.1195e-02, -8.9244e-03,  2.3637e-02,  1.2989e-02,  1.4826e-02,
         9.0885e-03,  7.8203e-02,  7.0702e-02, -1.4305e-02, -4.5225e-02,
        -1.9075e-02, -4.6145e-02,  3.7323e-02, -1.0343e-02,  3.6459e-03,
         1.4773e-01,  2.8087e-02,  5.1363e-02,  4.8472e-02, -5.0488e-02,
        -4.0483e-02,  8.7933e-03, -2.3237e-02,  3.7481e-02,  4.8504e-02,
         2.8285e-02, -7.1511e-02,  2.5699e-03, -9.1017e-03, -1.2956e-02,
        -3.8625e-02,  9.2647e-02, -2.8126e-02,  1.7734e-03, -5.4719e-03,
        -1.5013e-02, -3.1691e-02, -6.1693e-02, -1.0964e-02,  1.7722e-02,
        -5.9262e-02,  4.6259e-02,  2.4691e-02,  4.7669e-02,  1.8402e-02,
        -5.5208e-02,  1.4433e-02, -8.9684e-03, -1.8710e-02, -2.7497e-02,
         1.0197e-04, -1.4202e-02,  1.5448e-02, -4.8455e-04, -4.9294e-02,
         4.6630e-02, -4.3412e-02,  5.9871e-02, -3.4845e-02, -1.5788e-03,
        -9.7500e-03, -1.9590e-02, -2.5868e-02,  2.8230e-02, -3.9440e-02,
         1.2407e-02, -1.2420e-03,  4.4457e-03, -4.1523e-02,  6.1859e-02,
        -3.9683e-02, -3.5092e-02, -8.7534e-02,  4.0961e-03, -3.7102e-03,
        -2.7473e-02,  4.9517e-02, -7.7303e-03, -4.3731e-02, -2.3360e-02,
         3.7138e-03,  5.9801e-02,  3.3562e-02, -9.2789e-02, -3.2671e-02,
        -1.1626e-01,  5.0168e-02,  4.0292e-02,  6.1649e-02, -6.2561e-02,
        -2.4907e-02,  4.6708e-02,  1.3107e-02,  2.4170e-03, -2.7433e-04],
       device='cuda:0') 

encoder.module_2.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[-0.0714, -0.0392, -0.0356,  ..., -0.0798,  0.0388,  0.0674],
        [-0.0667,  0.0027, -0.0431,  ...,  0.0152, -0.0346, -0.0851],
        [-0.0463, -0.0910,  0.0027,  ..., -0.0039,  0.0769,  0.1074],
        ...,
        [-0.0886, -0.1117, -0.0496,  ..., -0.1281,  0.0689,  0.0848],
        [ 0.0035,  0.0261, -0.0839,  ..., -0.0037,  0.0622, -0.0565],
        [-0.0250, -0.0715,  0.0148,  ..., -0.1157, -0.0533,  0.0343]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-1.6415e-01, -8.6391e-02, -8.6996e-02,  ..., -1.5020e-01,
          1.8094e-02, -1.0989e-04],
        [-5.9447e-02, -3.1892e-02, -3.2745e-02,  ..., -4.1874e-02,
          1.9220e-02,  2.8295e-03],
        [-1.1792e-02, -1.4900e-02, -2.8217e-02,  ..., -4.5209e-03,
         -1.5128e-02, -3.2160e-02],
        ...,
        [ 3.2809e-02,  2.3903e-02,  3.3905e-02,  ...,  2.4865e-02,
          5.1046e-02,  9.2499e-02],
        [ 2.2908e-02,  5.7636e-04, -2.5496e-03,  ...,  1.4357e-02,
         -8.1528e-02, -1.0708e-01],
        [-5.5289e-02, -2.0188e-02, -1.3336e-02,  ..., -4.3028e-02,
          2.1608e-02,  5.5027e-02]], device='cuda:0') 

encoder.module_2.bias 100 torch.Size([100])
Parameter containing:
tensor([ 0.0223,  0.0137,  0.0570,  0.0667, -0.0929,  0.0297,  0.0731, -0.0617,
        -0.0880, -0.0989, -0.0739,  0.0616,  0.0249, -0.0603, -0.0741, -0.0950,
         0.0241,  0.0290,  0.0230, -0.0141,  0.0447,  0.0066,  0.0540,  0.0022,
        -0.0621, -0.0681,  0.0418,  0.0525,  0.0552, -0.0793,  0.0536, -0.0745,
         0.0283, -0.0697, -0.0434, -0.0342,  0.0889,  0.0979, -0.0487, -0.0054,
        -0.0909, -0.1428, -0.0645, -0.0184, -0.0789, -0.0364,  0.0265,  0.0188,
        -0.0137,  0.0286,  0.0889, -0.0894, -0.0586,  0.0200,  0.0338,  0.0686,
         0.0710, -0.1022,  0.0075, -0.1064,  0.0403,  0.0598, -0.1007, -0.0623,
         0.0450,  0.0248, -0.0534,  0.0023, -0.0668,  0.0308, -0.0260,  0.0449,
        -0.0249,  0.0117, -0.0646,  0.0856,  0.0041,  0.0047, -0.0008, -0.0869,
         0.0102,  0.0756,  0.0741,  0.0263,  0.0329,  0.0404,  0.0003,  0.0290,
         0.0364, -0.0194, -0.0586, -0.0139,  0.0492,  0.0585, -0.0553,  0.0033,
        -0.0569,  0.0390,  0.0279, -0.0514], device='cuda:0',
       requires_grad=True) 
grad:  tensor([-0.0676, -0.0009, -0.0184,  0.0370,  0.0399,  0.0072, -0.1339,  0.0409,
         0.0260,  0.1255,  0.0376, -0.0461,  0.0236,  0.0404, -0.0162, -0.0971,
         0.0254,  0.1763, -0.1226,  0.1191, -0.0431,  0.1001,  0.0367, -0.0169,
         0.1361,  0.0105, -0.0469, -0.0684, -0.0438,  0.0430, -0.0426, -0.0093,
        -0.0546,  0.0365,  0.0663,  0.0709, -0.0634,  0.0202, -0.0257, -0.0672,
         0.0853,  0.0149, -0.1576, -0.0269,  0.0043,  0.0110,  0.0117, -0.1712,
         0.1602, -0.0133,  0.0032, -0.0489, -0.1192,  0.0036, -0.0819,  0.0695,
        -0.0099, -0.0362, -0.0287,  0.0934, -0.1204, -0.0604, -0.0204, -0.0269,
         0.0025,  0.0538, -0.0219, -0.0313, -0.0140, -0.0392, -0.0087, -0.0785,
         0.0633, -0.0469,  0.0062, -0.0978,  0.0092,  0.0071, -0.0478, -0.1352,
        -0.0673,  0.1115, -0.1157, -0.0161,  0.0029, -0.0200, -0.0943, -0.0267,
         0.1183, -0.0343,  0.0269, -0.0789, -0.0137, -0.0772, -0.0983,  0.0100,
        -0.0024,  0.0813, -0.0952,  0.0032], device='cuda:0') 

encoder.module_4.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[ 0.1028,  0.0613,  0.0722,  ...,  0.0632,  0.0638,  0.1145],
        [ 0.0104,  0.0648,  0.0517,  ...,  0.1482,  0.0505,  0.0817],
        [-0.0270, -0.0825, -0.0045,  ...,  0.0423,  0.1305,  0.1122],
        ...,
        [-0.0140, -0.1073, -0.0832,  ...,  0.0858, -0.0852,  0.0722],
        [ 0.0888,  0.0713,  0.0265,  ..., -0.0741, -0.0319,  0.0471],
        [-0.0570, -0.0198,  0.0556,  ...,  0.0510, -0.0159,  0.0349]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-0.0090,  0.0222, -0.0377,  ..., -0.0039,  0.0653,  0.0306],
        [ 0.2319,  0.0519, -0.0031,  ...,  0.1093,  0.0843,  0.1958],
        [-0.7639, -0.2092,  0.0324,  ..., -0.2473, -0.2201, -0.5104],
        ...,
        [ 1.1355,  0.2055,  0.0644,  ...,  0.4894,  0.1147,  0.7276],
        [ 0.2017, -0.0252, -0.0421,  ...,  0.3796,  0.2579,  0.4226],
        [-0.2025, -0.0995,  0.0172,  ..., -0.0239, -0.0677, -0.0976]],
       device='cuda:0') 

encoder.module_4.bias 16 torch.Size([16])
Parameter containing:
tensor([-0.0418,  0.0354, -0.0492, -0.0591, -0.0699, -0.0146,  0.1076,  0.0699,
        -0.0539,  0.0864,  0.0979,  0.1042,  0.0064,  0.0250,  0.0783,  0.0960],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-0.0670,  0.1082, -0.4979,  0.4465,  0.5452,  0.1516, -0.4873, -1.0062,
         0.2565, -0.0696, -0.4157,  0.1110, -0.0556,  0.6863, -0.2168, -0.2739],
       device='cuda:0') 

model.module_0.bias 8 torch.Size([8])
Parameter containing:
tensor([ 0.0123, -0.0051, -0.0043,  0.0153, -0.0760,  0.0348, -0.0406, -0.0354],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-2.5764,  0.1126,  0.8841,  0.5724,  0.4835, -0.6531,  0.0483,  0.1814],
       device='cuda:0') 

model.module_0.lin.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[ 0.3963,  0.1965,  0.3616, -0.4670, -0.4691, -0.1212,  0.1323,  0.3222,
         -0.1461, -0.2284,  0.3304, -0.0855,  0.0025, -0.5247, -0.0454,  0.2975],
        [ 0.4808,  0.0541,  0.3272,  0.0772, -0.3761, -0.0257, -0.1663, -0.0647,
         -0.1832,  0.3635, -0.4155, -0.2746, -0.2065,  0.4140, -0.0971,  0.1913],
        [ 0.2433,  0.4442, -0.1126,  0.1113, -0.2279, -0.0452, -0.4252, -0.4075,
          0.1519, -0.3983,  0.2547,  0.4230,  0.1781,  0.1872, -0.4499, -0.2465],
        [-0.3751, -0.4796,  0.2409,  0.1441,  0.4959, -0.1449, -0.3269, -0.4292,
          0.0260, -0.2753,  0.0668,  0.3510,  0.4665, -0.0796, -0.3221, -0.2948],
        [ 0.3157,  0.1226,  0.0037, -0.4390,  0.2648,  0.3147,  0.0404, -0.1031,
         -0.2396, -0.0148,  0.0141,  0.1657,  0.0334,  0.5135,  0.3142,  0.0584],
        [-0.4892, -0.2851,  0.2119, -0.3661,  0.1102,  0.1410, -0.3138,  0.1019,
         -0.1173,  0.4171, -0.1088,  0.3266,  0.4102, -0.1870,  0.0757, -0.1107],
        [ 0.4271,  0.2741,  0.0031,  0.3271, -0.3666, -0.1614,  0.0877, -0.4773,
          0.4887, -0.0449,  0.4546, -0.0921,  0.0528, -0.1132, -0.2063, -0.0874],
        [ 0.3554,  0.4889,  0.1635,  0.3566,  0.2454, -0.0026, -0.3773,  0.1224,
         -0.1308,  0.1899, -0.3284,  0.0589, -0.2280, -0.4555, -0.4735,  0.4365]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-2.0227, -1.4545, -0.2578, -0.2144, -0.5132, -2.2052, -1.5540, -1.9931,
         -1.8657, -1.5365, -1.4025, -0.1468, -0.0841, -0.1016, -1.3624,  0.0140],
        [-0.2332, -0.1884, -0.0259, -0.0819,  0.0610,  0.1704,  0.0243,  0.1232,
         -0.0741,  0.1733, -0.0420, -0.0437, -0.0068, -0.0546,  0.0425, -0.0356],
        [-0.1948, -0.2060, -0.0216, -0.1893,  0.2536,  1.0159,  0.4264,  0.7712,
          0.1526,  0.8049,  0.1853, -0.1017, -0.0086, -0.1300,  0.4426, -0.1182],
        [-0.8769, -0.7042, -0.1248, -0.3162,  0.2341,  0.8729,  0.1829,  0.6136,
         -0.3567,  0.8793, -0.1693, -0.1843, -0.0479, -0.2074,  0.2417, -0.1805],
        [ 1.1218,  0.8439,  0.1563,  0.2392,  0.0445,  0.1598,  0.3790,  0.2768,
          0.8109, -0.0321,  0.5401,  0.1482,  0.0563,  0.1425,  0.2800,  0.1065],
        [-0.2788, -0.1698, -0.0525,  0.0281, -0.1732, -0.5663, -0.3591, -0.5132,
         -0.4111, -0.3951, -0.3045,  0.0034, -0.0220,  0.0289, -0.3310,  0.0150],
        [ 0.4450,  0.3251,  0.0743,  0.0952, -0.0250, -0.0852,  0.0780, -0.0516,
          0.3133, -0.2378,  0.2077,  0.0626,  0.0306,  0.0612,  0.0595,  0.0624],
        [ 0.1759,  0.1245,  0.0191,  0.0188,  0.0086,  0.1968,  0.1233,  0.1338,
          0.1140,  0.0955,  0.1025,  0.0092,  0.0034,  0.0120,  0.1137, -0.0068]],
       device='cuda:0') 

model.module_1.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[-3.1105e-02, -2.8826e-01,  6.7485e-02,  9.8603e-03,  2.5511e-01,
          3.7376e-01, -1.1282e-01, -2.0364e-01],
        [-2.0498e-01, -8.0064e-02, -2.0421e-01,  3.0165e-01, -1.3013e-01,
          1.8413e-01,  1.5431e-01,  9.9715e-02],
        [ 1.6752e-01,  2.8236e-01,  1.5330e-01,  1.7191e-01, -3.1348e-01,
         -8.0012e-03, -1.5084e-02,  2.7239e-01],
        [ 1.2172e-01,  2.2083e-01,  2.5724e-01, -1.4130e-01,  2.9219e-02,
          3.7794e-01,  7.4360e-02,  1.5624e-01],
        [ 1.1360e-01, -1.3765e-01,  6.8876e-02, -2.3367e-01,  3.1727e-01,
          5.4749e-02,  2.1291e-01, -2.7539e-01],
        [-3.3681e-01,  2.1580e-02, -2.4433e-03, -1.2246e-01,  1.7839e-01,
         -2.6227e-01,  3.7142e-01, -3.3422e-01],
        [ 2.8516e-02, -2.1960e-01,  7.5589e-02,  3.7270e-01, -6.7690e-02,
          1.4404e-01, -1.7337e-01, -1.9753e-01],
        [-3.4246e-01,  1.8494e-01, -1.9129e-02,  1.3832e-01, -2.9533e-01,
         -2.3564e-01, -3.8668e-01, -2.1992e-01],
        [-5.5261e-02, -9.1138e-02,  1.6647e-01, -1.6598e-01,  3.4194e-01,
         -1.6619e-01, -3.1304e-01,  2.7955e-01],
        [-2.2007e-01, -1.6714e-02, -4.9817e-02, -8.6656e-02,  1.1738e-02,
         -3.5189e-01,  3.1788e-01, -2.5516e-01],
        [ 2.1558e-01, -1.8552e-01, -8.7421e-02, -6.3833e-03, -1.4188e-01,
         -1.4312e-01, -3.1175e-01, -2.4807e-01],
        [-1.2088e-02, -1.5140e-01, -6.6784e-02,  7.9989e-02, -3.4651e-02,
         -3.2051e-01, -1.4530e-01,  9.4849e-02],
        [ 1.4298e-01,  1.6629e-01,  2.9450e-02,  2.3910e-01, -2.3573e-01,
         -3.0874e-01, -6.7175e-02,  5.3378e-03],
        [ 2.5288e-01, -1.8871e-01, -2.4534e-01,  3.6445e-03,  7.3714e-02,
         -3.0694e-01, -1.5487e-01, -2.7698e-01],
        [ 7.9964e-02,  7.3410e-02, -2.7815e-01, -2.2463e-01,  1.6010e-02,
         -1.5630e-01, -2.0187e-01, -7.8842e-02],
        [-3.5002e-01, -7.9756e-02, -4.1580e-02,  5.8372e-02, -6.6739e-03,
         -3.9364e-02,  2.4713e-01, -1.6217e-01],
        [ 1.4256e-01,  2.3326e-01,  1.7248e-02, -2.2448e-01, -3.2706e-01,
          8.4810e-02,  1.2871e-01,  2.8221e-01],
        [-1.4853e-01,  2.7460e-01,  3.4930e-01, -6.7039e-02, -1.2029e-01,
         -1.1841e-01, -3.0020e-01,  1.9985e-01],
        [ 1.5102e-02,  1.3634e-01,  2.1956e-01, -1.3891e-01, -2.2573e-02,
          3.1676e-01, -3.0071e-01,  3.0892e-01],
        [ 1.7016e-01, -9.8515e-02, -3.0051e-01,  1.9387e-01,  1.6033e-01,
         -1.3534e-01,  1.4040e-01,  1.1141e-01],
        [ 3.3830e-01,  2.0035e-01,  5.5826e-02, -3.4112e-01,  2.7517e-01,
          3.3065e-01, -1.1815e-01, -2.0239e-02],
        [ 5.3176e-03, -4.7484e-02,  1.8820e-01,  3.1319e-02, -2.8637e-01,
          8.5393e-02, -1.9918e-01,  8.0191e-02],
        [ 1.3715e-01, -1.8995e-01,  2.3893e-01,  2.6670e-02, -1.9510e-01,
          3.3643e-01,  1.8989e-01,  2.4522e-01],
        [-2.4620e-01, -2.6110e-01, -3.0492e-01,  2.4244e-01,  1.8623e-01,
         -2.0326e-01,  1.3572e-01,  8.1687e-02],
        [-1.5297e-01,  6.4365e-02, -2.0561e-01, -9.9627e-02,  1.3235e-01,
          3.3807e-02, -2.5607e-01,  9.2793e-02],
        [-4.0108e-02, -2.6421e-01, -3.3516e-01, -1.5925e-02, -2.1705e-01,
         -2.4590e-01,  9.3697e-02,  9.6869e-03],
        [-1.3203e-01,  2.8340e-02,  1.4050e-01, -1.7952e-01, -9.7996e-02,
          6.8797e-02,  7.5517e-02,  1.2027e-01],
        [ 2.4181e-01, -1.7374e-04,  1.1867e-01, -2.0153e-01, -4.8680e-02,
          2.7481e-01, -3.5525e-01, -2.3379e-01],
        [-2.9272e-01,  2.6797e-01, -6.5129e-02,  2.9369e-01, -1.7764e-01,
         -7.8417e-02,  2.0051e-01, -3.7997e-01],
        [-4.0990e-01, -1.8149e-01,  6.4314e-02, -2.5901e-01, -3.3089e-03,
          2.9517e-01, -3.6217e-02,  1.1312e-03],
        [-3.5758e-01, -9.4719e-02,  1.4764e-02,  8.7129e-02, -1.3390e-01,
         -1.6206e-01, -2.4383e-01,  2.0820e-01],
        [-2.1607e-01,  4.2272e-02, -6.4145e-02, -1.3980e-01, -3.0377e-02,
          2.9117e-01,  2.5246e-01, -3.8324e-02],
        [-8.6792e-02, -1.6723e-01, -1.4478e-01, -3.4279e-02,  2.3686e-01,
          7.4158e-02, -3.0246e-01, -7.7161e-02],
        [-2.9862e-01,  3.1296e-01,  7.7844e-03, -1.2618e-01,  1.7375e-01,
         -3.3674e-01, -1.0290e-01,  5.6094e-02],
        [ 2.3318e-01,  2.5997e-01, -6.7290e-02, -3.4862e-01,  5.5706e-02,
         -1.6294e-01,  2.4521e-01, -1.1890e-01],
        [-9.3539e-02, -4.5410e-02,  3.4303e-01,  1.5589e-01, -2.4330e-01,
          4.4704e-02,  1.5007e-01, -6.9169e-02],
        [ 1.0145e-01, -2.7621e-01, -1.4669e-01,  2.6045e-01,  2.9317e-01,
          1.1989e-01, -1.8356e-01,  1.6677e-01],
        [-1.7953e-01, -2.9471e-01, -2.5284e-01, -9.0433e-02,  1.4286e-01,
          1.5339e-02,  3.4578e-01, -4.1282e-02],
        [ 2.8640e-01, -2.5904e-01, -1.8464e-01,  6.0561e-02,  2.0429e-01,
          1.3883e-01,  3.1875e-01, -1.8853e-01],
        [ 3.2268e-01,  1.6895e-01,  1.4926e-01,  1.5099e-02, -2.8082e-01,
          1.7667e-01,  9.6364e-02,  2.9372e-01],
        [ 2.8863e-01, -2.5082e-01,  3.6120e-01, -9.3359e-02, -2.2862e-01,
          2.8493e-01, -3.0244e-02,  6.4273e-02],
        [ 3.2168e-02, -2.0015e-01,  2.3230e-01,  1.5999e-01,  2.6648e-01,
         -1.0684e-01, -2.5125e-01,  5.1846e-02],
        [-8.3489e-02, -1.6973e-02, -3.2633e-01,  2.7481e-01, -1.5571e-01,
         -1.0104e-02, -3.3325e-02, -1.6608e-01],
        [ 1.9340e-01, -3.0637e-01, -8.5635e-02, -2.3452e-01,  2.1152e-01,
         -1.8208e-01,  1.9118e-01, -3.2372e-01],
        [-4.0052e-01,  1.1367e-02, -3.2715e-01,  3.6870e-01,  2.8509e-01,
         -1.2396e-01,  2.5778e-01, -1.2286e-01],
        [ 1.0463e-01, -2.2019e-01, -1.8080e-02, -1.1322e-01,  7.5880e-02,
          8.6255e-02, -3.2365e-01,  5.0413e-02],
        [ 2.3777e-01,  2.9052e-01,  1.5232e-01,  9.1097e-03,  2.2734e-01,
          2.1249e-01, -2.4492e-01,  7.2949e-04],
        [-3.1904e-01,  4.3485e-02,  2.3940e-02, -2.3504e-01,  8.6026e-02,
          2.4907e-01, -3.0441e-01, -3.1985e-01],
        [-1.3762e-01,  6.3119e-02, -3.3675e-01, -1.0137e-01,  3.2211e-01,
         -3.1918e-01, -8.5174e-02, -6.3930e-02],
        [ 2.0809e-01, -1.3342e-01,  3.1493e-01, -1.5712e-01,  1.1653e-01,
         -9.4094e-02,  3.4099e-01, -1.7010e-01],
        [-1.2488e-01,  3.0643e-01, -2.9066e-01,  6.6265e-02,  2.2236e-01,
         -5.2981e-02,  3.2406e-01, -3.4115e-01],
        [-2.6399e-02, -2.1778e-01,  1.3242e-01,  3.2992e-01, -3.2699e-01,
         -1.7756e-01, -2.2954e-01, -2.1382e-01],
        [ 1.1249e-01,  1.2279e-02, -2.8247e-01, -2.1899e-01, -2.2848e-01,
          3.4419e-02, -3.0457e-01, -2.9239e-01],
        [-2.9936e-01,  2.7212e-01,  2.6164e-01, -1.5605e-01,  7.7544e-02,
         -3.1681e-02, -1.5716e-01,  1.5302e-01],
        [-2.1880e-01, -4.6232e-02,  2.5485e-01, -3.2692e-01,  3.2782e-01,
          2.0701e-01,  1.9311e-01, -6.5164e-02],
        [-1.3488e-01, -1.6833e-01, -2.5801e-01, -3.4285e-01, -5.4255e-02,
          9.1423e-02, -3.5922e-01,  3.4565e-01],
        [-2.3462e-01,  3.1255e-02, -1.3083e-01,  2.9025e-01, -1.2238e-01,
          8.8211e-02,  1.1965e-01,  1.8350e-01],
        [-2.6041e-01, -2.2830e-01,  2.6010e-02, -3.3328e-01, -1.4908e-01,
         -3.1422e-01,  1.7789e-01,  3.6079e-02],
        [-3.9016e-01,  3.2921e-01,  1.5207e-01, -1.6640e-01, -7.9570e-02,
          2.7085e-01, -2.3346e-01,  9.3460e-02],
        [ 1.3904e-01, -2.2240e-01, -1.8855e-01, -7.3196e-02, -2.6674e-01,
          2.8436e-01,  1.0909e-01, -1.2636e-01],
        [ 3.6420e-02,  1.0162e-02,  1.3107e-01,  2.2489e-01, -2.6835e-01,
         -1.6565e-01,  1.6781e-01, -2.0357e-01],
        [ 7.7995e-03, -1.0678e-01,  1.9865e-01, -2.0627e-01,  3.4135e-01,
          1.3069e-01, -2.4037e-01, -8.9174e-02],
        [-5.4689e-02, -3.2427e-01, -3.0437e-01,  2.8379e-01,  2.5517e-01,
         -2.1679e-01, -1.1055e-02,  1.2680e-01],
        [ 2.4087e-01,  3.4183e-01,  2.6169e-01,  2.8653e-01, -2.2471e-01,
         -1.1238e-01,  2.0386e-01, -2.6686e-01],
        [-3.2790e-01,  1.9004e-01,  2.5431e-01,  1.2548e-01,  2.4227e-01,
          1.3015e-01,  6.1038e-02, -8.8250e-02],
        [ 5.3333e-02, -1.3765e-01,  2.8482e-01,  2.9984e-01, -1.1267e-01,
          1.6259e-01, -1.1808e-01,  2.8092e-01],
        [-3.4194e-01,  2.3218e-02, -5.6838e-02,  2.3789e-01,  2.9806e-02,
          1.2978e-01, -4.1724e-01, -2.2075e-01],
        [ 3.2363e-01, -9.6597e-02,  9.8975e-02, -2.9975e-01,  1.9075e-01,
         -1.2369e-01, -1.2600e-01,  2.7322e-01],
        [ 2.4183e-01, -2.9647e-01, -1.4987e-01,  2.2654e-01, -8.3256e-02,
          2.9066e-01,  1.3817e-01, -3.6281e-02],
        [-2.1849e-01,  2.4592e-02,  2.8153e-01,  2.6954e-01, -1.5156e-01,
         -1.0160e-01,  1.1250e-01, -2.8719e-01],
        [ 4.0098e-02,  9.3389e-02,  3.3429e-01, -5.2883e-02,  3.4969e-01,
          3.6739e-01, -2.0297e-01,  4.4609e-02],
        [ 1.9742e-01, -1.4122e-02, -1.8479e-01,  8.7588e-02,  1.4479e-01,
         -2.8261e-01, -2.9280e-01, -2.8035e-01],
        [-3.0300e-01,  2.9485e-01, -1.3300e-01,  1.9787e-02, -1.5362e-01,
         -1.7816e-01,  2.9802e-01, -1.3775e-01],
        [ 1.9572e-01, -1.6670e-01,  3.6737e-01,  1.2379e-01, -9.6088e-02,
          7.1245e-03,  1.6440e-01, -2.1074e-01],
        [-1.0982e-01, -2.4545e-01, -2.3463e-01,  1.7780e-01, -4.3139e-02,
         -1.5075e-01,  3.0196e-03,  2.1548e-01],
        [ 3.3071e-01, -1.7061e-01,  1.7382e-01,  4.1902e-02, -1.9403e-01,
          6.9350e-02,  5.1089e-02,  2.2813e-01],
        [ 2.9106e-01,  1.8969e-01,  6.3812e-02, -2.6462e-01, -3.0146e-01,
          1.8066e-01, -2.3628e-01,  1.0163e-02],
        [ 2.7916e-01,  1.9766e-01, -4.5697e-02,  5.7302e-02,  5.3229e-03,
          3.0043e-02,  2.9259e-01, -2.2104e-01],
        [ 3.0902e-01, -1.6238e-02,  3.4602e-01, -1.4361e-01,  2.0966e-01,
         -2.0565e-01, -2.6849e-01,  2.3117e-01],
        [ 1.3798e-01,  3.5057e-01,  1.2590e-01, -1.6234e-01, -1.9851e-01,
          2.8984e-01, -9.0374e-02, -2.2663e-01],
        [-2.5267e-01, -2.2718e-01, -1.5716e-01, -2.9109e-01,  3.4520e-01,
          5.1543e-02,  1.0560e-01, -1.7706e-01],
        [ 5.6766e-02,  2.2979e-01, -1.3862e-01,  2.6391e-01, -9.0279e-02,
         -1.5390e-01, -2.6609e-01, -3.9251e-01],
        [ 1.1832e-01, -2.1359e-01, -1.6255e-01, -1.1486e-01, -2.8841e-01,
         -2.6154e-01, -2.1523e-01,  3.7921e-01],
        [ 6.2576e-02, -1.5799e-01, -4.8933e-02,  2.7327e-01, -1.8577e-01,
          1.3041e-01, -7.2506e-02, -3.3165e-01],
        [ 2.5021e-01,  1.5901e-01,  2.6295e-01,  1.5306e-01,  6.3146e-02,
          9.3341e-02, -2.3693e-01,  3.6173e-01],
        [-2.8113e-01,  3.5044e-01, -1.6498e-01, -2.0137e-01,  8.6249e-02,
          2.7365e-01, -4.5413e-02,  1.7023e-01],
        [-2.8446e-01, -2.9468e-02,  3.1888e-01,  3.1747e-01, -1.0262e-01,
          1.2767e-01,  3.3626e-01,  1.4496e-01],
        [ 5.1128e-02, -3.0040e-01,  5.7380e-02,  6.5600e-02, -1.9242e-01,
          2.3052e-01, -2.9184e-01,  3.0941e-01],
        [-9.6050e-02,  2.5074e-01, -4.2317e-03, -8.7477e-02,  1.7597e-01,
          2.0829e-01,  4.1284e-01,  1.7628e-01],
        [-1.7095e-01, -1.7330e-01, -3.0521e-01,  4.6832e-02,  3.1317e-01,
         -1.2401e-01, -3.7145e-02,  2.9980e-01],
        [ 3.1626e-01,  1.0688e-01,  3.4228e-02,  3.6030e-01,  2.7798e-01,
         -2.3330e-01, -2.1153e-01, -7.2282e-02],
        [ 1.5608e-01, -2.0270e-01, -1.3815e-01,  1.8496e-02, -7.7549e-02,
          2.0403e-01,  2.5762e-01,  2.9497e-01],
        [ 1.8040e-01, -1.6838e-01, -2.6863e-01, -2.2561e-01, -6.2460e-02,
          3.0092e-01, -1.1102e-01,  3.3616e-01],
        [ 2.4819e-01, -2.8026e-01,  2.0062e-01, -1.1872e-01, -3.7256e-01,
          1.3755e-01, -1.0836e-01, -2.5946e-01],
        [-2.4181e-01,  2.6329e-01, -1.0124e-01,  2.5894e-01, -1.1606e-01,
          3.5694e-01, -1.1246e-01,  3.4282e-01],
        [ 1.8448e-01, -2.3106e-01,  2.1025e-01,  1.3001e-01, -2.6807e-01,
         -3.7485e-01,  8.5404e-02,  2.0065e-01],
        [ 2.9861e-01, -1.1308e-01, -3.5605e-01,  1.3725e-01,  5.0398e-02,
          3.6902e-02,  1.8560e-01,  1.1722e-02],
        [ 3.4338e-01,  2.9287e-01,  1.3644e-01,  2.6314e-01,  1.2693e-01,
         -3.9621e-01,  3.5540e-01,  1.6310e-02],
        [-5.3662e-02,  2.1529e-01,  3.1820e-01, -2.4527e-01,  9.8527e-02,
         -1.7441e-01, -9.9548e-02,  5.6153e-02],
        [-1.7374e-01, -1.5090e-01,  1.8532e-01, -5.1416e-02,  9.3963e-02,
          3.7578e-01,  6.2443e-02,  9.0174e-02]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[-7.9757e-02,  2.0602e-02,  1.0716e-01,  2.3782e-01, -9.0722e-02,
          3.4243e-02, -4.9818e-02,  1.4430e-02],
        [ 1.2635e-02, -5.2158e-03, -3.5545e-02, -5.3437e-02,  1.9641e-02,
          2.5161e-03, -7.2277e-04, -5.5976e-03],
        [-2.2326e-03, -1.2925e-02, -6.0207e-02, -3.6631e-02,  1.3106e-02,
          3.1218e-02, -3.3733e-02, -1.8370e-02],
        [ 7.2962e-02,  1.8595e-02,  2.7226e-02, -1.4527e-01,  5.6226e-02,
         -9.6065e-02,  1.1084e-01,  3.3287e-02],
        [ 7.3868e-02,  7.6983e-03,  4.1410e-02, -1.1745e-01,  4.5574e-02,
         -9.8339e-02,  1.1729e-01,  2.7218e-02],
        [ 1.5531e-01, -3.2320e-02, -1.6856e-01, -4.4429e-01,  1.7205e-01,
         -8.8706e-02,  1.2172e-01, -1.5696e-02],
        [ 1.4357e-01, -1.7810e-01, -1.0990e+00, -1.1620e+00,  4.2411e-01,
          3.4388e-01, -3.3368e-01, -2.3613e-01],
        [ 8.5735e-02, -1.1462e-01, -8.0545e-01, -8.2059e-01,  3.0367e-01,
          2.7510e-01, -2.8202e-01, -1.7790e-01],
        [ 2.5129e-01,  2.0048e-02, -9.4743e-02, -6.2318e-01,  2.4744e-01,
         -2.3282e-01,  2.7534e-01,  4.1047e-02],
        [ 2.2621e-01, -2.7880e-02, -1.3702e-01, -5.6009e-01,  2.0942e-01,
         -1.8028e-01,  2.3697e-01,  1.6573e-02],
        [-8.4029e-02,  3.7947e-02,  2.2715e-01,  3.4318e-01, -1.2810e-01,
         -1.4593e-02,  1.5318e-03,  4.0818e-02],
        [ 1.7528e-02, -6.7157e-03, -3.8814e-02, -6.5061e-02,  2.4346e-02,
         -7.9539e-04,  4.0829e-03, -6.4010e-03],
        [ 1.4976e-02, -4.7655e-03, -3.3852e-02, -5.6771e-02,  2.1096e-02,
         -8.8240e-04,  2.8049e-03, -4.5335e-03],
        [-1.1701e-01,  1.0419e-02,  9.1795e-02,  3.1345e-01, -1.1939e-01,
          8.4410e-02, -1.0910e-01, -4.3117e-03],
        [ 5.2102e-02,  1.7108e-02,  6.1404e-02, -6.4595e-02,  2.5162e-02,
         -8.6231e-02,  9.8348e-02,  3.2475e-02],
        [-5.5296e-02, -1.1907e-02, -4.8218e-02,  8.3489e-02, -3.2582e-02,
          8.3243e-02, -9.9531e-02, -2.8825e-02],
        [-8.9920e-02, -5.5605e-03,  3.0848e-02,  2.1452e-01, -8.0099e-02,
          8.5491e-02, -1.0265e-01, -2.0421e-02],
        [ 1.2506e-02,  4.7956e-03,  1.1125e-02, -1.9929e-02,  7.5535e-03,
         -1.9792e-02,  2.1936e-02,  8.2555e-03],
        [ 4.7335e-02, -3.1634e-02, -2.8249e-01, -3.2365e-01,  1.1741e-01,
          7.9526e-02, -7.9358e-02, -5.3806e-02],
        [-3.4880e-02,  7.9949e-03,  6.7590e-02,  1.2586e-01, -4.6838e-02,
          7.7910e-03, -1.2742e-02,  6.8884e-03],
        [-5.0847e-02,  4.5243e-02,  2.4987e-01,  2.8780e-01, -1.0676e-01,
         -6.2013e-02,  5.8228e-02,  5.6684e-02],
        [ 1.5758e-03, -6.0065e-03, -2.6338e-02, -2.0827e-02,  7.5913e-03,
          1.1023e-02, -1.1384e-02, -7.7487e-03],
        [ 5.3205e-03, -1.0593e-02, -6.2648e-02, -5.6664e-02,  2.1268e-02,
          2.3200e-02, -2.5837e-02, -1.5872e-02],
        [-3.8603e-02,  2.0767e-02,  8.8631e-02,  1.3789e-01, -4.9753e-02,
         -4.6224e-04, -8.1781e-03,  1.6032e-02],
        [-3.8517e-02,  1.6513e-02,  1.1744e-01,  1.6936e-01, -6.6543e-02,
         -1.3004e-02,  1.1890e-02,  2.5206e-02],
        [ 1.2074e-02,  9.7209e-03,  4.6437e-02,  9.9393e-03, -1.9852e-03,
         -3.3537e-02,  3.7180e-02,  1.3993e-02],
        [ 6.2644e-02,  2.1958e-02,  5.8596e-02, -9.9962e-02,  3.8956e-02,
         -9.8874e-02,  1.1441e-01,  3.8617e-02],
        [-5.1908e-02,  2.2008e-02,  1.5536e-01,  2.2840e-01, -8.8427e-02,
         -1.5838e-02,  1.1439e-02,  3.0993e-02],
        [-3.6951e-02, -1.2093e-02, -6.3079e-02,  2.8422e-02, -1.1119e-02,
          6.8790e-02, -8.0845e-02, -2.5936e-02],
        [ 2.2787e-02, -1.3586e-02, -1.0789e-01, -1.3489e-01,  5.1623e-02,
          2.4810e-02, -2.4084e-02, -2.1888e-02],
        [ 3.5320e-02, -5.2935e-02, -3.4675e-01, -3.4170e-01,  1.1085e-01,
          1.1635e-01, -1.1091e-01, -5.9555e-02],
        [ 2.8462e-02,  6.8668e-03,  4.0106e-02, -2.7719e-02,  1.2928e-02,
         -4.9454e-02,  5.6002e-02,  1.5012e-02],
        [-7.1354e-02,  3.1757e-02,  1.6535e-01,  2.6647e-01, -1.0060e-01,
         -1.1546e-03, -1.1934e-02,  3.1528e-02],
        [ 4.0888e-02,  1.3801e-02,  4.7787e-02, -5.6351e-02,  2.2860e-02,
         -6.7887e-02,  7.9387e-02,  2.5433e-02],
        [-1.8090e-02, -5.2944e-03,  4.2157e-02,  8.3275e-02, -3.1011e-02,
          4.3912e-03, -3.1869e-03, -1.8271e-03],
        [ 5.4410e-02, -6.1449e-03, -6.2045e-02, -1.6548e-01,  6.1882e-02,
         -3.1852e-02,  4.3738e-02,  3.6464e-04],
        [-2.1091e-02,  1.3521e-02,  7.0511e-02,  9.4556e-02, -3.6332e-02,
         -1.0604e-02,  8.2398e-03,  1.5979e-02],
        [ 3.1034e-01,  7.5389e-02,  2.5831e-01, -4.7528e-01,  1.8295e-01,
         -4.6326e-01,  5.4549e-01,  1.6259e-01],
        [-1.3812e-02,  2.8899e-02,  1.8177e-01,  1.7151e-01, -6.4919e-02,
         -6.8572e-02,  7.1752e-02,  4.5090e-02],
        [-3.1559e-01, -4.9959e-02, -7.7226e-02,  6.2762e-01, -2.2857e-01,
          3.8999e-01, -4.7077e-01, -1.3388e-01],
        [-2.9752e-01, -5.3849e-02, -1.3096e-01,  5.5245e-01, -2.0204e-01,
          3.9516e-01, -4.7751e-01, -1.4218e-01],
        [-1.1451e-01, -5.2941e-02, -2.0907e-01,  9.9577e-02, -4.0932e-02,
          2.2577e-01, -2.5963e-01, -9.3471e-02],
        [ 4.0821e-02, -5.2556e-03, -4.3470e-02, -1.1859e-01,  4.4854e-02,
         -2.4379e-02,  3.2615e-02, -9.6749e-04],
        [-7.3235e-02,  3.9728e-02,  2.4954e-01,  3.4226e-01, -1.2757e-01,
         -3.5323e-02,  2.6347e-02,  4.6932e-02],
        [ 4.5933e-02, -4.7650e-02, -3.2190e-01, -3.5262e-01,  1.2594e-01,
          9.4638e-02, -9.0244e-02, -6.1355e-02],
        [ 1.4158e-02,  6.5401e-04,  5.9250e-03, -2.4248e-02,  1.0613e-02,
         -1.7712e-02,  2.0674e-02,  3.0124e-03],
        [ 1.8183e-02, -3.9563e-03, -2.0476e-02, -5.1383e-02,  2.0864e-02,
         -9.3407e-03,  1.2087e-02, -3.7009e-03],
        [-9.1474e-02,  3.3286e-02,  2.2003e-01,  3.5783e-01, -1.4004e-01,
         -3.5458e-03, -6.3691e-03,  4.2771e-02],
        [ 7.4896e-02,  4.3354e-02,  1.7024e-01, -4.1107e-02,  1.7387e-02,
         -1.6551e-01,  1.8531e-01,  7.3494e-02],
        [ 1.3989e-01, -3.0145e-02, -1.5158e-01, -3.9482e-01,  1.4947e-01,
         -7.9154e-02,  1.1046e-01, -1.2112e-02],
        [ 9.2607e-02,  3.8220e-02,  1.4492e-01, -9.8105e-02,  3.6566e-02,
         -1.7339e-01,  2.0060e-01,  7.3686e-02],
        [ 3.9566e-03, -9.0724e-03, -4.5871e-02, -4.1493e-02,  1.5318e-02,
          1.7239e-02, -1.7515e-02, -1.2176e-02],
        [-1.1527e-01,  4.5276e-02,  2.9771e-01,  4.6690e-01, -1.7469e-01,
         -1.2292e-02, -5.3160e-03,  4.9233e-02],
        [ 5.5952e-02,  1.8797e-02,  2.9133e-02, -1.0922e-01,  4.2441e-02,
         -7.8870e-02,  8.9268e-02,  3.0037e-02],
        [ 3.0823e-01,  4.0221e-02, -1.0425e-02, -6.9414e-01,  2.8197e-01,
         -3.3584e-01,  3.9523e-01,  7.4868e-02],
        [-9.5343e-02,  3.2999e-02,  1.9543e-01,  3.4053e-01, -1.3029e-01,
          1.1403e-02, -2.5754e-02,  3.4176e-02],
        [ 1.0569e-02,  2.2287e-04, -4.5014e-03, -2.5949e-02,  9.5639e-03,
         -9.6131e-03,  1.2024e-02,  2.2285e-03],
        [ 2.1892e-01, -1.1134e-02, -1.0244e-01, -5.3082e-01,  1.9736e-01,
         -1.9253e-01,  2.4513e-01,  3.2813e-02],
        [ 4.9376e-02, -4.4912e-02, -3.5482e-01, -3.8697e-01,  1.4482e-01,
          1.0992e-01, -1.1304e-01, -7.5203e-02],
        [-2.9416e-02,  2.3830e-02,  1.2330e-01,  1.5073e-01, -5.4742e-02,
         -2.5635e-02,  2.0590e-02,  2.5780e-02],
        [-2.2305e-01, -4.9182e-02, -1.2851e-01,  3.9714e-01, -1.4798e-01,
          3.1058e-01, -3.7189e-01, -1.1221e-01],
        [-3.5973e-02,  2.4920e-02,  2.2172e-01,  2.5717e-01, -1.0976e-01,
         -6.7372e-02,  7.6394e-02,  6.2928e-02],
        [ 5.0166e-02, -5.2533e-03, -4.4392e-02, -1.3740e-01,  5.1895e-02,
         -3.3914e-02,  4.4015e-02,  8.8059e-04],
        [-3.7850e-01, -8.8602e-02, -1.8047e-01,  7.1032e-01, -2.6801e-01,
          5.1169e-01, -6.0523e-01, -1.8198e-01],
        [ 1.5251e-02, -6.1811e-03, -3.7700e-02, -5.9884e-02,  2.2011e-02,
          8.4758e-04,  1.8923e-03, -5.7868e-03],
        [-2.7249e-03, -8.1207e-03, -3.9057e-02, -2.2859e-02,  8.3590e-03,
          2.1299e-02, -2.2893e-02, -1.1983e-02],
        [ 7.6814e-02, -7.5227e-02, -5.5497e-01, -6.0836e-01,  2.3308e-01,
          1.7269e-01, -1.7617e-01, -1.2539e-01],
        [ 4.3549e-02,  4.8767e-03,  7.4803e-02, -2.1365e-02,  9.9230e-03,
         -7.8113e-02,  9.3659e-02,  2.2834e-02],
        [-1.3531e-01,  3.6505e-02,  1.7324e-01,  3.9901e-01, -1.4757e-01,
          6.3498e-02, -9.6713e-02,  1.6082e-02],
        [ 1.0945e-02, -7.2979e-03, -4.9104e-02, -6.1231e-02,  2.2815e-02,
          1.0501e-02, -9.6413e-03, -9.7081e-03],
        [ 3.9733e-02, -7.7141e-03, -6.5311e-02, -1.3462e-01,  5.0523e-02,
         -1.3658e-02,  2.0583e-02, -5.7946e-03],
        [-4.8263e-02,  1.6500e-02,  1.4203e-01,  2.1551e-01, -8.7442e-02,
         -1.4269e-02,  1.2834e-02,  3.1579e-02],
        [-5.2100e-02, -2.0552e-02, -5.3014e-02,  8.1385e-02, -3.1929e-02,
          8.4593e-02, -9.6885e-02, -3.4264e-02],
        [-1.9207e-02, -3.6553e-02, -1.0709e-01, -1.7947e-02,  4.2349e-03,
          7.5845e-02, -7.9401e-02, -4.4121e-02],
        [-1.6443e-01,  6.4010e-02,  3.4559e-01,  5.9042e-01, -2.1444e-01,
          1.7418e-02, -5.3107e-02,  4.7999e-02],
        [-1.7154e-01, -4.9884e-02, -1.1368e-01,  3.0441e-01, -1.1555e-01,
          2.4854e-01, -2.9087e-01, -9.4252e-02],
        [-1.3916e-01,  3.2656e-02,  2.3377e-01,  4.6457e-01, -1.7303e-01,
          4.3331e-02, -6.7438e-02,  2.4648e-02],
        [-1.7583e-01,  4.6328e-03,  1.6955e-01,  5.2099e-01, -1.9556e-01,
          1.1954e-01, -1.5491e-01, -1.4828e-02],
        [ 8.9170e-02, -3.7347e-02, -1.5448e-01, -2.7970e-01,  1.0685e-01,
         -1.8241e-02,  3.6097e-02, -3.2647e-02],
        [-1.6818e-01,  3.7981e-02,  3.8492e-01,  6.5795e-01, -2.5900e-01,
          3.8777e-03, -1.4003e-02,  6.7231e-02],
        [ 6.1112e-04,  6.7076e-02,  3.1439e-01,  2.1808e-01, -8.1146e-02,
         -1.5150e-01,  1.6129e-01,  9.5806e-02],
        [-2.5794e-02, -1.5997e-02, -9.0044e-02, -1.6369e-02,  4.4697e-03,
          6.9388e-02, -7.7706e-02, -2.8727e-02],
        [-3.6600e-02,  3.7085e-02,  1.7888e-01,  2.0283e-01, -7.3853e-02,
         -4.5209e-02,  3.8866e-02,  4.1708e-02],
        [-7.6004e-02,  2.2719e-02,  1.0771e-01,  2.2825e-01, -8.7946e-02,
          2.8971e-02, -4.3249e-02,  1.8825e-02],
        [ 3.1420e-02, -2.7160e-03, -3.1560e-02, -9.1077e-02,  3.3809e-02,
         -2.0278e-02,  2.6735e-02,  1.3813e-03],
        [-3.7608e-02,  1.0944e-02,  8.3450e-02,  1.4169e-01, -5.5060e-02,
          1.8157e-03, -5.3279e-03,  1.4861e-02],
        [-3.4952e-02, -3.8637e-03, -2.3370e-02,  5.5901e-02, -1.9678e-02,
          4.8877e-02, -6.1944e-02, -1.6943e-02],
        [ 3.3214e-02, -3.5403e-02, -2.5212e-01, -2.6630e-01,  8.9603e-02,
          7.7276e-02, -7.3084e-02, -4.2567e-02],
        [ 4.6701e-02,  2.1153e-03, -6.0027e-03, -1.0390e-01,  3.7942e-02,
         -4.8929e-02,  6.1326e-02,  1.3197e-02],
        [ 3.5604e-02,  4.4899e-03,  9.6625e-03, -6.8365e-02,  2.5820e-02,
         -4.3788e-02,  5.2551e-02,  1.3088e-02],
        [-5.0087e-01, -8.6138e-02, -1.2748e-01,  1.0162e+00, -3.9979e-01,
          6.1907e-01, -7.3232e-01, -1.7949e-01],
        [ 5.0343e-02,  4.5263e-02,  1.6681e-01,  3.3256e-03,  8.9314e-03,
         -1.3257e-01,  1.4274e-01,  5.4374e-02],
        [-1.5986e-01,  3.2220e-02,  2.2251e-01,  4.9815e-01, -1.8542e-01,
          7.1044e-02, -1.0241e-01,  1.6613e-02],
        [-8.0755e-02,  2.5259e-02,  1.4465e-01,  2.7567e-01, -1.0059e-01,
          2.0092e-02, -3.9857e-02,  1.6108e-02],
        [ 2.9488e-02, -1.6075e-03, -2.8180e-02, -8.5287e-02,  3.1662e-02,
         -1.9855e-02,  2.5891e-02,  2.1089e-03],
        [-1.7331e-01, -6.1898e-02, -1.4963e-01,  2.8835e-01, -1.1181e-01,
          2.6886e-01, -3.0966e-01, -1.0612e-01],
        [ 8.3070e-03,  6.5934e-03,  3.8127e-02,  1.2051e-02, -4.0852e-03,
         -2.6492e-02,  2.9918e-02,  1.2026e-02],
        [-8.0941e-02, -5.1134e-02, -1.4477e-01,  9.0972e-02, -3.7268e-02,
          1.6367e-01, -1.8236e-01, -7.5634e-02],
        [ 4.1239e-02,  3.4147e-04, -3.1278e-02, -1.1212e-01,  4.4975e-02,
         -3.0240e-02,  3.5537e-02,  4.6950e-04],
        [-4.3737e-02, -1.0852e-02, -9.0968e-02,  1.3950e-02, -7.3225e-03,
          8.7092e-02, -1.0233e-01, -2.9695e-02]], device='cuda:0') 

model.module_1.bias 100 torch.Size([100])
Parameter containing:
tensor([ 0.3328, -0.1495, -0.0137, -0.3532, -0.1805, -0.0475,  0.3325,  0.2119,
        -0.1243, -0.0950,  0.0906, -0.1594, -0.0650,  0.1167, -0.1705,  0.2491,
         0.1479, -0.0366, -0.0759,  0.0298,  0.1856,  0.0871, -0.1138,  0.1495,
        -0.0073, -0.2551, -0.2369,  0.0102,  0.3932, -0.2005,  0.2230, -0.2203,
         0.2153, -0.1588, -0.1363,  0.0874,  0.2006, -0.2749, -0.0352,  0.0795,
         0.1074,  0.3316, -0.3245,  0.3105,  0.1690, -0.3741, -0.2201,  0.1639,
        -0.2922,  0.3042, -0.1773,  0.1514,  0.0801, -0.1486, -0.3321,  0.0480,
        -0.3035, -0.1218,  0.0450, -0.1008,  0.2433, -0.3178, -0.3555,  0.2287,
        -0.1922,  0.2880, -0.0399, -0.0536,  0.3621, -0.0393, -0.3003, -0.1468,
         0.0769,  0.2084,  0.3126, -0.1099,  0.0665,  0.2623, -0.1514,  0.0519,
        -0.1563,  0.1141,  0.3209,  0.3854, -0.2434,  0.1428,  0.3545, -0.0098,
         0.0276, -0.3881,  0.2324, -0.0617,  0.3315,  0.2139, -0.2080, -0.1102,
        -0.2757, -0.2930, -0.3239,  0.1676], device='cuda:0',
       requires_grad=True) 
grad:  tensor([-2.0048e-01,  4.7600e-02,  4.5277e-02,  8.3188e-02,  7.1750e-02,
         3.6656e-01,  1.1388e+00,  7.9210e-01,  4.3110e-01,  4.4581e-01,
        -3.0805e-01,  5.7585e-02,  4.9039e-02, -2.4465e-01,  2.2846e-02,
        -4.3654e-02, -1.5176e-01,  8.5134e-03,  2.9556e-01, -1.0604e-01,
        -2.7814e-01,  2.3710e-02,  5.7441e-02, -1.2914e-01, -1.4823e-01,
        -2.3253e-02,  4.4341e-02, -2.0071e-01, -1.4062e-03,  1.2078e-01,
         3.4593e-01,  8.0955e-03, -2.3991e-01,  2.1849e-02, -5.9204e-02,
         1.3252e-01, -8.7604e-02,  2.4189e-01, -1.7082e-01, -4.0252e-01,
        -3.3832e-01,  2.3797e-03,  9.5122e-02, -3.1198e-01,  3.3973e-01,
         1.5419e-02,  4.2012e-02, -3.0866e-01, -3.1360e-02,  3.2949e-01,
         2.0070e-02,  4.3782e-02, -4.1238e-01,  5.7059e-02,  4.5264e-01,
        -2.9601e-01,  1.9098e-02,  4.0536e-01,  3.5955e-01, -1.4529e-01,
        -2.2874e-01, -2.2435e-01,  1.0844e-01, -4.1045e-01,  5.3430e-02,
         2.8783e-02,  5.6764e-01,  9.1833e-04, -3.4283e-01,  5.6651e-02,
         1.1155e-01, -1.8267e-01, -3.2842e-02,  6.0864e-02, -5.2784e-01,
        -1.5993e-01, -3.9160e-01, -3.9999e-01,  2.5311e-01, -5.4615e-01,
        -2.5504e-01,  3.7799e-02, -2.0297e-01, -1.9577e-01,  7.1969e-02,
        -1.2022e-01, -3.5561e-02,  2.5826e-01,  7.4694e-02,  4.3950e-02,
        -6.3362e-01, -6.9475e-02, -4.1439e-01, -2.4147e-01,  6.6348e-02,
        -1.3139e-01, -1.9402e-02,  2.7666e-04,  8.2148e-02,  1.2039e-02],
       device='cuda:0') 

model.module_3.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[ 0.0760, -0.0588,  0.0821,  ..., -0.0800,  0.0114, -0.0060],
        [ 0.0052, -0.0849, -0.0371,  ..., -0.0757, -0.1199,  0.0808],
        [ 0.0997,  0.0026, -0.0495,  ..., -0.0157, -0.0751,  0.0476],
        ...,
        [-0.0218, -0.0114, -0.0478,  ..., -0.0855, -0.0004,  0.0204],
        [ 0.0615,  0.0372,  0.0191,  ...,  0.0333,  0.0459,  0.1070],
        [ 0.0213, -0.0371,  0.0976,  ...,  0.0193, -0.0548,  0.0977]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-0.0267,  0.0078,  0.0068,  ...,  0.0061,  0.0031, -0.0051],
        [-0.0688,  0.0222,  0.0150,  ..., -0.0153, -0.0070, -0.0158],
        [-0.1149,  0.0335,  0.0238,  ..., -0.0219, -0.0166, -0.0270],
        ...,
        [ 0.0012, -0.0013, -0.0005,  ...,  0.0021,  0.0012,  0.0002],
        [ 0.1504, -0.0212, -0.0268,  ..., -0.0179, -0.0064,  0.0407],
        [-0.0681,  0.0595,  0.0163,  ..., -0.1567, -0.0782, -0.0118]],
       device='cuda:0') 

model.module_3.bias 100 torch.Size([100])
Parameter containing:
tensor([ 0.1350, -0.0160,  0.0943,  0.0521,  0.0483,  0.0247,  0.1190, -0.0315,
         0.0344,  0.0023,  0.0145, -0.0237, -0.0788,  0.0804, -0.1086, -0.0491,
         0.1323, -0.0413, -0.0428, -0.0629, -0.0099, -0.0509,  0.0073,  0.1149,
        -0.0047,  0.0030,  0.0870,  0.0664, -0.0379, -0.0533, -0.0248,  0.0896,
        -0.0280, -0.0295,  0.0494, -0.0720,  0.0599,  0.0297, -0.0168,  0.0232,
         0.0315,  0.0227,  0.0998,  0.1394,  0.0437, -0.0201,  0.0179, -0.0761,
         0.0552, -0.0148, -0.0813, -0.0771, -0.0573, -0.0340,  0.0082,  0.0967,
        -0.0490, -0.0607, -0.0156,  0.0201,  0.0585,  0.0358, -0.0466,  0.0496,
        -0.1255, -0.0864,  0.0410,  0.1286,  0.0537, -0.0166, -0.0813,  0.1297,
        -0.0889,  0.1387, -0.0938, -0.1070,  0.0082,  0.0445, -0.1145, -0.0400,
         0.0320, -0.0210, -0.0146,  0.0848, -0.0512,  0.0673,  0.0383, -0.0224,
         0.0565, -0.0996, -0.0613,  0.0702, -0.0077,  0.0528, -0.0982,  0.0448,
        -0.0817,  0.0277,  0.0900,  0.0708], device='cuda:0',
       requires_grad=True) 
grad:  tensor([-0.0727, -0.1965, -0.2940, -0.1598, -0.2525, -0.4586, -0.6216,  0.0434,
        -0.3229,  0.1641,  0.4476, -0.0979,  0.0332,  0.1278,  0.0168, -0.2153,
        -0.3833,  0.0182,  0.1359, -0.3457, -0.3530,  0.0853,  0.0226, -0.0101,
         0.0404, -0.0912,  0.4038, -0.6511, -0.4631, -0.0364,  0.0489, -0.0101,
         0.0351, -0.3180, -0.0235, -0.3829,  0.0472, -0.3715, -0.0050, -0.0022,
        -0.0626, -0.4958, -0.2434, -0.1119,  0.0259,  0.2485, -0.0036,  0.0874,
         0.0192, -0.1909, -0.2423,  0.0069,  0.1825, -0.0124,  0.0414, -0.3172,
        -0.0769,  0.1055,  0.0735,  0.0262,  0.2836,  0.1326,  0.1705,  0.2027,
         0.0066,  0.3516,  0.0753, -0.6465, -0.4373,  0.1097,  0.0492, -0.3405,
         0.0548, -0.2184,  0.1231,  0.0469,  0.1469, -0.4100,  0.0826, -0.0703,
        -0.1834,  0.0519, -0.2367,  0.2976, -0.4268, -0.1851, -0.1014, -0.3854,
         0.0355, -0.0202, -0.1211, -0.5410, -0.4788,  0.1323,  0.0894, -0.3479,
        -0.1268,  0.0090,  0.2718, -0.3766], device='cuda:0') 

model.module_5.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[-0.0063,  0.0631,  0.0758,  ...,  0.0831, -0.1770,  0.0590],
        [-0.0089, -0.0594,  0.0349,  ...,  0.0404,  0.0448,  0.0193],
        [ 0.1343,  0.0333, -0.0734,  ...,  0.0105,  0.2551,  0.0880],
        ...,
        [ 0.0388,  0.0947,  0.0276,  ...,  0.0500,  0.0318,  0.1190],
        [-0.0253,  0.0941,  0.0905,  ..., -0.0022, -0.1402,  0.0359],
        [-0.0338, -0.0653,  0.0108,  ..., -0.0113, -0.0206,  0.0543]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-3.6771e-02, -3.2429e-02, -1.5857e-01,  ...,  5.1617e-03,
          2.4791e-03, -3.1346e-02],
        [-1.2884e-01, -1.0757e-01, -5.3990e-01,  ...,  1.4986e-02,
         -3.4739e-04, -1.0614e-01],
        [ 1.7865e-01,  1.2693e-01,  5.2898e-01,  ..., -1.9055e-02,
          3.5289e-02,  1.2465e-01],
        ...,
        [ 2.5986e-02,  1.0514e-02, -1.9481e-01,  ...,  5.2367e-03,
          3.7359e-02, -3.7887e-02],
        [-6.4251e-02, -6.7555e-02, -6.4421e-01,  ...,  1.7210e-02,
          4.6583e-02, -1.2454e-01],
        [-9.9317e-02, -1.0089e-01, -7.9502e-01,  ...,  2.3031e-02,
          4.5664e-02, -1.6996e-01]], device='cuda:0') 

model.module_5.bias 16 torch.Size([16])
Parameter containing:
tensor([ 0.0297,  0.0341,  0.0213, -0.0179, -0.0506, -0.1021,  0.1051,  0.0449,
         0.0994,  0.1091,  0.0031, -0.0693,  0.1144, -0.0837,  0.0205,  0.0572],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-0.2664, -0.9529,  0.9280, -1.1962, -1.4488, -0.3796, -0.1174,  0.8125,
        -1.7282, -0.6906,  0.6127, -0.1356, -0.9627, -0.2564, -1.0244, -1.3051],
       device='cuda:0') 

model.module_7.bias 8 torch.Size([8])
Parameter containing:
tensor([-0.0123,  0.0157,  0.0328, -0.0095,  0.0159, -0.0151,  0.0279,  0.0336],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-1.5242, -0.5274, -0.7606,  0.0882,  1.9083, -1.7250,  0.4168,  1.3004],
       device='cuda:0') 

model.module_7.lin.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[ 0.1637,  0.1342, -0.0825,  0.3195,  0.3938,  0.5429, -0.4241,  0.2342,
          0.4078, -0.2617, -0.4951,  0.2685,  0.0541,  0.4462,  0.2091,  0.3808],
        [-0.3816, -0.1300, -0.6135,  0.1033,  0.3457, -0.3645,  0.3530, -0.4910,
          0.3788, -0.4027, -0.4748, -0.2688,  0.1652, -0.4652,  0.2477, -0.4418],
        [-0.0098, -0.1513, -0.2074, -0.3112,  0.4915,  0.4865, -0.4869, -0.0894,
         -0.3709, -0.4179, -0.2321,  0.3135, -0.4540,  0.4994,  0.4437,  0.2281],
        [ 0.3625,  0.0849,  0.2815,  0.2695, -0.4355,  0.1391, -0.0262, -0.4833,
          0.3824, -0.1571,  0.0828, -0.2360,  0.3123,  0.0445, -0.1894, -0.2204],
        [ 0.1154, -0.4492,  0.2865, -0.4316, -0.3232,  0.0375, -0.2916,  0.1816,
         -0.3420, -0.1792,  0.2413,  0.2706, -0.1338,  0.1624, -0.4035, -0.1113],
        [ 0.3082, -0.0422, -0.5380, -0.0400, -0.0758,  0.1955, -0.1088, -0.3513,
          0.1020,  0.3732, -0.1664,  0.1571,  0.0794,  0.1419, -0.0889, -0.0137],
        [-0.4941,  0.3047, -0.2760, -0.3836, -0.2946,  0.1185, -0.1113, -0.2800,
          0.2732, -0.2544, -0.3461,  0.2471, -0.2163, -0.3305, -0.1546, -0.2382],
        [ 0.0071, -0.2210,  0.0670, -0.0357,  0.3429,  0.2954, -0.2610,  0.2240,
         -0.4583, -0.4085, -0.3086, -0.2164, -0.4908,  0.3113,  0.4148, -0.3917]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-3.6103e-02, -4.5076e-01, -4.8506e-03, -3.8446e-01, -6.3605e-01,
         -5.5749e-02, -6.8498e-01, -3.3756e-01, -5.0972e-01, -5.1808e-01,
          2.4215e-02,  7.4521e-02, -5.3921e-01, -2.7835e-01, -9.6980e-01,
         -3.0701e-01],
        [-1.7576e-02, -2.1368e-01, -1.8107e-02, -1.8158e-01, -2.4474e-01,
         -3.5993e-03, -3.2348e-01, -1.0111e-01, -2.3630e-01, -2.4800e-01,
         -7.4470e-03,  3.3464e-02, -2.5591e-01, -7.6749e-02, -3.5780e-01,
         -1.3642e-01],
        [-1.3490e-02, -1.8113e-01,  7.7141e-03, -1.5743e-01, -3.0140e-01,
         -4.4252e-02, -2.8053e-01, -1.7863e-01, -2.0597e-01, -2.1029e-01,
          2.3032e-02,  3.0012e-02, -2.2134e-01, -1.6207e-01, -4.7212e-01,
         -1.3599e-01],
        [ 8.9948e-04,  2.6677e-03, -5.9485e-03,  3.7448e-03,  2.8092e-02,
          8.2893e-03,  5.9115e-03,  3.0541e-02,  6.5660e-03,  3.0790e-03,
         -7.4103e-03, -2.4906e-03,  3.0939e-03,  2.2736e-02,  4.9843e-02,
          3.8300e-03],
        [ 6.1327e-02,  7.1704e-01,  4.6119e-02,  6.0766e-01,  8.5642e-01,
          2.1213e-02,  1.0812e+00,  3.8249e-01,  8.0333e-01,  8.2595e-01,
          1.0639e-02, -1.1559e-01,  8.5231e-01,  2.8317e-01,  1.2629e+00,
          4.5567e-01],
        [-4.3747e-02, -5.5068e-01, -1.7458e-02, -4.6832e-01, -7.3548e-01,
         -5.3608e-02, -8.3522e-01, -3.6600e-01, -6.1727e-01, -6.3412e-01,
          1.5966e-02,  8.8303e-02, -6.5924e-01, -3.0282e-01, -1.1100e+00,
         -3.7047e-01],
        [ 1.3051e-02,  1.1097e-01, -3.5455e-03,  9.6795e-02,  1.6662e-01,
          1.1032e-02,  1.6903e-01,  1.0358e-01,  1.3481e-01,  1.2709e-01,
         -9.4320e-03, -2.2347e-02,  1.2995e-01,  6.7630e-02,  2.5647e-01,
          6.9174e-02],
        [ 3.8028e-02,  4.7030e-01,  2.6433e-02,  3.9692e-01,  5.7538e-01,
          2.1778e-02,  7.0796e-01,  2.6099e-01,  5.2472e-01,  5.3992e-01,
          1.7940e-03, -7.4735e-02,  5.5898e-01,  2.0269e-01,  8.5288e-01,
          3.0378e-01]], device='cuda:0') 

model.module_8.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[-3.1939e-01, -7.0124e-02,  2.6218e-01,  9.8424e-02, -2.9351e-04,
          3.3477e-01,  2.7496e-01,  1.4622e-01],
        [-2.0673e-01, -1.0515e-01, -7.4715e-02, -4.2110e-02,  9.0537e-02,
          2.3221e-01, -1.9000e-01, -3.8583e-01],
        [-3.1825e-01,  8.7323e-02, -2.3753e-01,  1.6923e-01,  1.1589e-01,
          5.9594e-02, -1.3549e-01,  1.6794e-01],
        [ 2.4779e-01,  1.1058e-01,  3.9813e-02,  1.7337e-01,  3.9793e-02,
          1.9040e-01,  1.4874e-01,  3.4370e-01],
        [-8.0024e-02,  1.4053e-01,  2.9191e-01, -2.8806e-01,  2.0565e-02,
         -3.2099e-01, -2.5109e-01,  2.7737e-01],
        [-2.6613e-01,  3.3186e-01,  3.0757e-01, -2.2983e-01, -3.2245e-01,
         -1.4170e-02, -3.2378e-01,  1.9629e-01],
        [-1.0585e-01,  8.9111e-02, -1.5925e-02, -4.0591e-02, -2.0307e-01,
          7.9686e-02,  1.2664e-01, -1.6143e-02],
        [-1.7884e-02, -1.3814e-01, -1.5636e-01,  7.2192e-02,  1.4878e-01,
         -2.2123e-01, -1.6017e-01,  2.9389e-01],
        [ 2.5169e-01, -3.3572e-01, -1.8958e-01, -6.9380e-03, -1.6108e-01,
          1.2985e-01, -1.4286e-01, -3.4325e-01],
        [-2.6405e-01,  2.1698e-01,  6.3471e-02,  3.2316e-01,  3.0447e-01,
         -7.6943e-02,  2.0447e-01, -6.2744e-02],
        [ 1.7523e-01, -2.8764e-01, -1.1221e-01, -1.8624e-02,  6.5841e-02,
          4.5453e-02,  3.1479e-01,  3.0168e-01],
        [-2.4648e-01, -4.6009e-02, -3.5965e-02,  1.3305e-01, -2.4552e-01,
          1.4413e-01,  1.0509e-01,  1.4311e-01],
        [-9.0313e-02,  6.0085e-02,  1.8219e-01,  3.1978e-01, -1.1439e-01,
          1.9349e-01, -1.2985e-01,  1.2764e-01],
        [-1.0206e-01,  5.8027e-02, -2.7724e-01,  1.1158e-01, -2.6100e-01,
         -1.6568e-01, -1.4594e-01, -1.3750e-01],
        [ 3.0006e-01,  2.9960e-01,  1.8187e-01, -1.8000e-01,  2.2932e-01,
          3.4624e-01, -7.1778e-02, -2.5110e-01],
        [ 2.6841e-01,  3.0534e-01,  1.1307e-01, -3.1990e-01, -2.2096e-01,
          3.0318e-01, -2.9659e-01,  1.6671e-01],
        [ 2.1893e-01, -1.1587e-01, -3.1134e-01, -3.3374e-01,  2.8489e-01,
          1.1401e-01,  1.5948e-01, -2.0205e-01],
        [-1.4678e-01,  1.8946e-01, -2.5789e-01,  1.8864e-01, -7.0372e-03,
          1.9907e-01, -1.9608e-01, -1.7985e-01],
        [-2.6908e-01,  1.8474e-01, -6.2781e-02, -1.2719e-01, -3.3367e-01,
          3.1693e-01,  3.3729e-01, -2.1003e-01],
        [-3.2826e-02, -9.7941e-02, -2.7084e-01, -2.3967e-01, -6.5295e-02,
          1.6478e-01, -2.6043e-01,  2.6429e-01],
        [ 1.5126e-02, -2.4272e-01, -1.7464e-01,  3.0583e-01, -8.7664e-02,
          1.8409e-01, -7.9316e-03,  3.0877e-01],
        [-2.6749e-01,  1.2709e-01,  1.2225e-01, -1.0484e-01, -2.0785e-01,
         -2.3998e-02, -1.6973e-02, -2.7986e-01],
        [-2.3128e-01,  1.8474e-01,  4.1588e-02, -2.5761e-01, -1.5443e-01,
         -8.0183e-02,  1.0910e-01,  1.3102e-01],
        [ 2.7471e-01, -3.3646e-03,  1.2998e-01, -2.4844e-01,  1.9604e-01,
         -1.4839e-01,  3.1085e-01,  1.4876e-01],
        [-9.9605e-03, -1.1744e-01,  1.8441e-01,  1.3864e-01,  8.5443e-02,
          5.7344e-02, -2.9322e-01, -1.6872e-01],
        [-3.6075e-01, -1.2066e-01, -1.7215e-01, -7.1621e-02,  2.6242e-01,
          3.2384e-02,  1.5751e-01,  1.4279e-01],
        [ 3.0419e-01,  2.9203e-01,  6.5149e-02,  3.1367e-01, -3.2892e-01,
          2.6934e-01,  2.2945e-01, -3.4790e-01],
        [-2.8478e-01, -5.8715e-02,  1.3329e-01,  3.1619e-01, -3.2202e-01,
          3.6997e-01, -2.5779e-02, -7.7912e-02],
        [-8.1442e-02,  2.4089e-01,  1.5302e-01,  3.9990e-02, -3.0742e-01,
          2.5321e-02, -2.8992e-01, -3.5505e-01],
        [ 8.0140e-02, -1.0589e-01, -3.2692e-01, -2.6199e-01,  3.6619e-01,
          3.7643e-01, -2.0958e-01, -1.4734e-01],
        [ 2.2379e-01, -9.1665e-02,  7.1779e-04, -1.0571e-01,  1.7376e-01,
         -2.7902e-01, -3.2425e-01,  1.9207e-01],
        [ 1.1956e-01,  1.5917e-01, -8.8536e-02, -1.2070e-01, -1.2973e-01,
         -1.6245e-01, -2.6213e-01,  1.9289e-01],
        [-1.8317e-01, -3.3857e-01,  4.0456e-02,  3.0328e-01,  7.6095e-03,
         -2.8534e-01,  2.2420e-01, -2.4085e-01],
        [ 2.1228e-01, -2.6598e-01,  3.2890e-01, -8.3909e-02,  3.5297e-01,
          1.6516e-01,  2.8851e-01,  4.9905e-02],
        [-2.1292e-01,  3.4850e-02,  2.8983e-01, -3.0147e-01,  1.0342e-01,
          3.2149e-02,  2.4308e-01, -2.4142e-01],
        [-3.0826e-01,  7.1907e-02, -1.1147e-01, -1.0626e-01,  1.1138e-01,
          2.2462e-01, -2.3837e-01, -2.3321e-02],
        [-1.4293e-01, -2.6742e-02, -1.1447e-01,  3.0228e-01,  2.0516e-01,
          2.4856e-02, -8.9459e-02,  2.4807e-01],
        [-2.0892e-01, -3.2929e-01, -2.3314e-01, -9.5817e-02, -2.3983e-01,
          2.3156e-01, -1.5949e-02, -1.4687e-01],
        [-2.4468e-01,  3.4438e-01,  3.1781e-01, -2.3881e-01,  2.8656e-01,
         -8.8044e-02, -1.3119e-01,  9.4839e-02],
        [-2.5600e-01, -3.0356e-01, -3.2381e-02,  2.2324e-01,  2.4364e-01,
          2.7920e-01,  1.6548e-01,  6.0693e-02],
        [ 5.9261e-02, -2.0581e-01,  2.8200e-01,  3.0442e-01, -3.1517e-01,
         -2.7769e-01, -8.9196e-02, -2.3460e-01],
        [-1.0460e-01,  3.1580e-01, -8.5400e-02,  3.2484e-01, -3.2581e-02,
          8.1627e-02, -8.4657e-03, -1.2860e-01],
        [-5.5841e-02, -1.7226e-01, -2.5057e-01,  1.6898e-02,  7.7074e-02,
          6.8010e-02,  8.1572e-02, -1.3729e-01],
        [-2.9891e-01,  1.9102e-01,  1.2282e-01, -3.9293e-01,  3.0720e-01,
         -1.3320e-01, -3.2345e-01, -1.3610e-01],
        [-8.6547e-02, -2.7745e-01,  2.5085e-02, -1.6757e-01, -1.9009e-01,
          3.0804e-01, -1.1662e-01, -7.7878e-02],
        [-1.7287e-01, -1.9509e-02, -2.3031e-01, -2.0152e-01, -2.4998e-01,
         -1.0643e-01,  6.8436e-02,  2.0498e-01],
        [ 2.1090e-01, -1.2486e-01, -2.6491e-01, -5.4864e-02,  2.7921e-01,
         -9.3166e-03,  3.1193e-01,  2.8539e-01],
        [ 2.5666e-01, -2.4251e-02,  8.9868e-02, -2.4643e-01,  5.1545e-02,
          1.9707e-01, -2.2448e-01, -2.0049e-01],
        [-1.5844e-01,  8.0878e-03, -9.0257e-02,  1.4776e-01, -1.8717e-01,
          3.5803e-01, -1.7902e-01,  1.9394e-01],
        [ 3.2706e-01,  3.3209e-01, -1.8766e-01, -1.7600e-01, -1.6208e-01,
         -1.6973e-01, -9.6651e-02, -1.4147e-01],
        [ 1.5313e-01,  3.0458e-01,  1.3254e-01,  3.6054e-02, -1.3407e-01,
          2.2528e-02,  2.9579e-01, -3.1087e-01],
        [-3.4938e-02, -3.4623e-01, -1.1117e-01, -2.5202e-01, -3.4751e-01,
          1.9704e-01, -1.8319e-01,  1.1302e-01],
        [ 2.6999e-01, -1.0344e-01,  1.4762e-01, -1.0208e-01,  2.7725e-01,
          4.1433e-01, -8.3965e-02, -2.0789e-01],
        [ 2.2961e-01,  1.9987e-01,  1.2678e-01,  7.5869e-02,  1.5690e-01,
          1.4939e-01,  1.0095e-01, -1.3974e-01],
        [ 1.2133e-01,  3.3221e-01, -9.5544e-02, -2.9496e-01, -2.7846e-01,
          5.3207e-02,  1.0949e-01,  5.3867e-02],
        [ 2.7384e-01,  4.6266e-02,  1.8172e-01, -2.7663e-01,  2.7555e-01,
          2.6600e-01,  1.4794e-01,  1.8419e-01],
        [-3.2052e-01,  3.4133e-01,  8.1502e-03, -3.7383e-01,  1.1861e-01,
          1.5653e-01,  2.2410e-01,  3.6401e-01],
        [ 5.5617e-02,  1.9909e-01,  3.2982e-01,  1.7298e-01,  1.3313e-01,
          1.0550e-02, -2.6214e-01,  9.9440e-02],
        [-2.6711e-01, -7.3371e-03, -3.3805e-01, -3.6722e-01, -1.5321e-01,
         -4.2134e-01,  2.0087e-01,  8.0656e-02],
        [-9.0931e-02,  3.2192e-01,  1.6541e-01,  2.1833e-01, -2.3730e-01,
         -2.6054e-01, -1.3053e-01,  2.5337e-01],
        [-2.9921e-01, -2.4446e-01,  3.6665e-02,  1.2425e-01,  1.9941e-01,
          6.2677e-02, -5.2293e-02, -1.0573e-01],
        [-1.3946e-02,  2.3381e-01, -2.6260e-01, -3.1440e-01, -3.0191e-02,
          6.6352e-02,  2.0073e-01,  1.6839e-01],
        [ 3.7626e-01, -9.0694e-02,  1.2713e-01, -2.5811e-01, -2.9090e-01,
         -1.2377e-01,  2.7708e-01, -2.2703e-01],
        [-1.2433e-01,  1.0564e-01, -2.5597e-01,  1.3235e-01, -2.6593e-01,
          3.0875e-01,  2.7444e-01,  1.1727e-01],
        [ 1.9126e-01,  1.6434e-01,  6.7360e-02,  1.7607e-01,  6.2534e-02,
         -7.8800e-02,  1.0633e-01, -2.7621e-01],
        [-3.5515e-01, -5.3227e-03, -1.7229e-01, -1.5773e-01,  1.7168e-01,
         -1.3986e-01,  3.3186e-01, -1.9609e-01],
        [-3.1511e-01,  1.3301e-01,  1.8518e-02,  4.8721e-02,  7.6703e-02,
         -1.6453e-01, -3.7037e-01,  1.8653e-01],
        [-1.2478e-01,  2.8575e-01, -1.7136e-01,  2.4929e-01,  8.4083e-02,
         -1.5236e-01, -1.1715e-01,  3.4256e-01],
        [ 2.0860e-01, -4.4161e-01, -1.4784e-01, -4.9862e-02,  1.8959e-01,
         -2.7733e-01, -1.4885e-01,  8.4355e-02],
        [ 3.9449e-02, -2.0556e-01,  1.7502e-01,  3.2197e-01, -1.7477e-01,
          3.6713e-01,  7.4538e-02,  1.6819e-02],
        [-1.3075e-01,  3.0498e-01,  2.2049e-01, -2.8251e-01,  1.0093e-01,
         -2.3615e-01, -1.8685e-01, -2.5146e-01],
        [-3.9107e-02, -1.2763e-01, -8.3487e-02,  2.3393e-01,  7.5488e-02,
         -3.5406e-01, -1.5346e-01, -2.8423e-01],
        [-1.4921e-01,  2.0733e-01,  1.0842e-01, -1.2106e-01,  1.7177e-01,
         -3.4391e-02,  2.7064e-01, -1.5636e-01],
        [-3.3202e-01, -1.2259e-01,  3.9336e-03,  2.8215e-01,  7.0900e-02,
         -2.3602e-01,  1.9616e-01,  3.6483e-01],
        [-1.9085e-01, -6.3242e-02,  3.8250e-01,  2.9561e-01, -9.3533e-03,
          1.9131e-01,  2.1911e-01,  2.4219e-02],
        [-1.4119e-01,  8.9299e-03,  2.7754e-02,  3.2434e-01,  1.6017e-01,
         -1.8391e-01,  3.0914e-01, -1.6143e-01],
        [-1.4694e-01,  2.5379e-01,  2.1525e-01,  1.9660e-01,  8.8169e-05,
         -3.6591e-01,  3.4608e-01,  6.3938e-02],
        [ 1.7582e-01,  3.3336e-01,  1.2068e-01,  2.7539e-01,  2.4911e-02,
          2.4986e-01,  3.2547e-01,  3.1719e-01],
        [ 1.2361e-01,  1.6765e-01, -4.1155e-02, -8.7679e-02, -1.9222e-01,
          2.7072e-01, -9.2049e-02,  2.6557e-01],
        [ 5.3242e-02, -8.7268e-02, -1.4158e-01, -6.0426e-02, -2.1777e-01,
         -1.7595e-02, -1.1677e-01, -2.1726e-01],
        [ 3.3753e-01, -1.4984e-01,  3.4532e-01,  2.8697e-01,  1.8199e-01,
          3.1700e-01,  1.2675e-01, -2.4941e-01],
        [-2.3421e-01,  3.3371e-02,  3.0394e-02,  1.0369e-01, -1.3273e-01,
         -2.3263e-01, -1.9320e-02,  1.4582e-01],
        [ 1.4272e-01, -3.3570e-02,  1.8766e-01, -2.4430e-01, -2.3554e-01,
          2.0248e-01,  3.1006e-01, -1.8677e-01],
        [-2.0105e-01,  1.1679e-01,  5.8608e-03, -2.6934e-01, -2.8265e-01,
         -2.6486e-01, -1.2330e-01,  2.1938e-02],
        [-4.5185e-02, -4.8670e-02, -2.8523e-01,  2.0414e-01,  2.5290e-01,
         -3.8672e-02,  7.0196e-02,  2.8379e-01],
        [-2.1939e-01,  3.6083e-02, -1.6195e-01, -1.6907e-01, -3.4607e-02,
         -9.7040e-02, -3.6602e-01,  2.7284e-01],
        [-3.2459e-01,  2.1996e-01,  3.3870e-02,  1.0472e-01,  3.3845e-01,
          1.5546e-01,  3.3315e-01,  7.2718e-02],
        [-1.3621e-01,  2.4086e-02, -1.8459e-01, -2.3856e-01, -6.6386e-03,
         -1.7975e-01,  9.4572e-04, -1.0185e-01],
        [-2.1350e-01,  2.0063e-02, -2.4430e-01, -6.8048e-02, -1.7333e-01,
          3.7766e-01, -1.2031e-01, -2.5635e-01],
        [-2.9766e-02,  1.9771e-01,  5.3734e-02,  3.1690e-01, -5.8731e-02,
          1.2616e-01, -2.7997e-01,  2.7735e-02],
        [ 1.4839e-01, -1.0439e-01, -6.4435e-02, -1.0579e-02, -2.4671e-01,
         -1.0809e-01, -3.5939e-01, -1.1367e-01],
        [ 4.0474e-02, -4.7505e-02,  4.8609e-02, -1.1961e-01, -2.8271e-02,
          2.8372e-01, -3.2711e-02,  3.7885e-01],
        [-4.9822e-02,  1.8581e-01,  7.0345e-02,  8.7598e-03, -2.7232e-01,
          2.7721e-01,  3.6398e-02, -2.4732e-01],
        [-3.3084e-01, -1.3710e-01, -1.7984e-01, -3.1859e-01,  9.6714e-03,
         -2.7011e-01, -2.2342e-01,  3.6405e-01],
        [ 2.1106e-01,  3.4630e-01,  3.5852e-01, -3.2018e-01,  2.9988e-01,
          7.1406e-02,  9.5758e-02, -1.4915e-01],
        [ 9.8209e-03,  1.8887e-01, -1.6520e-02,  7.4319e-02, -1.5355e-01,
          2.4114e-01, -1.1955e-01,  1.8847e-01],
        [-2.4311e-01,  1.7734e-02,  3.4016e-01, -1.5080e-01, -2.6051e-01,
          2.1926e-01, -2.6388e-01,  5.0113e-02],
        [-2.5736e-01, -2.6314e-01, -3.0584e-01,  9.5212e-02,  1.2625e-02,
         -2.5724e-01, -3.2649e-01,  1.2342e-01],
        [ 2.3521e-01, -1.7165e-01,  1.0664e-01,  2.9057e-01,  2.8447e-01,
          2.2166e-01,  1.3949e-01,  2.1076e-01],
        [-3.3686e-01, -3.0815e-01, -2.0199e-01,  2.9344e-01,  3.2469e-01,
          2.8684e-01, -1.1925e-01, -3.0961e-01]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[ 5.3482e-03,  1.5242e-03,  1.7407e-03, -2.6660e-03, -6.5905e-03,
         -6.1965e-04, -4.1304e-03,  1.4974e-03],
        [-6.6897e-02, -3.2438e-02,  2.3120e-02,  1.9901e-02,  1.2912e-01,
          4.1044e-03,  6.8431e-02,  2.6811e-02],
        [ 2.0836e-02,  1.3277e-02, -1.7599e-02, -3.4638e-03, -5.0783e-02,
         -8.2835e-04, -2.5429e-02, -1.8106e-02],
        [-1.3909e-01, -5.8959e-02,  2.9686e-02,  4.5678e-02,  2.4978e-01,
          8.9625e-03,  1.3750e-01,  3.9801e-02],
        [ 4.2324e-02,  2.4769e-02, -3.1907e-02, -6.7952e-03, -1.0134e-01,
         -4.6751e-04, -5.0184e-02, -3.7202e-02],
        [-1.4171e-01, -7.1287e-02,  6.0408e-02,  3.9152e-02,  2.8625e-01,
          8.1007e-03,  1.5044e-01,  6.8832e-02],
        [ 5.2489e-02,  2.0071e-02, -2.1922e-03, -1.9993e-02, -8.5033e-02,
         -4.1510e-03, -4.8059e-02, -5.8082e-03],
        [ 2.5926e-02,  1.3441e-02, -1.2912e-02, -6.5474e-03, -5.4120e-02,
         -1.2969e-03, -2.8327e-02, -1.4418e-02],
        [-2.6042e-01, -1.2455e-01,  9.1711e-02,  7.7021e-02,  5.0557e-01,
          1.5879e-02,  2.6940e-01,  1.0761e-01],
        [ 5.2001e-02,  2.5450e-02, -2.0484e-02, -1.4726e-02, -1.0325e-01,
         -2.9907e-03, -5.4665e-02, -2.3747e-02],
        [ 2.6779e-02,  1.3669e-02, -1.2627e-02, -7.0204e-03, -5.5057e-02,
         -1.4334e-03, -2.9034e-02, -1.4028e-02],
        [-1.2146e-01, -7.0402e-02,  8.1031e-02,  2.5383e-02,  2.7545e-01,
          5.2542e-03,  1.3975e-01,  8.7299e-02],
        [-6.0224e-03, -2.2757e-03,  1.1454e-03,  1.7722e-03,  1.0974e-02,
          1.7287e-04,  5.9358e-03,  2.2333e-03],
        [-6.3853e-02, -4.0933e-02,  5.3277e-02,  1.0821e-02,  1.5520e-01,
          2.5039e-03,  7.7248e-02,  5.5015e-02],
        [-1.5237e-02, -7.4579e-03,  7.1968e-03,  3.7193e-03,  3.1736e-02,
          5.5969e-04,  1.6630e-02,  8.7904e-03],
        [-1.3741e-01, -6.8569e-02,  5.8335e-02,  3.8085e-02,  2.7672e-01,
          7.9770e-03,  1.4630e-01,  6.5992e-02],
        [-6.4005e-05,  1.2177e-03, -4.0267e-03,  1.1452e-03, -4.0376e-03,
          2.4075e-04, -1.4729e-03, -3.8940e-03],
        [ 4.9161e-02,  2.7928e-02, -3.1985e-02, -1.0693e-02, -1.0929e-01,
         -2.4011e-03, -5.6723e-02, -3.3118e-02],
        [-1.4281e-01, -8.3668e-02,  9.9013e-02,  2.8949e-02,  3.2710e-01,
          6.0649e-03,  1.6615e-01,  1.0566e-01],
        [-2.7743e-03, -1.6917e-03,  2.5525e-03,  2.3885e-04,  7.3788e-03,
         -7.0537e-05,  3.4758e-03,  3.2353e-03],
        [ 7.1053e-03,  4.2811e-03, -5.5806e-03, -1.2446e-03, -1.6820e-02,
         -2.5072e-04, -8.5868e-03, -5.8223e-03],
        [-1.3793e-02, -2.1095e-02,  5.2699e-02, -8.7676e-03,  7.5430e-02,
         -1.6350e-03,  3.3113e-02,  5.1168e-02],
        [ 8.2088e-03,  2.5065e-03,  1.1019e-03, -3.4246e-03, -1.1759e-02,
         -6.5102e-04, -7.0653e-03,  3.6561e-04],
        [ 1.5312e-02,  2.1260e-02, -4.4406e-02,  5.4047e-03, -6.9911e-02,
          7.8014e-04, -2.9569e-02, -4.2824e-02],
        [-1.8201e-03, -1.8347e-03,  4.3940e-03, -5.3779e-04,  7.3910e-03,
         -1.4922e-04,  3.4789e-03,  4.4999e-03],
        [ 3.2637e-02,  1.4708e-02, -8.6361e-03, -1.0421e-02, -6.0439e-02,
         -2.1500e-03, -3.2669e-02, -1.0749e-02],
        [-2.7350e-01, -1.3453e-01,  1.1099e-01,  7.5975e-02,  5.4680e-01,
          1.5021e-02,  2.8863e-01,  1.2924e-01],
        [-3.6390e-02, -2.6280e-02,  4.3150e-02,  2.4632e-03,  1.0071e-01,
          5.8527e-04,  4.9739e-02,  4.3409e-02],
        [-1.8419e-01, -8.7319e-02,  6.2946e-02,  5.4618e-02,  3.5647e-01,
          1.0988e-02,  1.8966e-01,  7.5555e-02],
        [-5.8629e-02, -1.7356e-02, -1.0729e-02,  2.5314e-02,  8.1430e-02,
          4.8491e-03,  4.9120e-02, -5.1819e-03],
        [-1.6399e-01, -4.2274e-02, -5.3471e-02,  7.8147e-02,  2.0575e-01,
          1.5467e-02,  1.2816e-01, -3.6526e-02],
        [-2.8972e-02, -2.1562e-02,  3.3960e-02,  2.6339e-03,  7.9855e-02,
          9.2667e-04,  3.9159e-02,  3.3415e-02],
        [ 7.1422e-03,  1.6979e-02, -4.0490e-02,  6.8618e-03, -5.2886e-02,
          4.9742e-04, -2.1245e-02, -3.7356e-02],
        [-1.4431e-01, -2.5085e-02, -8.0008e-02,  7.4967e-02,  1.4815e-01,
          1.3098e-02,  9.9749e-02, -5.9138e-02],
        [ 3.0571e-02,  1.4773e-02, -1.0857e-02, -9.0809e-03, -5.9555e-02,
         -1.9181e-03, -3.1584e-02, -1.2698e-02],
        [ 9.3765e-02,  5.1967e-02, -5.5985e-02, -2.1514e-02, -2.0546e-01,
         -4.4746e-03, -1.0581e-01, -6.0703e-02],
        [ 2.9015e-02,  1.6145e-02, -1.4048e-02, -8.8696e-03, -6.0345e-02,
         -2.7010e-03, -3.1532e-02, -1.3785e-02],
        [-1.2463e-01, -6.1666e-02,  4.8084e-02,  3.5759e-02,  2.4651e-01,
          7.3777e-03,  1.2980e-01,  5.5521e-02],
        [-6.6508e-02, -7.9837e-03, -4.7445e-02,  3.7600e-02,  5.7471e-02,
          6.7911e-03,  4.2361e-02, -3.7568e-02],
        [ 1.2656e-02,  6.1458e-03, -4.6015e-03, -3.7261e-03, -2.4759e-02,
         -7.8378e-04, -1.3120e-02, -5.3615e-03],
        [-2.1377e-01, -1.0446e-01,  8.3686e-02,  6.0544e-02,  4.2369e-01,
          1.2222e-02,  2.2443e-01,  9.7088e-02],
        [-7.6246e-02, -5.1025e-02,  7.4175e-02,  9.7450e-03,  1.9604e-01,
          2.1954e-03,  9.7187e-02,  7.6386e-02],
        [ 1.8010e-02,  6.7678e-03, -5.4987e-04, -6.8671e-03, -2.9078e-02,
         -1.3929e-03, -1.6427e-02, -1.9706e-03],
        [ 1.4506e-02,  8.1091e-03, -8.9644e-03, -3.2169e-03, -3.2053e-02,
         -6.4979e-04, -1.6491e-02, -9.6860e-03],
        [ 1.7002e-02,  5.7559e-03,  2.3963e-03, -7.4275e-03, -2.4278e-02,
         -1.6207e-03, -1.4241e-02,  1.3822e-03],
        [ 1.7952e-02,  5.6481e-03,  1.9260e-03, -7.4359e-03, -2.5903e-02,
         -1.4780e-03, -1.5682e-02,  7.2349e-04],
        [-7.2948e-03, -1.4147e-03, -3.8245e-03,  3.8299e-03,  7.7388e-03,
          7.3965e-04,  5.1295e-03, -2.9088e-03],
        [-2.4353e-01, -1.1741e-01,  9.2654e-02,  6.9931e-02,  4.7941e-01,
          1.4224e-02,  2.5560e-01,  1.0756e-01],
        [-4.4851e-02, -2.5264e-02,  3.1068e-02,  8.8465e-03,  1.0182e-01,
          1.6830e-03,  5.2939e-02,  3.2972e-02],
        [-1.1120e-01, -5.9026e-02,  5.7744e-02,  2.7730e-02,  2.3542e-01,
          5.6622e-03,  1.2200e-01,  6.4334e-02],
        [-1.0593e-01, -5.7456e-02,  5.9232e-02,  2.4849e-02,  2.2889e-01,
          4.7332e-03,  1.1759e-01,  6.6238e-02],
        [-2.0918e-01, -9.3029e-02,  5.3589e-02,  6.7308e-02,  3.8466e-01,
          1.3901e-02,  2.0944e-01,  6.6570e-02],
        [-9.8011e-02, -2.3172e-02, -3.6700e-02,  4.7349e-02,  1.1727e-01,
          9.0420e-03,  7.4878e-02, -2.6256e-02],
        [-1.0537e-01, -4.5438e-02,  2.4584e-02,  3.3942e-02,  1.9157e-01,
          6.5786e-03,  1.0478e-01,  3.2439e-02],
        [-1.9069e-01, -1.0409e-01,  1.0856e-01,  4.5282e-02,  4.1297e-01,
          9.4657e-03,  2.1321e-01,  1.1867e-01],
        [ 7.4507e-03,  7.9511e-03, -1.5705e-02,  1.5180e-03, -2.8179e-02,
          4.7811e-04, -1.2270e-02, -1.6094e-02],
        [ 1.5311e-01,  6.9818e-02, -2.8076e-02, -5.3436e-02, -2.7237e-01,
         -1.1497e-02, -1.4483e-01, -3.7374e-02],
        [-4.4641e-02, -1.6305e-02, -1.0473e-03,  1.8111e-02,  6.8625e-02,
          4.0106e-03,  3.9887e-02,  1.0328e-03],
        [ 1.4152e-01,  7.6938e-02, -8.0795e-02, -3.3638e-02, -3.0537e-01,
         -7.1150e-03, -1.5882e-01, -8.7161e-02],
        [-1.6986e-01, -7.4912e-02,  4.0203e-02,  5.5845e-02,  3.0911e-01,
          1.1724e-02,  1.6865e-01,  5.0548e-02],
        [ 8.6848e-03,  4.8040e-03, -4.6842e-03, -2.1952e-03, -1.8666e-02,
         -4.9928e-04, -9.5185e-03, -5.1426e-03],
        [ 5.0762e-03, -2.0113e-04,  8.5367e-03, -4.5440e-03,  8.5715e-04,
         -1.0769e-03, -8.8635e-04,  8.3364e-03],
        [-2.4493e-01, -1.3034e-01,  1.3145e-01,  5.9259e-02,  5.2193e-01,
          1.1588e-02,  2.7075e-01,  1.4617e-01],
        [-3.3652e-02, -2.3221e-02,  3.5034e-02,  3.5162e-03,  8.8972e-02,
          7.5319e-04,  4.3642e-02,  3.6133e-02],
        [-4.9839e-02, -2.2790e-02,  1.6910e-02,  1.4127e-02,  9.6690e-02,
          2.3077e-03,  5.1550e-02,  2.1817e-02],
        [ 4.2350e-02,  1.9731e-02, -1.3890e-02, -1.2610e-02, -8.1322e-02,
         -2.4675e-03, -4.3462e-02, -1.6950e-02],
        [ 3.3682e-02,  1.3590e-02, -4.8937e-03, -1.1569e-02, -5.8426e-02,
         -2.1815e-03, -3.2295e-02, -7.8418e-03],
        [ 2.3562e-02,  1.1223e-02, -8.7125e-03, -6.7831e-03, -4.6121e-02,
         -1.3557e-03, -2.4648e-02, -1.0226e-02],
        [ 7.2267e-02,  4.7665e-02, -6.7235e-02, -9.9367e-03, -1.8369e-01,
         -2.0044e-03, -9.0618e-02, -7.0585e-02],
        [-1.7116e-02, -9.7275e-03,  1.1951e-02,  3.2323e-03,  3.9446e-02,
          5.1553e-04,  2.0095e-02,  1.3259e-02],
        [ 5.4303e-02,  2.7058e-02, -2.5222e-02, -1.3670e-02, -1.1227e-01,
         -2.2574e-03, -5.8734e-02, -3.0057e-02],
        [ 4.5127e-02,  2.5425e-02, -3.0271e-02, -9.3393e-03, -1.0207e-01,
         -1.8665e-03, -5.2748e-02, -3.2540e-02],
        [ 1.8598e-02,  9.9487e-03, -9.7643e-03, -4.6504e-03, -3.9385e-02,
         -9.8319e-04, -2.0431e-02, -1.0710e-02],
        [ 6.3336e-02,  2.6724e-02, -1.1176e-02, -2.1971e-02, -1.1196e-01,
         -4.7009e-03, -6.1553e-02, -1.5523e-02],
        [-8.6240e-02, -6.9057e-04, -8.5076e-02,  5.3406e-02,  5.0639e-02,
          8.5753e-03,  4.6781e-02, -6.8211e-02],
        [ 9.3676e-03,  4.3083e-03, -2.6362e-03, -3.0553e-03, -1.7331e-02,
         -7.1623e-04, -9.4843e-03, -2.9197e-03],
        [ 9.6651e-02,  5.0832e-02, -3.1064e-02, -3.1293e-02, -1.8582e-01,
         -7.8267e-03, -9.4786e-02, -3.4080e-02],
        [-9.9847e-03, -4.0193e-03,  1.2678e-03,  3.5433e-03,  1.7157e-02,
          7.1143e-04,  9.5101e-03,  2.0790e-03],
        [-2.3260e-01, -1.0008e-01,  4.8882e-02,  7.6548e-02,  4.1874e-01,
          1.4913e-02,  2.2784e-01,  6.7081e-02],
        [-1.8201e-01, -9.2822e-02,  8.1283e-02,  4.9138e-02,  3.7150e-01,
          1.0104e-02,  1.9441e-01,  9.2128e-02],
        [-1.0065e-02,  6.3787e-04, -1.1059e-02,  5.8814e-03,  4.9401e-03,
          4.9189e-04,  4.8345e-03, -7.9597e-03],
        [ 8.1098e-02,  4.4309e-02, -4.8415e-02, -1.8054e-02, -1.7815e-01,
         -3.3728e-03, -9.1692e-02, -5.3766e-02],
        [-1.5080e-01, -6.9518e-02,  4.8074e-02,  4.5194e-02,  2.8775e-01,
          8.8001e-03,  1.5446e-01,  5.8879e-02],
        [-4.2460e-02, -3.1757e-02,  4.8840e-02,  4.4186e-03,  1.1657e-01,
          1.6789e-03,  5.6864e-02,  4.7956e-02],
        [ 9.7254e-03,  4.6126e-03, -3.4187e-03, -2.8027e-03, -1.8931e-02,
         -5.2503e-04, -1.0031e-02, -4.1702e-03],
        [-4.8411e-03,  1.3040e-03, -1.4221e-02,  6.4082e-03, -7.0417e-03,
          1.7972e-03, -1.9140e-03, -1.4660e-02],
        [ 3.6416e-02,  1.7939e-02, -1.4512e-02, -1.0232e-02, -7.2484e-02,
         -2.0462e-03, -3.8256e-02, -1.6832e-02],
        [ 7.4255e-02,  4.3981e-02, -5.4749e-02, -1.4149e-02, -1.7200e-01,
         -3.0880e-03, -8.8123e-02, -5.6833e-02],
        [-1.5363e-01, -8.5204e-02,  9.0431e-02,  3.5410e-02,  3.3536e-01,
          7.2543e-03,  1.7228e-01,  9.8321e-02],
        [-3.0747e-02, -1.6202e-02,  1.7287e-02,  7.1073e-03,  6.5963e-02,
          1.3207e-03,  3.4585e-02,  1.9043e-02],
        [-1.0328e-01, -6.2367e-02,  7.6173e-02,  2.0775e-02,  2.3983e-01,
          5.1130e-03,  1.2233e-01,  7.8039e-02],
        [-1.5541e-01, -3.8095e-02, -5.5851e-02,  7.5035e-02,  1.9005e-01,
          1.4662e-02,  1.1945e-01, -3.8756e-02],
        [-2.4632e-01, -1.4574e-01,  1.8024e-01,  4.7163e-02,  5.7403e-01,
          9.6430e-03,  2.9157e-01,  1.9229e-01],
        [ 3.3212e-01,  1.6698e-01, -1.4245e-01, -9.0893e-02, -6.7200e-01,
         -1.8419e-02, -3.5279e-01, -1.6324e-01],
        [-9.5147e-02, -1.9097e-02, -4.5516e-02,  4.8275e-02,  1.0473e-01,
          8.9774e-03,  6.8876e-02, -3.3514e-02],
        [-3.9623e-02, -1.2110e-02, -8.1079e-03,  1.7788e-02,  5.4065e-02,
          3.7028e-03,  3.2577e-02, -5.1412e-03],
        [-1.1619e-01, -4.2548e-02, -1.2697e-03,  4.5512e-02,  1.8290e-01,
          9.1565e-03,  1.0366e-01,  8.3182e-03],
        [ 2.9344e-02,  1.3688e-02, -9.5150e-03, -8.8114e-03, -5.6177e-02,
         -1.7550e-03, -3.0060e-02, -1.1521e-02],
        [ 3.3671e-02,  1.6301e-02, -1.1533e-02, -1.0872e-02, -6.4878e-02,
         -2.7813e-03, -3.5134e-02, -1.2330e-02],
        [ 1.3638e-02,  1.0154e-02, -1.5300e-02, -1.2558e-03, -3.7228e-02,
         -3.8073e-04, -1.7817e-02, -1.5430e-02]], device='cuda:0') 

model.module_8.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.2403,  0.2361,  0.1117,  0.3382,  0.1064, -0.1466, -0.3886, -0.1035,
         0.1389,  0.0429, -0.1848,  0.0220, -0.2588,  0.0664, -0.3124, -0.0798,
         0.1040, -0.2583, -0.0773, -0.3090, -0.0599,  0.0480, -0.1531,  0.2421,
        -0.2274,  0.2133,  0.1675, -0.2169,  0.1842,  0.2714, -0.1274,  0.0527,
         0.4355,  0.3792,  0.0122,  0.2343,  0.2544,  0.1912,  0.0850, -0.3332,
         0.1420, -0.0183, -0.1813, -0.2839, -0.2980, -0.2192, -0.0368, -0.1765,
        -0.2522, -0.1027, -0.0525,  0.0975,  0.2494,  0.1322, -0.1874,  0.1965,
         0.3028,  0.3042,  0.0804,  0.3167,  0.1739, -0.0341, -0.3141, -0.1219,
         0.0618,  0.1977, -0.2060,  0.0174,  0.2803, -0.3201,  0.1770,  0.0630,
         0.0652,  0.2217,  0.3113, -0.1654,  0.2220, -0.2901,  0.1576,  0.0446,
         0.0363,  0.2367,  0.1679, -0.0732, -0.0525,  0.2349,  0.1992, -0.1098,
         0.0876, -0.3116,  0.2999, -0.0978, -0.2239,  0.2821, -0.0270,  0.2606,
         0.2118, -0.2295,  0.0708,  0.3066], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 1.0449e-02, -1.3475e-01,  4.3496e-02, -2.7116e-01,  8.2269e-02,
        -2.8219e-01,  1.0263e-01,  5.1879e-02, -5.1711e-01,  1.0310e-01,
         5.3495e-02, -2.4794e-01, -1.1032e-02, -1.3267e-01, -2.9388e-02,
        -2.7347e-01,  3.6432e-04,  1.0049e-01, -2.9201e-01, -4.9553e-03,
         1.4495e-02, -3.2575e-02,  1.5556e-02,  3.7635e-02, -3.5657e-03,
         6.4412e-02, -5.4249e-01, -7.5336e-02, -3.6432e-01, -1.1187e-01,
        -3.0523e-01, -6.1523e-02,  2.0895e-02, -2.6287e-01,  6.0823e-02,
         1.8890e-01,  5.9955e-02, -2.4945e-01, -1.1875e-01,  2.5273e-02,
        -4.2496e-01, -1.5847e-01,  3.4941e-02,  2.9317e-02,  3.3526e-02,
         3.4454e-02, -1.3431e-02, -4.8121e-01, -8.9400e-02, -2.2288e-01,
        -2.1248e-01, -4.1166e-01, -1.8332e-01, -2.0596e-01, -3.8278e-01,
         1.5916e-02,  3.0696e-01, -8.8245e-02,  2.8682e-01, -3.3497e-01,
         1.7601e-02,  1.0202e-02, -4.8741e-01, -7.0352e-02, -9.6598e-02,
         8.3405e-02,  6.5184e-02,  4.6527e-02,  1.4873e-01, -3.3850e-02,
         1.0599e-01,  9.0377e-02,  3.7502e-02,  1.2451e-01, -1.4697e-01,
         1.8777e-02,  2.0281e-01, -1.9380e-02, -4.5535e-01, -3.6384e-01,
        -1.6212e-02,  1.6159e-01, -2.9661e-01, -9.0547e-02,  1.9194e-02,
        -1.0934e-02,  7.2437e-02,  1.5184e-01, -3.1176e-01, -6.0760e-02,
        -2.1269e-01, -2.8848e-01, -4.9914e-01,  6.6218e-01, -1.7414e-01,
        -7.6034e-02, -2.2568e-01,  5.7970e-02,  6.7106e-02,  2.9842e-02],
       device='cuda:0') 

model.module_10.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[-0.0557, -0.0041,  0.0041,  ..., -0.0614, -0.0290, -0.0356],
        [-0.0769, -0.0497, -0.0071,  ...,  0.0747,  0.0071,  0.0398],
        [ 0.0750, -0.0519,  0.1007,  ..., -0.0756, -0.0068,  0.0489],
        ...,
        [ 0.0188,  0.1041, -0.0594,  ..., -0.0854,  0.0486,  0.0502],
        [ 0.0583,  0.0502, -0.0180,  ...,  0.1010,  0.0656,  0.0830],
        [ 0.0688,  0.0460,  0.0853,  ...,  0.0866,  0.0482,  0.0691]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-1.3591e-03,  4.8240e-03,  2.2195e-04,  ...,  3.8604e-04,
         -1.9920e-03,  7.4609e-04],
        [ 1.7618e-02, -2.2479e-02,  2.9137e-03,  ...,  8.0722e-03,
          5.6665e-03,  4.9300e-03],
        [ 9.9016e-03, -1.0594e-02,  2.1894e-03,  ...,  5.4350e-03,
          2.2248e-03,  3.4860e-03],
        ...,
        [ 3.9928e-02, -6.6891e-02,  4.6500e-03,  ...,  1.3236e-02,
          2.0174e-02,  5.8080e-03],
        [ 7.6123e-03, -1.5490e-02,  3.1736e-04,  ...,  1.5055e-03,
          4.6531e-03,  9.0981e-06],
        [ 6.7346e-03, -1.4835e-02,  1.5775e-04,  ...,  9.8862e-04,
          4.8439e-03, -1.2689e-04]], device='cuda:0') 

model.module_10.bias 100 torch.Size([100])
Parameter containing:
tensor([ 0.0412, -0.0071,  0.0860, -0.0202,  0.0431, -0.0814,  0.0004, -0.0309,
         0.0929, -0.0267, -0.0960,  0.0567,  0.0060,  0.0078, -0.0194,  0.0767,
         0.0317,  0.1209,  0.0553,  0.0062,  0.0505,  0.0463,  0.0416, -0.0698,
         0.0326, -0.1290, -0.0215, -0.0037, -0.0667,  0.0700, -0.0237,  0.0128,
        -0.0403, -0.1058, -0.0817, -0.1047,  0.0707, -0.0726,  0.0637,  0.0128,
        -0.0160, -0.0292,  0.0329, -0.0890, -0.0162, -0.0216,  0.0596, -0.0206,
        -0.0366, -0.1253,  0.0360, -0.0095, -0.0300,  0.0473, -0.0009,  0.1177,
        -0.0390, -0.0495, -0.0166, -0.0878,  0.0652, -0.0079,  0.0547, -0.1276,
         0.0957,  0.1031, -0.0796,  0.0537, -0.0464, -0.0068, -0.1261, -0.1977,
         0.0593,  0.0332, -0.0545,  0.0643,  0.0730, -0.0890, -0.0769,  0.0569,
         0.0562, -0.0720, -0.0873, -0.0506, -0.0116, -0.0655, -0.0349,  0.0793,
         0.0479,  0.0096, -0.0294, -0.0463,  0.0232,  0.0246,  0.0912, -0.0822,
        -0.0772, -0.0745,  0.0999,  0.0848], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 2.4505e-03, -1.4354e-01, -8.6648e-02,  2.0728e-02, -1.4410e-01,
         5.3571e-02, -4.9915e-01, -3.6726e-02, -2.9864e-01,  4.7975e-05,
         2.9064e-02,  6.1522e-02,  1.1367e-01,  1.3541e-02, -1.8104e-01,
        -3.6117e-01, -2.8578e-02, -1.2066e-01,  1.1536e-01, -2.5757e-01,
         1.1201e-01, -3.0421e-01, -6.3668e-03, -2.0293e-01, -2.6232e-01,
        -3.3463e-02, -1.3401e-01, -1.0249e-01,  2.9687e-02, -3.8204e-01,
        -2.1991e-01, -1.8156e-01, -2.3928e-01, -1.1923e-02,  3.5605e-02,
         8.1698e-02, -2.1703e-01, -3.1728e-02, -2.7684e-02,  6.7012e-02,
        -1.5951e-02, -3.7260e-02, -5.6626e-01, -2.4096e-01, -3.6518e-01,
        -4.1605e-01,  5.3491e-02, -3.7387e-01,  8.9278e-02, -4.5722e-02,
        -5.3964e-01,  7.8290e-02, -2.4702e-01,  8.5600e-02, -1.8960e-01,
        -2.9695e-01,  3.7252e-02, -1.7823e-01, -2.9586e-01, -2.2235e-01,
         6.0705e-02,  4.2966e-02,  2.8090e-02, -1.0907e-02,  5.2802e-02,
         2.1524e-01, -5.2584e-01, -1.8397e-01,  5.2302e-02,  5.8118e-02,
         9.9783e-03, -6.8220e-03,  1.0098e-01, -2.0860e-02, -8.2479e-01,
        -2.0139e-01,  1.6709e-01, -2.3468e-01, -3.2361e-01,  4.8220e-02,
        -2.2325e-01, -4.9069e-01, -3.6131e-01, -2.1453e-02,  1.4272e-01,
         7.4586e-02,  1.3382e-01, -5.5373e-01,  1.2168e-03,  7.9067e-02,
        -6.3858e-02, -4.5833e-01,  1.8117e-02, -1.3566e-01, -1.1441e-01,
        -3.8187e-01,  8.0036e-02, -2.8061e-01, -4.6371e-02, -3.7706e-02],
       device='cuda:0') 

model.module_12.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[ 9.0513e-02, -3.8824e-02,  6.6042e-02,  ...,  9.3678e-02,
         -1.1493e-03,  9.3773e-05],
        [-7.2406e-02,  8.4624e-02,  9.0003e-02,  ...,  2.8940e-03,
          5.8813e-02, -7.4605e-03],
        [-2.9695e-02, -1.2597e-01, -1.2819e-01,  ...,  6.3530e-02,
          2.7655e-02,  1.0276e-01],
        ...,
        [ 7.3736e-03,  5.3044e-02,  8.5808e-02,  ..., -6.6677e-02,
          7.5379e-02, -8.0117e-02],
        [ 6.5646e-02,  3.2882e-02, -4.0678e-02,  ..., -9.3284e-02,
          8.0011e-02, -9.6005e-03],
        [-4.5884e-02, -7.6195e-02,  8.8583e-02,  ...,  9.1956e-02,
          5.9288e-02,  1.3359e-01]], device='cuda:0', requires_grad=True) 
grad:  tensor([[ 0.0152,  0.1512,  0.0250,  ...,  0.0299,  0.1738,  0.0737],
        [-0.0112, -0.3947, -0.0069,  ..., -0.2203, -0.4285, -0.4999],
        [ 0.0010, -0.0528,  0.0045,  ..., -0.0366, -0.0530, -0.0825],
        ...,
        [-0.0073, -0.0680, -0.0131,  ..., -0.0131, -0.0791, -0.0287],
        [ 0.0022,  0.0561,  0.0024,  ...,  0.0260,  0.0605,  0.0581],
        [ 0.0022, -0.1176,  0.0096,  ..., -0.0836, -0.1197, -0.1900]],
       device='cuda:0') 

model.module_12.bias 16 torch.Size([16])
Parameter containing:
tensor([-0.0132,  0.1046,  0.0317,  0.1101, -0.0027, -0.0320,  0.1423, -0.0306,
        -0.0036,  0.0132,  0.0714,  0.0375, -0.0407,  0.0324, -0.0032, -0.0093],
       device='cuda:0', requires_grad=True) 
grad:  tensor([ 0.6951, -2.1049, -0.2927, -0.8000, -2.3557, -0.6705,  0.7226, -1.1804,
         0.2751, -0.4613, -2.0734, -1.2628,  0.3020, -0.3086,  0.2847, -0.6609],
       device='cuda:0') 

model.module_14.bias 8 torch.Size([8])
Parameter containing:
tensor([ 0.0253,  0.0115,  0.0330, -0.0238, -0.0304,  0.0169,  0.0218, -0.0106],
       device='cuda:0', requires_grad=True) 
grad:  tensor([ 2.2768,  1.9959,  0.9673, -1.2349, -0.1241,  1.9428,  1.1130, -2.8786],
       device='cuda:0') 

model.module_14.lin.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[ 0.4372,  0.1303, -0.0775, -0.2714, -0.3255, -0.2873,  0.3987, -0.2108,
          0.1744,  0.1714, -0.2946, -0.2741, -0.1236, -0.3960,  0.5076, -0.2626],
        [-0.5575, -0.3496, -0.0123,  0.4725, -0.4614, -0.0406,  0.0306, -0.0245,
          0.1008, -0.2955,  0.1993,  0.1091,  0.5061,  0.2224,  0.1295, -0.3010],
        [-0.1384, -0.3795,  0.2084,  0.1309,  0.0039, -0.4854, -0.2810,  0.2667,
          0.3664, -0.3857, -0.3180,  0.1244,  0.2942, -0.2361, -0.0342,  0.4815],
        [-0.1944,  0.2307, -0.0659,  0.4306,  0.2118,  0.1816,  0.4470, -0.0047,
         -0.1285, -0.4238,  0.4639,  0.3347, -0.0866, -0.4362,  0.4961,  0.3851],
        [-0.4306,  0.1410, -0.0232,  0.2954, -0.0344, -0.1990, -0.0333,  0.0389,
         -0.2683,  0.2891,  0.4412,  0.4826,  0.3453, -0.2742,  0.1856, -0.1792],
        [-0.0015, -0.3040, -0.1731, -0.3838, -0.0008,  0.0351,  0.4570,  0.1769,
          0.2832, -0.2876,  0.0174, -0.0660,  0.0745, -0.2841,  0.2739,  0.4605],
        [ 0.1660,  0.0868, -0.0138, -0.3753, -0.2933, -0.2438, -0.2460, -0.4555,
          0.0947, -0.0234,  0.0798,  0.2336, -0.3176, -0.3363, -0.3775, -0.1063],
        [-0.1817,  0.3113,  0.0818, -0.1787,  0.1571, -0.0379, -0.0278,  0.2902,
          0.0760,  0.1505,  0.4079,  0.3720, -0.3071, -0.0875, -0.2596,  0.2389]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 5.6694e-01,  1.0775e+00,  6.5946e-01,  1.0667e+00,  7.6157e-01,
          2.5635e-01,  7.1831e-01,  5.4374e-01, -1.1375e-01,  4.2392e-01,
          6.4027e-01,  6.5760e-01, -1.8259e-01,  8.7667e-02, -6.9020e-02,
          2.8502e-01],
        [ 3.3085e-01,  8.2468e-01,  6.9645e-01,  9.2595e-01,  6.0899e-01,
          1.2586e-01,  4.9335e-01,  4.7065e-01, -8.2858e-02,  2.4103e-01,
          5.4251e-01,  6.3032e-01, -1.1768e-01,  2.0309e-02, -5.2624e-02,
          3.0648e-01],
        [ 8.8318e-02,  3.6080e-01,  4.2026e-01,  4.6940e-01,  2.8213e-01,
          1.5566e-02,  1.8143e-01,  2.3800e-01, -3.3883e-02,  5.7850e-02,
          2.6727e-01,  3.5042e-01, -3.8870e-02, -1.6231e-02, -2.2755e-02,
          1.8825e-01],
        [-3.4529e-01, -6.3852e-01, -3.9959e-01, -6.2919e-01, -4.5281e-01,
         -1.5762e-01, -4.2021e-01, -3.2220e-01,  6.7799e-02, -2.5759e-01,
         -3.7689e-01, -3.8961e-01,  1.0926e-01, -5.8221e-02,  4.0877e-02,
         -1.7399e-01],
        [ 2.3039e-04, -3.7297e-02, -6.0784e-02, -5.9432e-02, -3.1386e-02,
          5.1615e-03, -1.4349e-02, -2.9685e-02,  3.0777e-03,  2.5817e-03,
         -3.2598e-02, -4.8017e-02,  1.9317e-03,  6.1062e-03,  2.2165e-03,
         -2.7680e-02],
        [ 4.3503e-01,  8.8981e-01,  6.0986e-01,  9.1803e-01,  6.3777e-01,
          1.8853e-01,  5.7412e-01,  4.6741e-01, -9.2541e-02,  3.2218e-01,
          5.4613e-01,  5.8581e-01, -1.4347e-01,  5.7375e-02, -5.6840e-02,
          2.6586e-01],
        [ 2.3738e-01,  5.0810e-01,  3.7445e-01,  5.3770e-01,  3.6776e-01,
          9.9820e-02,  3.1955e-01,  2.7384e-01, -5.2379e-02,  1.7452e-01,
          3.1799e-01,  3.5069e-01, -7.9319e-02,  2.8195e-02, -3.2405e-02,
          1.6427e-01],
        [-7.1051e-01, -1.3748e+00, -8.8345e-01, -1.3790e+00, -9.7766e-01,
         -3.1810e-01, -9.0184e-01, -7.0387e-01,  1.4464e-01, -5.3016e-01,
         -8.2493e-01, -8.6272e-01,  2.2962e-01, -1.0769e-01,  8.8061e-02,
         -3.8371e-01]], device='cuda:0') 

model.module_15.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[-0.1088, -0.1247, -0.0128,  0.2022, -0.2917, -0.2733,  0.2757,  0.0650],
        [-0.0884, -0.3289, -0.0666,  0.2106, -0.1783, -0.1029, -0.2138, -0.0546],
        [ 0.0874,  0.1514, -0.2108, -0.2778,  0.0605, -0.2420,  0.2103, -0.2208],
        [-0.2597, -0.0258,  0.1329, -0.2426, -0.0302, -0.1582, -0.1757, -0.2557],
        [ 0.1834, -0.1559, -0.2131, -0.3384,  0.3203,  0.0455,  0.0157,  0.2987],
        [ 0.2326, -0.0248,  0.3547, -0.0208,  0.2965, -0.1925,  0.1058, -0.2814],
        [-0.1104,  0.0609, -0.2169, -0.0150, -0.0445,  0.3864,  0.0851,  0.1844],
        [ 0.2207,  0.2610,  0.2355,  0.0864,  0.2505,  0.3393, -0.0923,  0.1687],
        [ 0.1166,  0.2307, -0.1772,  0.0718,  0.0756,  0.1119,  0.0289,  0.2311],
        [-0.1602, -0.0267, -0.3056,  0.2860, -0.3027,  0.0962, -0.2907,  0.1219],
        [-0.1875,  0.2321, -0.2907,  0.2072, -0.0848, -0.3234, -0.1058, -0.1203],
        [ 0.1580,  0.3966,  0.2075, -0.0450, -0.0038, -0.2186, -0.1245,  0.2506],
        [ 0.2702, -0.0761,  0.0562,  0.3167, -0.1910, -0.0275, -0.3096,  0.0888],
        [-0.0342,  0.0143,  0.4671, -0.2095,  0.2514, -0.0672,  0.3264,  0.0161],
        [-0.1207, -0.0263,  0.1164,  0.0089, -0.0611, -0.1990, -0.0409, -0.2269],
        [-0.0663,  0.0895, -0.0795,  0.2369, -0.2564,  0.0430, -0.0213, -0.1852],
        [ 0.2396, -0.2361,  0.0251,  0.0886,  0.3039,  0.2083,  0.1765, -0.2501],
        [-0.0638,  0.1614,  0.0674,  0.2864,  0.2471,  0.2086, -0.1655,  0.1729],
        [-0.0887,  0.1371,  0.3308,  0.3338, -0.3082,  0.2014,  0.2879, -0.3135],
        [ 0.2580, -0.2130, -0.2582,  0.1475, -0.1385,  0.2835, -0.1283, -0.3419],
        [-0.2064, -0.0725, -0.2862, -0.2282, -0.3302, -0.1503, -0.0759,  0.1508],
        [ 0.2070, -0.3172, -0.0767, -0.1908,  0.1384, -0.3254, -0.2945,  0.1095],
        [-0.1122, -0.1808,  0.0271, -0.1543,  0.1054,  0.3840, -0.0771,  0.3115],
        [ 0.2357,  0.3376,  0.1115,  0.3047, -0.1903,  0.2868,  0.2324,  0.1986],
        [ 0.0062, -0.1544,  0.2683,  0.2179,  0.1478,  0.3613,  0.1779, -0.0202],
        [ 0.1865,  0.1130,  0.0102, -0.1434,  0.3135,  0.1339, -0.0828, -0.3197],
        [ 0.0218,  0.1433,  0.0123,  0.2172, -0.2814,  0.2150, -0.1692, -0.2332],
        [-0.1795,  0.2580, -0.0839, -0.3127, -0.2154, -0.1966, -0.1467,  0.1107],
        [-0.1175, -0.1495, -0.0845, -0.1541,  0.1146, -0.3463, -0.0444,  0.3374],
        [-0.0566, -0.0184, -0.0472,  0.1830,  0.3367, -0.3653, -0.2941,  0.0854],
        [-0.3106,  0.3402,  0.2425,  0.2114, -0.2907,  0.1663, -0.0582,  0.1743],
        [-0.1791, -0.2178,  0.3369, -0.1744, -0.2439, -0.1828, -0.1803, -0.2711],
        [-0.1480, -0.2032, -0.0799,  0.1092, -0.0556, -0.1007,  0.3164, -0.2287],
        [-0.0128, -0.0910,  0.2378,  0.0711, -0.2991,  0.1187, -0.2799,  0.1606],
        [ 0.2445,  0.2210, -0.1649,  0.2678,  0.0260,  0.0774, -0.1654,  0.2511],
        [ 0.2897,  0.2834,  0.0679,  0.2716, -0.1000,  0.0826,  0.3349, -0.0278],
        [ 0.1808,  0.1896, -0.1763,  0.0753,  0.0663, -0.2546,  0.1863, -0.1470],
        [-0.0117,  0.0095,  0.1999,  0.2849, -0.0145,  0.0234, -0.2348, -0.0452],
        [ 0.0564,  0.3312, -0.3016,  0.1860, -0.1428, -0.0652,  0.3180,  0.0492],
        [ 0.3426, -0.2400, -0.2025, -0.2066, -0.3102, -0.2236,  0.3285, -0.1785],
        [-0.3106, -0.2571, -0.0615,  0.1466, -0.0218,  0.3558, -0.0709,  0.3103],
        [ 0.2685,  0.0473, -0.2082, -0.1985,  0.0835, -0.0781, -0.2152, -0.1337],
        [-0.2496, -0.3008,  0.0693,  0.2944,  0.0879,  0.2041, -0.2901,  0.0767],
        [-0.0605,  0.3652,  0.2156, -0.0050, -0.1775,  0.2841,  0.3535,  0.1848],
        [-0.2684, -0.2444,  0.1719,  0.0563, -0.0753,  0.0361,  0.2913, -0.2946],
        [ 0.2440,  0.2903, -0.2492, -0.2963,  0.0136, -0.2385,  0.0029, -0.0041],
        [ 0.2693,  0.0699,  0.1764, -0.2173,  0.0120,  0.0908,  0.0574, -0.0012],
        [ 0.1787, -0.0195, -0.1050,  0.0531, -0.0070, -0.2280, -0.0595, -0.0553],
        [-0.3119, -0.0676, -0.0160,  0.0422,  0.3255,  0.0649, -0.2913,  0.1964],
        [ 0.2960, -0.3603, -0.2075, -0.3330,  0.2758, -0.2378,  0.2913,  0.2868],
        [ 0.0943, -0.1524,  0.0038, -0.1523, -0.3164, -0.2131, -0.0890,  0.0315],
        [ 0.2770,  0.0552,  0.0061, -0.1466,  0.2574,  0.0728, -0.2877, -0.3217],
        [ 0.3556,  0.1652,  0.4212, -0.0414,  0.0790, -0.2903, -0.2182,  0.2971],
        [-0.2328, -0.2076,  0.0329,  0.0020, -0.3144,  0.2314, -0.3641, -0.1578],
        [ 0.3122,  0.2806,  0.1634,  0.2504, -0.2402,  0.3529,  0.0223,  0.1058],
        [ 0.1741,  0.3433, -0.2366,  0.3232, -0.1401, -0.0210,  0.1250,  0.2874],
        [ 0.2180,  0.3387, -0.1105,  0.3452,  0.0782,  0.1309,  0.1691,  0.0516],
        [ 0.2240, -0.0766, -0.3284,  0.2000,  0.2864,  0.2696, -0.0292, -0.1486],
        [-0.2106,  0.1683,  0.2956,  0.0557,  0.3804,  0.1706,  0.1125, -0.2525],
        [ 0.2815,  0.0711, -0.2476,  0.1141,  0.0135, -0.2325,  0.2455, -0.2359],
        [-0.1124, -0.2789,  0.1487, -0.2643, -0.1384,  0.2482, -0.0222, -0.0521],
        [-0.1926,  0.1479, -0.0302, -0.2020, -0.1394,  0.0217, -0.1428,  0.0188],
        [-0.1665,  0.4546,  0.3858, -0.1389,  0.0214,  0.1208,  0.0700, -0.1497],
        [-0.2875, -0.3331, -0.2926, -0.0347, -0.0572, -0.2890,  0.2299, -0.1121],
        [ 0.2726,  0.3584, -0.2606, -0.2169, -0.2203, -0.2746, -0.2766,  0.2599],
        [ 0.0374,  0.1530, -0.2925, -0.1457, -0.3141,  0.0847, -0.2631, -0.1326],
        [-0.1036, -0.2416,  0.2147, -0.2213,  0.2696, -0.2142, -0.1390,  0.2766],
        [-0.1048, -0.2877,  0.0156,  0.2749,  0.0318,  0.1184, -0.0370, -0.2345],
        [ 0.0929, -0.0534,  0.2011,  0.1286, -0.1089,  0.1079,  0.2609, -0.1701],
        [ 0.0698,  0.1461,  0.3307, -0.2637, -0.1411,  0.1033, -0.2646, -0.2764],
        [-0.3030, -0.1423,  0.1274,  0.1888,  0.2597, -0.3339,  0.1133,  0.3507],
        [-0.1006,  0.2671, -0.3085,  0.3183,  0.1721, -0.0320, -0.1696,  0.2527],
        [-0.3327,  0.0466,  0.0788, -0.3118,  0.0655,  0.1119,  0.1713,  0.2013],
        [ 0.1358,  0.1386, -0.0073, -0.2706, -0.0750, -0.0178, -0.1413,  0.2842],
        [ 0.1381,  0.4817,  0.4033,  0.0019, -0.0930,  0.0789, -0.0428, -0.0546],
        [-0.2293, -0.2687,  0.1511, -0.3367,  0.2796,  0.0425,  0.1579,  0.2505],
        [ 0.0434,  0.1243,  0.0743,  0.2701,  0.1472, -0.0554, -0.3230, -0.2988],
        [-0.3342,  0.4478,  0.2502, -0.0184, -0.3206, -0.0324,  0.0384, -0.2217],
        [-0.1814,  0.0599, -0.1095, -0.3120, -0.1828,  0.2398, -0.2946,  0.1288],
        [ 0.2235,  0.2200, -0.2047,  0.2526,  0.1380,  0.2789,  0.1846, -0.0089],
        [-0.2546,  0.1542, -0.0489,  0.0129,  0.1887, -0.3162, -0.3241, -0.0258],
        [-0.0144,  0.2510,  0.1801, -0.0674,  0.0026,  0.2690, -0.2901,  0.0995],
        [-0.2206,  0.1539, -0.0325, -0.3307,  0.1439, -0.1995,  0.0092,  0.0056],
        [ 0.0701,  0.2586,  0.1695,  0.3765, -0.1190, -0.1271, -0.0554,  0.1390],
        [-0.0885,  0.3451,  0.4070,  0.2741,  0.1688,  0.0315,  0.3383, -0.0996],
        [ 0.2197, -0.2078,  0.1503, -0.3121, -0.1743, -0.1539, -0.0573, -0.2160],
        [-0.0311,  0.2227,  0.2641,  0.3512, -0.0602, -0.0802, -0.0325,  0.1381],
        [-0.0553, -0.1986,  0.0515, -0.1820,  0.2048,  0.0305,  0.1869, -0.1773],
        [-0.2450, -0.3473,  0.3586, -0.2450,  0.1276,  0.2903,  0.2648,  0.2455],
        [-0.0174, -0.2677, -0.3370, -0.1241,  0.0582,  0.1385, -0.2640, -0.2121],
        [ 0.3028,  0.0536, -0.1836,  0.2981,  0.0294, -0.1048,  0.0538, -0.3808],
        [-0.1897,  0.4482,  0.2756, -0.2141,  0.1191, -0.0908, -0.2511, -0.3147],
        [ 0.2865,  0.1653, -0.2639, -0.2420,  0.0623, -0.2482,  0.1321, -0.2837],
        [ 0.0999,  0.1545, -0.0645,  0.0732, -0.2075, -0.2928,  0.1160, -0.0577],
        [ 0.1168,  0.0034, -0.3006, -0.0374,  0.1645,  0.0240, -0.1242, -0.2607],
        [ 0.2491, -0.2807,  0.0218, -0.1225,  0.1382,  0.0624,  0.0106, -0.2095],
        [-0.1477, -0.2863,  0.2776,  0.1561, -0.0123,  0.0305, -0.1678,  0.2693],
        [-0.0759,  0.1189, -0.2373,  0.2872,  0.0044, -0.0568, -0.1015, -0.0570],
        [ 0.0079, -0.1067,  0.1621,  0.3014, -0.0122,  0.1432,  0.1367, -0.4008],
        [ 0.2957,  0.0559,  0.1566, -0.0464, -0.2466, -0.2529,  0.0449, -0.1405]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 4.4152e-02,  5.9411e-02,  5.4954e-02, -1.3278e-01, -6.1003e-02,
          4.6040e-02,  6.2779e-02, -9.4304e-02],
        [ 5.4249e-02,  7.9422e-02,  7.4865e-02, -1.6641e-01, -7.5091e-02,
          5.9360e-02,  8.0433e-02, -1.1904e-01],
        [ 9.2890e-05, -9.6558e-04, -1.2780e-03,  8.8156e-04,  1.8611e-04,
         -4.1184e-04, -5.9256e-04,  6.1888e-04],
        [ 7.0282e-03,  9.4818e-03,  8.6994e-03, -2.0850e-02, -9.5494e-03,
          7.3150e-03,  9.9367e-03, -1.4860e-02],
        [-5.5475e-02, -8.5681e-02, -8.1903e-02,  1.7325e-01,  7.7390e-02,
         -6.2728e-02, -8.4720e-02,  1.2441e-01],
        [-1.2272e-01, -7.9196e-02, -4.3991e-02,  2.8284e-01,  1.4553e-01,
         -8.7474e-02, -1.1991e-01,  1.9764e-01],
        [-4.9319e-02, -6.1266e-02, -5.4172e-02,  1.4012e-01,  6.5251e-02,
         -4.8866e-02, -6.6034e-02,  1.0014e-01],
        [-9.1360e-02, -1.0854e-01, -9.5539e-02,  2.6030e-01,  1.2195e-01,
         -8.8362e-02, -1.2097e-01,  1.8391e-01],
        [-1.8965e-02, -1.2609e-02, -7.5089e-03,  4.4826e-02,  2.3180e-02,
         -1.3844e-02, -1.8816e-02,  3.1622e-02],
        [ 5.0107e-02,  8.8429e-02,  8.7213e-02, -1.6509e-01, -7.1778e-02,
          6.1730e-02,  8.2805e-02, -1.1960e-01],
        [ 5.1581e-03,  7.8456e-03,  7.3716e-03, -1.5677e-02, -7.0219e-03,
          5.7620e-03,  7.7007e-03, -1.1333e-02],
        [-4.4179e-02, -2.6990e-02, -1.3530e-02,  9.8749e-02,  5.1454e-02,
         -3.0776e-02, -4.1624e-02,  6.9608e-02],
        [ 1.4792e-02,  4.4263e-02,  4.7863e-02, -6.3431e-02, -2.4738e-02,
          2.6655e-02,  3.4891e-02, -4.7578e-02],
        [-1.0868e-01, -7.3173e-02, -4.1686e-02,  2.4915e-01,  1.2795e-01,
         -7.8787e-02, -1.0669e-01,  1.7577e-01],
        [ 1.3597e-02,  1.9532e-02,  1.8322e-02, -4.1457e-02, -1.8791e-02,
          1.4715e-02,  1.9946e-02, -2.9636e-02],
        [-6.9142e-02, -8.8628e-02, -7.9425e-02,  1.9945e-01,  9.2254e-02,
         -6.9765e-02, -9.4433e-02,  1.4245e-01],
        [-1.1947e-02, -1.7331e-02, -1.6368e-02,  3.6811e-02,  1.6679e-02,
         -1.3029e-02, -1.7681e-02,  2.6289e-02],
        [ 1.9931e-02,  3.6830e-02,  3.6358e-02, -6.5816e-02, -2.8227e-02,
          2.5234e-02,  3.3587e-02, -4.8097e-02],
        [-1.3076e-01, -8.3400e-02, -4.5127e-02,  2.9844e-01,  1.5415e-01,
         -9.2751e-02, -1.2639e-01,  2.0941e-01],
        [-2.1368e-01, -4.1644e-01, -4.2682e-01,  7.6249e-01,  3.2561e-01,
         -2.8259e-01, -3.8386e-01,  5.4741e-01],
        [ 2.2643e-02,  6.7880e-02,  7.3863e-02, -9.8979e-02, -3.8788e-02,
          4.0970e-02,  5.3955e-02, -7.3776e-02],
        [-1.0893e-02, -2.2912e-02, -2.3811e-02,  4.0168e-02,  1.6921e-02,
         -1.5182e-02, -2.0528e-02,  2.8978e-02],
        [-2.1034e-02, -3.8052e-02, -3.7988e-02,  7.1052e-02,  3.0834e-02,
         -2.6415e-02, -3.5544e-02,  5.1335e-02],
        [-1.2518e-02, -1.6282e-02, -1.4755e-02,  3.6624e-02,  1.6949e-02,
         -1.2778e-02, -1.7291e-02,  2.6173e-02],
        [ 9.1919e-03,  8.1839e-03,  6.1764e-03, -2.3672e-02, -1.1546e-02,
          7.5857e-03,  1.0530e-02, -1.6459e-02],
        [-1.7477e-02, -2.2926e-02, -2.0823e-02,  5.1249e-02,  2.3622e-02,
         -1.7900e-02, -2.4285e-02,  3.6546e-02],
        [ 2.8993e-03,  3.0537e-03,  2.4749e-03, -7.6083e-03, -3.6213e-03,
          2.5990e-03,  3.5303e-03, -5.4037e-03],
        [ 1.6375e-02,  2.2898e-02,  2.1339e-02, -4.9534e-02, -2.2566e-02,
          1.7439e-02,  2.3693e-02, -3.5319e-02],
        [-3.5099e-03, -3.5692e-03, -2.9599e-03,  9.4802e-03,  4.6019e-03,
         -3.1307e-03, -4.2739e-03,  6.6831e-03],
        [ 1.2196e-01,  1.6549e-01,  1.5232e-01, -3.6335e-01, -1.6645e-01,
          1.2750e-01,  1.7304e-01, -2.5918e-01],
        [ 1.7163e-03,  2.5758e-03,  2.4418e-03, -5.3142e-03, -2.3956e-03,
          1.9116e-03,  2.5745e-03, -3.8200e-03],
        [-2.5133e-02, -4.8934e-02, -4.8860e-02,  8.4576e-02,  3.5758e-02,
         -3.2887e-02, -4.3796e-02,  6.1846e-02],
        [ 6.9946e-04, -2.6309e-03, -3.4621e-03,  8.4365e-04, -2.7177e-04,
         -9.2376e-04, -1.0761e-03,  9.4118e-04],
        [ 1.6350e-02,  2.2793e-02,  2.1223e-02, -4.9439e-02, -2.2537e-02,
          1.7383e-02,  2.3623e-02, -3.5241e-02],
        [ 1.3524e-01,  1.8097e-01,  1.6384e-01, -3.9328e-01, -1.8017e-01,
          1.3967e-01,  1.8850e-01, -2.8180e-01],
        [-1.9145e-01, -1.3488e-01, -8.4674e-02,  4.5908e-01,  2.3287e-01,
         -1.4199e-01, -1.9634e-01,  3.1928e-01],
        [-6.0976e-02, -1.2550e-01, -1.3045e-01,  2.2509e-01,  9.5134e-02,
         -8.3805e-02, -1.1402e-01,  1.6150e-01],
        [-4.5154e-02, -6.5253e-02, -6.1811e-02,  1.3991e-01,  6.3408e-02,
         -4.9160e-02, -6.6988e-02,  9.9611e-02],
        [-3.1445e-02, -4.8046e-02, -4.5327e-02,  9.6172e-02,  4.3048e-02,
         -3.5272e-02, -4.7186e-02,  6.9669e-02],
        [ 7.6233e-03,  6.5197e-03,  4.8545e-03, -1.9512e-02, -9.6334e-03,
          6.1957e-03,  8.5787e-03, -1.3586e-02],
        [ 1.6197e-02,  2.2849e-02,  2.1227e-02, -4.8917e-02, -2.2314e-02,
          1.7373e-02,  2.3397e-02, -3.5152e-02],
        [-4.0197e-03, -5.6657e-03, -5.1780e-03,  1.1746e-02,  5.3392e-03,
         -4.2819e-03, -5.7115e-03,  8.5146e-03],
        [ 9.9059e-02,  1.3454e-01,  1.2376e-01, -2.9466e-01, -1.3496e-01,
          1.0358e-01,  1.4049e-01, -2.1027e-01],
        [-1.1881e-01, -7.5870e-02, -4.1398e-02,  2.7220e-01,  1.4039e-01,
         -8.4323e-02, -1.1527e-01,  1.9058e-01],
        [ 1.3955e-03, -7.8054e-05, -6.4151e-04, -2.6272e-03, -1.5696e-03,
          5.5610e-04,  8.4934e-04, -1.6996e-03],
        [-1.2524e-02, -1.8682e-02, -1.7662e-02,  3.8578e-02,  1.7378e-02,
         -1.3873e-02, -1.8709e-02,  2.7712e-02],
        [-2.2709e-01, -1.9612e-01, -1.4661e-01,  5.8248e-01,  2.8690e-01,
         -1.8542e-01, -2.5654e-01,  4.0608e-01],
        [ 7.1131e-03,  2.6730e-02,  2.9827e-02, -3.5630e-02, -1.3254e-02,
          1.5363e-02,  2.0149e-02, -2.6798e-02],
        [ 1.0451e-01,  1.4407e-01,  1.3292e-01, -3.1206e-01, -1.4251e-01,
          1.1025e-01,  1.4924e-01, -2.2318e-01],
        [-5.4482e-02, -1.0740e-01, -1.1019e-01,  1.9496e-01,  8.3102e-02,
         -7.2601e-02, -9.8449e-02,  1.4012e-01],
        [-2.1919e-03, -5.4177e-03, -5.7508e-03,  8.6764e-03,  3.5219e-03,
         -3.4249e-03, -4.5792e-03,  6.3504e-03],
        [-2.2633e-01, -3.0116e-01, -2.7720e-01,  6.7634e-01,  3.1072e-01,
         -2.3409e-01, -3.1983e-01,  4.7960e-01],
        [ 3.8029e-02,  3.0173e-02,  2.1315e-02, -9.5421e-02, -4.7468e-02,
          2.9777e-02,  4.1498e-02, -6.6064e-02],
        [ 6.9896e-03,  6.8647e-03,  5.5021e-03, -1.8503e-02, -8.9639e-03,
          6.0920e-03,  8.3376e-03, -1.3033e-02],
        [-1.9316e-01, -1.2370e-01, -6.9626e-02,  4.5014e-01,  2.3135e-01,
         -1.3745e-01, -1.8998e-01,  3.1273e-01],
        [ 1.3014e-01,  1.8223e-01,  1.6828e-01, -3.8809e-01, -1.7636e-01,
          1.3830e-01,  1.8696e-01, -2.7794e-01],
        [-4.6842e-02, -6.1908e-02, -5.7443e-02,  1.4143e-01,  6.5328e-02,
         -4.8438e-02, -6.6337e-02,  1.0010e-01],
        [-5.9185e-02, -7.1386e-02, -6.3236e-02,  1.6978e-01,  7.9664e-02,
         -5.7905e-02, -7.8810e-02,  1.2055e-01],
        [-7.3058e-02, -4.9669e-02, -2.8969e-02,  1.6908e-01,  8.6707e-02,
         -5.3246e-02, -7.2341e-02,  1.1899e-01],
        [ 9.0553e-05,  1.1673e-03,  1.3170e-03, -8.5399e-04, -2.0034e-04,
          5.6673e-04,  6.5528e-04, -7.9333e-04],
        [-2.2211e-03, -4.6816e-03, -4.7720e-03,  7.8666e-03,  3.3033e-03,
         -3.0882e-03, -4.0856e-03,  5.7889e-03],
        [-4.5890e-02, -7.3956e-02, -7.1102e-02,  1.4447e-01,  6.3858e-02,
         -5.3205e-02, -7.1531e-02,  1.0425e-01],
        [-1.2866e-01, -8.0236e-02, -4.1521e-02,  2.8955e-01,  1.5034e-01,
         -9.0403e-02, -1.2240e-01,  2.0407e-01],
        [ 3.0186e-03,  1.1292e-02,  1.2377e-02, -1.4178e-02, -5.1663e-03,
          6.4483e-03,  8.2713e-03, -1.0984e-02],
        [-7.8831e-03, -1.0194e-02, -9.4856e-03,  2.4046e-02,  1.1099e-02,
         -8.0550e-03, -1.1182e-02,  1.6825e-02],
        [-7.4709e-03, -8.6570e-03, -7.5229e-03,  2.1017e-02,  9.9048e-03,
         -7.1270e-03, -9.7275e-03,  1.4874e-02],
        [ 1.0825e-02,  9.8067e-03,  7.9080e-03, -2.9632e-02, -1.4436e-02,
          9.1151e-03,  1.2932e-02, -2.0256e-02],
        [ 1.7792e-02,  2.3410e-02,  2.1331e-02, -5.2357e-02, -2.4153e-02,
          1.8275e-02,  2.4785e-02, -3.7356e-02],
        [-1.5262e-01, -1.0570e-01, -6.4402e-02,  3.6137e-01,  1.8405e-01,
         -1.1232e-01, -1.5437e-01,  2.5245e-01],
        [-1.3328e-01, -9.3726e-02, -5.6984e-02,  3.1294e-01,  1.5950e-01,
         -9.8691e-02, -1.3436e-01,  2.2019e-01],
        [ 9.9087e-02,  1.3390e-01,  1.2278e-01, -2.9366e-01, -1.3464e-01,
          1.0329e-01,  1.3994e-01, -2.0976e-01],
        [ 7.7655e-02,  1.1072e-01,  1.0344e-01, -2.3537e-01, -1.0678e-01,
          8.3600e-02,  1.1326e-01, -1.6829e-01],
        [-4.8782e-02, -3.6801e-02, -2.3372e-02,  1.1451e-01,  5.7913e-02,
         -3.7159e-02, -5.0059e-02,  8.1258e-02],
        [-2.7374e-02, -2.3675e-02, -1.6511e-02,  6.5815e-02,  3.2383e-02,
         -2.2100e-02, -2.9739e-02,  4.6897e-02],
        [-1.7194e-01, -1.1333e-01, -6.3255e-02,  3.9328e-01,  2.0270e-01,
         -1.2369e-01, -1.6750e-01,  2.7740e-01],
        [ 3.4594e-02,  1.9094e-02,  9.0527e-03, -7.9305e-02, -4.1507e-02,
          2.3304e-02,  3.2524e-02, -5.4599e-02],
        [ 1.1920e-02,  1.4367e-02,  1.2981e-02, -3.5157e-02, -1.6276e-02,
          1.1596e-02,  1.6305e-02, -2.4297e-02],
        [-9.3150e-02, -6.3391e-02, -3.7533e-02,  2.1774e-01,  1.1128e-01,
         -6.7945e-02, -9.3043e-02,  1.5240e-01],
        [-7.7361e-02, -1.1188e-01, -1.0495e-01,  2.3594e-01,  1.0672e-01,
         -8.4018e-02, -1.1380e-01,  1.6879e-01],
        [-6.3508e-02, -6.6878e-02, -5.5887e-02,  1.7356e-01,  8.3188e-02,
         -5.7551e-02, -7.8830e-02,  1.2230e-01],
        [ 5.2908e-02,  6.8256e-02,  6.1579e-02, -1.5386e-01, -7.1075e-02,
          5.3617e-02,  7.2801e-02, -1.0965e-01],
        [-5.2631e-02, -3.2843e-02, -1.7352e-02,  1.1969e-01,  6.1985e-02,
         -3.7001e-02, -5.0510e-02,  8.3846e-02],
        [ 8.8728e-03,  1.3069e-02,  1.2441e-02, -2.7652e-02, -1.2486e-02,
          9.7688e-03,  1.3300e-02, -1.9701e-02],
        [ 1.2222e-01,  8.2638e-02,  4.9203e-02, -2.8804e-01, -1.4691e-01,
          8.8886e-02,  1.2278e-01, -2.0024e-01],
        [-3.6349e-02, -1.9404e-02, -8.1883e-03,  8.0509e-02,  4.2447e-02,
         -2.4085e-02, -3.3133e-02,  5.5982e-02],
        [-6.0579e-03, -1.0879e-02, -1.0945e-02,  2.0745e-02,  9.0119e-03,
         -7.5819e-03, -1.0304e-02,  1.4860e-02],
        [ 8.7578e-02,  6.8923e-02,  4.7279e-02, -2.1528e-01, -1.0755e-01,
          6.8231e-02,  9.3883e-02, -1.5047e-01],
        [ 6.2912e-03,  6.3575e-03,  5.1452e-03, -1.6737e-02, -8.0734e-03,
          5.5645e-03,  7.5850e-03, -1.1832e-02],
        [ 2.6127e-02,  1.8526e-02,  1.1153e-02, -6.0644e-02, -3.1128e-02,
          1.9451e-02,  2.6056e-02, -4.3156e-02],
        [ 6.1045e-03,  1.6206e-02,  1.7337e-02, -2.4896e-02, -9.9951e-03,
          1.0060e-02,  1.3323e-02, -1.8401e-02],
        [-8.2681e-02, -1.0599e-01, -9.5598e-02,  2.4060e-01,  1.1135e-01,
         -8.3543e-02, -1.1354e-01,  1.7126e-01],
        [-1.5191e-01, -9.5970e-02, -5.1157e-02,  3.4547e-01,  1.7866e-01,
         -1.0730e-01, -1.4618e-01,  2.4243e-01],
        [-1.9091e-03, -2.8586e-03, -2.6765e-03,  5.7597e-03,  2.6002e-03,
         -2.1196e-03, -2.8131e-03,  4.2023e-03],
        [-2.9724e-03, -7.5106e-03, -7.9790e-03,  1.1863e-02,  4.8349e-03,
         -4.7365e-03, -6.2575e-03,  8.7864e-03],
        [-1.2785e-01, -2.5236e-01, -2.5974e-01,  4.6044e-01,  1.9627e-01,
         -1.7066e-01, -2.3197e-01,  3.3045e-01],
        [-2.3725e-03, -1.6104e-03, -8.8524e-04,  5.2807e-03,  2.7096e-03,
         -1.7159e-03, -2.2941e-03,  3.7669e-03],
        [ 2.0323e-01,  2.6166e-01,  2.3622e-01, -5.9179e-01, -2.7363e-01,
          2.0583e-01,  2.7961e-01, -4.2140e-01],
        [ 1.0046e-02, -3.6411e-03, -9.2352e-03, -1.2924e-02, -8.9474e-03,
          2.3381e-03,  3.4458e-03, -8.3495e-03],
        [-3.5327e-02, -5.1239e-02, -4.8969e-02,  1.1093e-01,  5.0155e-02,
         -3.8556e-02, -5.2999e-02,  7.8362e-02],
        [ 1.5853e-03,  4.1388e-04, -1.7628e-04, -3.1410e-03, -1.7482e-03,
          8.4358e-04,  1.1972e-03, -2.1250e-03]], device='cuda:0') 

model.module_15.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.0376, -0.0388, -0.1359, -0.2515,  0.2296,  0.1315,  0.3458,  0.2724,
        -0.0245, -0.2172,  0.0524, -0.0548, -0.3140,  0.1384, -0.3615,  0.3576,
        -0.0156, -0.0795,  0.1516,  0.1554, -0.0482, -0.1417,  0.2229, -0.1155,
        -0.0480,  0.0570, -0.2799, -0.3358, -0.2917, -0.2897, -0.2849,  0.3215,
         0.1596, -0.3523, -0.1791,  0.1232,  0.0630,  0.2870,  0.2112, -0.1537,
        -0.1565, -0.2071, -0.3133,  0.2090, -0.1016, -0.0275,  0.3154, -0.1109,
        -0.2764,  0.0475, -0.1670,  0.2042, -0.0085, -0.1496,  0.1095, -0.1201,
         0.0022,  0.3113, -0.0388, -0.2784, -0.0448,  0.1980,  0.2131, -0.2408,
         0.1288, -0.1966,  0.2458, -0.3348,  0.1648,  0.3688, -0.2530, -0.1402,
         0.0848,  0.1409,  0.1634,  0.0701, -0.1694,  0.2635,  0.3189,  0.2883,
         0.2050,  0.0286, -0.3430, -0.1901,  0.0427,  0.0355, -0.1737, -0.2875,
        -0.0207, -0.1636,  0.3003,  0.1997, -0.0226,  0.0353,  0.0769, -0.1504,
        -0.2350, -0.0729,  0.1909, -0.1175], device='cuda:0',
       requires_grad=True) 
grad:  tensor([-2.1391e-01, -2.5428e-01,  1.2381e-03, -3.1869e-02,  2.5991e-01,
         4.3172e-01,  2.1478e-01,  4.0463e-01,  8.3141e-02, -2.4687e-01,
        -2.2249e-02,  1.5156e-01, -9.5850e-02,  3.7703e-01, -6.4234e-02,
         3.0581e-01,  5.8385e-02, -9.4120e-02,  4.5890e-01,  1.2019e+00,
        -1.5682e-01,  6.1293e-02,  1.1062e-01,  5.9121e-02, -3.4615e-02,
         7.9815e-02, -1.0303e-02, -7.6983e-02,  1.4967e-02, -5.6641e-01,
        -8.4220e-03,  1.1101e-01,  1.9421e-03, -7.7179e-02, -5.7730e-01,
         7.1609e-01,  3.5748e-01,  2.2505e-01,  1.4632e-01, -3.0096e-02,
        -8.1147e-02,  1.7319e-02, -4.5465e-01,  4.1771e-01, -5.2694e-03,
         5.9852e-02,  9.1221e-01, -5.4318e-02, -4.8609e-01,  3.0227e-01,
         1.3361e-02,  1.0654e+00, -1.4543e-01, -2.8953e-02,  6.9923e-01,
        -5.7876e-01,  2.3478e-01,  2.7898e-01,  2.5771e-01, -1.0050e-03,
         1.1626e-02,  2.0983e-01,  4.4769e-01, -2.0773e-02,  4.0171e-02,
         3.2881e-02, -4.9122e-02, -8.2966e-02,  5.6951e-01,  4.9281e-01,
        -4.5574e-01, -3.6026e-01,  1.6998e-01,  8.7947e-02,  6.1149e-01,
        -1.2966e-01, -5.0138e-02,  3.3351e-01,  3.6240e-01,  2.7864e-01,
        -2.3712e-01,  1.8357e-01, -4.3628e-02, -4.3449e-01,  1.2632e-01,
         3.2726e-02, -3.2954e-01, -2.6349e-02, -9.8116e-02, -3.8181e-02,
         3.7362e-01,  5.2985e-01,  9.3449e-03,  2.0265e-02,  7.3100e-01,
         7.4281e-03, -9.1524e-01, -1.0500e-02,  1.7420e-01, -4.4757e-03],
       device='cuda:0') 

model.module_17.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[ 0.0445, -0.0511,  0.0835,  ...,  0.0842,  0.0281,  0.0260],
        [-0.1154, -0.0747,  0.0203,  ..., -0.0574,  0.0699,  0.0233],
        [ 0.0006,  0.0525,  0.1003,  ...,  0.0692,  0.0698, -0.0696],
        ...,
        [ 0.0318,  0.0832, -0.0227,  ...,  0.1470,  0.0004,  0.0179],
        [ 0.0615,  0.0445,  0.0817,  ...,  0.0395, -0.0628,  0.0262],
        [ 0.0203,  0.0663, -0.0261,  ...,  0.0277, -0.0587, -0.0197]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 2.1501e-02,  6.7671e-02, -2.1351e-02,  ...,  4.7624e-02,
          2.5530e-02, -1.9135e-02],
        [ 8.1813e-03,  2.5685e-02, -9.5264e-03,  ...,  1.9034e-02,
          1.2695e-02, -8.2991e-03],
        [ 2.6744e-02,  8.4127e-02, -2.6914e-02,  ...,  5.9026e-02,
          3.2790e-02, -2.4089e-02],
        ...,
        [-1.4525e-03, -4.6076e-03,  1.1505e-03,  ..., -3.3648e-03,
         -9.1789e-04,  1.0628e-03],
        [ 1.3945e-03,  4.0026e-03, -6.5789e-04,  ...,  2.0122e-03,
          1.0637e-04, -7.1272e-04],
        [ 3.5177e-02,  1.0871e-01, -3.9036e-02,  ...,  7.9848e-02,
          4.9325e-02, -3.4140e-02]], device='cuda:0') 

model.module_17.bias 100 torch.Size([100])
Parameter containing:
tensor([ 0.0881,  0.0247,  0.0215, -0.0696,  0.0497,  0.0551,  0.0114, -0.0597,
         0.0203,  0.0340, -0.0260,  0.0211,  0.0275, -0.0454,  0.0031,  0.0034,
        -0.1241,  0.0299, -0.0425, -0.0022,  0.0173,  0.0352, -0.0740,  0.0311,
         0.0865, -0.0802,  0.0713, -0.1001,  0.0677,  0.0367, -0.0548, -0.0218,
         0.0797,  0.0075,  0.0566,  0.0566, -0.0768, -0.0207,  0.0776,  0.0164,
        -0.0934,  0.1243, -0.0137, -0.0142,  0.0246, -0.0648, -0.0021,  0.0608,
        -0.0621, -0.1024, -0.0706, -0.0669,  0.0579, -0.0689, -0.0472, -0.0603,
         0.0168,  0.0657, -0.0930,  0.1065, -0.0043,  0.0061,  0.0510, -0.0197,
         0.0129, -0.0843, -0.0434, -0.0364,  0.0067, -0.0472, -0.0172,  0.1184,
         0.0128,  0.0253, -0.0335,  0.0755,  0.1091, -0.0397, -0.0375, -0.0262,
         0.0025, -0.0150,  0.0083,  0.0173, -0.0184,  0.0854,  0.0246, -0.0232,
        -0.0363,  0.0650, -0.0228, -0.0162,  0.0634, -0.0843, -0.0384, -0.0359,
         0.0780, -0.0408,  0.0048,  0.0856], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 0.2567,  0.1114,  0.3256, -0.0953,  0.0522,  0.1367, -0.2090,  0.4471,
         0.0531,  0.2294, -0.0339,  0.5170,  0.4204,  0.2105,  0.1613,  0.3052,
        -0.0590, -0.0502, -0.0114, -0.2164,  0.1875, -0.0307, -0.5495, -0.2960,
         0.0340, -0.1157,  0.3445, -0.0471,  0.3373,  0.2629,  0.2238,  0.4240,
         0.2686, -0.2224,  0.1028, -0.1133,  0.1231, -0.0858,  0.0170,  0.0326,
        -0.0102, -0.0137, -0.4046,  0.2555,  0.6024,  0.3860, -0.0258,  0.5903,
         0.0526, -0.0286, -0.0133, -0.0640,  0.3642,  0.0153, -0.1714,  0.0214,
         0.0431, -0.0019,  0.0587,  0.3988, -0.1130, -0.3325, -0.0992, -0.2881,
         0.0907, -0.2526,  0.1342, -0.1328,  0.1307, -0.0088,  0.0541,  0.1965,
         0.5313, -0.0600, -0.0818, -0.0172,  0.0381,  0.1949, -0.0374,  0.1715,
         0.6389, -0.0331, -0.0317, -0.0391,  0.1387,  0.3574,  0.1013,  0.1416,
        -0.0449,  0.1712, -0.0438, -0.3452,  0.2660, -0.0654, -0.0631, -0.0119,
        -0.1111, -0.0125,  0.0103,  0.4506], device='cuda:0') 

model.module_19.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[-0.0190, -0.0310,  0.0039,  ...,  0.0905,  0.0416,  0.0311],
        [ 0.0026,  0.0923, -0.0633,  ...,  0.0695,  0.0499, -0.0232],
        [-0.0819, -0.0963,  0.0116,  ...,  0.0496, -0.0881,  0.0216],
        ...,
        [ 0.0221, -0.0909,  0.0293,  ...,  0.0515,  0.0192, -0.0206],
        [ 0.0800,  0.1070,  0.0496,  ..., -0.0811, -0.0390,  0.0517],
        [ 0.0986,  0.0430,  0.1346,  ...,  0.0196,  0.0050, -0.0395]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-0.0703,  0.0518, -0.0675,  ..., -0.4067, -0.3160, -0.1512],
        [-0.0140,  0.0131, -0.0134,  ..., -0.1047, -0.0813, -0.0363],
        [-0.0084,  0.0060, -0.0083,  ..., -0.0478, -0.0371, -0.0184],
        ...,
        [ 0.0186, -0.0123,  0.0186,  ...,  0.0987,  0.0767,  0.0387],
        [ 0.0539, -0.0340,  0.0543,  ...,  0.2755,  0.2132,  0.1117],
        [ 0.0345, -0.0204,  0.0356,  ...,  0.1687,  0.1305,  0.0748]],
       device='cuda:0') 

model.module_19.bias 16 torch.Size([16])
Parameter containing:
tensor([ 0.0572, -0.0928,  0.0304, -0.0436, -0.0734,  0.0159,  0.0055,  0.0954,
        -0.0228,  0.0841,  0.0425,  0.0280, -0.0089,  0.0750,  0.0812,  0.0235],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-1.6543, -0.4310, -0.1975,  1.0000,  0.6306,  0.1510,  0.5845,  0.1392,
         0.5963,  0.4372,  1.1973,  1.2868, -0.0677,  0.4053,  1.1336,  0.7305],
       device='cuda:0') 

