#### ARCHITECTURE ####
Node Encoder:
 None 

Edge Encoder:
 None 

Model:
 Sequential(
  (0): WeightedGATv2Conv(1, 8, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (2): WeightedGATv2Conv(64, 8, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (4): WeightedGATv2Conv(64, 8, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (6): WeightedGATv2Conv(64, 8, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
) 

Head 1:
 LinearBlock(
  (model): Sequential(
    (0): Linear(in_features=64, out_features=8, bias=True)
    (1): PReLU(num_parameters=1)
  )
) 

Head 2:
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=32768, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1024, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['constant', 'ContactDistance', 'GeneticDistance_norm'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project2/depablo/erschultz/dataset_11_18_22'], scratch='/scratch/midway2/erschultz', root_name='ContactGNNEnergy3', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', y_zero_diag_count=0, log_preprocessing=None, output_preprocesing='log', kr=False, mean_filt=None, rescale=2, gated=False, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=False, use_scratch_parallel=True, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.0001, weight_decay=0.0, gpus=1, milestones=[50], gamma=0.1, loss='huber', autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_SD', model_type='ContactGNNEnergy', id=293, pretrained=False, resume_training=False, k=None, m=1024, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, message_passing='weighted_GAT', head_architecture='bilinear_8', head_architecture_2='fc-fill', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000, 1024], encoder_hidden_sizes_list=None, inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/293', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/293/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/293/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/293/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function huber_loss at 0x7f35a0e23820>, channels=1, node_feature_size=1, input_m=512, edge_transforms=["'ContactDistance'", 'ContactDistance(norm=False)', 'GeneticDistance(norm=True)'], node_transforms=['Constant(value=1.0)'], edge_dim=2, transforms_processed=None, diag=False, pre_transforms_processed=Compose([
  Constant(value=1.0),
  ContactDistance(norm=False),
  GeneticDistance(norm=True)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 32.61 minutes
Average num edges per graph:  219629.77916666667
Mean degree: [362.66 512.   449.47 ... 399.29 390.16 429.63] +- [70.54  0.   53.89 ... 85.38 67.92 62.93]

split sizes: train=2160, val=240, test=0, N=2400
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
#### TRAINING/VALIDATION ####
Epoch 2, loss = 0.3321
Mean test/val loss: 0.3382
[25, 50, 75] quantiles test/val loss: [0.2316 0.3537 0.4408]

Epoch 4, loss = 0.3115
Mean test/val loss: 0.3220
[25, 50, 75] quantiles test/val loss: [0.2243 0.3362 0.4145]

Epoch 6, loss = 0.2994
Mean test/val loss: 0.2922
[25, 50, 75] quantiles test/val loss: [0.1856 0.3049 0.394 ]

Epoch 8, loss = 0.2894
Mean test/val loss: 0.3040
[25, 50, 75] quantiles test/val loss: [0.1939 0.3171 0.4124]

Epoch 10, loss = 0.2852
Mean test/val loss: 0.2834
[25, 50, 75] quantiles test/val loss: [0.1743 0.2932 0.3893]

Epoch 12, loss = 0.2794
Mean test/val loss: 0.2735
[25, 50, 75] quantiles test/val loss: [0.1678 0.2823 0.3746]

Epoch 14, loss = 0.2737
Mean test/val loss: 0.2678
[25, 50, 75] quantiles test/val loss: [0.1584 0.2769 0.3686]

Epoch 16, loss = 0.2709
Mean test/val loss: 0.2643
[25, 50, 75] quantiles test/val loss: [0.159  0.2739 0.3651]

Epoch 18, loss = 0.2677
Mean test/val loss: 0.2782
[25, 50, 75] quantiles test/val loss: [0.1695 0.2822 0.3814]

Epoch 20, loss = 0.2676
Mean test/val loss: 0.2796
[25, 50, 75] quantiles test/val loss: [0.1785 0.2891 0.3677]

Epoch 22, loss = 0.2608
Mean test/val loss: 0.2605
[25, 50, 75] quantiles test/val loss: [0.1549 0.2583 0.3647]

Epoch 24, loss = 0.2557
Mean test/val loss: 0.2606
[25, 50, 75] quantiles test/val loss: [0.1615 0.2646 0.3557]

Epoch 26, loss = 0.2527
Mean test/val loss: 0.2528
[25, 50, 75] quantiles test/val loss: [0.1449 0.2514 0.3546]

Epoch 28, loss = 0.2486
Mean test/val loss: 0.2543
[25, 50, 75] quantiles test/val loss: [0.1535 0.2535 0.3547]

Epoch 30, loss = 0.2485
Mean test/val loss: 0.2519
[25, 50, 75] quantiles test/val loss: [0.1508 0.2491 0.3533]

Epoch 32, loss = 0.2474
Mean test/val loss: 0.2565
[25, 50, 75] quantiles test/val loss: [0.1562 0.2614 0.3548]

Epoch 34, loss = 0.2412
Mean test/val loss: 0.2532
[25, 50, 75] quantiles test/val loss: [0.1503 0.2557 0.3519]

Epoch 36, loss = 0.2406
Mean test/val loss: 0.2442
[25, 50, 75] quantiles test/val loss: [0.1468 0.2407 0.3408]

Epoch 38, loss = 0.2391
Mean test/val loss: 0.2428
[25, 50, 75] quantiles test/val loss: [0.1391 0.2411 0.3382]

Epoch 40, loss = 0.2381
Mean test/val loss: 0.2397
[25, 50, 75] quantiles test/val loss: [0.1344 0.238  0.3423]

Epoch 42, loss = 0.2372
Mean test/val loss: 0.2386
[25, 50, 75] quantiles test/val loss: [0.1401 0.2394 0.3354]

Epoch 44, loss = 0.2327
Mean test/val loss: 0.2442
[25, 50, 75] quantiles test/val loss: [0.1437 0.2392 0.339 ]

Epoch 46, loss = 0.2345
Mean test/val loss: 0.2402
[25, 50, 75] quantiles test/val loss: [0.1389 0.2409 0.3381]

Epoch 48, loss = 0.2324
Mean test/val loss: 0.2428
[25, 50, 75] quantiles test/val loss: [0.1386 0.2423 0.3451]

Epoch 50, loss = 0.2309
Mean test/val loss: 0.2383
[25, 50, 75] quantiles test/val loss: [0.1353 0.2323 0.337 ]

Epoch 52, loss = 0.2196
Mean test/val loss: 0.2289
[25, 50, 75] quantiles test/val loss: [0.1295 0.2292 0.3254]

Epoch 54, loss = 0.2182
Mean test/val loss: 0.2277
[25, 50, 75] quantiles test/val loss: [0.1263 0.2295 0.3213]

Epoch 56, loss = 0.2173
Mean test/val loss: 0.2270
[25, 50, 75] quantiles test/val loss: [0.1249 0.2284 0.3223]

Epoch 58, loss = 0.2166
Mean test/val loss: 0.2272
[25, 50, 75] quantiles test/val loss: [0.125  0.228  0.3237]

Epoch 60, loss = 0.2159
Mean test/val loss: 0.2266
[25, 50, 75] quantiles test/val loss: [0.1269 0.2295 0.3211]

Epoch 62, loss = 0.2152
Mean test/val loss: 0.2266
[25, 50, 75] quantiles test/val loss: [0.1254 0.2278 0.3215]

Epoch 64, loss = 0.2147
Mean test/val loss: 0.2264
[25, 50, 75] quantiles test/val loss: [0.1232 0.2274 0.3211]

Epoch 66, loss = 0.2141
Mean test/val loss: 0.2259
[25, 50, 75] quantiles test/val loss: [0.1272 0.2275 0.3195]

Epoch 68, loss = 0.2136
Mean test/val loss: 0.2258
[25, 50, 75] quantiles test/val loss: [0.123  0.2287 0.3194]

Epoch 70, loss = 0.2131
Mean test/val loss: 0.2257
[25, 50, 75] quantiles test/val loss: [0.1221 0.2289 0.3215]

Epoch 72, loss = 0.2126
Mean test/val loss: 0.2256
[25, 50, 75] quantiles test/val loss: [0.1219 0.2275 0.3212]

Epoch 74, loss = 0.2121
Mean test/val loss: 0.2253
[25, 50, 75] quantiles test/val loss: [0.1216 0.2271 0.3198]

Epoch 76, loss = 0.2117
Mean test/val loss: 0.2253
[25, 50, 75] quantiles test/val loss: [0.1234 0.2278 0.3196]

Epoch 78, loss = 0.2112
Mean test/val loss: 0.2248
[25, 50, 75] quantiles test/val loss: [0.1211 0.2268 0.3189]

Epoch 80, loss = 0.2109
Mean test/val loss: 0.2245
[25, 50, 75] quantiles test/val loss: [0.1223 0.2274 0.3191]

Epoch 82, loss = 0.2105
Mean test/val loss: 0.2247
[25, 50, 75] quantiles test/val loss: [0.1234 0.2272 0.3199]

Epoch 84, loss = 0.2101
Mean test/val loss: 0.2242
[25, 50, 75] quantiles test/val loss: [0.1223 0.2265 0.3177]

Epoch 86, loss = 0.2097
Mean test/val loss: 0.2249
[25, 50, 75] quantiles test/val loss: [0.1229 0.2279 0.3178]

Epoch 88, loss = 0.2094
Mean test/val loss: 0.2241
[25, 50, 75] quantiles test/val loss: [0.1219 0.228  0.3168]

Epoch 90, loss = 0.2090
Mean test/val loss: 0.2239
[25, 50, 75] quantiles test/val loss: [0.1201 0.2252 0.3172]

Epoch 92, loss = 0.2086
Mean test/val loss: 0.2236
[25, 50, 75] quantiles test/val loss: [0.1209 0.2256 0.3176]

Epoch 94, loss = 0.2083
Mean test/val loss: 0.2237
[25, 50, 75] quantiles test/val loss: [0.1217 0.2263 0.3169]

Epoch 96, loss = 0.2079
Mean test/val loss: 0.2234
[25, 50, 75] quantiles test/val loss: [0.1221 0.2253 0.3162]

Epoch 98, loss = 0.2076
Mean test/val loss: 0.2239
[25, 50, 75] quantiles test/val loss: [0.1225 0.2262 0.3145]

Epoch 100, loss = 0.2073
Mean test/val loss: 0.2234
[25, 50, 75] quantiles test/val loss: [0.1217 0.2266 0.3174]


Total parameters: 43346108
Total training + validation time: 9.0 hours, 25.0 mins, and 19.0 secs
Final val loss: 0.22343108059673492

split sizes: train=2160, val=240, test=0, N=2400
#### Plotting Script ####
Prediction Results:
dataset_11_18_22 sample1801: 0.16501140594482422
dataset_11_18_22 sample653: 0.40562471747398376
dataset_11_18_22 sample410: 0.19647108018398285
dataset_11_18_22 sample2290: 0.1949809193611145
dataset_11_18_22 sample1462: 0.11105883121490479
Loss: 0.215 +- 0.1

Downsampling (40%) Results:
dataset_11_18_22 sample1462-downsampling: 8.759921073913574
dataset_11_18_22 sample1801-downsampling: 7.216209888458252
dataset_11_18_22 sample2290-downsampling: 4.268296241760254
dataset_11_18_22 sample410-downsampling: 6.995684623718262
dataset_11_18_22 sample653-downsampling: 12.363237380981445
Loss: 7.921 +- 2.651

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy3downsample
Original sampling (100%) Results:
dataset_11_18_22 sample1462-regular: 8.087087631225586
dataset_11_18_22 sample1801-regular: 7.039183616638184
dataset_11_18_22 sample2290-regular: 4.096743583679199
dataset_11_18_22 sample410-regular: 6.536769866943359
dataset_11_18_22 sample653-regular: 11.697691917419434
Loss: 7.491 +- 2.477

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy3regsample
Upsampling (200%) Results:
dataset_11_18_22 sample1462-upsampling: 8.026482582092285
dataset_11_18_22 sample1801-upsampling: 7.063811779022217
dataset_11_18_22 sample2290-upsampling: 4.080925941467285
dataset_11_18_22 sample410-upsampling: 6.2132568359375
dataset_11_18_22 sample653-upsampling: 12.003335952758789
Loss: 7.478 +- 2.611

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy3upsample
