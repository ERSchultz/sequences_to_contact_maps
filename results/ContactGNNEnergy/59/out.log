Took 989.0 seconds to move data to scratch
#### ARCHITECTURE ####
Sequential(
  (0): Linear(3, 100, bias=True)
  (1): PReLU(num_parameters=1)
  (2): Linear(100, 100, bias=True)
  (3): PReLU(num_parameters=1)
  (4): Linear(100, 16, bias=True)
  (5): PReLU(num_parameters=1)
)
Sequential(
  (0): SignedConv(16, 8, first_aggr=True)
  (1): Linear(16, 100, bias=True)
  (2): PReLU(num_parameters=1)
  (3): Linear(100, 100, bias=True)
  (4): PReLU(num_parameters=1)
  (5): Linear(100, 16, bias=True)
  (6): PReLU(num_parameters=1)
  (7): SignedConv(8, 8, first_aggr=False)
  (8): Linear(16, 100, bias=True)
  (9): PReLU(num_parameters=1)
  (10): Linear(100, 100, bias=True)
  (11): PReLU(num_parameters=1)
  (12): Linear(100, 16, bias=True)
  (13): PReLU(num_parameters=1)
  (14): SignedConv(8, 8, first_aggr=False)
  (15): Linear(16, 100, bias=True)
  (16): PReLU(num_parameters=1)
  (17): Linear(100, 100, bias=True)
  (18): PReLU(num_parameters=1)
  (19): Linear(100, 16, bias=True)
  (20): PReLU(num_parameters=1)
)
Sequential(
  (0): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=32, out_features=100, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (1): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=100, out_features=100, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (2): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=100, out_features=1, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
) 

Namespace(GNN_mode=True, act='prelu', autoencoder_mode=False, batch_size=1, bottleneck=None, channels=1, classes=10, criterion=<function mse_loss at 0x7f2402db8dc0>, crop=None, cuda=True, data_folder='/scratch/midway2/erschultz/dataset_11_14_21', degree=True, delete_root=False, device=device(type='cuda'), dilation_list=None, dilation_list_head=None, dilation_list_trunk=None, down_sampling=None, encoder_hidden_sizes_list=[100, 100, 16], gamma=0.1, gpus=1, head_act='prelu', head_architecture='concat', head_hidden_sizes_list=[100, 100, 1], hidden_sizes_list=[8, 8, 8], id=59, ifile=None, ifile_folder=None, inner_act='prelu', k=2, kernel_w_list=None, log_file=<_io.TextIOWrapper name='results/ContactGNNEnergy/59/out.log' mode='a' encoding='UTF-8'>, loss='mse', lr=1e-05, m=1024, message_passing='SignedConv', milestones=None, min_subtraction=True, model_type='ContactGNNEnergy', n_epochs=100, nf=None, node_feature_size=3, num_workers=4, ofile_folder='results/ContactGNNEnergy/59', out_act='prelu', output_mode='energy', param_file=<_io.TextIOWrapper name='results/ContactGNNEnergy/59/params.log' mode='a' encoding='UTF-8'>, parameter_sharing=False, plot=True, plot_predictions=True, pre_transforms=['degree'], pre_transforms_processed=None, pretrained=False, print_mod=2, print_params=True, relabel_11_to_00=False, resume_training=False, root_name='ContactGNNEnergy3', save_mod=5, scratch='/scratch/midway2/erschultz', seed=42, shuffle=True, sparsify_threshold=0.176, sparsify_threshold_upper=None, split=[0.8, 0.1, 0.1], split_neg_pos_edges=True, split_neg_pos_edges_for_feature_augmentation=True, start_epoch=1, top_k=None, toxx=False, toxx_mode='mean', training_norm=None, transforms=None, transforms_processed=None, update_hidden_sizes_list=[100, 100, 16], use_bias=True, use_edge_weights=False, use_node_features=False, use_parallel=False, use_scratch=True, verbose=False, weighted_LDP=False, weighted_degree=False, x_reshape=True, y_log_transform=True, y_norm=None, y_preprocessing='diag', y_reshape=True, ydtype=torch.float32)

Dataset construction time: 16.881 minutes
Mean degree: [308.85 326.1  341.5  ... 348.04 352.85 328.51] +- [64.06 67.87 68.24 ... 72.57 76.24 72.96]

#### TRAINING/VALIDATION ####
Epoch 2, loss = 32.5558
Mean test/val loss: 32.7659

Epoch 4, loss = 32.1433
Mean test/val loss: 32.0815

Epoch 6, loss = 25.8655
Mean test/val loss: 19.6321

Epoch 8, loss = 18.8903
Mean test/val loss: 18.9249

Epoch 10, loss = 18.5595
Mean test/val loss: 18.5942

Epoch 12, loss = 18.3157
Mean test/val loss: 18.3996

Epoch 14, loss = 18.1553
Mean test/val loss: 18.2673

Epoch 16, loss = 18.0695
Mean test/val loss: 18.1608

Epoch 18, loss = 17.9930
Mean test/val loss: 18.0718

Epoch 20, loss = 17.9213
Mean test/val loss: 18.0344

Epoch 22, loss = 17.8627
Mean test/val loss: 18.2093

Epoch 24, loss = 17.7956
Mean test/val loss: 17.9100

Epoch 26, loss = 17.7424
Mean test/val loss: 17.8708

Epoch 28, loss = 17.6836
Mean test/val loss: 17.7872

Epoch 30, loss = 17.6324
Mean test/val loss: 17.7277

Epoch 32, loss = 17.5964
Mean test/val loss: 17.6855

Epoch 34, loss = 17.5447
Mean test/val loss: 17.6321

Epoch 36, loss = 17.5075
Mean test/val loss: 17.5980

Epoch 38, loss = 17.4720
Mean test/val loss: 17.5831

Epoch 40, loss = 17.4247
Mean test/val loss: 17.5049

Epoch 42, loss = 17.3761
Mean test/val loss: 17.4552

Epoch 44, loss = 17.3153
Mean test/val loss: 17.4285

Epoch 46, loss = 17.2459
Mean test/val loss: 17.3359

Epoch 48, loss = 17.1763
Mean test/val loss: 17.2545

Epoch 50, loss = 17.1039
Mean test/val loss: 17.1690

Epoch 52, loss = 17.0139
Mean test/val loss: 17.0999

Epoch 54, loss = 16.9101
Mean test/val loss: 16.9742

Epoch 56, loss = 16.8250
Mean test/val loss: 16.9169

Epoch 58, loss = 16.7637
Mean test/val loss: 16.8345

Epoch 60, loss = 16.7088
Mean test/val loss: 16.7832

Epoch 62, loss = 16.6606
Mean test/val loss: 16.7800

Epoch 64, loss = 16.6169
Mean test/val loss: 16.6948

Epoch 66, loss = 16.5793
Mean test/val loss: 16.6581

Epoch 68, loss = 16.5328
Mean test/val loss: 16.6270

Epoch 70, loss = 16.5097
Mean test/val loss: 16.8439

Epoch 72, loss = 16.4593
Mean test/val loss: 16.5426

Epoch 74, loss = 16.4184
Mean test/val loss: 16.5327

Epoch 76, loss = 16.3813
Mean test/val loss: 16.5165

Epoch 78, loss = 16.3384
Mean test/val loss: 16.4373

Epoch 80, loss = 16.2878
Mean test/val loss: 16.4643

Epoch 82, loss = 16.2527
Mean test/val loss: 16.3662

Epoch 84, loss = 16.2061
Mean test/val loss: 16.2955

Epoch 86, loss = 16.1683
Mean test/val loss: 16.3222

Epoch 88, loss = 16.1402
Mean test/val loss: 16.3159

Epoch 90, loss = 16.0769
Mean test/val loss: 16.1781

Epoch 92, loss = 16.0576
Mean test/val loss: 16.3923

Epoch 94, loss = 16.0229
Mean test/val loss: 16.1589

Epoch 96, loss = 15.9969
Mean test/val loss: 16.0790

Epoch 98, loss = 15.9664
Mean test/val loss: 16.3386

Epoch 100, loss = 15.9314
Mean test/val loss: 16.1802


Total parameters: 67,197
Total training + validation time: 8.0 hours
Final val loss: 16.18022126197815

#### Plotting Script ####
Prediction Results:
results/ContactGNNEnergy/59/sample1230: 15.981864929199219
results/ContactGNNEnergy/59/sample1761: 17.075748443603516
results/ContactGNNEnergy/59/sample40: 14.214750289916992
results/ContactGNNEnergy/59/sample1751: 18.787662506103516
results/ContactGNNEnergy/59/sample1718: 15.922590255737305
Loss: 16.39652328491211 +- 1.505694594605061

