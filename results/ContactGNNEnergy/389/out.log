#### ARCHITECTURE ####
Node Encoder:
 Sequential(
  (0): Linear(2, 64, bias=True)
  (1): PReLU(num_parameters=1)
) 

Edge Encoder:
 None 

Linear:
 Linear(in_features=72, out_features=64, bias=True) 

Model:
 Sequential(
  (0): WeightedGATv2Conv(64, 8, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (2): WeightedGATv2Conv(64, 8, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (4): WeightedGATv2Conv(64, 8, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (6): WeightedGATv2Conv(64, 8, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
) 

Head L:
 None 
 Bilinear 

Head D:
 None 
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=16384, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=512, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['GridSize', 'constant', 'ContactDistance', 'GeneticDistance_norm', 'AdjPCs_8'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project2/depablo/erschultz/dataset_03_01_23'], scratch='/scratch/midway3/erschultz', root_name='ContactGNNEnergy5', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', y_zero_diag_count=0, log_preprocessing=None, output_preprocesing=None, kr=False, mean_filt=None, rescale=2, gated=False, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, move_data_to_scratch=False, use_scratch_parallel=False, plaid_score_cutoff=None, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.0001, min_lr=1e-06, weight_decay=0.0, gpus=1, scheduler='MultiStepLR', milestones=[50], gamma=0.1, patience=10, loss='mse', w_reg=None, reg_lambda=0.1, autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_sym_diag', model_type='ContactGNNEnergy', id=389, pretrain_id=None, resume_training=False, k=8, m=512, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, use_sign_net=False, use_sign_plus=True, message_passing='weighted_GAT', head_architecture='bilinear', head_architecture_2='fc-fill_512', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000], encoder_hidden_sizes_list=[64], inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/389', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/389/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/389/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/389/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7f0bb268a310>, channels=1, node_feature_size=2, input_m=256, edge_transforms=["'ContactDistance'", 'ContactDistance(norm=False)', 'GeneticDistance(norm=True)'], node_transforms=['AdjPCs(k=8, normalize=False, sign_net=True)', 'Constant(value=1.0)', 'GridSize'], edge_dim=2, transforms_processed=None, diag=True, pre_transforms_processed=Compose([
  GridSize,
  Constant(value=1.0),
  ContactDistance(norm=False),
  GeneticDistance(norm=True),
  AdjPCs(k=8, normalize=False, sign_net=True)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 17.084 minutes
Number of samples: 5000
Average num edges per graph:  56704.524
Mean degree: [213.41 216.55 254.66 ... 131.15 191.38 139.77] +- [28.69 29.56  2.17 ... 56.93 37.85 46.18]

split sizes: train=4500, val=500, test=0, N=5000
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f0b7855c610>
#### TRAINING/VALIDATION ####
Epoch 2, loss = 9.4260
Mean test/val loss: 9.1402
[25, 50, 75] percentiles test/val loss: [3.4616 5.2742 8.8854]

Epoch 4, loss = 8.6214
Mean test/val loss: 9.1569
[25, 50, 75] percentiles test/val loss: [ 3.6718  5.529  10.0652]

Epoch 6, loss = 8.3367
Mean test/val loss: 8.5499
[25, 50, 75] percentiles test/val loss: [3.1783 5.1407 9.0774]

Epoch 8, loss = 7.8438
Mean test/val loss: 7.6829
[25, 50, 75] percentiles test/val loss: [3.1518 5.01   8.33  ]

Epoch 10, loss = 7.5701
Mean test/val loss: 7.7030
[25, 50, 75] percentiles test/val loss: [2.9801 4.6699 8.1465]

Epoch 12, loss = 7.1779
Mean test/val loss: 6.7748
[25, 50, 75] percentiles test/val loss: [3.1705 4.3161 7.2558]

Epoch 14, loss = 6.8100
Mean test/val loss: 6.5197
[25, 50, 75] percentiles test/val loss: [2.9445 4.1901 6.82  ]

Epoch 16, loss = 6.6268
Mean test/val loss: 6.2854
[25, 50, 75] percentiles test/val loss: [2.5955 4.1457 6.9778]

Epoch 18, loss = 6.1983
Mean test/val loss: 5.6627
[25, 50, 75] percentiles test/val loss: [2.7637 3.9826 6.4744]

Epoch 20, loss = 6.0499
Mean test/val loss: 5.7132
[25, 50, 75] percentiles test/val loss: [2.859  4.2159 6.3096]

Epoch 22, loss = 5.5101
Mean test/val loss: 5.3877
[25, 50, 75] percentiles test/val loss: [2.4144 3.7895 6.4935]

Epoch 24, loss = 5.2748
Mean test/val loss: 4.9232
[25, 50, 75] percentiles test/val loss: [2.5283 3.5859 5.6452]

Epoch 26, loss = 5.0476
Mean test/val loss: 5.1933
[25, 50, 75] percentiles test/val loss: [2.6416 3.7826 5.9235]

Epoch 28, loss = 4.8926
Mean test/val loss: 4.7561
[25, 50, 75] percentiles test/val loss: [2.3649 3.5545 5.6638]

Epoch 30, loss = 4.7701
Mean test/val loss: 4.8104
[25, 50, 75] percentiles test/val loss: [2.2429 3.5881 5.4695]

Epoch 32, loss = 4.6514
Mean test/val loss: 5.4880
[25, 50, 75] percentiles test/val loss: [2.3028 3.6025 6.1253]

Epoch 34, loss = 4.6222
Mean test/val loss: 6.1649
[25, 50, 75] percentiles test/val loss: [2.2875 3.6653 5.908 ]

Epoch 36, loss = 6.0990
Mean test/val loss: 5.4677
[25, 50, 75] percentiles test/val loss: [2.6007 3.8443 6.1432]

Epoch 38, loss = 4.3644
Mean test/val loss: 4.5312
[25, 50, 75] percentiles test/val loss: [2.0903 3.1739 5.1817]

Epoch 40, loss = 4.3382
Mean test/val loss: 5.0727
[25, 50, 75] percentiles test/val loss: [2.167  3.3044 5.4452]

Epoch 42, loss = 4.2507
Mean test/val loss: 4.5081
[25, 50, 75] percentiles test/val loss: [2.1638 3.1749 4.9522]

Epoch 44, loss = 4.6860
Mean test/val loss: 4.9583
[25, 50, 75] percentiles test/val loss: [2.552  3.7316 5.7444]

Epoch 46, loss = 4.1784
Mean test/val loss: 4.3329
[25, 50, 75] percentiles test/val loss: [2.1118 3.1827 4.946 ]

Epoch 48, loss = 4.1699
Mean test/val loss: 4.7443
[25, 50, 75] percentiles test/val loss: [2.2894 3.3349 5.4684]

Epoch 50, loss = 3.9710
Mean test/val loss: 4.7354
[25, 50, 75] percentiles test/val loss: [2.4571 3.4384 5.4166]

New lr: 1e-05
Epoch 52, loss = 3.3876
Mean test/val loss: 3.9960
[25, 50, 75] percentiles test/val loss: [2.0187 2.9585 4.711 ]

Epoch 54, loss = 3.3044
Mean test/val loss: 3.9461
[25, 50, 75] percentiles test/val loss: [1.9279 2.8468 4.5324]

Epoch 56, loss = 3.2531
Mean test/val loss: 3.9308
[25, 50, 75] percentiles test/val loss: [1.901  2.8572 4.449 ]

Epoch 58, loss = 3.2140
Mean test/val loss: 3.8959
[25, 50, 75] percentiles test/val loss: [1.8962 2.8153 4.4553]

Epoch 60, loss = 3.1776
Mean test/val loss: 3.9021
[25, 50, 75] percentiles test/val loss: [1.843  2.7999 4.4183]

Epoch 62, loss = 3.1453
Mean test/val loss: 3.9134
[25, 50, 75] percentiles test/val loss: [1.9371 2.8393 4.5436]

Epoch 64, loss = 3.1134
Mean test/val loss: 3.8656
[25, 50, 75] percentiles test/val loss: [1.8173 2.8024 4.3947]

Epoch 66, loss = 3.0854
Mean test/val loss: 3.9230
[25, 50, 75] percentiles test/val loss: [1.803  2.7646 4.4999]

Epoch 68, loss = 3.0577
Mean test/val loss: 3.8618
[25, 50, 75] percentiles test/val loss: [1.8213 2.7719 4.43  ]

Epoch 70, loss = 3.0312
Mean test/val loss: 3.8473
[25, 50, 75] percentiles test/val loss: [1.8188 2.7639 4.3028]

Epoch 72, loss = 3.0052
Mean test/val loss: 3.8654
[25, 50, 75] percentiles test/val loss: [1.8028 2.7267 4.3704]

Epoch 74, loss = 2.9799
Mean test/val loss: 3.8595
[25, 50, 75] percentiles test/val loss: [1.815  2.7339 4.35  ]

Epoch 76, loss = 2.9567
Mean test/val loss: 3.8732
[25, 50, 75] percentiles test/val loss: [1.8027 2.6963 4.3077]

Epoch 78, loss = 2.9340
Mean test/val loss: 3.8229
[25, 50, 75] percentiles test/val loss: [1.7851 2.7326 4.3248]

Epoch 80, loss = 2.9099
Mean test/val loss: 3.8287
[25, 50, 75] percentiles test/val loss: [1.8293 2.7041 4.2942]

Epoch 82, loss = 2.8863
Mean test/val loss: 3.8020
[25, 50, 75] percentiles test/val loss: [1.7895 2.6975 4.2692]

Epoch 84, loss = 2.8647
Mean test/val loss: 3.7840
[25, 50, 75] percentiles test/val loss: [1.7771 2.6564 4.3293]

Epoch 86, loss = 2.8424
Mean test/val loss: 3.8153
[25, 50, 75] percentiles test/val loss: [1.7741 2.7023 4.3597]

Epoch 88, loss = 2.8202
Mean test/val loss: 3.8207
[25, 50, 75] percentiles test/val loss: [1.7599 2.7043 4.2882]

Epoch 90, loss = 2.8004
Mean test/val loss: 3.7970
[25, 50, 75] percentiles test/val loss: [1.77   2.7048 4.3801]

Epoch 92, loss = 2.7815
Mean test/val loss: 3.7615
[25, 50, 75] percentiles test/val loss: [1.7204 2.6334 4.2189]

Epoch 94, loss = 2.7612
Mean test/val loss: 3.8253
[25, 50, 75] percentiles test/val loss: [1.7516 2.6896 4.393 ]

Epoch 96, loss = 2.7420
Mean test/val loss: 3.7759
[25, 50, 75] percentiles test/val loss: [1.7408 2.6946 4.3179]

Epoch 98, loss = 2.7212
Mean test/val loss: 3.7439
[25, 50, 75] percentiles test/val loss: [1.7689 2.6533 4.2979]

Epoch 100, loss = 2.7026
Mean test/val loss: 3.7889
[25, 50, 75] percentiles test/val loss: [1.7404 2.6684 4.3475]


Total parameters: 26466036
Total training + validation time: 9.0 hours, 1.0 mins, and 0.7999999999992724 secs
Final val loss: 3.788928156852722

split sizes: train=4500, val=500, test=0, N=5000
#### Plotting Script ####
Prediction Results:
dataset_03_01_23 sample981: 1.4453675746917725
dataset_03_01_23 sample324: 1.6309230327606201
dataset_03_01_23 sample3464: 2.2280666828155518
dataset_03_01_23 sample2834: 3.660551071166992
dataset_03_01_23 sample1936: 7.8138580322265625
Loss: 3.356 +- 2.361

Downsampling (40%) Results:
dataset_03_01_23 sample1936-downsampling: 7.813858985900879
dataset_03_01_23 sample2834-downsampling: 3.9024360179901123
dataset_03_01_23 sample324-downsampling: 1.853727102279663
dataset_03_01_23 sample3464-downsampling: 1.9641058444976807
dataset_03_01_23 sample981-downsampling: 1.618272304534912
Loss: 3.43 +- 2.339

Removing /scratch/midway3/erschultz/ContactGNNEnergy5downsample
Original sampling (100%) Results:
dataset_03_01_23 sample1936-regular: 6.516014575958252
dataset_03_01_23 sample2834-regular: 3.7093381881713867
dataset_03_01_23 sample324-regular: 1.6171988248825073
dataset_03_01_23 sample3464-regular: 2.228066921234131
dataset_03_01_23 sample981-regular: 1.4225938320159912
Loss: 3.099 +- 1.887

Removing /scratch/midway3/erschultz/ContactGNNEnergy5regsample
Upsampling (200%) Results:
