Took 56.0 seconds to move data to scratch
#### ARCHITECTURE ####
Sequential(
  (0): Linear(3, 100, bias=True)
  (1): PReLU(num_parameters=1)
  (2): Linear(100, 100, bias=True)
  (3): PReLU(num_parameters=1)
  (4): Linear(100, 16, bias=True)
  (5): PReLU(num_parameters=1)
)
Sequential(
  (0): SignedConv(16, 8, first_aggr=True)
  (1): Linear(16, 100, bias=True)
  (2): PReLU(num_parameters=1)
  (3): Linear(100, 100, bias=True)
  (4): PReLU(num_parameters=1)
  (5): Linear(100, 16, bias=True)
  (6): PReLU(num_parameters=1)
  (7): SignedConv(8, 8, first_aggr=False)
  (8): Linear(16, 100, bias=True)
  (9): PReLU(num_parameters=1)
  (10): Linear(100, 100, bias=True)
  (11): PReLU(num_parameters=1)
  (12): Linear(100, 16, bias=True)
  (13): PReLU(num_parameters=1)
  (14): SignedConv(8, 8, first_aggr=False)
  (15): Linear(16, 100, bias=True)
  (16): PReLU(num_parameters=1)
  (17): Linear(100, 100, bias=True)
  (18): PReLU(num_parameters=1)
  (19): Linear(100, 16, bias=True)
  (20): PReLU(num_parameters=1)
)
Sequential(
  (0): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=32, out_features=100, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (1): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=100, out_features=100, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
  (2): LinearBlock(
    (model): Sequential(
      (0): Linear(in_features=100, out_features=1, bias=True)
      (1): PReLU(num_parameters=1)
    )
  )
) 

Namespace(GNN_mode=True, act='prelu', autoencoder_mode=False, batch_size=1, bottleneck=None, channels=1, classes=10, criterion=<function mse_loss at 0x7f14f0f2d3a0>, crop=None, cuda=True, data_folder='/scratch/midway2/erschultz/dataset_01_17_22', degree=True, delete_root=False, device=device(type='cuda'), dilation_list=None, dilation_list_head=None, dilation_list_trunk=None, down_sampling=None, encoder_hidden_sizes_list=[100, 100, 16], gamma=0.1, gpus=1, head_act='prelu', head_architecture='concat', head_hidden_sizes_list=[100, 100, 1], hidden_sizes_list=[8, 8, 8], id=72, ifile=None, ifile_folder=None, inner_act='prelu', k=2, kernel_w_list=None, log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/72/out.log' mode='a' encoding='UTF-8'>, log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/72/out.log', loss='mse', lr=0.0001, m=1024, message_passing='SignedConv', milestones=None, min_subtraction=True, model_type='ContactGNNEnergy', n_epochs=100, nf=None, node_feature_size=3, num_workers=4, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/72', out_act='prelu', output_mode='energy', param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/72/params.log' mode='a' encoding='UTF-8'>, parameter_sharing=False, plot=True, plot_predictions=True, pre_transforms=['degree'], pre_transforms_processed=None, pretrained=False, print_mod=2, print_params=True, random_split=False, relabel_11_to_00=False, resume_training=False, root_name='ContactGNNEnergy1', save_mod=5, scratch='/scratch/midway2/erschultz', seed=42, shuffle=True, sparsify_threshold=0.176, sparsify_threshold_upper=None, split_neg_pos_edges=True, split_neg_pos_edges_for_feature_augmentation=True, split_percents=None, split_sizes=[1000, 200, 0], start_epoch=1, top_k=None, toxx=False, toxx_mode='mean', training_norm=None, transforms=None, transforms_processed=None, update_hidden_sizes_list=[100, 100, 16], use_bias=True, use_edge_weights=False, use_node_features=False, use_parallel=False, use_scratch=True, verbose=False, weighted_LDP=False, weighted_degree=False, x_reshape=True, y_log_transform=True, y_norm=None, y_preprocessing='diag', y_reshape=True, ydtype=torch.float32)

Dataset construction time: 303.634 minutes
Mean degree: [790.61 345.01 627.84 ... 708.24 764.45 812.16] +- [132.49  95.2  140.36 ... 150.46 152.31 124.44]

#### TRAINING/VALIDATION ####
Epoch 2, loss = 1.8031
Mean test/val loss: 1.7330

Epoch 4, loss = 1.7346
Mean test/val loss: 1.6350

Epoch 6, loss = 1.6546
Mean test/val loss: 1.5917

Epoch 8, loss = 1.6286
Mean test/val loss: 1.5625

Epoch 10, loss = 1.5999
Mean test/val loss: 1.5401

Epoch 12, loss = 1.5623
Mean test/val loss: 1.5181

Epoch 14, loss = 1.5424
Mean test/val loss: 1.5131

Epoch 16, loss = 1.5222
Mean test/val loss: 1.4956

Epoch 18, loss = 1.5081
Mean test/val loss: 1.4779

Epoch 20, loss = 1.5025
Mean test/val loss: 1.4655

Epoch 22, loss = 1.4883
Mean test/val loss: 1.4774

Epoch 24, loss = 1.4768
Mean test/val loss: 1.4565

Epoch 26, loss = 1.4670
Mean test/val loss: 1.4391

Epoch 28, loss = 1.4554
Mean test/val loss: 1.4302

Epoch 30, loss = 1.4478
Mean test/val loss: 1.4265

Epoch 32, loss = 1.4302
Mean test/val loss: 1.3962

Epoch 34, loss = 1.4207
Mean test/val loss: 1.4042

Epoch 36, loss = 1.4131
Mean test/val loss: 1.3905

Epoch 38, loss = 1.3975
Mean test/val loss: 1.4143

Epoch 40, loss = 1.3917
Mean test/val loss: 1.3755

Epoch 42, loss = 1.3834
Mean test/val loss: 1.3661

Epoch 44, loss = 1.3739
Mean test/val loss: 1.3557

Epoch 46, loss = 1.3689
Mean test/val loss: 1.3491

Epoch 48, loss = 1.3621
Mean test/val loss: 1.3394

Epoch 50, loss = 1.3546
Mean test/val loss: 1.3342

Epoch 52, loss = 1.3454
Mean test/val loss: 1.3272

Epoch 54, loss = 1.3403
Mean test/val loss: 1.3645

Epoch 56, loss = 1.3378
Mean test/val loss: 1.3242

Epoch 58, loss = 1.3303
Mean test/val loss: 1.3463

Epoch 60, loss = 1.3234
Mean test/val loss: 1.3134

Epoch 62, loss = 1.3222
Mean test/val loss: 1.3561

Epoch 64, loss = 1.3197
Mean test/val loss: 1.3140

Epoch 66, loss = 1.3144
Mean test/val loss: 1.3433

Epoch 68, loss = 1.3150
Mean test/val loss: 1.3099

Epoch 70, loss = 1.3104
Mean test/val loss: 1.3860

Epoch 72, loss = 1.3073
Mean test/val loss: 1.3455

Epoch 74, loss = 1.3008
Mean test/val loss: 1.3263

Epoch 76, loss = 1.2990
Mean test/val loss: 1.2956

Epoch 78, loss = 1.2980
Mean test/val loss: 1.2943

Epoch 80, loss = 1.2920
Mean test/val loss: 1.2881

Epoch 82, loss = 1.2890
Mean test/val loss: 1.2902

Epoch 84, loss = 1.2888
Mean test/val loss: 1.2882

Epoch 86, loss = 1.2862
Mean test/val loss: 1.2826

Epoch 88, loss = 1.2827
Mean test/val loss: 1.2969

Epoch 90, loss = 1.2838
Mean test/val loss: 1.2721

Epoch 92, loss = 1.2747
Mean test/val loss: 1.2728

Epoch 94, loss = 1.2764
Mean test/val loss: 1.2832

Epoch 96, loss = 1.2738
Mean test/val loss: 1.2963

Epoch 98, loss = 1.2716
Mean test/val loss: 1.2610

Epoch 100, loss = 1.2694
Mean test/val loss: 1.2611


Total parameters: 67,197
Total training + validation time: 19.0 hours
Final val loss: 1.2610915970802308

#### Plotting Script ####
Prediction Results:
/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/72/sample1: 1.8059477806091309
/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/72/sample2: 0.9769160747528076
/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/72/sample3: 1.0753579139709473
/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/72/sample4: 0.8049957752227783
/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/72/sample5: 1.4520080089569092
Loss: 1.2230451107025146 +- 0.3603764111792901

