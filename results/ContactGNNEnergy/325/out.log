#### ARCHITECTURE ####
Node Encoder:
 None 

Edge Encoder:
 None 

Model:
 Sequential(
  (0): WeightedGATv2Conv(1, 8, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (2): WeightedGATv2Conv(64, 8, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (4): WeightedGATv2Conv(64, 8, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (6): WeightedGATv2Conv(64, 8, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
) 

Head 1:
 Bilinear 

Head 2:
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=32768, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1024, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['constant', 'ContactDistance', 'GeneticDistance_norm'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project2/depablo/erschultz/dataset_11_18_22', '/project2/depablo/erschultz/dataset_11_21_22'], scratch='/scratch/midway2/erschultz', root_name='ContactGNNEnergy1', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', y_zero_diag_count=0, log_preprocessing=None, output_preprocesing=None, kr=False, mean_filt=None, rescale=2, gated=False, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=False, use_scratch_parallel=True, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.0001, weight_decay=0.0, gpus=1, milestones=[50], gamma=0.1, loss='mse', w_reg='l1', reg_lambda=100.0, autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_sym_diag', model_type='ContactGNNEnergy', id=325, pretrained=False, resume_training=False, k=None, m=1024, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, message_passing='weighted_GAT', head_architecture='bilinear_triu', head_architecture_2='fc-fill', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000, 1024], encoder_hidden_sizes_list=None, inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/325', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/325/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/325/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/325/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7f5d0a453a60>, channels=1, node_feature_size=1, input_m=512, edge_transforms=["'ContactDistance'", 'ContactDistance(norm=False)', 'GeneticDistance(norm=True)'], node_transforms=['Constant(value=1.0)'], edge_dim=2, transforms_processed=None, diag=False, pre_transforms_processed=Compose([
  Constant(value=1.0),
  ContactDistance(norm=False),
  GeneticDistance(norm=True)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 0.086 minutes
Average num edges per graph:  nan
split sizes: train=4302, val=478, test=0, N=4780
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
#### TRAINING/VALIDATION ####
Epoch 2, loss = 22.1753
Mean test/val loss: 17.5964
[25, 50, 75] quantiles test/val loss: [ 8.4878 13.4118 21.8885]

Epoch 4, loss = 21.7184
Mean test/val loss: 18.0272
[25, 50, 75] quantiles test/val loss: [ 9.3444 14.284  23.1803]

Epoch 6, loss = 22.0126
Mean test/val loss: 16.9988
[25, 50, 75] quantiles test/val loss: [ 9.0251 12.8936 20.5182]

Epoch 8, loss = 21.0278
Mean test/val loss: 18.8297
[25, 50, 75] quantiles test/val loss: [ 8.0195 12.9325 21.9778]

Epoch 10, loss = 20.7606
Mean test/val loss: 17.2183
[25, 50, 75] quantiles test/val loss: [ 7.4276 12.3261 20.9256]

Epoch 12, loss = 20.4907
Mean test/val loss: 19.7671
[25, 50, 75] quantiles test/val loss: [ 7.6531 12.5543 22.1672]

Epoch 14, loss = 20.4296
Mean test/val loss: 18.6263
[25, 50, 75] quantiles test/val loss: [10.432  15.2567 22.8153]

Epoch 16, loss = 20.1068
Mean test/val loss: 16.8377
[25, 50, 75] quantiles test/val loss: [ 8.2365 12.5906 20.8132]

Epoch 18, loss = 19.8384
Mean test/val loss: 16.1306
[25, 50, 75] quantiles test/val loss: [ 7.4342 12.1459 20.7385]

Epoch 20, loss = 19.7352
Mean test/val loss: 15.9363
[25, 50, 75] quantiles test/val loss: [ 7.1857 12.0891 20.336 ]

Epoch 22, loss = 19.6231
Mean test/val loss: 16.0734
[25, 50, 75] quantiles test/val loss: [ 7.3819 12.119  20.4553]

Epoch 24, loss = 19.5205
Mean test/val loss: 15.8872
[25, 50, 75] quantiles test/val loss: [ 7.3033 12.0402 20.2546]

Epoch 26, loss = 19.4645
Mean test/val loss: 16.2029
[25, 50, 75] quantiles test/val loss: [ 7.4616 12.3772 20.96  ]

Epoch 28, loss = 19.4963
Mean test/val loss: 16.0476
[25, 50, 75] quantiles test/val loss: [ 7.4465 12.1905 20.5348]

Epoch 30, loss = 19.3487
Mean test/val loss: 16.0712
[25, 50, 75] quantiles test/val loss: [ 7.405  11.9238 20.4156]

Epoch 32, loss = 19.3064
Mean test/val loss: 15.8611
[25, 50, 75] quantiles test/val loss: [ 7.194  11.9876 20.4548]

Epoch 34, loss = 19.3319
Mean test/val loss: 15.9162
[25, 50, 75] quantiles test/val loss: [ 7.1301 12.0509 20.3584]

Epoch 36, loss = 19.2409
Mean test/val loss: 15.9841
[25, 50, 75] quantiles test/val loss: [ 7.2022 12.0174 20.4064]

Epoch 38, loss = 19.1935
Mean test/val loss: 16.1809
[25, 50, 75] quantiles test/val loss: [ 7.6091 12.252  20.7455]

Epoch 40, loss = 19.1610
Mean test/val loss: 16.0106
[25, 50, 75] quantiles test/val loss: [ 7.2536 12.0275 20.4018]

Epoch 42, loss = 19.2292
Mean test/val loss: 15.9380
[25, 50, 75] quantiles test/val loss: [ 7.1719 12.0938 20.3099]

Epoch 44, loss = 19.1946
Mean test/val loss: 15.9191
[25, 50, 75] quantiles test/val loss: [ 7.1716 11.9423 20.4001]

Epoch 46, loss = 19.2239
Mean test/val loss: 15.9481
[25, 50, 75] quantiles test/val loss: [ 7.2594 12.1601 20.5739]

Epoch 48, loss = 19.1387
Mean test/val loss: 16.1898
[25, 50, 75] quantiles test/val loss: [ 7.4688 11.9582 20.5272]

Epoch 50, loss = 19.1926
Mean test/val loss: 15.9510
[25, 50, 75] quantiles test/val loss: [ 7.1398 11.9433 20.3636]

Epoch 52, loss = 14.9637
Mean test/val loss: 15.7743
[25, 50, 75] quantiles test/val loss: [ 7.0838 11.7876 20.2993]

Epoch 54, loss = 14.9349
Mean test/val loss: 15.7918
[25, 50, 75] quantiles test/val loss: [ 7.0759 11.8073 20.2656]

Epoch 56, loss = 14.9180
Mean test/val loss: 15.7663
[25, 50, 75] quantiles test/val loss: [ 7.071  11.7854 20.2586]

Epoch 58, loss = 14.9095
Mean test/val loss: 15.7699
[25, 50, 75] quantiles test/val loss: [ 7.0648 11.7316 20.2794]

Epoch 60, loss = 14.8957
Mean test/val loss: 15.8218
[25, 50, 75] quantiles test/val loss: [ 6.9887 11.7679 20.3014]

Epoch 62, loss = 14.8907
Mean test/val loss: 15.7653
[25, 50, 75] quantiles test/val loss: [ 7.0102 11.7615 20.2946]

Epoch 64, loss = 14.8852
Mean test/val loss: 15.7554
[25, 50, 75] quantiles test/val loss: [ 7.0361 11.7467 20.2614]

Epoch 66, loss = 14.8778
Mean test/val loss: 15.7564
[25, 50, 75] quantiles test/val loss: [ 7.0361 11.7609 20.2586]

Epoch 68, loss = 14.8735
Mean test/val loss: 15.7657
[25, 50, 75] quantiles test/val loss: [ 7.0231 11.7478 20.2725]

Epoch 70, loss = 14.8710
Mean test/val loss: 15.8017
[25, 50, 75] quantiles test/val loss: [ 6.99   11.7641 20.3209]

Epoch 72, loss = 14.8630
Mean test/val loss: 15.7901
[25, 50, 75] quantiles test/val loss: [ 7.2249 11.741  20.2519]

Epoch 74, loss = 14.8597
Mean test/val loss: 15.7790
[25, 50, 75] quantiles test/val loss: [ 7.0303 11.7721 20.255 ]

Epoch 76, loss = 14.8625
Mean test/val loss: 15.7654
[25, 50, 75] quantiles test/val loss: [ 7.0125 11.7549 20.2531]

Epoch 78, loss = 14.8584
Mean test/val loss: 15.7606
[25, 50, 75] quantiles test/val loss: [ 7.0129 11.746  20.2657]

Epoch 80, loss = 14.8563
Mean test/val loss: 15.7738
[25, 50, 75] quantiles test/val loss: [ 7.0043 11.772  20.2374]

Epoch 82, loss = 14.8527
Mean test/val loss: 15.7797
[25, 50, 75] quantiles test/val loss: [ 7.0186 11.7714 20.2522]

Epoch 84, loss = 14.8520
Mean test/val loss: 15.7856
[25, 50, 75] quantiles test/val loss: [ 7.1046 11.7513 20.254 ]

Epoch 86, loss = 14.8489
Mean test/val loss: 15.7828
[25, 50, 75] quantiles test/val loss: [ 7.0352 11.7362 20.2664]

Epoch 88, loss = 14.8457
Mean test/val loss: 15.7753
[25, 50, 75] quantiles test/val loss: [ 7.0491 11.7457 20.2537]

Epoch 90, loss = 14.8443
Mean test/val loss: 15.7692
[25, 50, 75] quantiles test/val loss: [ 7.1133 11.746  20.236 ]

Epoch 92, loss = 14.8419
Mean test/val loss: 15.8664
[25, 50, 75] quantiles test/val loss: [ 7.2005 11.813  20.3855]

Epoch 94, loss = 14.8393
Mean test/val loss: 15.7797
[25, 50, 75] quantiles test/val loss: [ 7.0274 11.7266 20.2315]

Epoch 96, loss = 14.8345
Mean test/val loss: 15.7795
[25, 50, 75] quantiles test/val loss: [ 7.0808 11.7399 20.2232]

Epoch 98, loss = 14.8356
Mean test/val loss: 15.7710
[25, 50, 75] quantiles test/val loss: [ 7.0222 11.7508 20.2356]

Epoch 100, loss = 14.8317
Mean test/val loss: 15.7721
[25, 50, 75] quantiles test/val loss: [ 7.018  11.7338 20.2283]


Total parameters: 43347604
Total training + validation time: 20.0 hours, 12.0 mins, and 8.60000000000582 secs
Final val loss: 15.772055676604415

split sizes: train=4302, val=478, test=0, N=4780
#### Plotting Script ####
Prediction Results:
dataset_11_21_22 sample939: 13.843441009521484
dataset_11_18_22 sample203: 17.364482879638672
dataset_11_21_22 sample743: 23.78985595703125
dataset_11_21_22 sample45: 4.563004970550537
dataset_11_18_22 sample559: 8.541045188903809
Loss: 13.62 +- 6.713

Downsampling (40%) Results:
dataset_11_18_22 sample203-downsampling: 18.112262725830078
dataset_11_18_22 sample45-downsampling: 61.166744232177734
dataset_11_18_22 sample559-downsampling: 8.541045188903809
dataset_11_18_22 sample743-downsampling: 28.34186553955078
dataset_11_18_22 sample939-downsampling: 8.208457946777344
Loss: 17.352 +- 16.888

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy1downsample
Original sampling (100%) Results:
dataset_11_18_22 sample203-regular: 16.535945892333984
dataset_11_18_22 sample45-regular: 60.84546661376953
dataset_11_18_22 sample559-regular: 8.516277313232422
dataset_11_18_22 sample743-regular: 27.852489471435547
dataset_11_18_22 sample939-regular: 8.239253044128418
Loss: 17.029 +- 16.753

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy1regsample
Upsampling (200%) Results:
dataset_11_18_22 sample203-upsampling: 15.759536743164062
dataset_11_18_22 sample45-upsampling: 61.422847747802734
dataset_11_18_22 sample559-upsampling: 8.61608600616455
dataset_11_18_22 sample743-upsampling: 28.17098617553711
dataset_11_18_22 sample939-upsampling: 8.265190124511719
Loss: 17.104 +- 16.934

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy1upsample
