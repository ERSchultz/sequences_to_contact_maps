#### ARCHITECTURE ####
Node Encoder:
 None 

Edge Encoder:
 None 

Model:
 Sequential(
  (0): WeightedGATv2Conv(1, 8, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (2): WeightedGATv2Conv(64, 8, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (4): WeightedGATv2Conv(64, 8, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (6): WeightedGATv2Conv(64, 8, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
) 

Head 1:
 Bilinear 

Head 2:
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=32768, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1024, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['constant', 'ContactDistance', 'GeneticDistance_norm'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project2/depablo/erschultz/dataset_11_18_22', '/project2/depablo/erschultz/dataset_11_21_22'], scratch='/scratch/midway2/erschultz', root_name='ContactGNNEnergy1', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', y_zero_diag_count=0, log_preprocessing=None, output_preprocesing=None, kr=False, mean_filt=None, rescale=2, gated=False, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, use_scratch=False, use_scratch_parallel=True, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.0001, weight_decay=0.0, gpus=1, milestones=[50], gamma=0.1, loss='mse', w_reg='l1', reg_lambda=100.0, autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_sym_diag', model_type='ContactGNNEnergy', id=325, pretrained=False, resume_training=False, k=None, m=1024, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, message_passing='weighted_GAT', head_architecture='bilinear', head_architecture_2='fc-fill', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000, 1024], encoder_hidden_sizes_list=None, inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/325', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/325/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/325/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/325/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7fc7d104aa60>, channels=1, node_feature_size=1, input_m=512, edge_transforms=["'ContactDistance'", 'ContactDistance(norm=False)', 'GeneticDistance(norm=True)'], node_transforms=['Constant(value=1.0)'], edge_dim=2, transforms_processed=None, diag=False, pre_transforms_processed=Compose([
  Constant(value=1.0),
  ContactDistance(norm=False),
  GeneticDistance(norm=True)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 0.084 minutes
Average num edges per graph:  nan
split sizes: train=4302, val=478, test=0, N=4780
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
#### TRAINING/VALIDATION ####
Epoch 2, loss = 18.8174
Mean test/val loss: 13.4847
[25, 50, 75] quantiles test/val loss: [ 7.1781  9.9289 14.9257]

Epoch 4, loss = 16.5689
Mean test/val loss: 13.8065
[25, 50, 75] quantiles test/val loss: [ 9.3391 11.4537 14.2964]

Epoch 6, loss = 15.8097
Mean test/val loss: 11.7062
[25, 50, 75] quantiles test/val loss: [ 6.7062  9.9239 13.9025]

Epoch 8, loss = 16.2763
Mean test/val loss: 12.6201
[25, 50, 75] quantiles test/val loss: [ 8.7897 11.4077 14.4532]

Epoch 10, loss = 15.0337
Mean test/val loss: 10.5379
[25, 50, 75] quantiles test/val loss: [ 5.7258  8.6905 12.9602]

Epoch 12, loss = 14.7735
Mean test/val loss: 10.5704
[25, 50, 75] quantiles test/val loss: [ 5.8468  8.6252 12.774 ]

Epoch 14, loss = 14.6273
Mean test/val loss: 9.7266
[25, 50, 75] quantiles test/val loss: [ 5.5283  8.1756 11.9172]

Epoch 16, loss = 14.4644
Mean test/val loss: 12.6178
[25, 50, 75] quantiles test/val loss: [ 7.5075 11.1194 15.1561]

Epoch 18, loss = 14.3439
Mean test/val loss: 9.5181
[25, 50, 75] quantiles test/val loss: [ 5.3768  7.9934 11.5683]

Epoch 20, loss = 14.1667
Mean test/val loss: 9.5010
[25, 50, 75] quantiles test/val loss: [ 5.4611  8.0487 11.5965]

Epoch 22, loss = 14.0509
Mean test/val loss: 11.6794
[25, 50, 75] quantiles test/val loss: [ 7.9313 10.5491 13.2423]

Epoch 24, loss = 13.9131
Mean test/val loss: 9.4186
[25, 50, 75] quantiles test/val loss: [ 5.4569  7.8176 11.2126]

Epoch 26, loss = 13.7751
Mean test/val loss: 10.1616
[25, 50, 75] quantiles test/val loss: [ 6.0423  8.7902 12.1196]

Epoch 28, loss = 13.7731
Mean test/val loss: 9.2088
[25, 50, 75] quantiles test/val loss: [ 5.1068  7.7112 11.4949]

Epoch 30, loss = 13.6649
Mean test/val loss: 9.5414
[25, 50, 75] quantiles test/val loss: [ 5.3066  8.243  11.6394]

Epoch 32, loss = 13.6225
Mean test/val loss: 10.5671
[25, 50, 75] quantiles test/val loss: [ 6.1142  9.037  12.9624]

Epoch 34, loss = 13.4966
Mean test/val loss: 8.9521
[25, 50, 75] quantiles test/val loss: [ 5.2103  7.6398 11.0894]

Epoch 36, loss = 13.4363
Mean test/val loss: 8.9436
[25, 50, 75] quantiles test/val loss: [ 5.1246  7.6209 10.9196]

Epoch 38, loss = 13.3916
Mean test/val loss: 9.3945
[25, 50, 75] quantiles test/val loss: [ 5.6675  7.8472 11.1018]

Epoch 40, loss = 13.4403
Mean test/val loss: 9.2783
[25, 50, 75] quantiles test/val loss: [ 5.0684  7.6154 11.3627]

Epoch 42, loss = 13.3286
Mean test/val loss: 9.3490
[25, 50, 75] quantiles test/val loss: [ 5.2289  8.0399 11.2299]

Epoch 44, loss = 13.4301
Mean test/val loss: 9.0678
[25, 50, 75] quantiles test/val loss: [ 5.1826  7.7142 11.0852]

Epoch 46, loss = 13.3798
Mean test/val loss: 10.8255
[25, 50, 75] quantiles test/val loss: [ 7.0918  9.6071 12.4935]

Epoch 48, loss = 13.2329
Mean test/val loss: 9.0701
[25, 50, 75] quantiles test/val loss: [ 5.094   7.6059 11.1327]

Epoch 50, loss = 13.2344
Mean test/val loss: 8.8543
[25, 50, 75] quantiles test/val loss: [ 5.0042  7.4192 10.785 ]

Epoch 52, loss = 8.5223
Mean test/val loss: 8.4760
[25, 50, 75] quantiles test/val loss: [ 4.7374  7.285  10.3739]

Epoch 54, loss = 8.4309
Mean test/val loss: 8.6096
[25, 50, 75] quantiles test/val loss: [ 4.9449  7.2896 10.4924]

Epoch 56, loss = 8.3768
Mean test/val loss: 8.4443
[25, 50, 75] quantiles test/val loss: [ 4.8051  7.3152 10.3093]

Epoch 58, loss = 8.3516
Mean test/val loss: 8.3324
[25, 50, 75] quantiles test/val loss: [ 4.7077  7.1986 10.2536]

Epoch 60, loss = 8.3228
Mean test/val loss: 8.4323
[25, 50, 75] quantiles test/val loss: [ 4.7745  7.1871 10.3398]

Epoch 62, loss = 8.3020
Mean test/val loss: 8.3834
[25, 50, 75] quantiles test/val loss: [ 4.7849  7.1855 10.2807]

Epoch 64, loss = 8.2876
Mean test/val loss: 8.3697
[25, 50, 75] quantiles test/val loss: [ 4.7287  7.211  10.2407]

Epoch 66, loss = 8.2795
Mean test/val loss: 8.2914
[25, 50, 75] quantiles test/val loss: [ 4.7024  7.1866 10.1966]

Epoch 68, loss = 8.2759
Mean test/val loss: 8.6598
[25, 50, 75] quantiles test/val loss: [ 5.2452  7.4989 10.4151]

Epoch 70, loss = 8.2450
Mean test/val loss: 8.3464
[25, 50, 75] quantiles test/val loss: [ 4.7574  7.2607 10.2091]

Epoch 72, loss = 8.2359
Mean test/val loss: 8.2374
[25, 50, 75] quantiles test/val loss: [ 4.6772  7.1771 10.1663]

Epoch 74, loss = 8.2196
Mean test/val loss: 8.4621
[25, 50, 75] quantiles test/val loss: [ 4.7754  7.1967 10.3534]

Epoch 76, loss = 8.2198
Mean test/val loss: 8.2854
[25, 50, 75] quantiles test/val loss: [ 4.6943  7.1757 10.1434]

Epoch 78, loss = 8.1570
Mean test/val loss: 8.2404
[25, 50, 75] quantiles test/val loss: [ 4.6459  7.1429 10.1145]

Epoch 80, loss = 8.1392
Mean test/val loss: 8.1857
[25, 50, 75] quantiles test/val loss: [ 4.6845  7.1634 10.0963]

Epoch 82, loss = 8.1165
Mean test/val loss: 8.1916
[25, 50, 75] quantiles test/val loss: [ 4.6806  7.0814 10.0695]

Epoch 84, loss = 8.1027
Mean test/val loss: 8.1730
[25, 50, 75] quantiles test/val loss: [ 4.6679  7.0754 10.0771]

Epoch 86, loss = 8.0970
Mean test/val loss: 8.1995
[25, 50, 75] quantiles test/val loss: [ 4.7117  7.1045 10.0972]

Epoch 88, loss = 8.0917
Mean test/val loss: 8.1472
[25, 50, 75] quantiles test/val loss: [ 4.6508  7.0886 10.0548]

Epoch 90, loss = 8.0776
Mean test/val loss: 8.4410
[25, 50, 75] quantiles test/val loss: [ 4.9427  7.4193 10.2344]

Epoch 92, loss = 8.0805
Mean test/val loss: 8.2408
[25, 50, 75] quantiles test/val loss: [ 4.7736  7.1582 10.1207]

Epoch 94, loss = 8.0799
Mean test/val loss: 8.3518
[25, 50, 75] quantiles test/val loss: [ 4.7132  7.2036 10.1342]

Epoch 96, loss = 8.0517
Mean test/val loss: 8.1612
[25, 50, 75] quantiles test/val loss: [ 4.6557  7.0728 10.0341]

Epoch 98, loss = 8.0463
Mean test/val loss: 8.3839
[25, 50, 75] quantiles test/val loss: [ 4.7963  7.2848 10.1995]

Epoch 100, loss = 8.0430
Mean test/val loss: 8.2120
[25, 50, 75] quantiles test/val loss: [ 4.6674  7.0806 10.0099]


Total parameters: 43349620
Total training + validation time: 18.0 hours, 48.0 mins, and 11.39999999999418 secs
Final val loss: 8.211957703948519

split sizes: train=4302, val=478, test=0, N=4780
#### Plotting Script ####
Prediction Results:
dataset_11_21_22 sample939: 9.61270523071289
dataset_11_18_22 sample203: 8.647252082824707
dataset_11_21_22 sample743: 11.221761703491211
dataset_11_21_22 sample45: 3.208367347717285
dataset_11_18_22 sample559: 5.6511688232421875
Loss: 7.668 +- 2.875

Downsampling (40%) Results:
dataset_11_18_22 sample203-downsampling: 8.69926929473877
dataset_11_18_22 sample45-downsampling: 23.557395935058594
dataset_11_18_22 sample559-downsampling: 5.651167869567871
dataset_11_18_22 sample743-downsampling: 13.336540222167969
dataset_11_18_22 sample939-downsampling: 4.903164863586426
Loss: 8.522 +- 6.293

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy1downsample
Original sampling (100%) Results:
dataset_11_18_22 sample203-regular: 8.710681915283203
dataset_11_18_22 sample45-regular: 21.63006591796875
dataset_11_18_22 sample559-regular: 5.664420127868652
dataset_11_18_22 sample743-regular: 12.193442344665527
dataset_11_18_22 sample939-regular: 4.805554389953613
Loss: 8.121 +- 5.77

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy1regsample
Upsampling (200%) Results:
dataset_11_18_22 sample203-upsampling: 9.151479721069336
dataset_11_18_22 sample45-upsampling: 23.39607048034668
dataset_11_18_22 sample559-upsampling: 5.7475762367248535
dataset_11_18_22 sample743-upsampling: 12.297025680541992
dataset_11_18_22 sample939-upsampling: 4.790694713592529
Loss: 8.378 +- 6.233

Removing /project2/depablo/erschultz/dataset_11_18_22/ContactGNNEnergy1upsample
