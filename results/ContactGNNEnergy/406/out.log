#### ARCHITECTURE ####
Node Encoder:
 Sequential(
  (0): Linear(1, 64, bias=True)
  (1): PReLU(num_parameters=1)
) 

Edge Encoder:
 None 

Linear:
 Linear(in_features=72, out_features=64, bias=True) 

Model:
 Sequential(
  (0): WeightedGATv2Conv(64, 8, heads=8)
  (1): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (2): WeightedGATv2Conv(64, 8, heads=8)
  (3): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (4): WeightedGATv2Conv(64, 8, heads=8)
  (5): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
  (6): WeightedGATv2Conv(64, 8, heads=8)
  (7): MLP(
  (model): Sequential(
    (0): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=64, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (1): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=1000, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
    (2): LinearBlock(
      (model): Sequential(
        (0): Linear(in_features=1000, out_features=64, bias=True)
        (1): PReLU(num_parameters=1)
      )
    )
  )
)
) 

Head L:
 None 
 Bilinear 

Head D:
 None 
 Sequential(
  (0): MLP(
    (model): Sequential(
      (0): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=32768, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (1): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (2): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (3): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (4): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (5): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1000, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (6): LinearBlock(
        (model): Sequential(
          (0): Linear(in_features=1000, out_features=1024, bias=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
  )
  (1): FillDiagonalsFromArray()
) 

Namespace(GNN_mode=True, transforms=[], pre_transforms=['constant', 'ContactDistance', 'GeneticDistance_norm', 'AdjPCs_8'], sparsify_threshold=None, sparsify_threshold_upper=None, top_k=None, use_node_features=False, use_edge_weights=False, use_edge_attr=True, keep_zero_edges=False, data_folder=['/project2/depablo/erschultz/dataset_05_23_23'], scratch='/scratch/midway3/erschultz', root_name='ContactGNNEnergy6', delete_root=False, toxx=False, toxx_mode='mean', y_preprocessing='sweeprand_log_inf', y_zero_diag_count=0, log_preprocessing=None, output_preprocesing='log', kr=False, mean_filt=None, rescale=2, gated=False, preprocessing_norm='mean', min_subtraction=True, x_reshape=True, ydtype=torch.float32, y_reshape=True, crop=None, classes=10, move_data_to_scratch=False, use_scratch_parallel=False, plaid_score_cutoff=None, split_percents=[0.9, 0.1, 0.0], split_sizes=None, random_split=True, shuffle=True, batch_size=1, num_workers=4, start_epoch=1, n_epochs=100, save_mod=5, print_mod=2, lr=0.0001, min_lr=1e-06, weight_decay=0.0, gpus=1, scheduler='MultiStepLR', milestones=[50], gamma=0.1, patience=10, loss='mse', w_reg=None, reg_lambda=0.1, autoencoder_mode=False, verbose=False, print_params=True, output_mode='energy_sym_diag', model_type='ContactGNNEnergy', id=406, pretrain_id=None, resume_training=False, k=8, m=1024, seed=42, act='prelu', inner_act='prelu', out_act='prelu', training_norm=None, dropout=0.0, parameter_sharing=False, use_bias=True, use_sign_net=False, use_sign_plus=True, message_passing='weighted_GAT', head_architecture='bilinear', head_architecture_2='fc-fill_1024', head_hidden_sizes_list=[1000, 1000, 1000, 1000, 1000, 1000], encoder_hidden_sizes_list=[64], inner_hidden_sizes_list=None, edge_encoder_hidden_sizes_list=None, update_hidden_sizes_list=[1000, 1000, 64], head_act='prelu', num_heads=8, concat_heads=True, max_diagonal=None, mlp_model_id=None, kernel_w_list=None, hidden_sizes_list=[8, 8, 8, 8], nf=None, dilation_list=None, dilation_list_trunk=None, bottleneck=None, dilation_list_head=None, down_sampling=None, plot=True, plot_predictions=True, ofile_folder='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/406', log_file_path='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/406/out.log', log_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/406/out.log' mode='a' encoding='UTF-8'>, param_file=<_io.TextIOWrapper name='/home/erschultz/sequences_to_contact_maps/results/ContactGNNEnergy/406/params.log' mode='a' encoding='UTF-8'>, split_neg_pos_edges=False, criterion=<function mse_loss at 0x7f29f72c1310>, channels=1, node_feature_size=1, input_m=512, edge_transforms=["'ContactDistance'", 'ContactDistance(norm=False)', 'GeneticDistance(norm=True)'], node_transforms=['AdjPCs(k=8, normalize=False, sign_net=True)', 'Constant(value=1.0)'], edge_dim=2, transforms_processed=None, diag=True, pre_transforms_processed=Compose([
  Constant(value=1.0),
  ContactDistance(norm=False),
  GeneticDistance(norm=True),
  AdjPCs(k=8, normalize=False, sign_net=True)
]), cuda=True, use_parallel=False, device=device(type='cuda'))

Dataset construction time: 32.09 minutes
Number of samples: 5000
Average num edges per graph:  212776.626
Mean degree: [305.27 435.8  504.58 ... 490.25 494.   504.66] +- [67.85 59.39  5.2  ... 10.14 12.83  8.11]

split sizes: train=4500, val=500, test=0, N=5000
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0
)
Scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f29b82ce580>
#### TRAINING/VALIDATION ####
Epoch 2, loss = 0.7427
Mean test/val loss: 0.6867
[25, 50, 75] percentiles test/val loss: [0.3366 0.6034 0.9539]

Epoch 4, loss = 0.6980
Mean test/val loss: 0.6399
[25, 50, 75] percentiles test/val loss: [0.3099 0.5733 0.859 ]

Epoch 6, loss = 1.4461
Mean test/val loss: 0.7252
[25, 50, 75] percentiles test/val loss: [0.3581 0.6158 0.9908]

Epoch 8, loss = 0.8297
Mean test/val loss: 0.7901
[25, 50, 75] percentiles test/val loss: [0.3656 0.6465 1.0733]

Epoch 10, loss = 2.4243
Mean test/val loss: 1.4852
[25, 50, 75] percentiles test/val loss: [0.5739 1.365  2.064 ]

Epoch 12, loss = 1.2683
Mean test/val loss: 1.1237
[25, 50, 75] percentiles test/val loss: [0.6489 0.9737 1.4381]

Epoch 14, loss = 0.9086
Mean test/val loss: 0.7904
[25, 50, 75] percentiles test/val loss: [0.4059 0.666  1.0699]

Epoch 16, loss = 0.7914
Mean test/val loss: 0.8075
[25, 50, 75] percentiles test/val loss: [0.3705 0.6645 1.099 ]

Epoch 18, loss = 0.6528
Mean test/val loss: 0.5994
[25, 50, 75] percentiles test/val loss: [0.2708 0.5255 0.8235]

Epoch 20, loss = 0.6768
Mean test/val loss: 0.6490
[25, 50, 75] percentiles test/val loss: [0.3098 0.5546 0.8738]

Epoch 22, loss = 0.6170
Mean test/val loss: 0.5975
[25, 50, 75] percentiles test/val loss: [0.292  0.5067 0.8223]

Epoch 24, loss = 0.6053
Mean test/val loss: 0.5586
[25, 50, 75] percentiles test/val loss: [0.2835 0.5092 0.7367]

Epoch 26, loss = 0.6605
Mean test/val loss: 0.5666
[25, 50, 75] percentiles test/val loss: [0.2713 0.483  0.7578]

Epoch 28, loss = 0.5739
Mean test/val loss: 0.5292
[25, 50, 75] percentiles test/val loss: [0.2639 0.4544 0.7032]

Epoch 30, loss = 0.6004
Mean test/val loss: 0.5567
[25, 50, 75] percentiles test/val loss: [0.2573 0.4775 0.7464]

Epoch 32, loss = 0.5694
Mean test/val loss: 0.5289
[25, 50, 75] percentiles test/val loss: [0.2532 0.4486 0.7233]

Epoch 34, loss = 0.5593
Mean test/val loss: 0.5244
[25, 50, 75] percentiles test/val loss: [0.2644 0.4547 0.709 ]

Epoch 36, loss = 156.5346
Mean test/val loss: 0.9842
[25, 50, 75] percentiles test/val loss: [0.4141 0.7845 1.3257]

Epoch 38, loss = 0.8315
Mean test/val loss: 0.7175
[25, 50, 75] percentiles test/val loss: [0.3482 0.5984 0.9658]

Epoch 40, loss = 0.6449
Mean test/val loss: 0.5577
[25, 50, 75] percentiles test/val loss: [0.2836 0.4946 0.7409]

Epoch 42, loss = 6.0644
Mean test/val loss: 0.5730
[25, 50, 75] percentiles test/val loss: [0.2502 0.4843 0.7672]

Epoch 44, loss = 0.5303
Mean test/val loss: 0.4940
[25, 50, 75] percentiles test/val loss: [0.2219 0.4212 0.6654]

Epoch 46, loss = 0.5318
Mean test/val loss: 0.7030
[25, 50, 75] percentiles test/val loss: [0.4128 0.6535 0.9258]

Epoch 48, loss = 0.5264
Mean test/val loss: 0.4993
[25, 50, 75] percentiles test/val loss: [0.2293 0.424  0.6558]

Epoch 50, loss = 0.5010
Mean test/val loss: 0.5468
[25, 50, 75] percentiles test/val loss: [0.2601 0.4741 0.736 ]

New lr: 1e-05
Epoch 52, loss = 0.4525
Mean test/val loss: 0.4449
[25, 50, 75] percentiles test/val loss: [0.2084 0.3947 0.6035]

Epoch 54, loss = 0.4317
Mean test/val loss: 0.4304
[25, 50, 75] percentiles test/val loss: [0.2049 0.3694 0.5698]

Epoch 56, loss = 0.4206
Mean test/val loss: 0.4226
[25, 50, 75] percentiles test/val loss: [0.1969 0.3606 0.5657]

Epoch 58, loss = 0.4116
Mean test/val loss: 0.4207
[25, 50, 75] percentiles test/val loss: [0.2003 0.3546 0.5728]

Epoch 60, loss = 0.4047
Mean test/val loss: 0.4192
[25, 50, 75] percentiles test/val loss: [0.1964 0.3566 0.5676]

Epoch 62, loss = 0.3989
Mean test/val loss: 0.4144
[25, 50, 75] percentiles test/val loss: [0.1923 0.3445 0.557 ]

Epoch 64, loss = 0.3917
Mean test/val loss: 0.4107
[25, 50, 75] percentiles test/val loss: [0.1849 0.3389 0.5652]

Epoch 66, loss = 0.3862
Mean test/val loss: 0.4091
[25, 50, 75] percentiles test/val loss: [0.1858 0.3381 0.5593]

Epoch 68, loss = 0.3820
Mean test/val loss: 0.4066
[25, 50, 75] percentiles test/val loss: [0.1866 0.3331 0.5572]

Epoch 70, loss = 0.3772
Mean test/val loss: 0.3975
[25, 50, 75] percentiles test/val loss: [0.1826 0.3321 0.5368]

Epoch 72, loss = 0.3726
Mean test/val loss: 0.3984
[25, 50, 75] percentiles test/val loss: [0.1799 0.3334 0.5424]

Epoch 74, loss = 0.3677
Mean test/val loss: 0.4049
[25, 50, 75] percentiles test/val loss: [0.1836 0.3413 0.5468]

Epoch 76, loss = 0.3627
Mean test/val loss: 0.4029
[25, 50, 75] percentiles test/val loss: [0.1887 0.3332 0.5375]

Epoch 78, loss = 0.3590
Mean test/val loss: 0.4009
[25, 50, 75] percentiles test/val loss: [0.176  0.3478 0.5408]

Epoch 80, loss = 0.3555
Mean test/val loss: 0.3952
[25, 50, 75] percentiles test/val loss: [0.1733 0.3341 0.5352]

Epoch 82, loss = 0.3517
Mean test/val loss: 0.3876
[25, 50, 75] percentiles test/val loss: [0.1719 0.3144 0.5189]

Epoch 84, loss = 0.3487
Mean test/val loss: 0.3944
[25, 50, 75] percentiles test/val loss: [0.1752 0.3244 0.5182]

Epoch 86, loss = 0.3446
Mean test/val loss: 0.3895
[25, 50, 75] percentiles test/val loss: [0.1681 0.3109 0.5269]

Epoch 88, loss = 0.3409
Mean test/val loss: 0.3857
[25, 50, 75] percentiles test/val loss: [0.1682 0.3118 0.5165]

Epoch 90, loss = 0.3369
Mean test/val loss: 0.3971
[25, 50, 75] percentiles test/val loss: [0.1846 0.3317 0.5393]

Epoch 92, loss = 0.3352
Mean test/val loss: 0.3817
[25, 50, 75] percentiles test/val loss: [0.1649 0.3082 0.5151]

Epoch 94, loss = 0.3313
Mean test/val loss: 0.3821
[25, 50, 75] percentiles test/val loss: [0.1607 0.3127 0.5151]

Epoch 96, loss = 0.3295
Mean test/val loss: 0.3879
[25, 50, 75] percentiles test/val loss: [0.1656 0.3181 0.5151]

Epoch 98, loss = 0.3252
Mean test/val loss: 0.3864
[25, 50, 75] percentiles test/val loss: [0.1642 0.3136 0.5181]

Epoch 100, loss = 0.3227
Mean test/val loss: 0.3923
[25, 50, 75] percentiles test/val loss: [0.1773 0.3216 0.5187]


Total parameters: 43362484
Total training + validation time: 17.0 hours, 31.0 mins, and 46.099999999998545 secs
Final val loss: 0.39233057663217186

split sizes: train=4500, val=500, test=0, N=5000
#### Plotting Script ####
Prediction Results:
dataset_05_23_23 sample981: 0.056036803871393204
dataset_05_23_23 sample324: 0.3280178904533386
dataset_05_23_23 sample3464: 0.6316757202148438
dataset_05_23_23 sample2834: 0.07604482024908066
dataset_05_23_23 sample1936: 0.2679448127746582
Loss: 0.272 +- 0.209

Downsampling (40%) Results:
dataset_05_23_23 sample1936-downsampling: 2.3427743911743164
dataset_05_23_23 sample2834-downsampling: 3.9526801109313965
dataset_05_23_23 sample324-downsampling: 4.607675075531006
dataset_05_23_23 sample3464-downsampling: 6.160243034362793
dataset_05_23_23 sample981-downsampling: 0.46671825647354126
Loss: 3.506 +- 1.952

Removing /scratch/midway3/erschultz/ContactGNNEnergy6downsample
Original sampling (100%) Results:
dataset_05_23_23 sample1936-regular: 2.690681219100952
dataset_05_23_23 sample2834-regular: 4.442139148712158
dataset_05_23_23 sample324-regular: 4.687561988830566
dataset_05_23_23 sample3464-regular: 4.863051414489746
dataset_05_23_23 sample981-regular: 2.805048942565918
Loss: 3.898 +- 0.949

Removing /scratch/midway3/erschultz/ContactGNNEnergy6regsample
Upsampling (200%) Results:
