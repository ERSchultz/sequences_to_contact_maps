#### INITIAL PARAMETERS ####
W torch.Size([16, 16])
Parameter containing:
tensor([[ 5.5193e-01,  1.7841e+00, -7.8111e-01, -7.0790e-01, -5.3947e-01,
         -9.0650e-01, -8.1475e-01,  1.8515e-01,  1.0201e-02, -1.6919e+00,
          7.2407e-01, -2.7400e+00, -6.2729e-01, -2.0232e+00, -1.7594e+00,
          2.9700e-01],
        [-5.9671e-01, -7.3231e-01, -1.1539e+00, -8.6158e-02,  2.2009e-01,
          2.0784e-01,  5.5776e-01, -9.6292e-01,  1.1099e+00,  1.2666e+00,
          6.6514e-01,  4.3804e-01, -1.2551e+00,  5.1348e-01, -4.5945e-01,
          1.0152e+00],
        [-1.3896e-01, -2.5582e-01,  1.5813e+00, -1.7797e+00, -5.7565e-01,
         -1.4387e+00, -1.4912e-01, -5.1830e-02, -3.1665e-01,  6.8103e-01,
         -6.2703e-01, -6.5944e-01,  1.0741e-01,  1.3740e+00, -4.3323e-01,
         -1.0451e+00],
        [ 8.0120e-01, -4.3278e-01, -1.2325e+00,  5.7920e-01,  7.7035e-01,
         -1.2957e+00, -1.7362e+00,  8.5306e-01, -5.9785e-01, -3.7705e-01,
          1.6806e+00, -1.8047e+00, -1.1833e+00, -5.1174e-01, -4.7663e-01,
         -8.8865e-01],
        [ 7.1815e-01, -1.0789e+00, -9.8014e-01,  1.6274e+00,  2.8522e-01,
         -1.6617e+00, -6.3389e-01, -5.6446e-01, -4.6914e-01, -2.1700e-01,
         -7.2586e-01,  4.4359e-01, -8.4268e-01,  4.0193e-01,  7.7239e-01,
         -2.3963e+00],
        [-7.7442e-01,  6.2117e-01,  9.7122e-01, -9.2406e-01, -3.6825e-01,
          3.7850e-01, -4.8950e-01,  3.1296e-01, -2.8273e-01, -9.8788e-01,
          2.6449e+00, -1.2837e+00, -2.0396e-01,  1.1637e+00,  9.7218e-01,
         -3.1807e-01],
        [ 8.6871e-02, -3.2262e-01,  2.2072e+00, -1.9866e+00,  1.9935e+00,
         -7.9875e-01, -1.0935e+00, -1.6023e+00,  3.2860e-02, -4.8885e-01,
         -2.1301e+00, -8.1850e-02, -1.5029e+00,  1.5887e-01, -8.3690e-01,
          3.8577e-01],
        [ 5.7048e-01,  1.1350e+00,  1.8400e+00, -1.1521e+00,  9.1663e-01,
          1.1457e+00, -3.1366e-01, -9.8601e-01,  1.3507e-01, -5.3392e-01,
          1.1923e+00, -1.1240e+00, -1.5876e+00, -5.9765e-01, -4.5828e-01,
         -6.1781e-01],
        [ 7.4140e-01,  5.4279e-01,  1.3911e-01,  8.3755e-01,  1.0956e+00,
          6.9739e-02, -1.5328e+00, -5.3254e-01,  4.5572e-01, -2.6772e+00,
          1.6198e+00, -2.4339e+00, -9.1764e-01, -6.1527e-01, -8.1734e-01,
          4.9609e-01],
        [-1.3043e+00,  1.1387e+00, -3.9136e-01,  2.5785e-01, -9.0135e-01,
          1.0383e+00, -8.0703e-01,  4.7501e-02, -2.4419e-03,  1.5646e+00,
         -3.2161e-01,  1.4621e+00, -1.1580e+00, -7.3285e-01, -9.1354e-02,
          4.2391e-01],
        [-1.9301e-01, -2.5345e+00, -1.0393e+00, -1.2853e+00, -5.7362e-01,
         -1.6246e+00,  9.9030e-01, -3.9575e-01, -1.1179e+00,  1.2089e+00,
         -7.0011e-02, -9.4612e-02,  9.3284e-01, -5.6601e-01,  6.0004e-01,
          1.0482e+00],
        [ 8.0372e-01, -1.6318e+00,  8.9558e-01,  1.3502e-01,  1.0705e+00,
          8.3433e-01,  3.3214e-02,  6.0050e-01,  4.7865e-01, -6.7606e-01,
         -9.1946e-01, -4.3952e-01,  5.5808e-01, -2.6134e-01, -6.4294e-01,
          2.1851e-01],
        [-1.2667e+00,  1.7995e+00,  3.8443e-03, -1.1177e-01,  7.0265e-01,
         -1.8724e+00,  1.3223e+00,  6.5501e-01,  1.1561e+00, -8.6618e-01,
         -3.7337e-01,  1.2990e+00,  8.5961e-01,  1.3649e+00,  8.9176e-01,
         -1.2844e+00],
        [-9.6392e-01,  2.9661e-01,  2.1207e-01, -1.3626e+00, -4.3905e-01,
         -4.5501e-01,  9.0822e-01, -8.8272e-01, -1.4548e+00,  9.8041e-01,
         -1.1472e+00, -6.1790e-01, -1.3665e-01,  8.0777e-01, -2.2339e+00,
          1.9065e+00],
        [ 3.3667e-01,  1.7058e-01, -4.8526e-01,  9.5503e-01,  2.8843e-01,
         -9.4035e-02,  1.7815e+00, -1.3378e+00, -1.5999e-01,  8.0652e-01,
          7.3844e-01,  4.2915e-01, -9.4423e-01, -8.5841e-01,  1.9957e+00,
          1.5562e+00],
        [ 7.1419e-02,  8.4606e-01, -1.4125e+00, -1.4514e+00, -7.6136e-01,
          6.3843e-01, -1.5975e+00,  1.5598e+00,  4.3852e-01,  8.2766e-01,
         -1.1279e+00,  1.1306e+00,  1.1251e+00, -1.3069e+00, -4.3475e-01,
         -4.0460e-01]], device='cuda:0', requires_grad=True) 

act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

inner_act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

out_act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

encoder.module_0.weight torch.Size([100, 13])
Parameter containing:
tensor([[ 0.2120,  0.2302, -0.0650,  ...,  0.2411,  0.0519,  0.2049],
        [ 0.0376,  0.1337, -0.0392,  ...,  0.1840, -0.2189, -0.1279],
        [-0.0783, -0.1668,  0.0262,  ...,  0.0432,  0.2241,  0.0303],
        ...,
        [ 0.2298, -0.1814, -0.1793,  ...,  0.0896, -0.0832,  0.0965],
        [-0.2372,  0.1922,  0.2365,  ..., -0.2049,  0.1866,  0.1882],
        [-0.2519,  0.0883,  0.1128,  ..., -0.2226,  0.0561,  0.1514]],
       device='cuda:0', requires_grad=True) 

encoder.module_0.bias torch.Size([100])
Parameter containing:
tensor([-1.3779e-01,  3.0546e-02, -4.0264e-04,  7.0199e-02, -1.4903e-01,
         1.5644e-01,  1.8444e-01, -1.9244e-01,  2.6868e-03,  7.6953e-04,
         8.9061e-02,  2.5838e-01,  8.1337e-02, -6.3020e-02,  2.4910e-01,
        -1.0554e-01, -8.0535e-02,  1.8936e-02, -2.1120e-01,  3.0180e-02,
        -1.8818e-01,  2.8517e-02,  2.6572e-02,  3.8391e-02, -2.3389e-01,
        -2.6342e-01,  1.2761e-01,  2.3785e-01, -2.4611e-01,  1.0273e-01,
        -2.0416e-01,  1.7387e-02,  2.5803e-01,  2.1040e-01, -2.0278e-01,
         1.7156e-01,  1.4486e-01, -4.2542e-04,  2.6868e-01, -1.1016e-01,
        -6.4544e-02, -1.4018e-01,  3.9910e-02,  7.3439e-02,  2.2099e-02,
        -1.5605e-01, -1.2485e-01,  9.4341e-02, -2.4319e-01, -4.3193e-02,
        -6.1437e-03, -1.1237e-01,  1.0093e-01,  1.7876e-02,  1.9472e-01,
        -2.4632e-02, -1.7505e-01,  1.9596e-01,  3.8732e-02, -7.9433e-02,
        -1.8280e-01,  6.5008e-02, -2.6452e-01,  7.3048e-02,  1.3713e-01,
        -2.4329e-01, -1.8157e-01, -1.9939e-01,  2.3311e-01,  2.3578e-01,
         1.7362e-02,  2.6038e-01, -9.2719e-02, -2.6926e-01,  9.6877e-02,
         9.8256e-02,  2.7191e-01, -8.0276e-05,  2.1256e-01,  1.7001e-01,
         2.0074e-01, -2.7522e-01,  2.2839e-01, -2.3643e-01,  2.4865e-01,
        -1.1494e-02, -2.4579e-01,  7.7129e-02, -5.6454e-02, -2.4911e-01,
        -1.0055e-01,  2.8596e-02,  2.1601e-01, -8.5266e-02,  1.6474e-01,
         3.4732e-02,  9.3489e-03,  5.3070e-02, -1.8202e-01, -2.3053e-01],
       device='cuda:0', requires_grad=True) 

encoder.module_2.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0314, -0.0932, -0.0466,  ...,  0.0261,  0.0610,  0.0939],
        [ 0.0852, -0.0058,  0.0194,  ..., -0.0477, -0.0680,  0.0788],
        [-0.0894,  0.0500, -0.0900,  ...,  0.0393, -0.0163, -0.0312],
        ...,
        [ 0.0145, -0.0630,  0.0150,  ..., -0.0838, -0.0755,  0.0149],
        [ 0.0289,  0.0232,  0.0622,  ...,  0.0261,  0.0347, -0.0602],
        [ 0.0742,  0.0714,  0.0718,  ...,  0.0190,  0.0631,  0.0773]],
       device='cuda:0', requires_grad=True) 

encoder.module_2.bias torch.Size([100])
Parameter containing:
tensor([-0.0054,  0.0942,  0.0529, -0.0612,  0.0072, -0.0486,  0.0189, -0.0604,
        -0.0372, -0.0412, -0.0969,  0.0918, -0.0342, -0.0306, -0.0021,  0.0018,
        -0.0840,  0.0278, -0.0623, -0.0794, -0.0600, -0.0780,  0.0783,  0.0382,
         0.0876, -0.0805, -0.0794,  0.0397, -0.0468, -0.0306, -0.0588, -0.0841,
        -0.0589, -0.0629,  0.0512, -0.0026,  0.0625,  0.0869,  0.0660, -0.0814,
         0.0586,  0.0570, -0.0453, -0.0211,  0.0336, -0.0102, -0.0612, -0.0177,
        -0.0276,  0.0612,  0.0436,  0.0625, -0.0042, -0.0910,  0.0976,  0.0031,
         0.0426, -0.0567, -0.0050,  0.0267, -0.0407, -0.0554,  0.0281,  0.0803,
         0.0780,  0.0340,  0.0085,  0.0449, -0.0312,  0.0771,  0.0528, -0.0997,
         0.0912,  0.0047, -0.0756, -0.0383,  0.0971, -0.0835,  0.0250, -0.0336,
        -0.0821,  0.0386,  0.0583,  0.0983, -0.0816,  0.0489,  0.0712, -0.0025,
         0.0771,  0.0913, -0.0810,  0.0502,  0.0238,  0.0113,  0.0737,  0.0054,
        -0.0372,  0.0854,  0.0579,  0.0485], device='cuda:0',
       requires_grad=True) 

encoder.module_4.weight torch.Size([16, 100])
Parameter containing:
tensor([[-0.0269, -0.0834, -0.0139,  ...,  0.0622,  0.0829,  0.0987],
        [ 0.0305,  0.0128,  0.0279,  ..., -0.0546,  0.0095,  0.0571],
        [ 0.0206,  0.0051,  0.0390,  ...,  0.0256, -0.0076, -0.0335],
        ...,
        [-0.0685, -0.0025,  0.0810,  ...,  0.0540, -0.0536,  0.0207],
        [-0.0359,  0.0392, -0.0613,  ..., -0.0551,  0.0601,  0.0034],
        [ 0.0002,  0.0135, -0.0008,  ..., -0.0276, -0.0662, -0.0861]],
       device='cuda:0', requires_grad=True) 

encoder.module_4.bias torch.Size([16])
Parameter containing:
tensor([ 0.0062, -0.0548,  0.0177,  0.0661,  0.0855, -0.0163, -0.0650, -0.0543,
         0.0635,  0.0259,  0.0063, -0.0972,  0.0539,  0.0633,  0.0103, -0.0180],
       device='cuda:0', requires_grad=True) 

model.module_0.att torch.Size([1, 1, 8])
Parameter containing:
tensor([[[ 0.1126, -0.2848,  0.6629,  0.6897, -0.2501,  0.3603, -0.2217,
           0.6533]]], device='cuda:0', requires_grad=True) 

model.module_0.bias torch.Size([8])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

model.module_0.lin_l.weight torch.Size([8, 16])
Parameter containing:
tensor([[-4.8729e-01, -3.3483e-01,  8.5073e-03, -4.5999e-01,  9.2577e-02,
          4.2286e-01, -1.0135e-01, -8.8036e-02, -4.4003e-01, -1.0569e-01,
          4.1354e-02,  1.0235e-01, -1.6465e-01, -3.0555e-01, -2.6195e-01,
          3.4476e-01],
        [-2.7201e-01,  3.8872e-02, -8.7884e-02, -2.0105e-01, -2.1598e-02,
          3.7794e-01,  3.7858e-01, -1.0444e-01, -1.0057e-01, -2.8008e-01,
         -2.3256e-01, -8.5411e-02,  3.7101e-01,  7.1231e-02, -4.2794e-01,
         -1.2853e-01],
        [-4.3195e-01,  4.6206e-01,  4.6292e-02, -1.2691e-01,  2.0049e-01,
         -4.6873e-01, -1.6507e-01,  4.6904e-02,  3.6079e-01,  4.0784e-01,
         -1.6714e-02, -4.9981e-01,  9.2366e-02, -2.8197e-01,  4.5097e-01,
         -1.3463e-01],
        [-1.3607e-01, -7.4260e-02,  4.6344e-01,  2.1926e-01, -3.4481e-01,
          8.7620e-02,  1.5898e-01, -1.2987e-01,  1.6599e-01, -4.4881e-01,
         -2.5775e-01,  3.1942e-01,  4.6451e-01,  1.5883e-01, -2.8327e-01,
          1.8222e-01],
        [-2.8799e-01, -4.0063e-01, -3.2992e-01, -4.7389e-02,  1.0618e-01,
          3.7228e-02,  4.8055e-01, -3.5477e-02,  4.5996e-01, -3.7159e-01,
         -2.5740e-01,  6.8553e-02,  2.9801e-01,  1.4841e-01,  4.9032e-01,
         -2.6653e-01],
        [ 4.6793e-01,  1.5964e-01,  1.3202e-01, -1.2819e-02, -3.5989e-01,
          2.6748e-01,  1.0845e-01,  3.4467e-01,  3.6796e-01, -4.2466e-01,
          4.6318e-01, -1.1514e-01, -3.3498e-01,  4.3640e-01, -7.9075e-02,
          8.2386e-02],
        [ 7.5049e-02, -2.6895e-01,  3.1707e-01,  1.8959e-01,  4.0274e-01,
         -1.3896e-01, -3.6688e-01,  9.7934e-02, -1.3434e-01,  2.5815e-04,
         -4.0666e-01,  4.4842e-01, -2.6296e-01, -4.5173e-02,  1.2687e-02,
         -2.1721e-01],
        [ 2.9707e-01, -4.0741e-01, -6.7257e-02, -3.2380e-01,  2.9650e-01,
         -3.6400e-01,  3.9586e-01, -4.3245e-01, -4.9972e-01,  1.2194e-02,
         -4.9223e-01,  4.6576e-01,  4.6705e-01, -2.2833e-01,  3.7374e-01,
         -1.9230e-01]], device='cuda:0', requires_grad=True) 

model.module_0.lin_l.bias torch.Size([8])
Parameter containing:
tensor([ 0.0612, -0.1752, -0.0169, -0.0763,  0.0561,  0.0804, -0.2333,  0.0169],
       device='cuda:0', requires_grad=True) 

model.module_0.lin_r.weight torch.Size([8, 16])
Parameter containing:
tensor([[ 0.3872,  0.4028,  0.2264,  0.0116,  0.3430,  0.2653, -0.3289, -0.0285,
         -0.4632,  0.0352,  0.0380, -0.3292,  0.1194,  0.3458, -0.4254, -0.4454],
        [-0.2443,  0.0648, -0.4853, -0.0995,  0.3839, -0.4127, -0.1336, -0.1057,
          0.3022, -0.1859,  0.3796, -0.2506,  0.1855, -0.0924,  0.4352, -0.2452],
        [-0.1879,  0.4510, -0.3961,  0.1414,  0.2485, -0.0434,  0.4396, -0.4650,
         -0.0726, -0.2631,  0.1970,  0.4889, -0.4894, -0.2229, -0.3703, -0.2804],
        [ 0.1512,  0.0074, -0.3916, -0.3066, -0.3275,  0.0379, -0.4118, -0.3910,
         -0.4006,  0.4033,  0.3652, -0.2366,  0.1174, -0.0698, -0.2010,  0.2331],
        [-0.3363, -0.0016,  0.3737, -0.4342,  0.4122,  0.3303,  0.2211, -0.0653,
         -0.1945, -0.2745, -0.3625, -0.4874, -0.0717,  0.0994, -0.4840,  0.4922],
        [-0.3573,  0.0395, -0.1695,  0.4550, -0.2177,  0.1306,  0.1594,  0.2293,
         -0.3505, -0.2769,  0.0056, -0.4932, -0.1951, -0.4195,  0.2210,  0.0518],
        [-0.4672,  0.4890,  0.2050, -0.2866, -0.0503,  0.3391, -0.2972,  0.1250,
          0.1626, -0.3214, -0.2628, -0.0887, -0.3911,  0.4303,  0.1428, -0.1592],
        [-0.0059,  0.0055,  0.1656,  0.3552, -0.4202, -0.1779,  0.1803, -0.2793,
         -0.0246, -0.1463,  0.2865, -0.2681,  0.4506,  0.2377, -0.3585, -0.0994]],
       device='cuda:0', requires_grad=True) 

model.module_0.lin_r.bias torch.Size([8])
Parameter containing:
tensor([-0.0235, -0.2447, -0.2143,  0.2069,  0.1796, -0.1703, -0.0025,  0.0672],
       device='cuda:0', requires_grad=True) 

model.module_0.lin_edge.weight torch.Size([8, 2])
Parameter containing:
tensor([[ 0.4726,  0.6861],
        [ 0.4859,  0.6424],
        [-0.5022, -0.1766],
        [ 0.3706, -0.5962],
        [-0.7501,  0.4366],
        [ 0.5648,  0.3096],
        [ 0.4920,  0.3624],
        [ 0.1049, -0.1744]], device='cuda:0', requires_grad=True) 

model.module_1.weight torch.Size([100, 8])
Parameter containing:
tensor([[-0.3181,  0.0503, -0.0272,  0.2414,  0.0375,  0.0671, -0.3462, -0.1945],
        [ 0.3300, -0.0317,  0.1511, -0.2891,  0.1820, -0.1538, -0.0363,  0.3331],
        [ 0.2505, -0.3100, -0.1586,  0.2086, -0.0650,  0.2792,  0.1453, -0.0392],
        [-0.2204,  0.0203,  0.2789,  0.2717, -0.1526, -0.0977,  0.1140, -0.3005],
        [ 0.0472,  0.0903,  0.3470, -0.0438,  0.3440,  0.3439, -0.1819,  0.0550],
        [ 0.2026, -0.0411, -0.1937,  0.0754,  0.1558, -0.2865, -0.2849, -0.2668],
        [-0.2709,  0.3096, -0.1573, -0.0420, -0.0941, -0.1817,  0.2991, -0.1262],
        [ 0.2147, -0.1634,  0.3468,  0.0894, -0.0624,  0.0025,  0.1465, -0.1899],
        [-0.1049, -0.2624, -0.2371,  0.1701, -0.0296, -0.1765,  0.0164,  0.2017],
        [ 0.3247, -0.2070,  0.1443,  0.0338, -0.1794,  0.0784,  0.0397,  0.2089],
        [ 0.2893,  0.1661,  0.0669, -0.2656, -0.2960,  0.1656, -0.2169,  0.0049],
        [ 0.2722,  0.1775, -0.0449,  0.0557,  0.0122,  0.0305,  0.3083, -0.2163],
        [ 0.3078,  0.0170,  0.3353, -0.1507,  0.2173, -0.1944, -0.2897,  0.2570],
        [ 0.1222,  0.3476,  0.1433, -0.1492, -0.2103,  0.2894, -0.0701, -0.2101],
        [-0.2611, -0.2367, -0.1485, -0.2843,  0.3403,  0.0408,  0.1166, -0.1739],
        [ 0.0100,  0.2410, -0.1198,  0.2854, -0.1099, -0.1322, -0.2602, -0.3504],
        [ 0.1541, -0.2281, -0.1938, -0.1446, -0.2704, -0.2718, -0.2308,  0.3447],
        [ 0.0205, -0.1332, -0.0295,  0.2956, -0.2057,  0.1428, -0.0659, -0.3004],
        [ 0.2338,  0.1633,  0.2598,  0.1619,  0.0576,  0.1087, -0.2639,  0.3407],
        [-0.2277,  0.2494, -0.2239, -0.2555,  0.1457,  0.2317, -0.0963,  0.0990],
        [-0.3082, -0.0397,  0.3119,  0.3304, -0.1126,  0.1306,  0.3261,  0.1311],
        [ 0.0648, -0.2849,  0.1016,  0.0944, -0.1992,  0.1765, -0.2306,  0.3385],
        [-0.0178,  0.2407, -0.0928, -0.1796,  0.2572,  0.2147,  0.3472,  0.1039],
        [-0.1484, -0.2076, -0.3374,  0.0224,  0.3385, -0.1172, -0.0682,  0.2490],
        [ 0.3145,  0.0960,  0.0281,  0.3457,  0.2961, -0.2250, -0.2467, -0.0811],
        [ 0.1401, -0.2164, -0.1513,  0.0293, -0.0893,  0.2372,  0.2239,  0.2435],
        [ 0.1881, -0.2045, -0.2721, -0.2376, -0.0453,  0.2779, -0.0785,  0.3253],
        [ 0.2639, -0.3356,  0.1633, -0.1491, -0.3373,  0.1239, -0.1215, -0.3141],
        [-0.2488,  0.2601, -0.0847,  0.2771, -0.1227,  0.3454, -0.0885,  0.3346],
        [ 0.1371, -0.2657,  0.1545,  0.1485, -0.2968, -0.3057,  0.0205,  0.1915],
        [ 0.3012, -0.0980, -0.3311,  0.1615,  0.0247,  0.0090,  0.2232,  0.0422],
        [ 0.3065,  0.2714,  0.0905,  0.2634,  0.1132, -0.3355,  0.3173,  0.0108],
        [-0.0437,  0.2914,  0.3084, -0.2798,  0.1393, -0.1944, -0.0908,  0.0760],
        [-0.1312, -0.1493,  0.1760, -0.0850,  0.1335,  0.3390,  0.0858,  0.0822],
        [ 0.3102, -0.1329,  0.0005, -0.3272, -0.1505, -0.0277,  0.3206,  0.1997],
        [-0.0657, -0.0962,  0.0866, -0.1535, -0.0517,  0.0936, -0.1096,  0.2588],
        [ 0.1400, -0.0367, -0.0617,  0.0352,  0.1849,  0.0991, -0.0964,  0.1233],
        [-0.0150, -0.2580, -0.2787,  0.0026,  0.3059, -0.1374,  0.2219, -0.1050],
        [ 0.2114, -0.0792, -0.1466,  0.1037,  0.1871, -0.2695, -0.0258,  0.0734],
        [ 0.0636,  0.3447, -0.3099,  0.3017,  0.1828, -0.3334, -0.1362,  0.1228],
        [-0.2661,  0.3306, -0.1330,  0.1355,  0.0682, -0.1376, -0.3327,  0.0259],
        [-0.2889, -0.0772,  0.0743, -0.1238,  0.2019, -0.3176, -0.2791,  0.1883],
        [-0.1841,  0.2904, -0.0715, -0.0633,  0.3371, -0.0392, -0.2835, -0.1473],
        [ 0.1100,  0.2408,  0.2981, -0.1298,  0.0520,  0.2576, -0.1446,  0.0236],
        [-0.1713,  0.0504,  0.3440,  0.2988, -0.2325,  0.1735,  0.3326, -0.0626],
        [ 0.1255, -0.3175,  0.1964, -0.0662,  0.3247,  0.2476, -0.2032, -0.1563],
        [-0.2780, -0.3266, -0.3208,  0.1712,  0.2345, -0.2243,  0.2474, -0.1109],
        [ 0.1055,  0.2961,  0.2743, -0.2818,  0.1392, -0.1776, -0.3036, -0.0157],
        [-0.0792,  0.0742,  0.0399,  0.2047,  0.1824, -0.3170, -0.3090, -0.2234],
        [ 0.1821,  0.3265, -0.2070,  0.0662,  0.0197,  0.1319,  0.1366,  0.0551],
        [ 0.2352, -0.1175,  0.3375, -0.0100, -0.3204,  0.1723,  0.2489,  0.2370],
        [ 0.0389,  0.1196,  0.1097, -0.1510, -0.0141,  0.0083, -0.1958, -0.1319],
        [-0.1409, -0.0580, -0.2326,  0.2051, -0.0089,  0.2719, -0.2270,  0.0982],
        [-0.1160,  0.1873, -0.1414, -0.1753,  0.0281, -0.2027,  0.2440, -0.0133],
        [ 0.1982, -0.1037, -0.0870, -0.3344,  0.0988,  0.1206,  0.2321,  0.0469],
        [-0.0338, -0.0475,  0.1442,  0.3382,  0.0227, -0.2983, -0.3156,  0.1354],
        [ 0.3147, -0.1869,  0.1782,  0.2959,  0.3095,  0.2246, -0.2294,  0.2480],
        [ 0.0124, -0.2122, -0.3510, -0.1388,  0.2941,  0.3533,  0.2597, -0.2499],
        [ 0.2039,  0.1955,  0.3191, -0.2081,  0.2928, -0.0462,  0.1412, -0.3022],
        [-0.0548, -0.2237, -0.1006, -0.0367, -0.1267,  0.1569,  0.3276,  0.0821],
        [-0.1559, -0.0789, -0.1094,  0.0262, -0.0315,  0.2068,  0.0271, -0.3171],
        [-0.1265, -0.1713,  0.1242,  0.3169,  0.2873,  0.0837, -0.2283, -0.0121],
        [ 0.0552,  0.0071,  0.1950,  0.1707, -0.1086, -0.1310,  0.0411,  0.0339],
        [ 0.0072, -0.3409, -0.3317,  0.3181,  0.3450, -0.3099, -0.2477, -0.0514],
        [-0.2001, -0.3466,  0.1094, -0.2262,  0.1134, -0.2284, -0.0185, -0.1123],
        [-0.0669, -0.1531, -0.2963,  0.2864, -0.0294, -0.1904,  0.3302,  0.0451],
        [-0.0833,  0.1027, -0.0216,  0.0887,  0.2969,  0.1306,  0.2492,  0.1870],
        [-0.1424, -0.0291, -0.0666,  0.3515, -0.1339,  0.2527, -0.1024,  0.2957],
        [ 0.1508,  0.1949, -0.2528, -0.0105,  0.3296, -0.2808, -0.0773, -0.3486],
        [-0.3267,  0.2607, -0.2088,  0.0337, -0.3014, -0.2677,  0.3191,  0.0692],
        [-0.0970, -0.0938,  0.3411,  0.2519,  0.2503,  0.3180,  0.0134,  0.0527],
        [ 0.0207, -0.1413, -0.3069,  0.3155,  0.2934,  0.0332, -0.1256,  0.3072],
        [-0.1572, -0.0134, -0.1212, -0.2063, -0.2696,  0.3450,  0.3104,  0.1738],
        [-0.1299, -0.1155,  0.2072,  0.2681,  0.3534,  0.1652, -0.1346, -0.1548],
        [ 0.3368, -0.2493, -0.2976, -0.0367, -0.0578,  0.1760, -0.2403, -0.0805],
        [-0.2735,  0.2412,  0.0803, -0.1766, -0.0951,  0.2228,  0.2804, -0.3252],
        [-0.2056,  0.0607,  0.0895, -0.2241,  0.1350,  0.0168, -0.1963, -0.2704],
        [-0.0034,  0.1103,  0.1612,  0.1331,  0.2486,  0.3154, -0.2130, -0.1255],
        [-0.2969,  0.2751, -0.3365, -0.1711, -0.3202, -0.0552, -0.1391,  0.2073],
        [-0.2861,  0.2128, -0.1323,  0.0677, -0.2273,  0.0973,  0.2770,  0.1204],
        [ 0.1072, -0.0921, -0.3331,  0.1019,  0.2524,  0.1989,  0.3039, -0.1867],
        [ 0.2019,  0.2423,  0.2620, -0.1815,  0.2628, -0.3068, -0.1894,  0.1849],
        [ 0.2795,  0.2333, -0.0926, -0.2655,  0.2177, -0.1764,  0.2458, -0.0033],
        [ 0.1425,  0.0637, -0.0470, -0.1503, -0.0752, -0.0934, -0.2905,  0.1201],
        [ 0.1396, -0.3531, -0.1693, -0.2809, -0.0032, -0.1976,  0.2816, -0.2696],
        [-0.1188,  0.3122,  0.0139,  0.2834, -0.1677,  0.3057, -0.2394, -0.1406],
        [-0.3114,  0.3349,  0.1348, -0.1151,  0.0399, -0.0090, -0.2572, -0.2337],
        [ 0.1454,  0.2566,  0.0075,  0.3418, -0.0222,  0.2125,  0.1360,  0.3513],
        [ 0.1487, -0.2256,  0.2319, -0.1688, -0.2823, -0.2848,  0.3510,  0.0833],
        [ 0.1471, -0.1524, -0.2836,  0.0988, -0.2898,  0.0745, -0.0469,  0.0351],
        [ 0.2242, -0.3191,  0.1532, -0.1603, -0.0667, -0.1823, -0.1181,  0.1344],
        [ 0.1755, -0.2838,  0.0593, -0.0005,  0.2343, -0.0014,  0.3280,  0.2814],
        [-0.3165,  0.2837,  0.0263, -0.0351, -0.2154, -0.2200,  0.1041, -0.1391],
        [ 0.1278, -0.0467, -0.0828,  0.2123, -0.2533, -0.1226,  0.2444,  0.1898],
        [ 0.3445,  0.2658, -0.2372,  0.2022,  0.0294,  0.2493, -0.0851,  0.1878],
        [-0.0824,  0.1587, -0.1748,  0.1759,  0.2077,  0.2687, -0.1890, -0.1925],
        [ 0.1201, -0.2335, -0.2126,  0.0445,  0.3335, -0.2505, -0.0615, -0.2602],
        [-0.0376,  0.3127, -0.2712,  0.2381,  0.1934,  0.0463,  0.2327,  0.1747],
        [ 0.1121,  0.0500, -0.2299, -0.3358,  0.2369, -0.1292, -0.3198, -0.1155],
        [-0.2489,  0.2882,  0.2611, -0.3147,  0.1436, -0.1443,  0.3379,  0.0333]],
       device='cuda:0', requires_grad=True) 

model.module_1.bias torch.Size([100])
Parameter containing:
tensor([-0.0217,  0.1391, -0.3032, -0.1402,  0.2920,  0.3029, -0.0622,  0.2660,
        -0.2902, -0.2786, -0.0717, -0.3310,  0.3040, -0.0519, -0.1884,  0.1083,
        -0.0597,  0.2080,  0.2029, -0.2607,  0.0784, -0.0710,  0.1738, -0.2460,
         0.0057,  0.1068, -0.2809,  0.1088, -0.1357,  0.1312, -0.1500, -0.0768,
        -0.3385, -0.0480,  0.2662,  0.1246, -0.2660, -0.2945,  0.2678, -0.1521,
        -0.2812, -0.1448,  0.1856,  0.0429, -0.1807,  0.1753,  0.3527,  0.0795,
        -0.2651, -0.0966, -0.3520,  0.3017, -0.2314, -0.0102, -0.2076, -0.0125,
        -0.2500, -0.2793, -0.2549,  0.1505, -0.3536,  0.2946,  0.1525,  0.1896,
         0.3307,  0.0262, -0.0901, -0.3260, -0.2101, -0.2416, -0.3239, -0.1465,
        -0.0073, -0.0108,  0.0550, -0.2430,  0.2099, -0.3285,  0.1208, -0.1406,
         0.3024, -0.1857,  0.3298, -0.2574, -0.2338, -0.0363, -0.2461,  0.0359,
        -0.2527, -0.0373, -0.0453, -0.1252,  0.0574, -0.2009,  0.2063, -0.1008,
        -0.2015, -0.1034,  0.1293, -0.2018], device='cuda:0',
       requires_grad=True) 

model.module_3.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0933, -0.0226, -0.0678,  ...,  0.0994,  0.0608,  0.0021],
        [-0.0388, -0.0371,  0.0607,  ...,  0.0095,  0.0950, -0.0687],
        [ 0.0588, -0.0496,  0.0595,  ..., -0.0210,  0.0532,  0.0896],
        ...,
        [ 0.0929, -0.0252,  0.0570,  ...,  0.0130,  0.0908, -0.0630],
        [ 0.0530,  0.0314,  0.0761,  ..., -0.0336, -0.0321,  0.0323],
        [ 0.0944,  0.0100, -0.0381,  ..., -0.0365, -0.0947,  0.0331]],
       device='cuda:0', requires_grad=True) 

model.module_3.bias torch.Size([100])
Parameter containing:
tensor([ 0.0443,  0.0582,  0.0827,  0.0590, -0.0615,  0.0971, -0.0658,  0.0891,
        -0.0870, -0.0540, -0.0717,  0.0059, -0.0380,  0.0910, -0.0150, -0.0490,
        -0.0733, -0.0226, -0.0532, -0.0218, -0.0386,  0.0919,  0.0994, -0.0543,
         0.0824, -0.0113, -0.0294, -0.0972, -0.0685, -0.0456, -0.0642, -0.0657,
        -0.0137, -0.0510, -0.0655,  0.0739, -0.0748, -0.0629, -0.0331,  0.0722,
         0.0032, -0.0358, -0.0693,  0.0174,  0.0846, -0.0801, -0.0268, -0.0572,
        -0.0101, -0.0062, -0.0482,  0.0568,  0.0256, -0.0906,  0.0655, -0.0286,
        -0.0023,  0.0172,  0.0650,  0.0118,  0.0844,  0.0045, -0.0356,  0.0836,
         0.0787, -0.0196,  0.0761,  0.0256,  0.0411, -0.0494, -0.0945,  0.0389,
        -0.0566,  0.0313, -0.0747, -0.0296, -0.0866, -0.0592, -0.0121, -0.0681,
         0.0783,  0.0199,  0.0672,  0.0084, -0.0305, -0.0972, -0.0098, -0.0266,
         0.0104, -0.0661,  0.0761, -0.0043,  0.0830,  0.0486, -0.0546, -0.0101,
        -0.0112, -0.0487,  0.0356,  0.0068], device='cuda:0',
       requires_grad=True) 

model.module_5.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0949,  0.0133,  0.0722,  ...,  0.0426,  0.0976,  0.0559],
        [-0.0207, -0.0169, -0.0634,  ..., -0.0090,  0.0898, -0.0943],
        [-0.0048,  0.0029, -0.0758,  ..., -0.0955, -0.0880,  0.0606],
        ...,
        [-0.0149,  0.0343, -0.0207,  ...,  0.0267,  0.0377,  0.0077],
        [-0.0049, -0.0380, -0.0445,  ..., -0.0330, -0.0631, -0.0705],
        [-0.0132,  0.0468, -0.0670,  ..., -0.0540, -0.0871,  0.0380]],
       device='cuda:0', requires_grad=True) 

model.module_5.bias torch.Size([16])
Parameter containing:
tensor([-0.0439, -0.0970,  0.0158,  0.0800, -0.0041, -0.0814,  0.0532, -0.0546,
         0.0630, -0.0688,  0.0907, -0.0242,  0.0918,  0.0472,  0.0743,  0.0182],
       device='cuda:0', requires_grad=True) 

model.module_7.att torch.Size([1, 1, 8])
Parameter containing:
tensor([[[-0.4558, -0.2241,  0.0241,  0.2227,  0.5675,  0.3815, -0.4424,
           0.4591]]], device='cuda:0', requires_grad=True) 

model.module_7.bias torch.Size([8])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

model.module_7.lin_l.weight torch.Size([8, 16])
Parameter containing:
tensor([[-0.1740,  0.4326,  0.3528, -0.4367,  0.1429, -0.3334, -0.2502, -0.2655,
          0.0038, -0.1384, -0.1200,  0.3532,  0.0671, -0.3712, -0.2429, -0.4093],
        [-0.2256,  0.2847,  0.1543, -0.1498,  0.2588,  0.0217,  0.4041, -0.2064,
         -0.4764, -0.1805, -0.0551,  0.4537,  0.0978, -0.2143,  0.2858,  0.4478],
        [-0.2772, -0.0828,  0.4960,  0.4475, -0.0270,  0.2979,  0.2913, -0.0168,
         -0.2187, -0.0057,  0.0292,  0.4662,  0.2373, -0.2455,  0.4473, -0.2117],
        [-0.2151,  0.3485,  0.2741,  0.3042,  0.0034, -0.4410,  0.4949,  0.0855,
          0.2699,  0.4539,  0.1788,  0.3827,  0.0325,  0.3984,  0.4349,  0.4546],
        [ 0.1675,  0.2437, -0.0705, -0.1436, -0.2682,  0.2925, -0.1358,  0.3395,
          0.0440, -0.1259, -0.2216, -0.0860, -0.2889, -0.1192, -0.1472, -0.3324],
        [ 0.4558, -0.1729,  0.4286,  0.4489,  0.2535,  0.4515,  0.1901, -0.4263,
         -0.2733,  0.0922,  0.0817,  0.1107, -0.2365, -0.2999, -0.0640,  0.2442],
        [ 0.2044, -0.0522,  0.2738, -0.3807, -0.3359,  0.1804,  0.4258, -0.2854,
         -0.2927,  0.1705,  0.0056, -0.3828, -0.3987, -0.4233, -0.1704,  0.0036],
        [-0.1050, -0.1123, -0.3800,  0.3366,  0.3973,  0.0438,  0.1489,  0.4555,
         -0.3213,  0.0288, -0.1815, -0.2664, -0.0212, -0.1640, -0.4898,  0.4332]],
       device='cuda:0', requires_grad=True) 

model.module_7.lin_l.bias torch.Size([8])
Parameter containing:
tensor([-0.2243,  0.1549,  0.0356,  0.0838,  0.2375,  0.1646,  0.2399,  0.0762],
       device='cuda:0', requires_grad=True) 

model.module_7.lin_r.weight torch.Size([8, 16])
Parameter containing:
tensor([[-0.2011,  0.0246, -0.2309, -0.3181, -0.0032, -0.1970,  0.0172, -0.0831,
         -0.2752,  0.0537, -0.3059, -0.1685, -0.2691,  0.4041, -0.1991, -0.3418],
        [-0.0800,  0.2587,  0.0982,  0.4377, -0.0450,  0.1509, -0.3568,  0.0322,
          0.2004, -0.1553, -0.0704, -0.0153, -0.3329, -0.1902, -0.4964, -0.1514],
        [-0.0168, -0.0700, -0.0977, -0.1004, -0.0094,  0.3655, -0.0075,  0.3242,
         -0.1605,  0.1926,  0.0716,  0.0569, -0.3281,  0.2484,  0.0819, -0.3648],
        [-0.4319, -0.1560, -0.2869, -0.4468, -0.0278, -0.2743, -0.3468,  0.4479,
          0.2381,  0.4995,  0.3566, -0.3669,  0.4454,  0.0933,  0.1617, -0.4106],
        [ 0.0440,  0.3407, -0.0693,  0.0792, -0.2632,  0.2682, -0.2123,  0.1809,
         -0.3446,  0.0338,  0.4998, -0.2337, -0.3627,  0.2633, -0.3675,  0.0782],
        [-0.3815, -0.3564, -0.4620,  0.1517,  0.0169, -0.3591, -0.4522,  0.1264,
          0.3296, -0.2118,  0.1163,  0.4293,  0.3825,  0.3295,  0.1901,  0.2666],
        [-0.4780, -0.4282, -0.3013,  0.4320,  0.4690,  0.4646, -0.1469, -0.4838,
         -0.3895,  0.3557,  0.1377,  0.4573,  0.1584, -0.2062, -0.4906, -0.1500],
        [ 0.2027,  0.0593, -0.2540, -0.0251, -0.3112,  0.0934, -0.3804, -0.0808,
          0.1239, -0.3071, -0.1204, -0.3763, -0.0031,  0.1417, -0.2206,  0.2943]],
       device='cuda:0', requires_grad=True) 

model.module_7.lin_r.bias torch.Size([8])
Parameter containing:
tensor([-0.1594,  0.1429,  0.1208, -0.0825,  0.1363,  0.1808, -0.0961,  0.0416],
       device='cuda:0', requires_grad=True) 

model.module_7.lin_edge.weight torch.Size([8, 2])
Parameter containing:
tensor([[ 0.7537,  0.6011],
        [ 0.0236,  0.5373],
        [ 0.4833,  0.3944],
        [-0.1194, -0.7584],
        [ 0.3120,  0.0327],
        [-0.3679, -0.6771],
        [-0.5510, -0.4474],
        [-0.1444, -0.4230]], device='cuda:0', requires_grad=True) 

model.module_8.weight torch.Size([100, 8])
Parameter containing:
tensor([[ 2.3660e-01,  3.0046e-01,  8.3210e-02,  3.1519e-01,  1.3821e-01,
         -4.5123e-02, -3.3628e-01, -8.2052e-02],
        [ 1.3764e-01,  2.0595e-01, -2.0659e-01,  3.2660e-04,  2.9933e-01,
         -2.5085e-01,  1.5807e-01,  7.0358e-02],
        [ 5.9888e-02,  1.8644e-01,  1.9863e-01, -1.5930e-01,  1.6904e-01,
         -3.2656e-01,  1.6127e-01,  4.4750e-02],
        [-4.2302e-02,  2.6215e-01,  1.6587e-01, -6.7752e-02, -7.6882e-02,
          2.2880e-01,  1.8903e-01, -1.0846e-01],
        [ 1.0903e-01, -2.9777e-01,  2.9752e-01, -1.3413e-01, -2.4973e-01,
          2.7788e-01, -1.6083e-01,  3.1376e-01],
        [ 2.0915e-01, -2.1088e-01,  4.3167e-02,  2.9375e-01, -2.5500e-01,
          1.6795e-02, -2.5761e-02, -3.0281e-01],
        [ 9.9125e-02,  2.9482e-01,  2.4980e-01,  1.5386e-01,  2.5535e-02,
         -1.1743e-01,  6.9211e-02,  3.9184e-04],
        [ 2.2367e-01, -2.2659e-01, -8.0401e-02, -2.6796e-01,  2.3761e-01,
          2.0438e-01, -3.0134e-01,  2.5764e-02],
        [ 2.6754e-01, -1.5394e-02,  3.4900e-01, -7.9409e-02,  2.9620e-01,
         -5.8776e-03,  2.3049e-01, -2.7589e-01],
        [ 3.4429e-01,  2.5034e-02,  2.0616e-01,  1.4434e-01,  1.7849e-01,
         -9.5372e-02, -3.3586e-01,  2.1740e-01],
        [-2.4013e-01,  1.4721e-01,  2.5475e-01, -9.8620e-02,  3.3737e-01,
         -1.5747e-01, -3.3162e-01, -2.6540e-01],
        [-1.1617e-01,  1.1190e-01, -1.9354e-01,  6.0064e-03, -3.7987e-04,
          2.7732e-01, -2.2556e-01,  7.4922e-02],
        [ 3.0114e-01, -7.2727e-02, -5.4758e-03,  2.9370e-01,  2.4933e-01,
          1.8343e-01, -3.2402e-01, -3.5051e-02],
        [-3.2559e-01, -1.5528e-01, -1.1954e-01,  8.0368e-02,  3.3943e-01,
          2.8254e-01, -2.9974e-01,  1.4855e-01],
        [-1.7803e-01, -2.7154e-01,  2.5775e-01,  3.1312e-01, -2.4073e-01,
         -3.2868e-01,  1.5600e-01,  2.6629e-01],
        [ 1.4690e-01,  2.0285e-01, -2.7654e-01,  1.7609e-01, -8.5484e-02,
         -9.0473e-02, -3.4018e-01,  2.7768e-01],
        [ 2.5911e-01, -1.6740e-01,  1.5234e-01,  2.0647e-01,  3.5221e-02,
         -2.4162e-01,  1.9530e-02, -9.8324e-02],
        [ 2.6838e-01, -1.4618e-01, -2.9885e-01, -3.4228e-01, -1.3814e-01,
         -1.9335e-01, -1.3955e-01, -1.1439e-01],
        [-3.0329e-01, -1.6840e-01, -1.2728e-03,  1.8410e-01,  2.9613e-01,
          1.0548e-02,  6.2621e-03, -1.4372e-01],
        [ 1.9127e-01,  2.2631e-01, -2.1012e-01, -1.6424e-01, -1.9743e-01,
         -1.1383e-01, -1.3878e-01,  1.6604e-01],
        [-1.3825e-01, -2.7157e-01, -6.1837e-03,  5.3736e-02,  1.9877e-01,
         -2.5496e-01,  3.7997e-03,  3.1095e-01],
        [ 3.0400e-01,  2.7077e-01, -3.5071e-02, -7.7941e-02,  3.2681e-01,
          3.1705e-01,  2.0255e-01,  9.2155e-02],
        [ 4.9080e-02, -1.7636e-01,  2.6214e-01, -3.8303e-02, -3.0569e-01,
          7.7993e-02,  1.3991e-01,  1.8872e-01],
        [-1.1051e-02,  9.8460e-02,  8.5637e-02, -7.0362e-02, -2.7493e-01,
          3.3616e-01,  1.4570e-01,  8.9389e-02],
        [-2.5934e-01,  7.7385e-02,  3.7357e-02,  2.0426e-01,  3.5088e-01,
         -9.0070e-02, -3.5181e-01, -2.7756e-01],
        [ 2.3983e-01,  3.7147e-02,  2.0697e-01, -1.6715e-01,  1.3431e-01,
         -2.7936e-02, -6.4044e-02,  6.2392e-02],
        [ 3.5383e-02, -1.4230e-02, -1.3615e-01, -1.5826e-01, -9.7618e-02,
         -2.4629e-01, -1.4105e-01, -1.6420e-03],
        [-1.6255e-01,  7.3592e-02,  1.9831e-01,  8.1038e-02, -1.0451e-01,
          3.2105e-02, -1.8175e-01,  2.8659e-01],
        [ 2.6563e-01,  3.0729e-01, -9.5050e-02,  2.6820e-01,  6.4903e-02,
         -7.2091e-02,  2.3779e-01, -2.1416e-01],
        [-3.1607e-01,  3.2566e-01,  1.4562e-01,  1.9714e-01, -3.3005e-01,
          6.6082e-02,  1.5270e-01, -1.0376e-01],
        [-2.2655e-01,  2.8084e-01,  8.7597e-02,  1.6963e-01,  3.4098e-01,
         -2.7546e-01,  2.4603e-01, -1.3299e-01],
        [ 1.3186e-01,  2.2972e-01,  2.5725e-01,  1.1699e-01,  4.2694e-02,
          9.3131e-03, -9.3101e-02,  1.8667e-01],
        [ 3.3779e-01,  4.6762e-03, -3.0401e-01, -7.6189e-02, -9.9894e-02,
          1.8031e-01, -2.7857e-01, -9.7684e-02],
        [-1.4724e-01, -2.6530e-01, -1.5684e-01,  2.0298e-01,  8.2387e-02,
          2.7386e-01, -1.7293e-02,  1.7608e-01],
        [ 1.4753e-01,  2.3156e-01, -3.7735e-02,  2.6062e-01, -3.7550e-02,
         -1.2708e-01,  1.4544e-01,  1.2416e-01],
        [-2.3521e-01, -1.2202e-01, -3.2998e-01,  3.4030e-01,  8.4710e-02,
          2.8912e-01, -3.0311e-01,  3.4040e-01],
        [ 3.2881e-01,  3.2528e-01, -2.1894e-01,  3.2140e-01, -2.9534e-01,
         -2.5556e-01, -1.2429e-01,  3.4635e-01],
        [-9.9448e-02,  1.4171e-01, -4.1452e-02,  1.7923e-01,  2.0855e-01,
          3.1879e-01,  2.0548e-01,  2.8512e-01],
        [ 3.1809e-01,  1.2790e-01,  2.4962e-01,  3.0485e-01,  1.5497e-01,
         -1.1431e-01,  2.6616e-01,  5.6159e-02],
        [ 2.1753e-01, -1.0918e-01, -3.2876e-01, -2.1685e-01, -1.7590e-02,
         -2.3503e-01, -1.4729e-01,  1.7774e-01],
        [ 1.2752e-01, -1.0336e-01, -1.4370e-02, -3.3604e-01, -1.8351e-02,
         -1.2519e-02, -2.1856e-01,  3.2038e-01],
        [-1.7417e-01,  5.0074e-02, -2.3990e-01,  6.9497e-02, -2.6580e-01,
          2.8042e-03,  1.5484e-01,  2.9434e-01],
        [ 3.7475e-02,  8.2629e-02,  6.4454e-02, -1.8120e-01,  9.6210e-02,
         -3.0384e-01, -1.1419e-01,  7.3737e-03],
        [-1.0786e-01,  1.5069e-01, -2.4643e-01,  1.1989e-01, -2.0730e-01,
         -2.8249e-01, -4.8469e-02, -1.5114e-02],
        [-1.4507e-01,  3.4218e-01, -1.0441e-01, -8.8559e-02,  3.8961e-02,
         -1.3969e-01,  4.6392e-02,  3.3062e-01],
        [-2.7786e-02, -1.3758e-01,  2.2489e-01,  8.4922e-02,  1.8090e-01,
          9.5330e-02, -1.9592e-01, -2.8174e-01],
        [-1.2102e-01, -2.9757e-01, -3.0506e-01,  2.0632e-01, -2.2941e-02,
         -1.1026e-02, -2.6831e-01,  1.8519e-01],
        [ 2.7646e-01,  2.1949e-01, -2.1151e-01,  3.5266e-02, -1.6933e-01,
          1.6415e-01,  1.8855e-01, -1.8394e-01],
        [-2.5106e-01, -2.4984e-01,  1.5096e-01,  8.6455e-02,  2.4694e-01,
         -5.0450e-02,  2.7635e-01,  3.2595e-01],
        [-2.7272e-01, -6.0347e-02,  4.0799e-02,  2.2063e-01, -3.1532e-01,
          1.5436e-01,  2.8272e-02,  2.6035e-01],
        [-3.0591e-01,  2.8694e-01,  2.6010e-01, -5.3879e-03, -9.6828e-02,
          1.7647e-01, -1.0549e-01, -7.6771e-02],
        [-2.0666e-01,  3.2856e-01,  2.4362e-01,  5.5717e-02,  2.7191e-02,
         -2.2641e-01,  2.8151e-01,  1.5005e-01],
        [ 1.1363e-01,  1.3406e-01, -3.1340e-01, -1.2328e-01,  2.3897e-01,
         -1.1008e-01,  2.9582e-01, -2.5245e-01],
        [ 2.6845e-01,  3.5037e-01, -3.0413e-01,  2.8844e-01,  9.6585e-02,
          1.7257e-01, -1.0879e-01,  2.5334e-01],
        [ 7.8827e-02, -2.6047e-01,  3.0873e-01,  1.5459e-03, -8.4871e-02,
          9.0540e-02,  4.2749e-02, -3.2407e-01],
        [ 3.4947e-01, -3.8100e-02,  1.0325e-01, -6.5358e-02, -3.2788e-01,
         -3.0272e-01, -1.0173e-01, -1.1301e-01],
        [ 2.8179e-01,  4.8600e-02,  3.3951e-01,  2.8833e-01,  3.8893e-02,
         -1.3279e-01,  8.0050e-03, -1.2396e-01],
        [-3.5150e-01,  9.6572e-02,  1.4219e-01, -1.0871e-01,  3.1975e-01,
          3.7508e-02, -1.6600e-02, -8.8829e-02],
        [ 3.3878e-01,  1.8922e-01, -2.5110e-01, -2.6628e-01, -2.8551e-01,
          3.1953e-01,  2.9307e-01,  1.7813e-01],
        [ 1.7330e-01, -2.3780e-01,  2.5778e-01, -2.4617e-02, -1.0353e-02,
          4.3183e-02, -1.0310e-01,  3.2634e-01],
        [ 4.4175e-02,  2.2808e-01, -2.1902e-01, -3.0377e-01, -1.1811e-01,
          1.0978e-01, -2.4487e-01, -1.9049e-01],
        [ 1.1118e-01,  3.4576e-01,  3.0408e-01,  3.2497e-01, -7.2088e-02,
         -2.4720e-01,  1.2821e-01, -2.0283e-01],
        [ 3.3585e-01,  8.8444e-02, -3.1189e-01,  2.5307e-03, -2.2870e-01,
          1.2999e-01, -1.7865e-01, -1.1805e-02],
        [ 2.5823e-01, -2.6029e-01,  2.4577e-01,  2.1991e-01,  2.1434e-02,
          2.9267e-01, -2.3657e-01, -2.7627e-01],
        [-1.2776e-01,  2.9729e-01, -2.0462e-01,  1.2841e-01, -2.4805e-01,
          2.4208e-02,  3.0032e-01,  2.5171e-01],
        [ 1.5978e-01, -1.4925e-01,  1.7208e-01,  3.0044e-01, -3.2179e-01,
          9.0229e-02, -1.7977e-01,  1.7171e-01],
        [-2.1609e-02, -7.7251e-02, -2.4802e-01, -2.4356e-01,  4.5257e-02,
          1.0752e-01, -9.5436e-03,  2.8460e-01],
        [-2.5026e-02, -2.4743e-01,  1.2408e-01, -2.3610e-01,  2.9829e-01,
          5.0740e-02,  1.1471e-02,  1.2500e-01],
        [ 1.7391e-01, -2.6299e-01, -1.4094e-01, -1.1770e-01, -6.9875e-03,
          1.6360e-01, -1.6733e-01,  1.1810e-01],
        [ 4.1881e-02, -2.7906e-01,  1.8445e-01,  8.8871e-03, -2.2971e-01,
          7.7827e-02, -1.6457e-01,  9.4567e-03],
        [-2.8450e-01,  2.8214e-01, -4.1063e-02,  3.3115e-01,  2.6241e-01,
         -3.1654e-01, -3.5147e-01,  2.1970e-01],
        [-1.0872e-01,  2.1403e-01,  7.5367e-02,  1.4650e-01,  2.3939e-01,
          1.4036e-01,  3.0746e-01, -3.6061e-02],
        [ 2.7741e-01, -2.9329e-01, -3.3969e-01, -2.5263e-01,  1.3815e-01,
         -3.3803e-01,  1.4330e-01,  1.2574e-01],
        [-2.4996e-01, -2.8669e-01, -8.9102e-02, -1.9448e-01, -1.3959e-01,
         -5.4369e-02,  8.9140e-02, -1.9481e-01],
        [-2.4006e-01, -3.0623e-01,  1.2532e-01, -1.4534e-01,  2.8231e-01,
         -2.5171e-02,  4.8270e-03, -7.8716e-02],
        [-2.3461e-01,  2.0060e-01,  2.7353e-01, -2.4344e-01,  1.5414e-01,
         -3.1280e-02, -3.2294e-01, -2.7620e-02],
        [-1.0953e-01, -1.1318e-01, -2.5636e-01, -4.3248e-02,  3.4966e-01,
          3.9886e-02, -3.4767e-01,  1.8506e-02],
        [-2.8953e-01,  1.4516e-01,  3.1433e-01,  1.6503e-01, -2.5411e-03,
         -1.6048e-01, -1.3387e-01, -3.1748e-01],
        [-1.4525e-01, -1.7659e-01, -1.4339e-01, -2.2191e-01, -7.6660e-02,
         -1.9206e-01, -2.2248e-02, -8.2906e-02],
        [-2.3592e-01, -3.4027e-01,  1.1740e-01,  2.6380e-01, -1.8136e-01,
         -1.8463e-01,  2.2883e-01,  4.7466e-03],
        [-2.7340e-02,  3.3487e-01, -4.3849e-02,  2.1891e-01,  1.2122e-01,
          1.5901e-01,  4.6638e-02,  5.4838e-03],
        [-2.7804e-01, -8.6776e-02, -3.2059e-01,  3.9347e-02,  2.2162e-01,
         -1.2292e-02,  7.4169e-02, -8.3207e-03],
        [-6.4460e-02, -2.8703e-01, -2.2775e-02, -2.8757e-01,  2.4973e-01,
         -2.0103e-01,  1.0456e-03, -3.9343e-02],
        [ 2.9282e-01, -3.2726e-01,  3.1335e-01,  1.7377e-01, -2.4547e-01,
         -2.3150e-02,  3.3066e-01,  1.7654e-01],
        [ 2.5246e-02,  2.9879e-01,  1.4031e-01,  3.1788e-01,  2.4880e-01,
          1.3482e-01,  1.2033e-02, -1.4902e-01],
        [-2.0799e-01, -1.1030e-01,  1.5942e-01, -2.4990e-01,  3.4529e-01,
         -8.1718e-02, -2.7167e-01, -3.0511e-01],
        [-8.4629e-02,  3.5211e-01, -2.4909e-01, -3.1012e-01, -3.4645e-01,
         -2.1039e-01,  2.3655e-01,  2.6134e-01],
        [ 8.1899e-02, -1.5349e-01,  3.3898e-01, -1.5344e-01, -3.2887e-01,
          1.7651e-01,  3.3687e-01, -1.5963e-01],
        [-1.6181e-01, -8.6479e-02, -1.9536e-01,  1.8486e-01, -1.1678e-01,
          5.6338e-02,  4.5435e-02,  1.9658e-01],
        [-9.8344e-02, -1.3621e-01, -4.2921e-03,  7.4291e-02,  1.1642e-01,
         -2.5120e-01,  3.7787e-02,  2.8139e-01],
        [-1.5872e-01,  5.2812e-02, -9.4730e-02,  2.9741e-01, -3.5257e-01,
          5.9281e-02,  1.0543e-01,  2.6007e-02],
        [ 2.0787e-01,  2.5913e-01, -2.9089e-01, -1.6184e-01, -1.3887e-01,
         -1.4011e-01, -3.4325e-01,  2.0779e-01],
        [-2.9105e-01, -5.9774e-02, -3.1537e-01,  1.1778e-01,  3.0472e-01,
         -1.3992e-01, -1.5787e-01, -3.8998e-02],
        [-1.5589e-01, -7.0450e-02,  1.2094e-01, -1.8676e-01, -1.1210e-01,
         -2.7812e-01,  2.3685e-01,  6.4929e-02],
        [ 4.0757e-02,  3.3958e-03,  3.3553e-01,  3.2081e-01,  2.7859e-01,
         -1.8807e-01,  3.5057e-01,  2.7951e-01],
        [-3.1341e-01, -2.7865e-01, -3.2431e-01, -1.1356e-01, -3.3519e-01,
         -2.2673e-01, -2.2395e-01,  3.3418e-01],
        [-1.5161e-01, -3.5414e-02,  2.7366e-01,  6.8337e-02,  1.5445e-02,
         -1.2588e-01,  2.6372e-01, -2.7102e-01],
        [ 1.1976e-01,  6.0102e-02,  2.1023e-01, -2.1635e-01,  2.1395e-01,
          1.9881e-01, -2.8384e-01,  3.3957e-01],
        [-4.2829e-02,  2.1509e-01, -1.7119e-01,  2.4115e-02, -2.6311e-01,
         -2.2645e-01,  2.8091e-02,  1.6906e-01],
        [ 3.1126e-01, -3.5108e-01,  2.1033e-01,  1.2544e-01,  3.3448e-01,
         -7.5344e-03, -1.9629e-02, -3.4769e-01]], device='cuda:0',
       requires_grad=True) 

model.module_8.bias torch.Size([100])
Parameter containing:
tensor([ 0.1991, -0.0472, -0.1030, -0.0773, -0.2387, -0.1065,  0.0991,  0.2232,
        -0.2494, -0.3287,  0.0577,  0.2929,  0.0012, -0.0574, -0.1932, -0.0457,
        -0.2000,  0.1881,  0.0115, -0.0287, -0.1568,  0.1914, -0.3097,  0.2944,
        -0.1517, -0.1960,  0.0068,  0.3484, -0.1474,  0.2206, -0.0360, -0.2769,
        -0.0143,  0.1085,  0.2272, -0.0715, -0.1987, -0.1046,  0.1958,  0.0318,
        -0.1378,  0.1476, -0.2337,  0.0477,  0.1087,  0.0295,  0.2449, -0.3216,
         0.3186,  0.0879, -0.3145, -0.0170, -0.2765, -0.1731,  0.0488,  0.0534,
        -0.2901,  0.3042, -0.0252,  0.1527, -0.1303,  0.1387, -0.1098,  0.2559,
         0.0521, -0.1781, -0.0033, -0.2007,  0.2811, -0.2600, -0.1706,  0.2085,
         0.0038,  0.1790, -0.0412,  0.2673, -0.0819,  0.0398,  0.2166,  0.1226,
         0.1317,  0.1824, -0.3507,  0.3114,  0.2102, -0.0667, -0.1108, -0.1956,
         0.0385,  0.1660, -0.1315, -0.1057,  0.1875, -0.2577, -0.0555,  0.2786,
         0.0406,  0.2474, -0.0310,  0.3390], device='cuda:0',
       requires_grad=True) 

model.module_10.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0500, -0.0975, -0.0423,  ...,  0.0167, -0.0869,  0.0562],
        [-0.0180,  0.0884,  0.0735,  ..., -0.0054, -0.0801, -0.0839],
        [ 0.0466,  0.0442,  0.0813,  ..., -0.0728,  0.0881, -0.0903],
        ...,
        [ 0.0913, -0.0998,  0.0384,  ..., -0.0309, -0.0264,  0.0448],
        [-0.0816, -0.0623,  0.0350,  ...,  0.0888,  0.0066, -0.0048],
        [ 0.0447, -0.0599,  0.0383,  ..., -0.0442, -0.0792,  0.0987]],
       device='cuda:0', requires_grad=True) 

model.module_10.bias torch.Size([100])
Parameter containing:
tensor([-0.0612,  0.0564,  0.0412, -0.0478,  0.0996,  0.0074, -0.0968,  0.0093,
         0.0158,  0.0566, -0.0316,  0.0675, -0.0828,  0.0344,  0.0391,  0.0754,
        -0.0144, -0.0687,  0.0882, -0.0441, -0.0875,  0.0333, -0.0384,  0.0340,
         0.0934,  0.0470,  0.0819,  0.0235,  0.0464, -0.0942,  0.0625,  0.0736,
         0.0499, -0.0845, -0.0768,  0.0206,  0.0405, -0.0675,  0.0281,  0.0626,
        -0.0954, -0.0040, -0.0184, -0.0839,  0.0480, -0.0736,  0.0880,  0.0830,
        -0.0743,  0.0449,  0.0114, -0.0458, -0.0384, -0.0241,  0.0049, -0.0137,
        -0.0333, -0.0744,  0.0827, -0.0639, -0.0345, -0.0811,  0.0979, -0.0873,
         0.0776, -0.0416, -0.0005,  0.0781, -0.0939, -0.0116,  0.0618, -0.0456,
         0.0129, -0.0522, -0.0110,  0.0548,  0.0317,  0.0296,  0.0120,  0.0266,
         0.0728, -0.0305, -0.0276,  0.0669, -0.0771, -0.0853, -0.0621,  0.0309,
         0.0198,  0.0213, -0.0473,  0.0940,  0.0102,  0.0571,  0.0529,  0.0922,
         0.0480, -0.0899, -0.0724, -0.0874], device='cuda:0',
       requires_grad=True) 

model.module_12.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0074, -0.0445, -0.0619,  ...,  0.0839,  0.0068, -0.0910],
        [ 0.0918,  0.0009, -0.0217,  ...,  0.0305, -0.0410,  0.0922],
        [-0.0945,  0.0436, -0.0761,  ..., -0.0320,  0.0879, -0.0285],
        ...,
        [-0.0305,  0.0177,  0.0956,  ..., -0.0694, -0.0163, -0.0118],
        [-0.0860, -0.0234, -0.0031,  ..., -0.0732,  0.0486, -0.0715],
        [-0.0347,  0.0698, -0.0094,  ...,  0.0321,  0.0497,  0.0533]],
       device='cuda:0', requires_grad=True) 

model.module_12.bias torch.Size([16])
Parameter containing:
tensor([ 0.0338,  0.0466, -0.0017, -0.0674, -0.0131, -0.0085, -0.0488,  0.0848,
         0.0549,  0.0972,  0.0814, -0.0171, -0.0434,  0.0242,  0.0029, -0.0287],
       device='cuda:0', requires_grad=True) 

model.module_14.att torch.Size([1, 1, 8])
Parameter containing:
tensor([[[-0.3158,  0.3942, -0.6489, -0.7462, -0.6339, -0.7569, -0.7868,
           0.4610]]], device='cuda:0', requires_grad=True) 

model.module_14.bias torch.Size([8])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

model.module_14.lin_l.weight torch.Size([8, 16])
Parameter containing:
tensor([[-0.1016, -0.2468,  0.4290,  0.2688, -0.0636,  0.0390,  0.0932, -0.2420,
         -0.3585, -0.0399,  0.3796, -0.2808,  0.2819, -0.1985,  0.4019, -0.3104],
        [ 0.3431, -0.1549, -0.2748,  0.1182,  0.2004, -0.1023,  0.3842, -0.4895,
          0.4265, -0.4504,  0.1714,  0.1548,  0.0834, -0.3729,  0.3717, -0.2810],
        [-0.4083,  0.0569,  0.4463,  0.2508,  0.2765, -0.2161,  0.3292, -0.3969,
         -0.1151, -0.1141,  0.2610,  0.0693, -0.3338,  0.1678,  0.3960, -0.1918],
        [ 0.4219,  0.1655, -0.4040,  0.4527,  0.1598, -0.4110, -0.2569, -0.3234,
          0.4033,  0.0612, -0.4243, -0.0219, -0.3736,  0.1771,  0.3285, -0.0674],
        [-0.3605,  0.4021, -0.2153,  0.0752, -0.2374, -0.3605,  0.3988,  0.3354,
          0.2962,  0.3860,  0.4319,  0.0943,  0.0429, -0.3439, -0.2023,  0.2717],
        [-0.1069,  0.4208,  0.1753,  0.3252,  0.0749, -0.3052, -0.1250,  0.3963,
          0.0591, -0.1896,  0.2449, -0.2572, -0.0872, -0.4967,  0.1564,  0.1627],
        [ 0.1141,  0.2598,  0.4180,  0.3077,  0.0972,  0.1392, -0.4224, -0.4524,
          0.2743,  0.0318, -0.3989, -0.0395,  0.3483,  0.4348,  0.0641,  0.1047],
        [-0.4391, -0.2324,  0.0448, -0.0839,  0.1535,  0.4847,  0.1882,  0.1483,
          0.0092,  0.4673, -0.3380,  0.3897,  0.4087,  0.0555, -0.4025, -0.1379]],
       device='cuda:0', requires_grad=True) 

model.module_14.lin_l.bias torch.Size([8])
Parameter containing:
tensor([ 0.2420,  0.0887,  0.2198,  0.2210,  0.1044,  0.0335, -0.1929,  0.1329],
       device='cuda:0', requires_grad=True) 

model.module_14.lin_r.weight torch.Size([8, 16])
Parameter containing:
tensor([[-0.0908,  0.0145,  0.1770,  0.1386,  0.2972,  0.2271, -0.0362, -0.3292,
         -0.0968,  0.4067, -0.1446,  0.1272, -0.3387,  0.2081, -0.1624,  0.4481],
        [-0.4580,  0.2650, -0.3267,  0.0621,  0.3298,  0.1558,  0.1903,  0.4957,
          0.0265,  0.1591,  0.2576, -0.4530,  0.4299, -0.3088, -0.2362, -0.0751],
        [-0.4908,  0.2504, -0.3200,  0.2006,  0.0807,  0.1974,  0.3930, -0.4351,
         -0.4080,  0.2346, -0.1132, -0.4900,  0.4160,  0.2807, -0.3780,  0.3102],
        [ 0.1659,  0.1368,  0.0219,  0.0574,  0.4844,  0.0388,  0.2468, -0.4673,
         -0.0101,  0.4213, -0.4002, -0.2230,  0.3796,  0.1973, -0.2649,  0.0293],
        [ 0.2398,  0.0128,  0.2998,  0.4951, -0.0851,  0.3617, -0.4258,  0.1770,
         -0.4308, -0.2282,  0.3360,  0.0512,  0.1493,  0.3166,  0.4681, -0.3827],
        [-0.3940, -0.1511, -0.0871, -0.1197,  0.2923,  0.3569,  0.3630,  0.2485,
          0.0484, -0.2350, -0.2062, -0.1417,  0.4041, -0.0976,  0.3788,  0.2324],
        [-0.1377,  0.3415,  0.3787,  0.1105,  0.3797, -0.4331,  0.3780,  0.4997,
          0.0825, -0.3546, -0.2212, -0.3406,  0.3868,  0.3469,  0.1686,  0.2585],
        [-0.3330,  0.3643,  0.1676, -0.1213, -0.4783,  0.2588,  0.0127, -0.0945,
         -0.4261,  0.0286,  0.2995, -0.0806, -0.0976,  0.0807,  0.2286, -0.4481]],
       device='cuda:0', requires_grad=True) 

model.module_14.lin_r.bias torch.Size([8])
Parameter containing:
tensor([ 0.1424, -0.0194, -0.2206, -0.1095, -0.0573, -0.0377, -0.0725, -0.1319],
       device='cuda:0', requires_grad=True) 

model.module_14.lin_edge.weight torch.Size([8, 2])
Parameter containing:
tensor([[-0.7151,  0.5352],
        [ 0.1334,  0.1069],
        [ 0.2569, -0.4533],
        [ 0.0372,  0.5694],
        [ 0.1561, -0.0292],
        [-0.6916,  0.2189],
        [ 0.5862, -0.1093],
        [ 0.2602,  0.7233]], device='cuda:0', requires_grad=True) 

model.module_15.weight torch.Size([100, 8])
Parameter containing:
tensor([[-2.4896e-01,  1.4229e-02, -3.2114e-01,  2.7304e-01,  3.7580e-02,
          1.1205e-01,  2.9343e-01,  8.2851e-02],
        [-1.0894e-02, -2.1559e-01, -1.7603e-01, -1.8479e-01,  1.2501e-01,
          2.6207e-01,  1.9355e-01, -2.6120e-01],
        [ 1.3981e-01,  1.9453e-01, -1.7537e-01,  2.8383e-01, -2.6557e-01,
          1.4875e-01,  1.7992e-01, -1.8888e-01],
        [ 2.6669e-01, -7.1765e-02,  2.8013e-01,  1.0375e-01, -5.0137e-03,
         -2.2252e-01, -1.6139e-01,  1.5631e-01],
        [-2.7351e-01,  5.8835e-02,  1.7964e-01, -1.7146e-01, -5.2084e-02,
          1.6208e-02, -1.9997e-01,  1.4438e-01],
        [ 1.1572e-02, -1.9656e-01, -2.3552e-01,  1.1909e-01, -2.3105e-01,
          3.1249e-01,  2.6514e-01,  1.2891e-01],
        [ 8.2487e-02, -1.8436e-01, -1.4741e-01,  2.0428e-01, -1.4078e-01,
         -2.7599e-01, -2.4038e-01,  3.3914e-01],
        [-1.4761e-01, -1.0779e-01,  1.3575e-01, -2.0794e-01, -1.3302e-01,
         -2.4824e-03,  2.4515e-01, -2.6219e-01],
        [ 1.7898e-01, -3.0391e-01,  2.2241e-01, -1.9579e-01,  4.1468e-02,
          3.0716e-01, -9.0572e-02, -9.0143e-02],
        [-1.6896e-02, -3.3635e-01, -2.3419e-01, -2.3537e-01,  1.7755e-01,
          4.8510e-02,  2.7429e-01, -1.5559e-02],
        [ 3.2996e-01,  1.2803e-01,  1.1043e-01,  1.0616e-01, -1.3108e-01,
          3.1478e-01,  2.4539e-01, -1.0656e-01],
        [ 1.5032e-01,  2.4203e-01,  1.3999e-01,  2.8903e-01,  2.9685e-01,
         -2.6023e-01,  2.7326e-01, -1.5618e-01],
        [-3.2129e-03, -1.6214e-01, -8.4288e-02,  1.5286e-01,  2.6704e-01,
         -1.9394e-01,  1.3054e-01,  2.0482e-01],
        [ 3.1653e-01,  2.2239e-01,  1.8751e-01, -1.5950e-01, -1.0644e-01,
          9.3350e-02,  6.6175e-02, -5.5781e-02],
        [ 2.6940e-01, -3.9908e-02, -2.7636e-01, -1.4374e-01,  3.0324e-01,
         -2.8170e-01, -1.0328e-01,  1.0767e-01],
        [ 2.3812e-01,  2.4508e-01,  1.2100e-01, -1.3032e-01,  2.2958e-01,
         -1.7624e-01,  1.2698e-01,  1.4610e-02],
        [-2.5875e-01,  2.6638e-01,  9.3436e-03,  1.2062e-02,  1.6255e-01,
          3.1149e-01, -1.4591e-01,  2.0660e-01],
        [ 3.5291e-01,  2.6123e-01, -1.3248e-02,  1.7148e-01, -2.6014e-01,
          2.3859e-01, -3.3708e-01, -8.7632e-02],
        [ 3.1405e-02, -2.4931e-01, -1.6613e-01, -1.7990e-01, -1.4475e-01,
         -8.1843e-02,  3.1553e-02, -2.0645e-01],
        [ 3.5276e-01, -1.8188e-01, -2.9087e-01,  1.3482e-01,  2.6837e-01,
         -2.2375e-01, -2.8212e-01, -8.1168e-03],
        [-4.2855e-02,  1.9372e-01,  1.8441e-01, -3.2860e-01,  3.2444e-01,
         -8.4726e-02, -3.9258e-02,  2.7094e-01],
        [-2.4400e-01,  2.1072e-01, -2.5048e-01, -1.1215e-01, -3.5177e-02,
         -1.9549e-01,  5.0970e-02,  2.5692e-01],
        [-1.9740e-01, -1.8557e-01, -1.0528e-01,  9.8150e-02, -3.5205e-01,
          2.1285e-01,  3.2349e-03,  1.9394e-02],
        [-2.2835e-01, -2.3390e-01, -2.5632e-01, -1.0311e-01,  2.8967e-01,
         -2.4063e-01,  2.7516e-01,  1.0081e-02],
        [ 1.7984e-01, -4.9751e-02,  1.7242e-03,  1.5011e-01, -7.6286e-02,
          5.3061e-02, -1.3994e-01,  1.7614e-01],
        [ 3.1170e-01, -1.0754e-01, -1.3619e-01, -3.4205e-01,  1.5937e-01,
         -2.4127e-01, -3.1577e-01,  1.5458e-01],
        [ 2.0638e-02,  3.4573e-01,  1.4242e-01,  2.3268e-01, -3.2956e-02,
         -1.1063e-01, -2.9620e-01, -3.3443e-01],
        [ 9.2470e-02, -3.8748e-02,  3.3725e-01, -7.6922e-02, -3.0322e-01,
          5.3445e-02, -2.7645e-01, -2.6674e-01],
        [ 1.6538e-01,  1.7330e-01, -5.4121e-02,  2.0406e-01,  2.8524e-01,
          2.7717e-02,  1.3938e-01,  3.5193e-01],
        [-1.4670e-01, -2.5511e-02,  8.9098e-02,  1.8163e-01,  2.2112e-01,
         -1.1623e-01,  1.8505e-01,  4.0639e-02],
        [-2.6472e-01, -1.4587e-01, -4.3256e-02, -3.4383e-01,  8.8387e-02,
         -1.5125e-01, -1.4498e-01,  1.0604e-01],
        [-7.1675e-02,  2.2991e-01,  3.3096e-02, -6.9440e-02,  2.7585e-01,
         -1.4719e-01,  3.0083e-01, -7.0966e-03],
        [ 2.4249e-01,  2.2550e-01, -1.5427e-01, -7.3826e-02, -1.8337e-02,
          1.5188e-01, -7.9805e-02, -9.3983e-02],
        [-1.4323e-02, -9.2509e-02,  2.9426e-01,  3.2526e-01, -1.7172e-01,
          3.1588e-01,  3.4344e-01, -2.4515e-01],
        [ 6.6870e-02, -3.0758e-01, -3.0601e-01,  2.2476e-01, -7.0791e-02,
         -2.0664e-01, -1.0316e-01, -6.3946e-02],
        [-2.4859e-01,  1.4412e-01,  1.3053e-01,  9.2444e-02, -9.4306e-02,
         -2.1081e-01, -1.3625e-01,  1.0629e-01],
        [-2.1114e-01,  2.2897e-01, -1.2594e-01, -1.8018e-01,  7.6293e-02,
         -3.4051e-01,  3.5299e-01,  3.1109e-01],
        [-3.1295e-01, -2.4885e-01,  3.4320e-01, -1.9665e-01, -9.2421e-02,
         -1.1285e-01, -2.2207e-01,  1.5449e-01],
        [ 2.1504e-01,  1.5845e-01, -2.4653e-03,  2.4966e-01, -2.5916e-01,
         -7.6202e-02,  1.7134e-01,  1.9942e-01],
        [-3.5223e-02, -2.2284e-01,  1.9416e-01,  2.5783e-01, -2.8303e-01,
         -3.2364e-01, -2.2021e-01, -2.9559e-03],
        [ 7.2577e-05, -3.3543e-01, -2.6786e-01, -1.8788e-01,  8.6537e-02,
         -1.8084e-01, -4.6978e-02,  3.2586e-01],
        [-1.5189e-01, -1.8328e-01,  2.0967e-01, -1.5943e-01, -2.2403e-01,
          8.4833e-02, -1.9628e-03, -2.4748e-01],
        [ 3.0143e-01, -3.9737e-02,  3.0090e-01, -2.6493e-01, -7.1106e-02,
          9.3293e-02,  1.8346e-01,  2.9569e-01],
        [-2.2135e-01, -7.9853e-02, -1.9281e-01,  2.5027e-01,  2.1637e-01,
         -2.1283e-01,  2.1972e-02, -2.2464e-01],
        [-7.9772e-02,  1.2277e-02,  3.0336e-01,  2.9894e-01, -2.8800e-01,
         -2.6198e-01,  1.6603e-02,  3.1561e-01],
        [ 3.1021e-01,  3.0731e-01,  2.1246e-01, -6.9633e-02,  1.8698e-01,
          1.6544e-01,  2.5449e-01, -1.8427e-01],
        [-2.8372e-01,  1.3357e-01,  1.1506e-01, -3.3040e-01, -1.7704e-01,
          2.8218e-01,  6.3912e-02,  1.7615e-01],
        [-2.4032e-01, -5.9863e-02,  5.1975e-02, -3.1168e-01, -3.4646e-01,
          2.7076e-01,  3.3477e-01,  3.4549e-01],
        [-3.1057e-01, -1.6279e-02, -2.8894e-02, -1.2250e-01, -3.3365e-01,
         -3.4186e-01, -2.6597e-01,  2.1926e-01],
        [ 6.4676e-02,  2.3681e-01,  1.9731e-01, -2.8992e-01,  2.4814e-01,
          2.6961e-01, -3.0969e-01,  2.3214e-01],
        [-5.1981e-02, -3.2211e-01,  1.3574e-01,  1.4391e-01,  3.4100e-01,
          2.1997e-01, -1.2066e-01, -2.0437e-02],
        [ 1.2302e-01,  2.5694e-01,  4.5987e-02, -2.4919e-01,  3.4905e-01,
          5.5843e-02,  1.7042e-01,  1.1976e-01],
        [ 2.4259e-01,  5.9994e-02, -3.5219e-01,  2.1912e-01,  2.7214e-01,
         -1.0131e-01,  9.5643e-02, -3.3910e-01],
        [ 1.4048e-01,  5.8572e-02, -8.5450e-02,  1.9273e-01,  5.1525e-02,
          2.9463e-01,  3.4351e-01, -1.6874e-01],
        [ 1.9643e-01, -7.2145e-02,  9.9604e-02, -1.6406e-01,  2.4158e-01,
         -2.8129e-01,  3.4527e-01,  3.0031e-01],
        [ 7.7554e-02, -2.4374e-01,  6.8918e-02, -1.1472e-01,  3.0399e-01,
          9.1067e-02, -1.2713e-01, -2.6030e-01],
        [-4.1666e-02, -1.0606e-01, -3.1214e-01, -2.9036e-01,  1.2187e-01,
          3.1639e-01,  3.4645e-01, -1.1201e-02],
        [ 2.6476e-01, -7.6367e-02,  3.4340e-01, -3.3176e-01,  3.0152e-01,
         -1.9229e-01,  1.1251e-01, -6.1614e-02],
        [ 2.2167e-01, -4.5132e-02, -3.0204e-01,  3.2315e-01, -2.8206e-01,
         -2.5800e-01,  2.3351e-01,  3.2162e-01],
        [ 2.1349e-01,  2.3682e-01,  4.9186e-02, -9.2849e-02,  1.0653e-01,
          3.0863e-02,  1.1067e-01, -1.2962e-01],
        [-8.6334e-02, -5.8347e-02, -9.7211e-02, -2.7445e-01,  1.4845e-01,
          2.9639e-01, -1.0143e-01, -9.5357e-02],
        [-3.9884e-02,  2.9702e-01, -2.7714e-01,  1.6749e-01, -4.5624e-02,
          2.6242e-01, -3.0071e-01,  8.6544e-02],
        [ 1.9372e-01, -1.3442e-01,  1.9571e-01, -3.0509e-01,  3.4313e-01,
         -2.1137e-01, -2.9456e-01,  3.4537e-01],
        [ 1.0115e-01,  1.4203e-01, -1.6054e-01,  1.7927e-01, -3.1621e-01,
         -3.4082e-01,  8.5951e-02, -1.7658e-01],
        [-7.0673e-02,  4.0302e-02, -2.5092e-01, -1.8738e-02,  9.4365e-02,
          1.4752e-01, -1.4365e-01, -3.3073e-01],
        [ 2.3202e-01,  1.6297e-01,  9.3438e-02,  2.0076e-01, -6.5450e-02,
         -7.8998e-02,  3.3788e-01,  2.6386e-01],
        [ 3.3580e-01, -1.1862e-01,  2.9888e-01,  5.4488e-02, -2.7550e-01,
          1.2356e-01, -3.4341e-01, -3.1059e-01],
        [ 2.9237e-01, -2.2217e-01, -2.5775e-01,  2.1714e-01,  1.1593e-01,
          2.2480e-02, -2.1245e-01,  1.9749e-01],
        [ 2.4617e-01,  1.6342e-01, -3.1097e-01,  8.2178e-02, -3.2066e-02,
          2.7455e-01, -2.4265e-01, -1.6481e-01],
        [-1.1514e-01, -2.3599e-01, -1.1703e-01, -5.0938e-02, -2.7849e-02,
          3.5058e-01,  2.9765e-01, -8.1622e-02],
        [ 3.0295e-01,  3.3444e-01,  1.4079e-01,  2.9601e-01,  3.2340e-01,
          3.3784e-01,  8.4474e-02,  1.0084e-01],
        [-2.5112e-01, -2.2298e-02, -1.4822e-01, -2.2558e-01, -2.9455e-01,
         -2.2828e-01,  9.5395e-02, -9.0685e-02],
        [-2.8416e-01, -1.1477e-01, -2.1298e-01, -6.1241e-02, -2.1311e-01,
         -2.8579e-02, -2.6258e-01, -1.1905e-01],
        [ 3.5226e-01, -7.4940e-02, -2.6704e-01, -8.1536e-02,  5.3298e-02,
         -1.6896e-01,  3.8517e-02, -1.9220e-01],
        [ 6.0652e-02,  1.6641e-01,  2.6111e-01, -1.4104e-01, -9.0208e-02,
         -3.1489e-01,  1.6693e-01,  2.5415e-01],
        [-4.9817e-02, -1.4945e-01,  1.0965e-01,  2.3599e-01, -1.4250e-01,
         -4.2316e-02, -3.0879e-01,  8.6230e-02],
        [-3.0358e-01,  6.2272e-02, -1.3180e-01,  2.0337e-01,  2.5279e-01,
         -1.6448e-01,  5.9282e-02,  3.4045e-01],
        [-1.3081e-01,  1.5657e-01,  6.4084e-02,  2.4392e-01,  1.7980e-01,
          1.3508e-01,  2.0875e-01,  1.8757e-01],
        [ 2.6403e-01, -2.8838e-01, -9.8023e-02,  2.2664e-01, -1.5172e-01,
         -3.2518e-02,  1.3909e-01,  3.4279e-01],
        [ 4.8130e-02,  2.8486e-01, -3.3975e-01, -1.0222e-01,  1.0293e-01,
         -1.1643e-01, -3.4288e-01, -1.3812e-01],
        [ 4.3601e-02, -1.2442e-01,  3.1141e-02,  1.2140e-01, -1.7900e-01,
          1.7480e-01, -1.3424e-01,  1.1839e-01],
        [ 5.1499e-02, -3.4468e-01,  2.6946e-02,  3.4446e-01,  2.9189e-01,
         -3.1167e-01, -2.0375e-01,  2.2401e-01],
        [ 3.1041e-01, -1.7218e-01, -1.0759e-01, -2.2006e-01,  2.6802e-01,
          1.2743e-01,  3.0799e-01, -2.5879e-01],
        [ 3.6959e-02,  9.3103e-02, -3.4503e-02,  8.6140e-02, -6.4014e-02,
          3.1389e-01, -2.9147e-01,  2.0715e-01],
        [ 7.4523e-02, -1.0698e-01, -2.2796e-01,  2.2870e-01,  1.6998e-02,
         -3.4293e-01,  2.6836e-01,  2.9317e-01],
        [ 1.4744e-01,  3.2396e-01,  2.3954e-01, -3.4447e-01,  1.3892e-01,
          3.3896e-01,  1.2279e-01,  1.2115e-01],
        [-9.0449e-02, -3.0770e-01,  1.0865e-01, -3.0621e-01, -2.8484e-01,
         -2.4584e-01,  1.4935e-01, -1.1959e-01],
        [ 1.7395e-01,  2.8731e-01,  4.3727e-03, -7.7819e-02,  7.7516e-02,
          3.6458e-02, -9.1462e-02, -3.2550e-01],
        [ 1.8796e-01,  2.7628e-01,  5.0272e-02,  7.3190e-02,  3.3976e-01,
          3.3797e-02, -2.2982e-01,  3.2739e-01],
        [-2.2405e-01,  3.2022e-01,  4.2145e-02,  1.9312e-02,  2.3552e-01,
          2.5673e-01,  1.8457e-01,  8.9725e-03],
        [-1.6592e-01, -2.6152e-01, -1.9008e-01,  1.1564e-01,  7.2751e-02,
          9.1171e-02, -1.1047e-01, -3.1471e-01],
        [ 1.7632e-01, -9.6728e-02, -1.2649e-01,  3.4833e-01, -1.7797e-01,
          1.1763e-01,  1.6241e-01,  1.8859e-01],
        [-2.6700e-01,  3.1495e-03, -1.5022e-01,  2.6318e-01,  3.0934e-01,
          2.6138e-01,  3.1890e-01, -2.5901e-01],
        [-1.0608e-01, -3.6615e-02, -1.6539e-01,  1.9653e-01, -1.9775e-01,
         -1.7117e-01, -1.9630e-01,  2.7498e-01],
        [ 2.2932e-01, -2.2390e-01,  1.8156e-01,  2.8642e-03,  1.9144e-01,
         -2.8693e-02,  2.8256e-01, -7.8382e-02],
        [ 2.0543e-01, -3.4480e-01,  3.3223e-02, -2.1951e-01,  3.1941e-01,
         -1.4560e-01, -5.7235e-02,  3.5293e-01],
        [ 3.3026e-01, -2.2553e-01, -3.3064e-01,  2.5364e-01,  2.9190e-01,
          1.6655e-01, -1.3758e-02,  3.0462e-01],
        [-3.3607e-02, -1.4940e-01,  7.5162e-02, -5.0635e-02, -3.1787e-01,
          1.8889e-01,  2.8799e-02, -2.1199e-02],
        [-1.6148e-01, -1.6698e-01,  1.0711e-01,  1.6053e-01,  1.8604e-01,
          1.6247e-01, -1.9479e-01,  3.4093e-01],
        [-1.2032e-01, -1.9755e-01,  1.2999e-01, -3.5459e-02, -1.7091e-01,
         -2.2813e-01, -3.4979e-01, -2.8933e-01]], device='cuda:0',
       requires_grad=True) 

model.module_15.bias torch.Size([100])
Parameter containing:
tensor([-0.3187, -0.2387, -0.3529, -0.0466,  0.0160,  0.2257, -0.3475, -0.1684,
        -0.3494, -0.1635, -0.0413, -0.3202,  0.1151, -0.2602, -0.2141, -0.1541,
         0.2357,  0.1243, -0.1488, -0.2044, -0.3240,  0.1063,  0.2612,  0.0553,
        -0.3331,  0.1160, -0.1817, -0.1523,  0.2086,  0.1989, -0.1109,  0.0243,
        -0.2246, -0.3110, -0.2326,  0.1964,  0.0522, -0.0834,  0.1578, -0.2004,
        -0.0969, -0.3338,  0.1147,  0.0997, -0.1730,  0.2911, -0.1275,  0.0168,
        -0.2219, -0.0911, -0.0008,  0.1118, -0.3478,  0.2406, -0.1949, -0.2713,
        -0.1064, -0.0289, -0.3275,  0.0122, -0.0835,  0.0628, -0.0062, -0.0213,
         0.0921,  0.3097,  0.2296,  0.1196, -0.1345,  0.1939, -0.0639,  0.1669,
         0.1724, -0.1885, -0.0630,  0.1402,  0.3246,  0.0975,  0.2044, -0.1096,
        -0.3146,  0.0779,  0.0915,  0.0264,  0.0260,  0.0863, -0.0360, -0.1615,
        -0.3383,  0.0144,  0.3443,  0.0780,  0.1175, -0.0181, -0.0180,  0.2417,
        -0.1121, -0.0683, -0.2389, -0.3362], device='cuda:0',
       requires_grad=True) 

model.module_17.weight torch.Size([100, 100])
Parameter containing:
tensor([[ 0.0669, -0.0094, -0.0904,  ..., -0.0357, -0.0753, -0.0864],
        [ 0.0432,  0.0796, -0.0173,  ...,  0.0274, -0.0026,  0.0988],
        [ 0.0813, -0.0252,  0.0587,  ...,  0.0722, -0.0839,  0.0139],
        ...,
        [ 0.0612, -0.0923,  0.0367,  ...,  0.0212,  0.0968, -0.0429],
        [-0.0135, -0.0586, -0.0875,  ..., -0.0507, -0.0494, -0.0777],
        [ 0.0297, -0.0552,  0.0414,  ..., -0.0977, -0.0075, -0.0901]],
       device='cuda:0', requires_grad=True) 

model.module_17.bias torch.Size([100])
Parameter containing:
tensor([-0.0025,  0.0730,  0.0462, -0.0473, -0.0499,  0.0335, -0.0615, -0.0848,
         0.0785,  0.0291, -0.0764, -0.0920,  0.0340, -0.0309, -0.0531,  0.0992,
         0.0498,  0.0765,  0.0161, -0.0023, -0.0655,  0.0400, -0.0316, -0.0104,
         0.0054,  0.0753,  0.0372, -0.0982,  0.0015,  0.0726, -0.0059,  0.0840,
        -0.0427, -0.0734,  0.0908, -0.0356,  0.0740,  0.0754, -0.0662, -0.0898,
        -0.0119, -0.0559,  0.0731,  0.0492,  0.0848, -0.0454,  0.0192,  0.0023,
        -0.0733, -0.0488,  0.0461,  0.0079,  0.0885,  0.0078,  0.0294,  0.0357,
        -0.0672, -0.0751, -0.0632, -0.0358,  0.0318, -0.0536, -0.0796, -0.0293,
        -0.0851, -0.0083, -0.0941, -0.0122, -0.0773, -0.0916,  0.0718,  0.0973,
        -0.0700,  0.0158, -0.0838, -0.0696, -0.0885, -0.0729,  0.0970,  0.0253,
         0.0448, -0.0583,  0.0413,  0.0355,  0.0297,  0.0071, -0.0484,  0.0368,
         0.0790, -0.0192,  0.0836,  0.0177,  0.0235,  0.0687, -0.0133,  0.0216,
        -0.0190, -0.0826,  0.0068,  0.0271], device='cuda:0',
       requires_grad=True) 

model.module_19.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0053,  0.0230, -0.0224,  ...,  0.0045,  0.0460, -0.0301],
        [-0.0469, -0.0605,  0.0838,  ...,  0.0970, -0.0358,  0.0907],
        [-0.0895,  0.0938,  0.0889,  ...,  0.0671, -0.0375, -0.0623],
        ...,
        [-0.0331,  0.0334, -0.0245,  ..., -0.0839, -0.0647,  0.0452],
        [ 0.0467, -0.0359, -0.0168,  ...,  0.0006, -0.0475,  0.0764],
        [-0.0510,  0.0895, -0.0680,  ..., -0.0230, -0.0429, -0.0716]],
       device='cuda:0', requires_grad=True) 

model.module_19.bias torch.Size([16])
Parameter containing:
tensor([ 0.0925, -0.0472, -0.0113,  0.0508,  0.0960,  0.0381,  0.0429, -0.0805,
         0.0052,  0.0628,  0.0170, -0.0585,  0.0650,  0.0021,  0.0096,  0.0284],
       device='cuda:0', requires_grad=True) 



#### FINAL PARAMETERS ####
W 256 torch.Size([16, 16])
Parameter containing:
tensor([[ 0.5690,  1.8181, -0.6840, -0.4082, -0.4715, -0.7041, -0.6588,  0.2175,
          0.0419, -1.5730,  0.7028, -2.6033, -0.4168, -1.8786, -1.7388,  0.3231],
        [-0.5627, -0.8982, -1.3579,  0.4289,  0.1843,  0.0401,  0.5681, -0.8937,
          1.3262,  1.1153,  0.7682,  0.3594, -1.3361,  0.4761, -0.3170,  0.9965],
        [-0.0418, -0.4598,  1.7311, -1.0117, -0.3455, -1.2418, -0.2976, -0.0530,
         -0.2357,  0.7092, -0.5178, -0.7354,  0.2192,  1.2720, -0.4934, -0.7769],
        [ 1.1009,  0.0823, -0.4645,  0.4797,  0.7914, -0.5113, -1.4501,  0.9903,
         -0.6264,  0.2583,  2.0632, -1.6557, -0.5936, -0.0038, -0.4342, -0.6079],
        [ 0.7861, -1.1147, -0.7500,  1.6485,  0.3087, -1.4263, -0.5562, -0.5837,
         -0.4573, -0.1110, -0.6002,  0.3950, -0.7080,  0.6120,  0.6774, -2.1548],
        [-0.5720,  0.4534,  1.1681, -0.1397, -0.1328,  0.5702, -0.5448,  0.3073,
         -0.1763, -0.9026,  2.7404, -1.3510, -0.0133,  1.0380,  0.8328, -0.1502],
        [ 0.2428, -0.3123,  2.0587, -1.7006,  2.0712, -0.8540, -1.1236, -1.5991,
          0.2166, -0.4641, -2.0072, -0.0315, -1.4717,  0.0754, -0.7822,  0.2964],
        [ 0.6028,  1.2043,  1.8389, -1.0149,  0.8973,  1.1400, -0.3105, -1.0007,
          0.2123, -0.4660,  1.3629, -1.0308, -1.5854, -0.5450, -0.3327, -0.8417],
        [ 0.7731,  0.7592,  0.2200,  0.8090,  1.1075,  0.1762, -1.3491, -0.4553,
          0.5904, -2.5476,  1.7036, -2.1307, -0.8503, -0.4382, -0.7447,  0.3553],
        [-1.1854,  0.9874, -0.3632,  0.8932, -0.7954,  1.1237, -0.7823,  0.1154,
          0.1272,  1.5623, -0.3727,  1.4791, -1.0193, -0.7885, -0.1232,  0.3745],
        [-0.2143, -2.4314, -0.9301, -0.9027, -0.4479, -1.5291,  1.1132, -0.2251,
         -1.0341,  1.1578, -0.1122,  0.0528,  0.9794, -0.5424,  0.5754,  1.0564],
        [ 0.9405, -1.7104,  0.8196,  0.2840,  1.0219,  0.7671,  0.0835,  0.6937,
          0.7819, -0.6591, -0.7720, -0.4437,  0.4166, -0.2019, -0.5690,  0.1286],
        [-1.0562,  1.7185,  0.1156,  0.4780,  0.8373, -1.6817,  1.3535,  0.6572,
          1.2235, -0.7275, -0.3268,  1.1575,  0.9667,  1.3791,  0.7979, -1.2032],
        [-0.8194,  0.2592,  0.1101, -0.8547, -0.2290, -0.5808,  0.8248, -0.8301,
         -1.2777,  0.9247, -1.1237, -0.5584, -0.1224,  0.8597, -2.2036,  1.7278],
        [ 0.3574,  0.3130, -0.5455,  0.9974,  0.1935, -0.2334,  1.8362, -1.2122,
         -0.0873,  0.7746,  0.7138,  0.5031, -1.0381, -0.8281,  1.9390,  1.2428],
        [ 0.0975,  0.8274, -1.1443, -1.1706, -0.5198,  0.8063, -1.6869,  1.3359,
          0.2977,  0.7782, -1.1196,  1.0407,  1.2063, -1.4856, -0.7482, -0.4894]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-6.2724e-03, -6.5957e-04, -2.4137e-04, -1.2399e-02, -1.0275e-02,
         -6.7488e-04, -7.0450e-04, -1.0351e-03, -1.0387e-03, -1.0630e-03,
         -8.4570e-04, -8.1211e-04,  3.3174e-03, -2.7246e-04, -1.5933e-03,
          8.1595e-05],
        [-6.5957e-04, -2.9626e-05, -1.2466e-05, -6.2779e-04, -9.8687e-04,
         -4.0788e-04, -5.1401e-05, -6.5846e-05, -7.0130e-05, -4.2746e-04,
         -4.1529e-05, -5.1313e-05, -1.6381e-04, -1.7254e-05, -8.4704e-05,
          3.3606e-06],
        [-2.4137e-04, -1.2466e-05, -5.0394e-06, -2.5051e-04, -3.5996e-04,
         -1.3837e-04, -1.9640e-05, -2.5664e-05, -2.6934e-05, -1.4715e-04,
         -1.6299e-05, -2.0158e-05, -4.4225e-05, -6.7799e-06, -3.3601e-05,
         -1.1256e-06],
        [-1.2399e-02, -6.2779e-04, -2.5051e-04, -1.2134e-02, -1.8100e-02,
         -7.4415e-03, -9.9531e-04, -1.2892e-03, -1.3457e-03, -7.9483e-03,
         -7.6113e-04, -1.0241e-03, -2.8708e-03, -3.4365e-04, -1.6395e-03,
         -2.5278e-04],
        [-1.0275e-02, -9.8687e-04, -3.5996e-04, -1.8100e-02, -1.6173e-02,
         -2.1617e-03, -1.0922e-03, -1.5763e-03, -1.5793e-03, -2.8169e-03,
         -1.2000e-03, -1.2487e-03,  3.7411e-03, -4.1877e-04, -2.3436e-03,
         -1.0301e-04],
        [-6.7488e-04, -4.0788e-04, -1.3837e-04, -7.4415e-03, -2.1617e-03,
          2.9489e-03, -2.7269e-04, -4.8684e-04, -4.6135e-04,  2.7720e-03,
         -5.3740e-04, -3.7662e-04,  5.0203e-03, -1.2649e-04, -9.1712e-04,
          1.9616e-04],
        [-7.0450e-04, -5.1401e-05, -1.9640e-05, -9.9531e-04, -1.0922e-03,
         -2.7269e-04, -6.6009e-05, -9.1380e-05, -9.3783e-05, -3.0539e-04,
         -6.6548e-05, -7.1721e-05,  7.1661e-05, -2.4089e-05, -1.3035e-04,
          2.1708e-06],
        [-1.0351e-03, -6.5846e-05, -2.5664e-05, -1.2892e-03, -1.5763e-03,
         -4.8684e-04, -9.1380e-05, -1.2357e-04, -1.2788e-04, -5.3080e-04,
         -8.5220e-05, -9.7098e-05, -2.7667e-05, -3.2612e-05, -1.7038e-04,
         -1.7593e-06],
        [-1.0387e-03, -7.0130e-05, -2.6934e-05, -1.3457e-03, -1.5793e-03,
         -4.6135e-04, -9.3783e-05, -1.2788e-04, -1.3149e-04, -5.0955e-04,
         -8.8338e-05, -1.0088e-04,  1.1091e-05, -3.3866e-05, -1.7747e-04,
         -7.4205e-06],
        [-1.0630e-03, -4.2746e-04, -1.4715e-04, -7.9483e-03, -2.8169e-03,
          2.7720e-03, -3.0539e-04, -5.3080e-04, -5.0955e-04,  2.5942e-03,
         -5.7633e-04, -4.0874e-04,  5.0367e-03, -1.3739e-04, -9.8303e-04,
          2.3701e-04],
        [-8.4570e-04, -4.1529e-05, -1.6299e-05, -7.6113e-04, -1.2000e-03,
         -5.3740e-04, -6.6548e-05, -8.5220e-05, -8.8338e-05, -5.7633e-04,
         -4.5083e-05, -6.8653e-05, -2.4769e-04, -2.3008e-05, -1.0398e-04,
         -3.3509e-05],
        [-8.1211e-04, -5.1313e-05, -2.0158e-05, -1.0241e-03, -1.2487e-03,
         -3.7662e-04, -7.1721e-05, -9.7098e-05, -1.0088e-04, -4.0874e-04,
         -6.8653e-05, -7.5893e-05, -1.0411e-05, -2.5508e-05, -1.3508e-04,
          5.7671e-06],
        [ 3.3174e-03, -1.6381e-04, -4.4225e-05, -2.8708e-03,  3.7411e-03,
          5.0203e-03,  7.1661e-05, -2.7667e-05,  1.1091e-05,  5.0367e-03,
         -2.4769e-04, -1.0411e-05,  5.4642e-03, -4.0113e-06, -3.0757e-04,
          2.9535e-04],
        [-2.7246e-04, -1.7254e-05, -6.7799e-06, -3.4365e-04, -4.1877e-04,
         -1.2649e-04, -2.4089e-05, -3.2612e-05, -3.3866e-05, -1.3739e-04,
         -2.3008e-05, -2.5508e-05, -4.0113e-06, -8.5709e-06, -4.5340e-05,
          1.4769e-06],
        [-1.5933e-03, -8.4704e-05, -3.3601e-05, -1.6395e-03, -2.3436e-03,
         -9.1712e-04, -1.3035e-04, -1.7038e-04, -1.7747e-04, -9.8303e-04,
         -1.0398e-04, -1.3508e-04, -3.0757e-04, -4.5340e-05, -2.2043e-04,
         -2.7821e-05],
        [ 8.1595e-05,  3.3606e-06, -1.1256e-06, -2.5278e-04, -1.0301e-04,
          1.9616e-04,  2.1708e-06, -1.7593e-06, -7.4205e-06,  2.3701e-04,
         -3.3509e-05,  5.7671e-06,  2.9535e-04,  1.4769e-06, -2.7821e-05,
          1.2045e-04]], device='cuda:0') 

act.weight 1 torch.Size([1])
Parameter containing:
tensor([-0.0287], device='cuda:0', requires_grad=True) 
grad:  tensor([-0.4385], device='cuda:0') 

inner_act.weight 1 torch.Size([1])
Parameter containing:
tensor([-0.1046], device='cuda:0', requires_grad=True) 
grad:  tensor([-1.9014e-05], device='cuda:0') 

out_act.weight 1 torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 
grad:  None 

encoder.module_0.weight 1300 torch.Size([100, 13])
Parameter containing:
tensor([[ 0.0574,  0.2004, -0.2086,  ...,  0.2928, -0.0744, -0.1098],
        [-0.2436,  0.0858, -0.1630,  ...,  0.0550, -0.3402, -0.1976],
        [-0.3888, -0.3541, -0.1991,  ...,  0.1071,  0.2185,  0.1531],
        ...,
        [-0.0441,  0.0500, -0.5700,  ..., -0.0394, -0.1299, -0.0402],
        [-0.2168,  0.5053,  0.0927,  ..., -0.2593, -0.0800,  0.2960],
        [-0.3409,  0.2656, -0.0080,  ..., -0.1758, -0.0512,  0.0836]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-1.7354e-02, -1.9062e-03, -1.6398e-02,  ..., -1.3954e-04,
         -5.6045e-03,  4.3388e-04],
        [-2.2684e-04, -1.7641e-04, -7.7427e-05,  ..., -1.1570e-04,
          2.5240e-04, -4.0321e-04],
        [-3.2224e-03, -1.8424e-03, -1.6940e-03,  ..., -1.2083e-02,
         -1.1807e-02,  1.4705e-02],
        ...,
        [ 1.6013e-03,  1.6854e-03,  1.3921e-04,  ..., -1.6325e-02,
         -9.1362e-03,  4.1143e-03],
        [-1.9025e-02, -2.9626e-03, -1.7219e-02,  ...,  1.0672e-03,
          1.0287e-02,  1.8840e-02],
        [ 2.4094e-03,  2.1568e-03,  5.5930e-04,  ..., -1.6403e-02,
         -1.7448e-03, -5.0381e-03]], device='cuda:0') 

encoder.module_0.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.3183, -0.1960, -0.2603,  0.0196, -0.3810,  0.1359, -0.2696, -0.4727,
        -0.2947, -0.0954, -0.0518, -0.0109, -0.2295, -0.2300, -0.1894, -0.2999,
        -0.3993, -0.2627, -0.4892,  0.1714, -0.1693, -0.0466, -0.2174, -0.1813,
        -0.2600, -0.2805, -0.1762,  0.0755, -0.3724, -0.0968, -0.4521, -0.3671,
        -0.0704, -0.1578, -0.2240,  0.4161, -0.0572, -0.0835,  0.2114, -0.2700,
        -0.2531, -0.4994,  0.2357,  0.2333, -0.2104, -0.3687, -0.2596,  0.0121,
        -0.1922, -0.2217, -0.2829, -0.2784, -0.0035, -0.3271,  0.0023, -0.3739,
        -0.3344,  0.4216,  0.1455, -0.0907, -0.3710, -0.3344, -0.4191,  0.1815,
         0.1634, -0.6193, -0.4029, -0.4444,  0.4159,  0.1369, -0.1677, -0.0985,
         0.0873, -0.2458,  0.0648, -0.0845, -0.0309,  0.0318,  0.1317,  0.0536,
        -0.1720, -0.2713,  0.0716, -0.3894, -0.0936, -0.3095, -0.5792, -0.2169,
        -0.2636, -0.3792, -0.3156, -0.1892, -0.1794, -0.3112, -0.1281, -0.1629,
        -0.1354, -0.1878, -0.1089, -0.1701], device='cuda:0',
       requires_grad=True) 
grad:  tensor([-2.3862e-02, -1.1233e-04, -4.4630e-03,  6.4653e-04,  4.6432e-03,
        -1.6360e-03,  4.1510e-03, -3.8530e-04,  4.3828e-03,  3.0116e-03,
        -4.0208e-02,  6.3352e-03,  4.4928e-03,  1.3756e-04,  4.0144e-05,
        -2.4745e-03, -1.8924e-04,  2.8150e-03,  4.9912e-03,  2.7080e-03,
        -3.4783e-03,  1.7794e-03,  1.0093e-02,  5.6081e-03, -7.7282e-04,
        -2.2212e-04, -2.7916e-03,  4.3427e-03, -9.4783e-03, -7.2834e-03,
         8.6883e-05,  4.5110e-04, -1.0001e-03,  1.6107e-03,  3.7927e-04,
         1.4773e-02, -8.4647e-04, -1.2939e-02,  6.0053e-03, -1.0096e-02,
        -2.6370e-03, -3.5544e-04,  5.3419e-03, -7.2145e-03, -1.3734e-02,
         7.2276e-03, -4.6900e-03, -4.2934e-03, -8.8150e-03,  2.1758e-03,
        -1.4391e-03,  1.9571e-03, -1.3372e-03,  9.8165e-03, -1.1838e-04,
         5.2013e-03, -1.2870e-02,  3.4395e-03, -8.0485e-03, -1.4854e-03,
        -7.5904e-03,  9.3242e-03,  4.7768e-03,  7.6106e-03, -2.4726e-02,
        -3.3872e-03, -3.7320e-04, -1.0559e-02,  4.6014e-03, -1.3432e-02,
         3.0315e-03,  7.4022e-04, -4.0287e-04, -2.7964e-03, -8.4775e-04,
         2.5738e-03, -2.9523e-03,  3.4381e-03, -2.2674e-02, -2.4980e-03,
         5.2495e-05, -8.5754e-03,  7.1463e-04, -5.3880e-03, -6.6034e-03,
        -9.2964e-04,  3.6517e-03,  2.6309e-06, -1.0148e-02, -2.9121e-03,
         3.6701e-03,  7.6680e-03, -1.6880e-03,  3.7312e-04,  3.1232e-03,
         2.5817e-04,  1.5346e-02,  1.4303e-03, -2.2640e-02,  3.6867e-03],
       device='cuda:0') 

encoder.module_2.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[-0.2256, -0.2040, -0.1731,  ..., -0.0081, -0.2345, -0.0728],
        [ 0.1676,  0.1373,  0.0385,  ...,  0.0694, -0.1121,  0.1818],
        [-0.0086,  0.2637, -0.2477,  ...,  0.0165, -0.1051, -0.0259],
        ...,
        [ 0.2302,  0.1803, -0.1459,  ..., -0.0119,  0.1974,  0.1655],
        [ 0.1747,  0.1168,  0.0225,  ...,  0.1983,  0.2033,  0.2134],
        [ 0.0139,  0.1550,  0.1235,  ...,  0.1211,  0.1201,  0.2241]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 2.0177e-04, -3.5744e-05,  3.3494e-04,  ...,  8.5979e-06,
          1.1546e-04,  1.4480e-04],
        [-2.2567e-07, -2.3290e-04, -3.0022e-03,  ...,  1.3457e-03,
         -4.5446e-04,  3.1647e-03],
        [ 2.2946e-05, -1.8725e-05, -2.6230e-05,  ..., -3.5750e-05,
         -8.3870e-05, -1.1671e-04],
        ...,
        [-1.7081e-04,  9.1815e-05,  2.4947e-04,  ...,  7.2625e-04,
          4.3451e-04,  8.1332e-04],
        [-4.3746e-04, -3.6188e-04, -5.0964e-03,  ...,  2.1491e-03,
         -2.3483e-03,  3.5195e-03],
        [ 1.2937e-04, -4.5211e-05,  1.3959e-04,  ...,  1.0628e-03,
          1.3800e-03,  1.1223e-03]], device='cuda:0') 

encoder.module_2.bias 100 torch.Size([100])
Parameter containing:
tensor([ 0.2266, -0.1284, -0.1462, -0.3323, -0.2038, -0.0467, -0.1584, -0.2625,
        -0.2422,  0.1311, -0.2916, -0.1976, -0.1544, -0.1826,  0.2894, -0.1787,
        -0.3350, -0.1473, -0.2204, -0.3468,  0.1349,  0.1382, -0.2053,  0.1308,
         0.3072, -0.2552, -0.0069, -0.2159, -0.0785, -0.1476, -0.1978, -0.1220,
        -0.2303, -0.3834, -0.1564, -0.1394, -0.2376,  0.2351, -0.0691, -0.0885,
        -0.1909, -0.2272, -0.0503, -0.0456,  0.1055, -0.0107, -0.3303, -0.1184,
        -0.1084,  0.2794, -0.2550, -0.1740,  0.2239, -0.1409,  0.3705, -0.1570,
        -0.2330,  0.1259,  0.0022,  0.2390, -0.0369, -0.2497,  0.2865,  0.0652,
         0.1112, -0.1876,  0.3330, -0.0494, -0.3725, -0.1337,  0.0292, -0.3200,
        -0.3014, -0.1748,  0.1918,  0.2683, -0.1804, -0.3576, -0.1864,  0.2238,
        -0.2044, -0.0283, -0.2710, -0.1592, -0.4804,  0.0031, -0.2337,  0.3532,
         0.1265, -0.0120, -0.2056, -0.0302, -0.2329, -0.1207, -0.0081, -0.1436,
        -0.3786, -0.0132,  0.0943, -0.2741], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 2.8101e-03,  8.3576e-04,  1.2041e-04,  1.1820e-03, -7.8044e-04,
        -1.7222e-03,  2.9963e-04, -1.3072e-02, -2.0405e-03,  2.2507e-03,
         1.7228e-03, -2.4684e-03,  8.4892e-04,  1.1350e-03,  2.0728e-03,
         2.0624e-03,  1.2525e-03,  2.4628e-03, -8.2606e-04,  3.6429e-05,
        -3.4794e-04,  2.6973e-03, -8.2318e-04,  2.4759e-03,  4.8412e-03,
         4.6034e-04, -5.6338e-04, -5.8809e-05, -6.3853e-04,  1.4049e-03,
        -1.3007e-03, -9.6985e-05,  2.6085e-04, -7.2576e-05, -8.4595e-05,
         1.5669e-03,  5.6046e-04,  9.0733e-04,  4.3478e-04,  3.2442e-03,
        -3.5192e-05, -2.4143e-04, -4.3897e-03,  2.5697e-05, -2.1388e-03,
        -3.9787e-03, -5.0982e-05,  1.3981e-04, -5.0385e-05,  5.5478e-03,
        -3.0484e-04, -2.9990e-04,  3.0290e-03,  7.0093e-04,  2.2777e-03,
        -2.1634e-03,  2.8534e-03,  2.3182e-03,  1.1469e-03,  2.2509e-03,
         2.2030e-03,  3.9969e-04,  5.0350e-03,  8.9609e-04,  6.1574e-04,
         3.6975e-04,  4.0473e-03, -5.1930e-05,  5.3015e-04,  1.7592e-03,
        -7.4346e-05, -1.9524e-03, -6.9271e-04, -3.8473e-05,  1.3362e-03,
         4.8889e-03,  1.5026e-03, -3.4144e-03,  6.4645e-04, -1.5994e-04,
         5.5903e-05,  1.4542e-03, -8.5307e-04,  1.3064e-05,  6.5851e-04,
         5.6363e-03, -3.9780e-03,  7.4264e-03,  6.2200e-03, -4.4505e-04,
        -6.7559e-04,  1.9490e-04, -3.9746e-03,  3.6541e-04,  2.0445e-04,
        -2.7933e-03,  1.3657e-04,  1.3783e-03,  1.0442e-04, -1.6727e-04],
       device='cuda:0') 

encoder.module_4.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[-0.1474, -0.1459, -0.1095,  ..., -0.1787, -0.1441,  0.0797],
        [ 0.0413, -0.0851,  0.1631,  ...,  0.0827,  0.0276, -0.0914],
        [ 0.1539, -0.1004, -0.1288,  ..., -0.1339, -0.2412,  0.0157],
        ...,
        [-0.1158,  0.0084,  0.1712,  ...,  0.0923, -0.1125,  0.0326],
        [-0.0225,  0.0611, -0.0213,  ...,  0.1034,  0.2760,  0.1101],
        [-0.0641,  0.0409, -0.0516,  ..., -0.1907, -0.1403, -0.0703]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-1.5110e-04, -1.0222e-03,  2.1450e-05,  ..., -2.5280e-04,
         -1.3956e-03, -7.4298e-04],
        [-8.4490e-03, -7.9520e-03,  8.1842e-04,  ..., -1.7162e-02,
         -1.9092e-02, -8.6616e-03],
        [ 5.0761e-03, -4.4343e-04,  3.4358e-05,  ...,  3.4269e-03,
          7.0194e-04, -2.2289e-04],
        ...,
        [-1.0922e-03,  9.6601e-03,  1.0555e-03,  ..., -3.9974e-03,
          1.2838e-02,  3.9393e-03],
        [-9.9203e-03,  6.8440e-03, -1.1527e-03,  ...,  4.7236e-03,
          1.9833e-02,  9.6836e-03],
        [-8.8681e-05, -1.4740e-04, -9.3453e-07,  ..., -2.6493e-04,
         -3.6818e-04, -1.1676e-04]], device='cuda:0') 

encoder.module_4.bias 16 torch.Size([16])
Parameter containing:
tensor([-0.1586, -0.2809,  0.2693,  0.0203, -0.1162,  0.1172, -0.0625,  0.2544,
        -0.0905, -0.0420,  0.0066, -0.1259, -0.0838,  0.1877,  0.0386, -0.2210],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-1.2074e-04, -8.5733e-03,  6.0837e-03,  2.6077e-03,  1.7347e-04,
         1.9294e-05,  1.3500e-03, -2.8700e-03, -1.5917e-03,  5.0351e-03,
        -9.7169e-03,  3.9370e-03,  5.3434e-03,  4.0383e-03, -7.3546e-03,
        -9.6140e-05], device='cuda:0') 

model.module_0.att 8 torch.Size([1, 1, 8])
Parameter containing:
tensor([[[ 0.1928, -0.4914,  0.7585,  0.6316, -0.2246,  0.2875, -0.1767,
           0.7512]]], device='cuda:0', requires_grad=True) 
grad:  tensor([[[ 0.0125,  0.0960, -0.0520,  0.0688,  0.0525,  0.0044, -0.0056,
           0.1429]]], device='cuda:0') 

model.module_0.bias 8 torch.Size([8])
Parameter containing:
tensor([ 0.2513,  0.0312, -0.1044, -0.0845,  0.1508,  0.0491, -0.0201, -0.1517],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-0.0061,  0.0142, -0.0050,  0.0049,  0.0017, -0.0060,  0.0015,  0.0003],
       device='cuda:0') 

model.module_0.lin_l.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[-0.4524,  0.0622, -0.1007, -0.3957,  0.2005,  0.5059,  0.0445, -0.1239,
         -0.4583, -0.0215, -0.0666,  0.0432, -0.1112, -0.3441, -0.4298,  0.1593],
        [-0.1426,  0.0188,  0.1126, -0.1677, -0.0295,  0.5342,  0.3770,  0.0412,
         -0.0049, -0.3217, -0.2080,  0.0371,  0.3287,  0.0878, -0.4115, -0.1410],
        [-0.4324,  0.2352, -0.1042, -0.1172,  0.1092, -0.5113, -0.2423, -0.0305,
          0.4195,  0.4087,  0.0598, -0.5442, -0.0006, -0.2633,  0.3946, -0.1211],
        [-0.1852, -0.0832,  0.3780,  0.1994, -0.1753, -0.0743,  0.1624, -0.1840,
          0.3065, -0.2662, -0.1298,  0.3236,  0.5863,  0.1575, -0.1778,  0.1446],
        [-0.2068, -0.4503, -0.3904, -0.1891,  0.0448, -0.1513,  0.4128, -0.1491,
          0.2727, -0.5044, -0.4053,  0.0421,  0.2075,  0.0504,  0.3852, -0.2531],
        [ 0.3437,  0.1748,  0.0459, -0.0300, -0.2820,  0.2535,  0.1736,  0.3266,
          0.4530, -0.4219,  0.4242, -0.1500, -0.2314,  0.3666, -0.1146, -0.0375],
        [ 0.1922, -0.2833,  0.5399,  0.2810,  0.3627, -0.1213, -0.3900,  0.1783,
         -0.1391, -0.0323, -0.4093,  0.3646, -0.2762, -0.0860,  0.1002, -0.1379],
        [ 0.3479, -0.4422, -0.1327, -0.2955,  0.3075, -0.3933,  0.3180, -0.4772,
         -0.4633,  0.0919, -0.3851,  0.4513,  0.4510, -0.2078,  0.3870, -0.1043]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-1.3565e-03,  2.7119e-03, -8.4899e-04,  2.9466e-03, -5.0544e-04,
         -4.2525e-02,  1.6257e-02,  4.6142e-04, -1.6143e-03, -8.6332e-02,
         -1.3326e-03, -1.6472e-02, -7.4787e-02,  4.2049e-03, -6.3156e-02,
         -7.9672e-04],
        [-1.0228e-03, -2.7719e-03,  7.1377e-03,  1.4360e-02, -3.2903e-04,
         -8.1079e-03, -5.3885e-02,  1.8862e-02,  1.5785e-03, -2.9092e-02,
          1.8649e-02, -6.1086e-02, -5.0840e-02,  1.1886e-02, -3.0085e-02,
         -3.1148e-04],
        [-7.7709e-04, -5.9391e-03, -7.1366e-03, -1.6069e-02, -4.7689e-04,
         -4.8321e-02,  1.4810e-02, -1.5855e-02, -2.8807e-03, -3.9544e-02,
         -1.9249e-02,  1.5289e-02, -1.0308e-02, -1.9768e-02, -3.6994e-02,
         -8.1918e-04],
        [ 2.8388e-03,  2.7554e-02,  7.3813e-03,  2.1908e-02,  1.1523e-03,
          1.1201e-01,  1.0833e-01,  1.1178e-02,  1.6487e-03,  4.5088e-02,
          1.0103e-03,  1.1884e-01,  7.6787e-02,  3.1951e-02,  6.5401e-02,
          2.0179e-03],
        [-5.9975e-04, -4.3118e-03,  1.8455e-03,  2.1096e-03, -2.0779e-04,
         -1.2508e-02, -3.0420e-02,  5.7541e-03,  4.7578e-04, -1.3041e-02,
          5.6107e-03, -2.8473e-02, -2.1141e-02, -4.2020e-04, -1.6427e-02,
         -2.9885e-04],
        [ 1.2674e-03, -1.8101e-03, -2.1416e-03, -1.0029e-02,  3.6410e-04,
          3.7186e-02,  6.1761e-03, -8.1602e-03,  7.4234e-05,  7.6224e-02,
         -9.6142e-03,  3.5525e-02,  7.5861e-02, -9.1866e-03,  5.3616e-02,
          7.2335e-04],
        [ 5.3764e-05,  5.3527e-03,  4.3562e-03,  1.0595e-02,  8.4957e-05,
          1.6309e-02, -5.2962e-03,  1.0509e-02,  1.3447e-03, -3.8162e-03,
          9.0139e-03, -5.5580e-03, -7.4393e-03,  1.0993e-02, -2.3857e-03,
          2.3731e-04],
        [ 1.1074e-03,  1.4317e-02,  3.1520e-03,  3.6181e-03,  3.6812e-04,
          3.9067e-02,  9.4933e-02,  4.2645e-03, -6.6583e-04, -2.1076e-02,
         -1.1027e-02,  9.4896e-02,  3.5152e-02,  5.0808e-03, -2.1145e-03,
          6.7725e-04]], device='cuda:0') 

model.module_0.lin_l.bias 8 torch.Size([8])
Parameter containing:
tensor([ 0.1890, -0.2381, -0.1637, -0.3117,  0.0865,  0.1738, -0.2681, -0.1232],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-0.0051,  0.0061, -0.0038,  0.0082,  0.0014, -0.0072,  0.0009,  0.0018],
       device='cuda:0') 

model.module_0.lin_r.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[ 5.7323e-01,  4.0862e-02,  2.2506e-01, -4.0844e-01,  1.9011e-01,
          2.1562e-01, -5.3017e-01,  2.0667e-01, -2.4041e-01, -1.4315e-01,
         -2.0286e-01, -8.5246e-01, -5.3830e-02, -4.7678e-02, -4.9519e-01,
         -2.7134e-01],
        [-3.8443e-01,  7.3398e-01, -7.2225e-01,  1.5149e-01,  6.5713e-01,
         -2.5906e-01,  1.0870e-01, -2.4849e-01, -7.6434e-02,  1.0875e-01,
          6.9632e-01,  1.9254e-01,  4.3476e-01,  2.0643e-01,  7.6056e-01,
         -4.3208e-01],
        [-2.7878e-01,  8.0645e-01, -7.3568e-01,  2.7958e-01,  5.4199e-01,
         -1.4921e-01,  4.6160e-01, -8.4088e-01, -3.4514e-01, -1.2945e-02,
          4.4173e-01,  6.2138e-01, -1.8633e-01, -1.3366e-01,  1.1243e-02,
         -1.3034e-01],
        [ 2.1994e-01, -3.9320e-01, -5.1474e-01, -4.7077e-01, -4.9638e-01,
         -5.5306e-02, -3.5429e-01, -4.1901e-01, -1.7158e-01,  5.4876e-01,
          3.3255e-01, -3.1843e-01,  4.5885e-02, -1.0306e-01, -3.7308e-01,
          1.4328e-01],
        [-5.2827e-01, -6.9972e-02,  3.7718e-01, -4.9207e-01,  3.5525e-01,
          2.8654e-01,  3.5645e-01,  8.6171e-02, -9.0988e-02, -4.7484e-01,
         -3.5962e-01, -8.9098e-01, -3.3498e-01, -8.2343e-02, -7.1357e-01,
          2.7808e-01],
        [-1.9206e-01, -4.0168e-01,  1.7191e-01,  1.6566e-01, -4.0194e-01,
          1.7652e-01, -6.3105e-02,  5.4285e-01, -3.7702e-01, -6.5576e-01,
         -3.5488e-01, -1.0359e+00, -6.1585e-01, -6.2828e-01, -1.2983e-02,
         -2.2178e-02],
        [-5.5795e-01,  5.0867e-01,  6.5932e-02, -3.1213e-01,  3.8124e-04,
          2.7856e-01, -3.4982e-01, -8.7236e-02,  1.8902e-01, -4.2171e-01,
         -1.8300e-01, -7.1958e-02, -3.8475e-01,  4.6001e-01, -1.1731e-03,
         -2.5384e-01],
        [-1.7139e-01,  5.3550e-01, -1.8023e-01,  6.2671e-01, -1.0355e-01,
         -3.9504e-01,  4.8756e-01, -6.8897e-01, -4.8172e-03,  4.0894e-01,
          6.0293e-01,  1.7607e-01,  1.0656e+00,  5.0008e-01, -6.4754e-02,
          6.7862e-02]], device='cuda:0', requires_grad=True) 
grad:  tensor([[ 6.3640e-05,  5.1820e-04,  2.7439e-03,  1.9999e-03,  4.4280e-05,
          6.5650e-03,  4.4290e-04,  4.6989e-03,  3.9032e-05,  6.5409e-05,
          3.6497e-04,  1.2468e-03,  1.2168e-04,  1.4724e-03,  8.7507e-04,
          7.0401e-05],
        [-5.6413e-04, -6.9854e-03, -1.8785e-02, -1.8721e-02, -3.8723e-04,
         -5.4402e-02, -6.2469e-03, -3.5189e-02, -3.0241e-04, -4.4389e-04,
         -5.9374e-03, -1.1339e-02, -8.9736e-04, -1.4666e-02, -8.4841e-03,
         -6.1958e-04],
        [ 2.7993e-05,  2.3423e-03,  2.3014e-03,  5.8053e-03,  7.5987e-05,
          7.2583e-03, -3.6098e-03,  7.6719e-03, -1.3002e-04, -2.1640e-03,
          1.1137e-02, -4.1923e-03, -1.1562e-03,  4.9760e-03, -2.3922e-03,
          7.0983e-05],
        [ 2.7874e-04,  4.8598e-03,  5.4638e-03,  8.7010e-03,  1.6585e-04,
          2.4141e-02,  7.3829e-03,  1.1693e-02,  1.9092e-04, -2.0027e-04,
          4.6475e-04,  8.7289e-03, -2.7242e-05,  7.1863e-03,  5.2109e-03,
          2.9776e-04],
        [-4.0815e-05, -2.6304e-04, -1.2909e-03, -4.9712e-04, -1.5456e-05,
         -3.6509e-03, -1.9740e-03, -1.5917e-03, -6.1423e-05,  3.0755e-06,
          2.5605e-03, -2.6841e-03,  3.5514e-06, -1.5500e-04, -1.0288e-03,
         -3.9610e-05],
        [-1.2135e-04, -4.3660e-03,  1.2919e-03, -6.3252e-03, -9.1683e-05,
         -8.7125e-03, -1.3424e-03, -2.7722e-03,  4.3245e-05, -1.3813e-04,
         -9.0723e-03,  1.9490e-04, -3.2707e-04, -6.3574e-03, -1.8231e-03,
         -1.3965e-04],
        [-3.9008e-05, -6.5338e-04, -1.3513e-03, -1.9123e-03, -3.5349e-05,
         -4.0562e-03,  6.1293e-04, -3.1480e-03,  7.2201e-06, -6.1245e-05,
         -2.4048e-03,  4.0911e-04, -1.3041e-04, -1.6419e-03, -2.9435e-04,
         -4.6232e-05],
        [ 1.0725e-04,  5.0402e-03, -3.1356e-03,  6.9044e-03,  9.2233e-05,
          6.6855e-03,  3.6027e-04,  1.0955e-03, -1.0906e-04,  1.5301e-04,
          1.3046e-02, -2.6349e-03,  3.8478e-04,  7.4833e-03,  1.2788e-03,
          1.3394e-04]], device='cuda:0') 

model.module_0.lin_r.bias 8 torch.Size([8])
Parameter containing:
tensor([-0.3707, -0.1099, -0.3669, -0.0670,  0.1575, -0.0632, -0.0864, -0.0615],
       device='cuda:0', requires_grad=True) 
grad:  tensor([ 0.0010, -0.0081,  0.0011,  0.0033, -0.0003, -0.0012, -0.0006,  0.0015],
       device='cuda:0') 

model.module_0.lin_edge.weight 16 torch.Size([8, 2])
Parameter containing:
tensor([[ 0.2962,  0.1565],
        [ 0.6945,  0.7682],
        [-0.4946, -0.1286],
        [ 0.0470, -0.8975],
        [-0.5249,  0.4510],
        [ 0.2095,  0.0813],
        [ 0.7829,  0.5107],
        [-0.1030, -0.0310]], device='cuda:0', requires_grad=True) 
grad:  tensor([[-3.0457e-04,  4.0560e-04],
        [ 7.2087e-04, -4.8811e-03],
        [-4.9222e-03,  2.0509e-03],
        [ 5.1737e-05,  2.5211e-03],
        [-8.4942e-04, -4.2281e-04],
        [ 4.5274e-04, -9.5877e-05],
        [ 2.5650e-04, -6.3558e-04],
        [-2.7122e-03,  3.9263e-03]], device='cuda:0') 

model.module_1.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[-4.9645e-02,  1.3316e-01, -1.0623e-04,  1.8662e-01,  1.7787e-01,
         -6.5369e-02, -2.0327e-01, -1.0950e-02],
        [ 5.2893e-01,  3.4402e-02,  7.9586e-02, -3.3717e-01, -3.6252e-02,
         -1.2956e-02,  2.5599e-02,  1.1702e-01],
        [ 3.0310e-01, -2.9918e-01, -1.0366e-01,  1.7273e-01,  3.7804e-02,
          2.2198e-01,  3.0857e-01,  2.3140e-02],
        [ 3.2363e-03,  1.4965e-01,  1.8219e-01,  3.1294e-01, -1.1106e-01,
          6.0780e-02,  2.1729e-01, -3.8497e-01],
        [ 1.6888e-01,  1.4045e-01,  2.9354e-01,  8.9983e-02,  4.0404e-01,
          4.0268e-01,  7.4210e-02, -3.4915e-02],
        [ 2.1810e-01, -3.2801e-02, -3.0698e-01,  1.3720e-01,  1.4140e-01,
         -2.3772e-01, -1.5074e-01, -2.9180e-01],
        [-2.0270e-01,  2.3035e-01, -1.0463e-01, -1.6725e-01, -6.7740e-02,
         -1.2862e-01,  2.5120e-01, -1.8358e-01],
        [ 1.7173e-01, -2.3585e-01,  3.8395e-01,  1.1297e-01, -2.0783e-01,
          7.2528e-02,  1.4290e-01, -3.0128e-01],
        [-8.5074e-02, -2.9902e-01, -2.0353e-01,  8.0731e-02,  4.1586e-03,
         -2.6163e-01,  3.4186e-02,  2.7273e-01],
        [ 3.3679e-01, -2.9212e-01,  2.2977e-01,  1.8734e-03, -2.7194e-01,
          6.7157e-02,  7.6620e-02,  1.9934e-01],
        [ 3.8348e-01,  3.8498e-01, -2.2269e-02, -2.4845e-02, -1.4900e-01,
          9.1559e-02,  1.0074e-01,  1.4770e-01],
        [ 9.3873e-02,  3.7506e-02,  1.3660e-01, -2.8417e-02,  2.8813e-02,
         -3.3340e-02,  1.6053e-01, -1.5058e-01],
        [ 4.8197e-01,  2.2173e-01,  2.0852e-01, -8.7282e-02,  8.4093e-02,
         -1.1513e-02, -2.4806e-01, -8.0240e-03],
        [ 1.5809e-01,  6.1829e-01,  4.4006e-02,  5.8397e-02,  1.0428e-01,
          1.2991e-01,  1.6644e-01,  6.8811e-02],
        [-1.6459e-01, -1.6218e-01, -1.7713e-01, -3.3300e-01,  3.1770e-01,
          9.9384e-02,  2.0774e-01, -2.2106e-01],
        [-6.0742e-03,  2.3754e-01, -9.4679e-02,  2.1426e-01, -3.2591e-02,
         -1.7601e-01, -1.5947e-01, -3.2171e-01],
        [ 2.6106e-01, -2.7741e-01, -1.8458e-01, -2.2055e-01, -4.1219e-01,
         -2.4561e-01, -1.4810e-01,  2.7925e-01],
        [ 3.3121e-02, -6.4490e-02, -1.2957e-01,  3.4555e-01, -8.3092e-02,
          1.0184e-01,  6.6446e-02, -2.2417e-01],
        [ 3.1498e-01,  2.2274e-01,  2.2248e-01,  1.1194e-01, -1.0067e-01,
          9.4723e-02, -2.7405e-01,  2.0952e-01],
        [-1.1772e-01,  1.4348e-01, -1.2942e-01, -4.1233e-01,  1.0937e-01,
          7.4429e-02,  2.5152e-02,  1.7323e-01],
        [-2.6790e-01,  1.2798e-02,  3.1025e-01,  3.1927e-01, -1.4874e-01,
          1.3293e-01,  3.8178e-01,  9.7248e-02],
        [ 1.5938e-01, -3.2503e-01,  3.5049e-03, -3.4479e-02, -4.4091e-01,
          4.3932e-01, -2.2590e-01,  1.1771e-02],
        [ 4.2010e-03,  2.8166e-01, -1.8590e-01, -1.8373e-01,  2.4283e-01,
          2.6379e-01,  3.9167e-01,  8.4563e-02],
        [-2.0650e-02, -2.9029e-01, -2.8342e-01, -1.2522e-01,  1.6866e-01,
          1.4307e-01, -1.4265e-02,  4.0243e-02],
        [ 1.9650e-01, -2.5570e-02,  1.3615e-01,  3.0485e-01,  2.8041e-01,
         -2.2210e-01, -3.1731e-01, -9.9345e-02],
        [ 1.1802e-01, -8.4497e-02, -2.5634e-01,  1.2242e-02,  5.9886e-03,
          3.2749e-01,  1.7702e-01,  1.4432e-01],
        [ 1.5461e-02, -1.4055e-01, -2.3095e-01, -2.1384e-01, -1.3808e-01,
          3.0632e-01, -2.7906e-01,  2.9250e-01],
        [ 2.4766e-01, -2.4990e-01,  1.6382e-01, -1.3453e-01, -1.7150e-01,
          7.3561e-02, -4.9178e-02, -2.6479e-01],
        [-1.9103e-01,  1.3405e-01,  3.6483e-02,  8.9469e-02, -7.7139e-02,
          3.2529e-01, -6.0742e-02,  3.5700e-01],
        [ 3.0982e-01, -2.3153e-01,  1.4411e-01,  9.0275e-02, -5.2738e-01,
         -2.1763e-01,  8.1674e-02,  4.5483e-02],
        [ 2.2556e-01, -2.2992e-01, -2.4154e-01, -6.9063e-02, -1.1190e-01,
          1.1474e-01, -4.8301e-03, -3.4531e-02],
        [ 2.6687e-01,  1.8629e-01,  1.2091e-01,  2.6250e-01, -4.1658e-03,
         -1.9164e-01,  2.8061e-01, -1.5136e-01],
        [ 9.2400e-02,  3.9478e-01,  2.6435e-01, -2.2858e-01,  6.3933e-02,
         -1.0698e-01, -1.7398e-03, -9.9946e-03],
        [-4.3552e-02, -4.7090e-02,  5.8941e-02, -5.3291e-02,  5.4645e-02,
          4.5598e-01,  6.4736e-02, -6.1263e-02],
        [ 4.1160e-01, -1.6874e-01,  3.6076e-02, -4.1148e-01, -3.4910e-01,
         -4.2737e-02,  3.7449e-01,  1.3592e-01],
        [ 4.8550e-02, -8.0175e-02,  4.8810e-02, -3.0422e-01, -2.5687e-01,
          2.0442e-01, -3.6164e-02,  5.5347e-02],
        [ 5.6726e-02, -1.6080e-01, -3.0552e-02, -2.5249e-02,  8.4765e-02,
          2.5978e-01, -1.7594e-01, -1.1203e-02],
        [ 1.0398e-02, -3.0032e-01, -2.3404e-01, -1.0131e-01,  2.9391e-01,
         -7.1633e-02,  1.1755e-01, -1.5520e-01],
        [ 3.0205e-01, -9.5349e-02, -9.7148e-02, -4.6095e-02,  6.7382e-02,
         -9.3366e-02,  4.4290e-02, -2.1014e-01],
        [-1.9529e-01,  7.6903e-02, -6.6043e-02,  2.1828e-01,  1.7285e-01,
         -3.4095e-01, -1.2653e-01,  7.7108e-02],
        [-2.2153e-01,  2.0821e-01, -6.9418e-02,  8.6154e-02,  9.7907e-02,
         -8.3363e-02, -2.1565e-01,  1.6451e-02],
        [-1.8074e-01,  2.1287e-02, -3.8661e-02, -1.6115e-01,  1.5554e-01,
         -2.5963e-01, -1.7050e-01,  1.1121e-01],
        [ 5.7508e-02,  2.8157e-01,  4.4801e-02, -8.2368e-02,  3.3930e-01,
          8.2450e-03, -1.1760e-01, -1.2098e-01],
        [ 1.6155e-01,  2.6712e-01,  2.3749e-01, -8.6206e-02,  3.6790e-03,
          2.1825e-01, -8.9478e-02,  5.2213e-02],
        [-1.4454e-01,  6.9764e-02,  4.0546e-01,  2.7918e-01, -4.6285e-02,
          1.4829e-01,  3.5752e-01, -2.9980e-02],
        [ 1.4519e-01, -2.5648e-01,  1.6410e-01, -3.9838e-02,  3.4021e-01,
          3.3481e-01, -2.7768e-01, -1.8822e-01],
        [-1.1468e-01, -2.2755e-01, -4.0523e-01, -1.7216e-02,  9.9634e-02,
         -1.9054e-01,  4.7228e-01, -2.3227e-01],
        [ 1.8950e-01,  4.3111e-01,  6.0932e-02, -2.1024e-01,  1.3773e-01,
         -6.9546e-02, -2.4619e-01, -1.3174e-01],
        [-8.5884e-03, -3.7192e-02,  5.5218e-02,  2.3242e-01,  1.7114e-01,
         -2.9014e-01, -1.0924e-01, -2.5657e-01],
        [ 2.7910e-01,  3.3538e-01, -1.8752e-01,  1.0131e-01,  8.5506e-02,
          1.3145e-01,  1.9551e-01,  6.1426e-02],
        [ 3.1651e-01,  1.4818e-01,  1.2556e-01,  1.0181e-01, -2.5727e-01,
          1.9057e-01,  3.1308e-01,  1.4708e-01],
        [ 6.1747e-02,  2.1917e-01, -7.6052e-03,  2.7756e-02,  8.4182e-02,
          1.7883e-03,  5.7461e-02, -1.1530e-01],
        [-1.3768e-01, -1.7018e-01, -1.3170e-01,  2.9337e-02,  1.3312e-03,
          2.2062e-01, -1.7126e-01,  1.8195e-01],
        [-9.3719e-02,  2.4723e-01, -2.0754e-01, -1.2105e-01,  3.0376e-03,
         -1.3477e-01,  2.8555e-01, -8.7507e-02],
        [ 9.8858e-02,  7.1808e-03, -8.6236e-02, -2.2029e-01,  1.4135e-01,
          7.8093e-02,  1.4699e-01,  1.2432e-01],
        [ 6.7470e-03,  2.3745e-03,  1.1248e-01,  3.1950e-01, -1.4176e-03,
         -2.7711e-01, -2.4850e-01,  1.0796e-01],
        [ 2.5184e-01, -2.7261e-01,  1.4834e-01,  1.4985e-01,  4.1073e-02,
          5.0865e-01, -3.2989e-01, -3.7167e-02],
        [ 7.2153e-02, -3.1330e-01, -2.4420e-01, -3.9043e-01,  3.8919e-01,
          2.7556e-01,  1.4232e-01, -1.7777e-01],
        [ 2.6243e-01,  3.1040e-01,  2.4208e-01, -6.5406e-02,  4.3774e-01,
         -7.2377e-02,  2.8785e-01, -2.5096e-01],
        [ 2.6798e-02, -6.0973e-02, -2.4332e-01,  2.9524e-02, -3.8284e-02,
          2.1069e-01,  3.8230e-01,  6.9351e-02],
        [-3.7127e-02, -8.9624e-02, -5.8443e-02, -1.4160e-01, -3.8344e-02,
          2.3785e-01, -4.5928e-02, -2.6893e-01],
        [ 5.9274e-02,  1.1150e-02, -4.5222e-02,  3.4055e-01,  2.2092e-01,
          2.3401e-01, -5.3100e-02, -1.3205e-01],
        [ 1.1816e-01,  5.8332e-02,  1.2647e-01,  1.1971e-01, -3.1876e-01,
         -1.6221e-02,  9.0127e-02, -1.5857e-01],
        [ 1.5016e-01, -3.6838e-01, -3.3540e-01,  1.8521e-01,  2.2324e-01,
         -1.7764e-01, -1.3017e-01, -1.8262e-01],
        [ 9.3715e-02, -1.5535e-01, -8.0452e-02, -1.7441e-01,  2.1923e-03,
         -1.1637e-01,  1.1764e-01, -2.8224e-01],
        [ 1.1656e-01, -2.9362e-01, -3.0949e-01, -8.2010e-02, -1.4924e-01,
          5.7208e-02,  2.4149e-01, -1.7097e-01],
        [ 7.3069e-02, -2.5867e-02,  5.4621e-02, -1.1659e-01,  1.8606e-01,
          2.3296e-01,  2.8423e-01,  5.1992e-02],
        [-4.5445e-02, -1.2677e-01,  4.2853e-03,  1.6601e-01, -1.3185e-01,
          3.4343e-01, -7.5429e-04,  2.7985e-01],
        [ 1.3851e-01,  1.3441e-01, -2.3716e-01,  2.1846e-02,  3.8049e-01,
         -3.2596e-01,  5.1556e-02, -2.8442e-01],
        [-3.3771e-01,  2.0200e-01, -1.4225e-01, -2.4564e-02, -1.6792e-01,
         -2.5871e-01,  2.9722e-01,  3.2744e-02],
        [-7.6022e-02, -6.3609e-02,  2.3951e-01,  3.1068e-01,  2.9394e-01,
          3.3580e-01,  1.0123e-01,  8.8446e-02],
        [ 1.3151e-01, -2.2246e-01, -2.5672e-01,  7.6482e-02,  1.7081e-01,
          1.4037e-01, -1.8137e-01,  1.1701e-01],
        [-7.3939e-02, -3.8457e-02, -1.6061e-01, -3.2931e-01, -1.9579e-01,
          3.2291e-01,  3.5639e-01,  1.9677e-01],
        [-4.0671e-03, -4.8184e-02,  1.4731e-01,  2.9570e-01,  3.9652e-01,
          1.5572e-01, -5.8851e-02, -9.2846e-02],
        [ 1.0805e-01, -1.7412e-01, -3.9131e-01,  5.2234e-02,  3.6967e-02,
          6.1218e-02, -1.5312e-01,  2.0325e-02],
        [-9.6584e-02,  3.3966e-01,  1.1855e-01, -2.1582e-01,  5.4482e-02,
          1.6753e-01,  3.7766e-01, -1.7245e-01],
        [ 1.0841e-01,  2.4321e-01,  4.0667e-02, -8.4407e-02,  3.7101e-01,
          9.8756e-03,  4.4371e-02, -2.2957e-01],
        [ 3.3806e-02,  4.2419e-02,  1.5291e-01,  1.1386e-01,  3.6329e-01,
          3.8779e-01, -2.0932e-01, -4.5908e-02],
        [-7.7052e-02,  3.6347e-01, -3.8871e-01, -2.1229e-01, -3.1919e-01,
          9.1019e-02, -1.0045e-02,  1.0466e-01],
        [-2.8560e-01,  2.1941e-01, -9.3123e-02,  2.4651e-02, -8.5359e-02,
          7.1959e-02,  2.4817e-01,  1.6350e-01],
        [ 9.5328e-02, -2.3336e-02, -3.9394e-01,  8.1951e-02,  3.2234e-01,
          1.8913e-01,  3.4647e-01, -1.1771e-01],
        [ 2.9571e-01,  2.3055e-01,  2.3596e-01, -1.7822e-01,  1.5918e-01,
         -2.4230e-01, -6.5052e-02,  1.0615e-01],
        [ 9.7428e-02,  1.7813e-01,  1.2054e-01, -2.5947e-01,  2.5098e-01,
         -1.9752e-01,  1.7292e-01,  3.9612e-02],
        [ 1.7915e-01, -1.0325e-03, -4.7992e-02, -1.1122e-01, -1.5121e-01,
          6.3234e-02, -3.5648e-01, -3.6284e-03],
        [ 1.3503e-01, -3.2177e-01, -2.8412e-01, -1.9926e-01, -5.4180e-02,
         -4.0545e-02,  2.0635e-01, -3.8691e-01],
        [-9.7233e-02,  3.5124e-01,  5.7443e-02,  1.8499e-01, -1.0003e-01,
          2.2570e-01, -1.2335e-01, -4.9643e-02],
        [-3.8143e-02,  3.0566e-01,  1.6055e-01, -7.1298e-02,  4.7556e-02,
          5.7977e-02,  2.7150e-03, -2.2601e-01],
        [ 1.5054e-01,  5.6564e-02,  2.3752e-01,  5.8839e-02, -2.8216e-01,
          4.1609e-01,  1.4809e-01,  8.8760e-02],
        [ 4.0203e-01, -1.7832e-01,  1.1330e-01, -1.0948e-01, -4.1929e-01,
         -2.1187e-01,  5.0417e-01, -3.0121e-02],
        [ 2.1748e-01, -7.1391e-02, -3.0969e-01,  5.4789e-02, -1.8446e-01,
          2.6463e-02,  5.6445e-02,  5.8010e-02],
        [ 3.6321e-01, -2.5828e-01,  1.6456e-01, -8.9734e-02, -1.2979e-01,
         -2.2794e-01, -2.5604e-02,  1.3631e-01],
        [ 3.3855e-01, -3.1361e-01,  4.3340e-02, -6.8819e-02,  8.9937e-02,
          1.2846e-01,  4.0118e-01,  1.0769e-01],
        [-2.2236e-01,  2.7987e-01, -4.3894e-03, -8.3485e-02, -2.8987e-01,
         -5.1687e-02,  2.5394e-01, -2.0744e-01],
        [-6.0836e-02, -8.0847e-02,  2.4764e-02,  1.8373e-01, -2.2686e-01,
         -1.9809e-01,  2.2012e-01,  2.4464e-01],
        [ 3.4126e-01,  3.1362e-01, -3.2651e-01,  1.6877e-01,  7.0916e-02,
          3.0602e-01, -9.6873e-02,  1.3553e-01],
        [-6.0259e-02,  6.3064e-02, -4.1775e-02,  4.8547e-02,  3.5582e-01,
          1.2216e-01, -7.1406e-02,  4.1738e-02],
        [ 1.5241e-01, -2.8568e-01, -9.2835e-02, -2.9722e-01,  2.5066e-01,
         -1.3250e-01, -2.1443e-01, -3.5728e-01],
        [-9.0276e-02,  8.7209e-02, -1.0006e-01, -1.2470e-01,  1.8572e-01,
          1.3898e-01,  4.5113e-02,  1.3101e-01],
        [ 7.6429e-02,  9.0515e-02, -3.3005e-01, -1.6453e-01,  2.9728e-01,
         -1.1889e-01, -1.2365e-01, -9.0507e-02],
        [-1.1430e-01,  3.1113e-01,  1.9872e-01, -2.2822e-01,  8.8886e-02,
         -8.3627e-02,  4.9696e-01, -4.7537e-02]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[-2.5411e-03,  2.6129e-03,  1.1579e-03,  7.3034e-03, -2.3138e-03,
         -1.6661e-02, -5.3380e-03,  2.1927e-02],
        [ 6.4821e-04,  7.5617e-04, -1.8360e-03,  2.0167e-04,  4.8853e-04,
          2.0774e-03,  6.3468e-04, -2.0209e-03],
        [-6.6146e-05,  3.3398e-05,  6.8745e-05,  1.3929e-04, -6.1681e-05,
         -3.4315e-04, -1.1036e-04,  4.2690e-04],
        [-3.3190e-04, -2.0970e-03,  3.2528e-03, -5.6634e-04,  1.2951e-03,
         -2.0623e-03,  6.7148e-04,  1.9957e-03],
        [ 9.6956e-05, -1.8464e-05, -1.1960e-04, -9.5686e-05,  1.8882e-04,
          3.2864e-04,  1.1445e-04, -3.0426e-04],
        [ 1.7492e-03,  4.7358e-03, -8.9617e-03, -1.1369e-03, -2.7495e-03,
          1.2394e-02,  5.9657e-04, -1.4436e-02],
        [ 3.3058e-04,  1.1300e-03, -1.9385e-03,  6.0124e-05, -6.4169e-04,
          1.8499e-03, -1.0838e-04, -2.0295e-03],
        [-5.6526e-04, -1.8731e-03,  2.9477e-03, -5.9559e-04,  1.0912e-03,
         -2.1720e-03, -5.8853e-05,  2.5360e-03],
        [ 3.8259e-03, -1.1686e-03, -5.0610e-03, -6.5328e-03,  4.6807e-03,
          1.7370e-02,  5.2843e-03, -2.0014e-02],
        [ 5.0661e-04, -6.8247e-04, -9.4796e-04, -2.4324e-03,  1.2796e-03,
          5.3470e-03,  1.3128e-03, -6.0119e-03],
        [ 2.0485e-03,  9.9062e-03, -1.6600e-02,  3.4393e-03, -1.4367e-03,
          1.2002e-02, -2.5042e-03, -8.5482e-03],
        [ 9.2246e-06,  1.2038e-04, -1.8529e-04,  8.3529e-05,  4.4528e-05,
          3.3993e-05, -6.6807e-05,  9.2142e-05],
        [-2.7815e-03, -1.6185e-03,  6.5373e-03,  1.9021e-03, -3.3323e-03,
         -1.2760e-02, -3.3652e-03,  1.3124e-02],
        [ 1.4528e-03,  7.1967e-03, -1.1748e-02,  1.8633e-03, -2.5754e-03,
          9.5337e-03, -1.4729e-03, -8.5963e-03],
        [-7.8407e-04, -3.1808e-03,  5.0994e-03, -4.0275e-04,  1.9953e-03,
         -4.2236e-03,  4.7372e-04,  4.6280e-03],
        [-3.4748e-04,  5.5116e-03, -8.0256e-03,  2.9710e-03, -2.3778e-03,
          2.1758e-03, -3.3018e-03,  6.0709e-04],
        [ 6.7361e-03, -4.7365e-03, -3.3686e-03, -1.3142e-02,  8.3916e-03,
          3.1262e-02,  1.2184e-02, -3.9486e-02],
        [ 2.5799e-04,  4.7890e-03, -7.9424e-03,  1.6153e-03, -1.0794e-03,
          4.2510e-03, -2.5502e-03, -1.6224e-03],
        [ 6.1333e-04,  1.7068e-03, -3.1471e-03,  6.2334e-04,  1.3442e-03,
          1.9333e-03, -5.7284e-04, -1.6442e-04],
        [ 5.5938e-04,  2.2907e-03, -3.6906e-03,  1.1481e-03,  2.4676e-04,
          2.3511e-03, -4.3338e-04, -1.1656e-03],
        [ 7.0359e-04,  5.1805e-04, -1.9631e-03, -5.1278e-04,  6.2742e-04,
          2.6675e-03,  7.7952e-04, -2.4032e-03],
        [-8.7795e-04, -6.7060e-03,  1.0698e-02, -1.3228e-03,  4.3574e-03,
         -7.3300e-03,  2.5197e-03,  7.1214e-03],
        [ 2.1999e-03,  3.7680e-03, -7.6884e-03, -2.4562e-03, -3.6268e-03,
          1.4113e-02,  2.4139e-03, -1.8591e-02],
        [-2.9678e-04, -7.0814e-04,  1.3371e-03,  7.1291e-05,  3.2327e-04,
         -1.5082e-03, -6.2022e-05,  1.6768e-03],
        [ 3.6278e-03, -3.2275e-04, -4.8714e-03, -4.9153e-03,  3.7395e-03,
          1.4765e-02,  4.6697e-03, -1.7117e-02],
        [ 9.7291e-04, -1.6895e-03,  1.0355e-03, -3.8558e-03, -1.9007e-03,
          6.9451e-03,  3.3026e-03, -1.2134e-02],
        [-2.1715e-03,  1.7183e-03, -7.9310e-04,  4.2866e-03,  1.2205e-03,
         -9.0337e-03, -5.1334e-03,  1.5455e-02],
        [-5.1238e-05, -4.6086e-04,  7.4651e-04,  1.8520e-05,  5.4842e-04,
         -6.8023e-04,  1.3909e-04,  8.8380e-04],
        [-1.1278e-03, -6.5198e-04,  2.5552e-03,  1.5571e-03, -1.2591e-03,
         -6.8577e-03, -1.3503e-03,  7.5279e-03],
        [ 3.6435e-03, -1.6439e-03, -4.6822e-03, -8.2825e-03,  4.4143e-03,
          2.1210e-02,  6.0014e-03, -2.5289e-02],
        [ 1.7180e-05, -1.1522e-03,  1.7850e-03, -6.4290e-04,  2.9867e-04,
         -3.7044e-04,  8.1062e-04, -3.3512e-04],
        [ 6.2023e-04, -3.1965e-04, -7.9766e-04, -1.5398e-03,  6.3626e-04,
          3.6983e-03,  9.6748e-04, -4.4620e-03],
        [ 3.6074e-03, -1.4028e-03, -5.9108e-03, -8.0498e-03,  5.1989e-03,
          2.2093e-02,  6.3338e-03, -2.5413e-02],
        [-9.0095e-04, -5.0182e-03,  7.8869e-03, -1.1575e-03,  2.9765e-03,
         -5.5175e-03,  1.4274e-03,  5.4873e-03],
        [-3.7494e-04, -3.2180e-04,  8.4614e-04, -1.7625e-04, -4.2520e-04,
         -9.8346e-04, -5.6823e-04,  1.0234e-03],
        [-6.9663e-04, -3.7129e-03,  5.9930e-03, -9.3444e-04,  1.9705e-03,
         -4.2390e-03,  8.2674e-04,  4.2020e-03],
        [-4.1820e-04, -4.6562e-03,  7.4563e-03, -1.1202e-03,  2.6991e-03,
         -4.5292e-03,  2.1498e-03,  3.7562e-03],
        [ 5.7504e-06, -4.5587e-05,  1.0218e-04,  9.9249e-06,  2.1711e-05,
         -8.5548e-05,  3.8084e-05,  5.7895e-05],
        [-8.8396e-05, -1.8116e-03,  2.8555e-03, -8.6259e-04,  7.0636e-04,
         -1.0017e-03,  1.0431e-03,  2.5061e-04],
        [ 2.0937e-03, -5.7730e-04, -2.2084e-03, -2.9463e-03,  1.9564e-03,
          8.4170e-03,  3.2360e-03, -1.0435e-02],
        [-1.2332e-03,  3.5455e-04,  1.2915e-03,  2.3724e-03, -2.6908e-04,
         -6.8806e-03, -2.3833e-03,  9.2492e-03],
        [ 4.2914e-03, -5.4275e-04, -4.8682e-03, -4.7737e-03,  4.3524e-03,
          1.4827e-02,  5.8636e-03, -1.7432e-02],
        [ 2.6571e-04,  9.2244e-04, -1.4640e-03,  2.8402e-04, -1.1706e-05,
          1.3047e-03, -5.1283e-05, -1.0497e-03],
        [-3.6973e-04, -1.8054e-03,  2.9202e-03, -2.7115e-04,  1.1357e-03,
         -2.3408e-03,  4.0887e-04,  2.4721e-03],
        [ 2.0035e-03,  1.4522e-03, -4.5739e-03, -3.9405e-04,  1.0926e-03,
          5.6378e-03,  2.1377e-03, -5.6449e-03],
        [-8.3976e-04, -4.0165e-03,  6.3736e-03, -6.2206e-04,  2.7178e-03,
         -5.0279e-03,  8.2113e-04,  5.4962e-03],
        [ 9.6478e-04,  7.3177e-03, -1.1388e-02,  3.0361e-03, -2.2021e-03,
          5.9348e-03, -2.8288e-03, -3.3592e-03],
        [ 3.1469e-07,  6.3528e-04, -1.4294e-03, -3.7361e-04, -5.6899e-04,
          1.8862e-03, -3.3829e-04, -1.9794e-03],
        [-2.3752e-04,  2.7251e-04, -2.2843e-04,  4.4943e-04, -2.4849e-04,
         -7.6921e-04, -4.6039e-04,  1.1925e-03],
        [ 7.7057e-04,  3.7219e-03, -6.0967e-03,  1.1215e-03, -1.6147e-03,
          5.0404e-03, -5.8764e-04, -4.7880e-03],
        [-1.0248e-04, -2.5182e-04,  2.8935e-04, -1.5847e-04, -5.9815e-05,
          5.6845e-05,  8.8905e-05, -2.2528e-04],
        [ 6.1029e-04,  1.0620e-03, -2.1173e-03, -5.6987e-04, -9.0444e-04,
          3.7135e-03,  6.1528e-04, -4.8211e-03],
        [-2.9560e-04, -5.3006e-03,  7.6908e-03, -4.7651e-03, -2.0473e-03,
         -7.8983e-06,  2.9520e-03, -6.1019e-03],
        [ 8.5545e-04,  6.4317e-03, -9.6769e-03,  2.9507e-03, -1.4598e-03,
          4.6081e-03, -2.4471e-03, -1.9414e-03],
        [-2.2387e-05,  2.8858e-05,  5.1100e-05,  1.1621e-04, -3.2806e-05,
         -2.5895e-04, -4.7655e-05,  3.0680e-04],
        [ 4.3463e-03,  1.0027e-03, -8.1254e-03, -4.8269e-03,  4.8126e-03,
          1.8501e-02,  5.2322e-03, -2.0075e-02],
        [-1.1070e-03, -6.0069e-03,  9.4679e-03, -1.4044e-03,  3.4882e-03,
         -6.6384e-03,  1.6841e-03,  6.5606e-03],
        [-7.1560e-04, -2.8972e-03,  4.7389e-03, -2.1160e-04,  2.0143e-03,
         -4.1959e-03,  4.1427e-04,  4.7805e-03],
        [-3.3416e-05, -9.3543e-05,  2.1801e-04,  2.1115e-05, -3.9710e-05,
         -2.4481e-04,  2.8692e-05,  1.8647e-04],
        [ 1.0669e-03,  2.3617e-04, -1.6961e-03, -3.0260e-03, -2.5045e-03,
          8.0962e-03,  2.4335e-03, -1.2540e-02],
        [-9.5561e-04, -5.1338e-03,  8.1541e-03, -1.1155e-03,  3.0167e-03,
         -5.8710e-03,  1.4142e-03,  5.8652e-03],
        [ 5.1648e-04,  4.1894e-03, -6.5988e-03,  1.4801e-03, -1.1671e-03,
          4.1276e-03, -1.5619e-03, -2.6818e-03],
        [-4.3464e-04, -4.0551e-03,  6.3977e-03, -7.9252e-04,  3.0226e-03,
         -4.2706e-03,  1.6606e-03,  4.3266e-03],
        [ 9.0390e-04,  2.7410e-03, -4.3623e-03,  1.4899e-03,  3.0118e-04,
          2.7646e-03, -2.6815e-04, -1.5714e-03],
        [ 1.3627e-04, -1.8063e-03,  3.1473e-03,  1.4428e-04,  1.9274e-03,
         -2.2996e-03,  1.3916e-03,  2.3137e-03],
        [ 2.6928e-05, -6.0778e-04,  9.5138e-04, -4.0649e-04,  1.2983e-04,
         -7.5953e-05,  4.6453e-04, -3.6410e-04],
        [ 2.9354e-05, -1.6350e-06, -2.2239e-05, -3.6539e-05,  3.3716e-06,
          1.2860e-04,  5.5897e-05, -1.8275e-04],
        [ 4.2705e-04, -3.3213e-03,  4.2157e-03, -3.2496e-03, -1.1687e-03,
          1.1076e-03,  2.6430e-03, -5.3731e-03],
        [ 1.2011e-03,  6.0701e-03, -9.6470e-03,  2.0037e-03, -1.8276e-03,
          6.9282e-03, -1.5091e-03, -5.6211e-03],
        [-1.2634e-03, -4.7988e-06,  1.6116e-03,  1.6035e-03, -1.1739e-03,
         -5.5876e-03, -1.7288e-03,  6.6351e-03],
        [ 9.4080e-05, -1.9039e-05, -2.0347e-04, -3.4186e-04, -1.5556e-04,
          8.0024e-04,  1.5286e-04, -1.1401e-03],
        [-4.1104e-06,  1.7984e-03, -2.4463e-03,  1.6105e-03,  3.8774e-04,
         -4.6695e-04, -1.2629e-03,  2.4291e-03],
        [ 4.6477e-04,  1.0252e-03, -1.5305e-03,  4.2063e-04, -2.4087e-04,
          1.2409e-03,  2.1971e-04, -1.3431e-03],
        [ 9.3226e-05, -4.7656e-04,  4.7151e-04, -6.5333e-04, -9.8483e-05,
          6.9613e-04,  4.5201e-04, -1.3785e-03],
        [ 6.2456e-04,  3.9681e-03, -6.9962e-03, -2.1775e-04, -3.1519e-03,
          7.7307e-03, -6.9280e-04, -8.7592e-03],
        [ 7.0118e-05,  1.8718e-04, -3.8839e-04, -3.9398e-05, -5.1336e-05,
          4.9639e-04, -8.6685e-06, -5.1961e-04],
        [ 3.3756e-05, -1.5168e-04,  1.6526e-04, -1.0498e-04,  1.2348e-04,
          4.3580e-05,  1.3296e-04, -9.2437e-05],
        [-8.2365e-04, -8.2978e-03,  1.2148e-02, -4.8063e-03,  6.5906e-04,
         -3.9378e-03,  3.7214e-03, -1.1151e-03],
        [ 6.3047e-04,  5.2137e-03, -8.4183e-03,  1.9562e-03, -1.3507e-03,
          5.4266e-03, -1.8687e-03, -3.5577e-03],
        [-9.3623e-03, -5.3027e-04,  1.4994e-02,  1.2151e-02, -8.3144e-03,
         -4.0599e-02, -1.2473e-02,  4.6623e-02],
        [ 2.6882e-03,  1.2387e-03, -4.8939e-03, -5.8254e-03, -5.0506e-03,
          1.8101e-02,  5.2733e-03, -2.7107e-02],
        [ 7.3774e-03,  3.7221e-04, -1.3442e-02, -1.1681e-02,  9.6259e-03,
          3.7639e-02,  9.0309e-03, -4.1155e-02],
        [ 5.7023e-03, -1.3461e-03, -7.9544e-03, -1.0381e-02,  5.8354e-03,
          2.9142e-02,  8.6623e-03, -3.4636e-02],
        [-7.2422e-04,  2.0767e-03, -1.7204e-03,  4.2593e-03,  2.6318e-03,
         -6.9278e-03, -3.4429e-03,  1.2901e-02],
        [-5.5662e-04, -2.9933e-03,  4.7199e-03, -6.4405e-04,  1.8487e-03,
         -3.3611e-03,  8.5446e-04,  3.4465e-03],
        [-5.7562e-04,  4.4501e-03, -7.4335e-03,  8.7468e-04, -2.9015e-03,
          4.4159e-03, -3.4401e-03, -2.7943e-03],
        [-5.5428e-05, -9.9750e-05,  2.0900e-04,  8.0792e-06, -3.0760e-05,
         -2.3189e-04, -1.4060e-05,  2.0535e-04],
        [ 2.0804e-04,  5.8998e-04, -1.0855e-03,  5.1609e-05, -1.3119e-04,
          1.0216e-03, -5.6826e-05, -9.6467e-04],
        [-2.2863e-03, -2.3236e-04,  4.2885e-03,  2.7895e-03, -2.7990e-03,
         -1.0992e-02, -3.5046e-03,  1.2285e-02],
        [ 1.5978e-03, -8.7018e-04,  3.8204e-04, -1.8363e-03,  1.2962e-04,
          5.2424e-03,  3.6740e-03, -8.6255e-03],
        [ 2.1350e-03, -7.1409e-04, -3.5829e-03, -4.8826e-03,  3.1397e-03,
          1.3469e-02,  3.7003e-03, -1.5367e-02],
        [ 5.8126e-05, -7.2471e-06, -4.0311e-05, -6.4520e-05,  2.2243e-05,
          2.1240e-04,  9.5493e-05, -2.9401e-04],
        [ 3.0234e-04,  5.7730e-04, -1.1999e-03, -1.7942e-04, -2.0971e-04,
          1.6064e-03,  1.1463e-04, -1.8230e-03],
        [ 1.8389e-03,  2.1705e-03, -6.7869e-03, -1.0584e-03,  3.5394e-03,
          9.3194e-03,  1.0168e-03, -7.3829e-03],
        [ 2.0880e-03,  4.7280e-03, -8.5987e-03, -1.0167e-03, -2.8371e-03,
          1.2283e-02,  1.3144e-03, -1.4885e-02],
        [ 6.7810e-04,  7.4930e-03, -1.0766e-02,  4.9974e-03,  4.3609e-04,
          2.2007e-03, -3.8814e-03,  3.5283e-03],
        [-3.5933e-04, -1.4012e-03,  2.2267e-03, -7.7786e-05,  1.1641e-03,
         -2.0286e-03,  1.3712e-04,  2.4767e-03],
        [ 8.6099e-04, -1.7328e-04, -8.7705e-04, -1.9176e-03, -4.7996e-04,
          5.5135e-03,  1.9204e-03, -7.8998e-03],
        [ 6.7710e-04,  4.6880e-03, -7.6626e-03,  1.4317e-03, -1.6143e-03,
          5.4154e-03, -1.5617e-03, -4.1807e-03],
        [ 5.9036e-05,  7.7092e-05, -2.0369e-04, -5.8720e-05,  2.3714e-05,
          3.6469e-04,  5.2894e-05, -3.9508e-04]], device='cuda:0') 

model.module_1.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.2606,  0.1637, -0.5403, -0.3156, -0.0509,  0.3721, -0.5141,  0.1700,
        -0.4312, -0.6131, -0.2146, -0.0825,  0.0019, -0.1937, -0.1791,  0.1263,
        -0.0752,  0.2164,  0.1377, -0.2251, -0.3958, -0.2232,  0.2588, -0.3350,
         0.1532,  0.0772, -0.2711, -0.2706, -0.6111, -0.1296, -0.0775, -0.1203,
        -0.6011, -0.1275, -0.0559,  0.0134, -0.0846, -0.2039,  0.1828, -0.4454,
        -0.5099, -0.1899, -0.0721, -0.2248, -0.5227,  0.0853,  0.3462, -0.0109,
        -0.2962, -0.1451, -0.4951,  0.1208, -0.6808, -0.4349, -0.2537, -0.1727,
        -0.1619, -0.2225, -0.3807,  0.1462, -0.5152,  0.3320,  0.0028,  0.1897,
         0.2143,  0.0335, -0.4067, -0.5384, -0.1859, -0.5446, -0.3228, -0.3799,
         0.0069, -0.1709,  0.2471, -0.2778, -0.0350, -0.2645, -0.0819, -0.5617,
         0.4443, -0.1934,  0.0584, -0.1643, -0.2179, -0.0502, -0.5144, -0.3290,
        -0.2975,  0.0473, -0.3661, -0.2639, -0.3904, -0.3873,  0.4611,  0.1303,
        -0.2665, -0.2793,  0.0663, -0.2362], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 2.6887e-03,  2.3572e-05,  3.6254e-05, -1.0905e-03, -3.5387e-05,
         7.0042e-04,  4.6852e-04, -7.4499e-04, -6.6994e-04, -3.9912e-04,
         3.6406e-03,  6.8605e-05,  9.9146e-04,  2.3031e-03, -1.3128e-03,
         2.9699e-03, -5.3624e-03,  2.7366e-03,  9.1269e-04,  4.0822e-04,
        -8.8112e-05, -3.8150e-03, -7.9677e-04, -2.5862e-04, -1.0364e-03,
        -2.1942e-03,  3.2097e-03, -3.2677e-04,  8.9723e-04, -1.9756e-03,
        -9.1919e-04, -2.6956e-04, -1.5817e-03, -2.4511e-03,  9.4409e-05,
        -1.7139e-03, -2.8961e-03, -4.6772e-05, -1.3193e-03, -8.5952e-04,
         1.4307e-03, -1.5788e-03,  6.3517e-05, -8.3835e-04, -3.9410e-04,
        -1.8057e-03,  3.6231e-03,  4.2685e-04,  3.6516e-04,  1.0598e-03,
        -5.9227e-05, -1.9266e-04, -2.0674e-03,  2.7234e-03,  1.4386e-06,
        -8.0256e-04, -2.9058e-03, -1.2826e-03, -6.2851e-05, -1.3254e-03,
        -2.5264e-03,  1.7274e-03, -2.4648e-03,  6.1568e-04, -1.7161e-03,
        -5.3415e-04, -3.3352e-05, -1.5367e-03,  2.0228e-03,  8.9161e-04,
         3.6879e-05,  1.0189e-03,  8.5270e-05, -2.3376e-04,  1.2112e-03,
         8.3938e-05, -9.5946e-05, -3.5583e-03,  2.1467e-03,  3.9948e-03,
        -2.9163e-03, -1.6928e-03, -2.6599e-03,  2.3572e-03, -1.5112e-03,
         3.4406e-03, -3.0722e-05,  2.5260e-04,  8.2302e-04, -2.5781e-03,
        -1.1300e-03, -5.4295e-05,  1.8471e-04,  1.0315e-03, -6.1788e-05,
         3.3499e-03, -6.4793e-04, -1.4573e-03,  1.8868e-03, -4.1954e-06],
       device='cuda:0') 

model.module_3.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[-0.0133, -0.1875, -0.0906,  ...,  0.1000,  0.1230, -0.0493],
        [-0.0087, -0.2260, -0.1382,  ..., -0.0508,  0.2244, -0.1143],
        [ 0.0150, -0.0698,  0.0518,  ...,  0.0149,  0.1336,  0.1351],
        ...,
        [ 0.0570, -0.1390,  0.0441,  ...,  0.0281,  0.0716, -0.0740],
        [ 0.0328,  0.0933,  0.0430,  ..., -0.1031,  0.0528, -0.0014],
        [-0.0209, -0.1280, -0.1154,  ..., -0.0965, -0.1059, -0.0444]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 2.3150e-04,  8.6923e-06,  9.2037e-06,  ...,  4.8880e-04,
          1.3389e-03,  3.6174e-05],
        [ 1.0713e-03,  1.5316e-05,  7.8852e-05,  ...,  5.1340e-04,
          2.1492e-03,  9.1090e-05],
        [-6.5999e-04,  3.0537e-06, -2.5029e-05,  ...,  1.5469e-04,
          9.7434e-04,  8.0732e-06],
        ...,
        [ 1.0159e-04, -3.4338e-06,  7.1067e-06,  ..., -7.7988e-06,
         -5.5740e-05,  1.8956e-06],
        [-2.6587e-04,  9.7039e-06, -1.8854e-06,  ...,  1.5018e-04,
          5.6902e-04,  1.1117e-05],
        [-1.4537e-04, -2.1766e-06, -3.7913e-06,  ..., -3.5499e-07,
         -2.8504e-08, -2.5617e-06]], device='cuda:0') 

model.module_3.bias 100 torch.Size([100])
Parameter containing:
tensor([ 0.2025,  0.2753,  0.1022,  0.1963, -0.0175,  0.1211, -0.0225,  0.2816,
         0.2295, -0.0227, -0.0526,  0.2261,  0.1190,  0.2129,  0.3081,  0.0545,
        -0.0593,  0.2791, -0.1495, -0.2110,  0.3084,  0.5119,  0.1630, -0.0341,
         0.0909, -0.0718, -0.1188, -0.1819, -0.0028,  0.0967, -0.0307, -0.1073,
        -0.1401, -0.2518,  0.1279, -0.0674, -0.1445,  0.0281,  0.4526,  0.2266,
        -0.0364,  0.0271, -0.0456,  0.0272,  0.2778, -0.0872, -0.1776, -0.1238,
        -0.0665,  0.1021, -0.1158, -0.0807, -0.0936, -0.4662,  0.1180,  0.1375,
        -0.0842,  0.2160, -0.0641, -0.1571, -0.0749,  0.0941,  0.0928,  0.1124,
        -0.1737,  0.1589,  0.0784,  0.0414,  0.2508, -0.3207, -0.2596,  0.2152,
         0.1809,  0.3407, -0.1763,  0.0702, -0.1974, -0.1474,  0.3608,  0.1071,
         0.2228, -0.0052, -0.2977, -0.0358,  0.0630,  0.1530, -0.0366, -0.0182,
         0.2536, -0.0775, -0.0979,  0.2216, -0.1140, -0.5472, -0.2617,  0.0999,
        -0.1163, -0.0650,  0.2037, -0.0754], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 1.0379e-03,  2.9767e-03,  5.0047e-04, -1.8668e-03,  1.2759e-03,
        -1.4755e-03, -9.4503e-05, -2.0510e-04,  1.0746e-03, -2.2195e-05,
        -1.3170e-03,  3.0883e-04,  1.0940e-03,  5.5553e-03, -7.7574e-05,
        -1.8634e-03, -5.4677e-04, -1.5557e-03, -1.2839e-05, -4.4327e-04,
         8.6662e-04,  4.5302e-03,  3.2630e-03,  9.0106e-07, -8.6056e-04,
        -1.6556e-03, -1.0938e-05, -1.2847e-04, -8.1995e-05, -4.2431e-04,
        -5.6774e-05,  9.3470e-06, -3.5374e-04, -1.2516e-04, -2.6620e-04,
        -4.1127e-05,  1.2693e-04, -1.2468e-05, -2.0101e-03,  1.1744e-03,
        -5.5732e-05, -8.3476e-05,  1.4360e-04,  1.7129e-03, -1.6159e-05,
         2.8046e-04,  2.9695e-05,  1.5224e-05,  1.6936e-05,  1.5892e-03,
        -4.1696e-05,  7.5483e-06,  6.6067e-05,  4.1621e-05,  2.7364e-03,
         6.0456e-04,  5.4636e-04, -4.8304e-03,  1.6298e-04, -2.4961e-03,
         3.4595e-03, -5.0221e-04,  3.8842e-03,  2.4824e-03, -2.7859e-05,
         8.2101e-05, -1.1522e-03, -4.4357e-05, -1.6286e-03,  1.3921e-03,
        -6.1118e-04,  2.0055e-03,  1.2308e-03, -5.4758e-03,  1.6472e-04,
         1.5064e-03,  3.9405e-05,  4.2704e-05,  2.6657e-03,  6.3954e-05,
         4.6545e-04,  3.1906e-04, -9.2493e-04,  1.1801e-05,  1.2799e-05,
         9.0934e-04, -1.9705e-04,  1.3215e-03, -3.1973e-03,  2.0212e-04,
        -1.3758e-04,  2.9954e-03, -1.2862e-04, -4.5185e-04,  1.2980e-04,
         9.3428e-04,  2.9146e-05,  1.2479e-05,  5.2140e-04, -1.5381e-05],
       device='cuda:0') 

model.module_5.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[ 0.2416,  0.1766,  0.1047,  ...,  0.1083,  0.1078,  0.0271],
        [-0.1576, -0.0949, -0.1993,  ..., -0.1028,  0.1696, -0.2063],
        [-0.0853, -0.0707, -0.1730,  ..., -0.0728, -0.0441, -0.0445],
        ...,
        [-0.0137,  0.0093,  0.0197,  ...,  0.0770, -0.0058, -0.1580],
        [-0.0594,  0.0069,  0.1042,  ...,  0.0343,  0.1073, -0.0397],
        [-0.0283, -0.0502, -0.0822,  ..., -0.0836, -0.2020, -0.1593]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 3.4445e-03,  1.1541e-03,  7.7570e-03,  ...,  3.7903e-04,
          9.4013e-03,  1.9332e-04],
        [-3.1580e-04, -1.2015e-04, -6.7675e-04,  ..., -2.1526e-05,
         -8.4412e-04, -2.7076e-05],
        [-1.5306e-03, -9.3576e-04, -3.0955e-03,  ..., -9.6614e-04,
         -6.9483e-03, -3.3255e-04],
        ...,
        [-1.4817e-05, -1.3751e-04,  2.9937e-04,  ..., -1.9271e-04,
          3.1728e-04, -3.9508e-05],
        [ 2.7540e-04, -2.5730e-04,  2.3995e-03,  ..., -2.6856e-04,
          3.3401e-03, -7.4922e-07],
        [ 8.9626e-04,  5.4344e-04,  1.5733e-03,  ...,  4.1720e-04,
          2.0553e-03,  6.7039e-05]], device='cuda:0') 

model.module_5.bias 16 torch.Size([16])
Parameter containing:
tensor([ 0.2152, -0.2083,  0.3675, -0.0737,  0.1108, -0.3249, -0.0345, -0.1642,
         0.3894, -0.1670,  0.2058, -0.1841, -0.0115,  0.0863,  0.1923, -0.3408],
       device='cuda:0', requires_grad=True) 
grad:  tensor([ 8.6271e-03, -3.7018e-04, -1.3775e-02,  1.4874e-03, -1.0392e-02,
        -8.5315e-05, -2.1792e-02, -6.7734e-04,  1.7162e-02,  1.1121e-04,
         5.3625e-03,  1.3338e-03, -2.9480e-04, -4.5769e-04,  2.2876e-03,
         2.1704e-03], device='cuda:0') 

model.module_7.att 8 torch.Size([1, 1, 8])
Parameter containing:
tensor([[[-1.3747, -1.4965, -1.0939,  0.6811,  1.6100,  0.5622, -1.3035,
           1.7518]]], device='cuda:0', requires_grad=True) 
grad:  tensor([[[-0.0756,  0.0340,  0.0202,  0.0166,  0.0296,  0.0059,  0.0481,
           0.0040]]], device='cuda:0') 

model.module_7.bias 8 torch.Size([8])
Parameter containing:
tensor([ 0.0644, -0.2618, -0.0196, -0.3861,  0.1402, -0.0909, -0.1322, -0.3147],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-0.0577, -0.0545, -0.0109, -0.0204,  0.1022, -0.0174,  0.0082, -0.0552],
       device='cuda:0') 

model.module_7.lin_l.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[ 0.0937,  0.3403,  0.1914, -0.3440,  0.3482, -0.2398, -0.2175, -0.1769,
          0.2088, -0.0719, -0.3754,  0.3747,  0.1791, -0.0783, -0.3892, -0.2177],
        [-0.2802,  0.1879,  0.0942, -0.2633,  0.1673,  0.1496,  0.4154, -0.1073,
         -0.4944, -0.2599, -0.1091,  0.3302,  0.0109, -0.0801,  0.2874,  0.4412],
        [-0.3072, -0.1515,  0.4095,  0.4348,  0.0069,  0.3531,  0.2318,  0.0910,
         -0.1631, -0.0827, -0.0538,  0.3913,  0.2468, -0.1039,  0.3153, -0.2366],
        [-0.2962,  0.3542,  0.1128,  0.4444, -0.0513, -0.1647,  0.3344,  0.2641,
          0.2327,  0.6150,  0.1378,  0.4260,  0.0278,  0.4795,  0.2971,  0.4616],
        [-0.0300,  0.2459,  0.0886,  0.0055, -0.3796,  0.3144,  0.0154,  0.3270,
         -0.1257,  0.0184, -0.0670,  0.0881, -0.3369, -0.2342,  0.0447, -0.2175],
        [ 0.4223, -0.2462,  0.3484,  0.3733,  0.2065,  0.3132,  0.0491, -0.5802,
         -0.3354,  0.1395, -0.0767, -0.0395, -0.2644, -0.3644, -0.1218,  0.2167],
        [ 0.1291,  0.0392,  0.4760, -0.3284, -0.3016,  0.2555,  0.3893, -0.0366,
         -0.2803,  0.0893,  0.1483, -0.2456, -0.4138, -0.2186,  0.0454, -0.0684],
        [-0.0565, -0.0568, -0.2339,  0.4316,  0.3391,  0.1195,  0.0578,  0.4410,
         -0.3443,  0.1978, -0.1582, -0.2076, -0.0627, -0.2270, -0.4458,  0.3190]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 6.6035e-02, -1.1737e-02, -1.8027e-02, -3.1119e-03,  1.1569e-01,
         -6.3329e-03, -2.5575e-01, -5.2801e-03,  1.2613e-01, -8.4488e-03,
         -1.4296e-02, -4.1020e-03,  1.1944e-01,  7.8484e-04, -1.2304e-02,
         -4.4126e-03],
        [-1.6760e-02, -1.8029e-02, -1.9887e-02, -9.6708e-03, -1.0628e-02,
         -1.0324e-02, -3.4457e-01, -1.3206e-02, -1.3207e-02, -1.5900e-02,
         -1.6071e-02, -7.9922e-03, -3.1254e-03, -1.6061e-03, -1.4309e-02,
         -9.7501e-03],
        [ 3.2385e-03, -5.7650e-03, -1.1483e-02, -2.4712e-03,  2.1518e-02,
         -2.9970e-03, -1.0682e-01, -3.5604e-03,  1.5607e-02, -4.6419e-03,
         -8.9319e-03, -2.2951e-03,  2.2219e-02, -2.7762e-04, -7.9923e-03,
         -2.6823e-03],
        [-3.0271e-02, -6.1333e-04,  9.7682e-05, -1.4060e-03, -3.9529e-02,
         -6.9534e-04, -5.3876e-03, -1.6061e-03, -5.0755e-02, -1.1183e-03,
         -1.9992e-03, -6.9033e-04, -4.1409e-02, -6.0891e-04, -6.9562e-04,
         -9.8695e-04],
        [ 4.9624e-02,  2.6063e-02,  3.0373e-02,  1.4799e-02,  4.4745e-02,
          1.5056e-02,  4.8648e-01,  1.9931e-02,  5.9312e-02,  2.3370e-02,
          2.4536e-02,  1.1878e-02,  3.6059e-02,  2.8165e-03,  2.1081e-02,
          1.4576e-02],
        [-1.9804e-02, -2.2410e-03, -4.9152e-03, -1.8154e-03, -2.3756e-02,
         -1.4037e-03, -3.6960e-02, -2.2819e-03, -2.9617e-02, -2.3016e-03,
         -3.2939e-03, -1.2181e-03, -2.3649e-02, -5.6844e-04, -2.7908e-03,
         -1.5805e-03],
        [ 3.3514e-03, -6.0294e-03, -5.4639e-03, -2.8352e-03,  1.1023e-02,
         -3.3085e-03, -1.1636e-01, -4.0314e-03,  9.8328e-03, -5.0881e-03,
         -7.3911e-03, -2.5140e-03,  1.3793e-02, -3.1714e-04, -6.5996e-03,
         -3.0397e-03],
        [-5.1444e-02, -9.9953e-03, -7.3542e-03, -7.0846e-03, -7.0066e-02,
         -6.4119e-03, -1.8856e-01, -9.1725e-03, -8.2039e-02, -9.8278e-03,
         -8.2399e-03, -5.1232e-03, -6.6900e-02, -1.7006e-03, -6.5951e-03,
         -6.4936e-03]], device='cuda:0') 

model.module_7.lin_l.bias 8 torch.Size([8])
Parameter containing:
tensor([-0.2785,  0.0753,  0.0623, -0.2958,  0.2298, -0.0029,  0.2180, -0.2470],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-0.0333, -0.0820, -0.0271, -0.0115,  0.1285, -0.0176, -0.0248, -0.0552],
       device='cuda:0') 

model.module_7.lin_r.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[-0.1235, -0.0764,  0.2048, -0.2816,  0.0570, -0.0343,  0.0956, -0.2530,
         -0.1927,  0.0111,  0.0992,  0.0534, -0.2622,  0.5109,  0.1439, -0.3421],
        [-0.1348,  0.3071, -0.0212,  0.3982,  0.0620, -0.1309, -0.2638,  0.2430,
          0.3008, -0.2801, -0.1668, -0.0719, -0.2214, -0.1809, -0.4553, -0.2285],
        [-0.0335, -0.0355, -0.4983,  0.0495,  0.1183,  0.1112, -0.1982,  0.4221,
          0.0454,  0.1787, -0.2623,  0.1244, -0.2318,  0.3263, -0.2620, -0.3489],
        [-0.6534, -0.3569, -0.0799, -0.4272, -0.1209,  0.0394, -0.2376,  0.4163,
          0.0293,  0.5794,  0.5735, -0.5225,  0.3264, -0.0783,  0.1648, -0.3018],
        [ 0.2050,  0.0316,  0.1674, -0.1626, -0.1629, -0.0758,  0.0269, -0.1973,
         -0.2389, -0.3831,  0.7078, -0.0714, -0.1745,  0.1399,  0.0553, -0.4029],
        [-0.6129, -0.2635, -0.0629,  0.1633, -0.1735, -0.4026, -0.2804,  0.0116,
          0.0846, -0.1856,  0.5332,  0.4968,  0.1048,  0.2828,  0.4498,  0.1297],
        [-0.3500, -0.4100, -0.2028,  0.5968,  0.5698,  0.1952, -0.1611, -0.2061,
         -0.1842,  0.2942,  0.1173,  0.4731,  0.2992, -0.0047, -0.2988, -0.2914],
        [-0.0675,  0.1640, -0.2854,  0.2039, -0.5112,  0.1565, -0.7516, -0.0206,
         -0.0479,  0.0788, -0.3788, -0.2086, -0.1554,  0.1320, -0.2769,  0.6398]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 5.3359e-04,  7.3579e-03,  1.2602e-04,  3.8942e-03,  3.9628e-03,
          4.3542e-03,  1.4794e-01,  5.3199e-03, -7.7266e-05,  6.5271e-03,
          2.3279e-03,  3.2777e-03, -5.4469e-04,  5.1522e-04,  2.1689e-03,
          3.9508e-03],
        [-1.5078e-03, -8.1118e-03, -3.8864e-04, -4.3149e-03, -4.7663e-03,
         -4.8575e-03, -1.6439e-01, -5.8703e-03, -3.9925e-04, -7.2104e-03,
         -2.6231e-03, -3.6548e-03,  2.2215e-04, -5.8475e-04, -2.5139e-03,
         -4.3631e-03],
        [-8.9683e-04, -4.7366e-03, -5.2267e-04, -2.5269e-03, -3.2396e-03,
         -2.8091e-03, -9.5538e-02, -3.4439e-03, -6.4751e-04, -4.2135e-03,
         -1.4801e-03, -2.1206e-03, -3.2744e-04, -3.4684e-04, -1.4238e-03,
         -2.5545e-03],
        [ 5.8356e-04,  2.5088e-03,  1.3785e-04,  1.3297e-03,  1.5141e-03,
          1.4392e-03,  4.8584e-02,  1.8004e-03,  1.3835e-04,  2.2165e-03,
          7.9540e-04,  1.1137e-03, -3.3546e-05,  2.0232e-04,  7.7249e-04,
          1.3370e-03],
        [ 2.0305e-03,  7.4588e-03,  9.6764e-04,  3.9739e-03,  5.1143e-03,
          4.3897e-03,  1.4747e-01,  5.3903e-03,  1.0529e-03,  6.6090e-03,
          2.3442e-03,  3.3420e-03,  5.5354e-04,  5.7526e-04,  2.3440e-03,
          4.0065e-03],
        [-3.8137e-05, -1.9622e-05, -1.4603e-04, -1.0754e-05, -3.5749e-05,
         -8.8122e-06, -3.0570e-04, -1.4709e-05, -5.4520e-05, -1.5633e-05,
         -2.3220e-05, -7.7907e-06, -3.1354e-05, -2.7999e-06, -1.3904e-05,
         -1.0913e-05],
        [-1.4077e-03, -9.8232e-03, -8.2256e-04, -5.2116e-03, -5.7329e-03,
         -5.8573e-03, -1.9823e-01, -7.1062e-03, -3.1707e-04, -8.7149e-03,
         -3.2156e-03, -4.3957e-03,  3.3310e-04, -6.9530e-04, -2.9829e-03,
         -5.2780e-03],
        [-8.8380e-12,  6.2003e-11, -4.0770e-11,  3.2568e-11,  3.5269e-11,
          3.1726e-11,  1.0395e-09,  4.3689e-11, -1.1181e-11,  5.5606e-11,
          1.9535e-11,  2.5540e-11, -7.1953e-12,  6.7485e-12, -1.5729e-11,
          3.1085e-11]], device='cuda:0') 

model.module_7.lin_r.bias 8 torch.Size([8])
Parameter containing:
tensor([-0.2811,  0.3269,  0.2448, -0.2917,  0.1579,  0.2313,  0.1584, -0.3756],
       device='cuda:0', requires_grad=True) 
grad:  tensor([ 2.4383e-02, -2.7511e-02, -1.6168e-02,  8.9037e-03,  2.6316e-02,
        -1.9502e-04, -3.3039e-02,  1.7609e-10], device='cuda:0') 

model.module_7.lin_edge.weight 16 torch.Size([8, 2])
Parameter containing:
tensor([[ 3.6918,  2.7246],
        [-3.1030,  2.7099],
        [-2.0483,  3.5418],
        [ 2.6637, -2.5417],
        [ 2.0418, -2.4744],
        [ 0.5796, -3.0063],
        [-4.0606,  0.9359],
        [ 0.3116, -5.6402]], device='cuda:0', requires_grad=True) 
grad:  tensor([[-1.2628e-02,  2.6234e-03],
        [-5.2555e-03, -5.4145e-03],
        [-4.2778e-03, -2.4733e-03],
        [ 3.2140e-03,  2.0334e-03],
        [ 7.9951e-03,  5.7778e-03],
        [ 9.9176e-04,  4.9502e-05],
        [-3.5126e-03, -5.3621e-03],
        [ 2.9278e-03,  8.9438e-05]], device='cuda:0') 

model.module_8.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[ 1.9775e-01,  2.1181e-01, -2.1855e-02,  2.4232e-01,  2.3787e-01,
         -5.7176e-02, -2.5435e-01, -9.4591e-03],
        [ 2.0023e-01,  2.6123e-01, -1.6744e-01,  2.8268e-02,  1.3129e-01,
         -1.0660e-01,  2.0554e-01,  8.1706e-02],
        [ 2.9007e-01,  6.4371e-02,  2.1148e-01, -1.3011e-01,  7.5193e-02,
         -4.6459e-01, -9.1440e-02,  1.7945e-01],
        [ 5.9633e-02,  1.7630e-01,  1.0904e-01, -5.8252e-02, -7.7215e-02,
          1.6548e-01,  3.1279e-02,  1.0687e-01],
        [-1.0154e-01, -2.1899e-01,  2.6739e-01, -1.0668e-01, -2.1537e-02,
          3.5944e-01,  4.4749e-02,  1.8977e-01],
        [ 1.0316e-01, -2.9971e-01,  2.3617e-02,  1.6410e-01,  3.0082e-02,
         -8.9189e-02,  4.0905e-02, -1.8872e-01],
        [ 9.2227e-02,  1.9463e-01,  1.1702e-01,  4.5105e-02,  2.4744e-01,
         -1.9577e-01, -2.0594e-03,  1.8862e-01],
        [ 4.9518e-02,  8.5369e-03, -1.0841e-01, -1.5631e-01,  2.8152e-01,
          2.2933e-01, -1.1812e-01,  8.2653e-02],
        [ 3.1019e-01, -9.7180e-02,  1.8891e-01, -1.5094e-01,  4.4249e-01,
         -2.0048e-03,  2.0246e-01, -1.7881e-01],
        [ 2.9792e-01,  1.6039e-02,  3.2259e-01,  6.3467e-03,  1.6684e-01,
         -2.4712e-01, -3.3678e-01,  3.0654e-01],
        [-1.8103e-01,  4.9808e-02,  9.2604e-02, -1.0499e-01,  4.1933e-01,
         -1.4450e-01, -3.5296e-01, -1.9611e-01],
        [-5.3789e-02,  7.2211e-02, -3.1645e-01, -9.4438e-02, -9.2382e-03,
          2.0605e-01, -2.9193e-01,  6.5054e-02],
        [ 2.1412e-01, -1.1170e-02,  2.6629e-02,  2.6952e-01,  4.1087e-01,
          1.1837e-01, -1.5246e-01,  3.2242e-02],
        [-2.4326e-01, -1.1171e-01, -2.0632e-03,  1.3007e-01,  2.7428e-01,
          1.8667e-01, -2.6802e-01,  3.7926e-02],
        [-6.3662e-02, -4.0647e-01,  1.8769e-01,  2.1691e-01, -3.0627e-02,
         -4.4871e-01,  3.9767e-02,  2.1931e-01],
        [-7.4768e-03,  1.8508e-01, -3.5745e-01,  8.7684e-02,  1.5347e-01,
         -2.2313e-02, -1.6503e-01,  1.9948e-01],
        [ 1.5128e-01, -1.7805e-01,  5.7202e-02,  1.3806e-01,  1.7397e-01,
         -2.5220e-01,  7.1611e-02, -7.0689e-02],
        [ 1.2978e-01,  1.8591e-02, -2.4060e-01, -2.7280e-01, -1.0026e-01,
         -4.0393e-02,  3.2872e-02, -7.4531e-02],
        [-3.0435e-01, -2.4024e-01, -1.2250e-01, -2.9228e-02,  4.6664e-01,
          1.9023e-02,  3.6341e-02, -2.3854e-01],
        [-3.9250e-02,  3.4888e-01, -1.4849e-01, -3.0592e-02, -2.6222e-01,
          7.0580e-02, -3.2891e-03,  2.1110e-01],
        [-9.3081e-02, -2.4267e-01, -4.7486e-03,  5.3658e-02, -2.2604e-02,
         -1.0710e-01, -2.0363e-02,  5.5359e-02],
        [ 3.2197e-01,  2.5025e-01, -1.1595e-01,  5.4852e-02,  2.5320e-01,
          2.0348e-01,  1.0679e-01,  4.2907e-01],
        [-1.1529e-01, -1.0561e-01,  2.5391e-01,  9.6965e-02, -2.6583e-01,
          1.6893e-01,  2.8014e-01,  4.2415e-01],
        [ 1.2010e-01, -3.0149e-02, -7.4439e-02, -2.7925e-01, -2.0866e-01,
          2.0121e-01, -6.1435e-03,  8.5399e-02],
        [-1.8186e-01, -3.6663e-03, -1.9960e-02,  1.5835e-01,  3.5339e-01,
         -1.2535e-01, -3.3465e-01, -2.7927e-01],
        [ 4.8256e-02,  3.1147e-02,  1.2990e-01, -9.5043e-02,  1.3103e-01,
          3.4382e-02, -2.0394e-02,  1.5311e-01],
        [-5.0730e-02,  6.8922e-02, -4.5470e-02, -9.0543e-02, -1.1370e-01,
         -1.8902e-01, -6.4271e-02,  3.4175e-02],
        [-1.5841e-01,  2.8729e-02,  1.9412e-01,  1.5312e-01,  7.1507e-03,
         -2.7788e-04, -1.7155e-01,  4.2447e-01],
        [ 3.9825e-01,  1.4520e-01, -2.2633e-01,  1.7934e-01,  1.4045e-01,
         -2.4481e-01,  5.4232e-02, -5.0589e-02],
        [-1.7988e-01,  1.4409e-01, -8.0979e-02, -2.2854e-02, -2.2209e-01,
         -5.8599e-02,  2.0470e-02, -4.0649e-02],
        [-1.8276e-01,  1.9372e-01, -2.8947e-02,  9.0515e-03,  4.9327e-01,
         -1.9325e-01,  2.1123e-01, -1.6110e-01],
        [ 1.0273e-01,  4.9902e-02,  1.7021e-01,  8.0470e-02,  1.1236e-01,
         -7.8678e-02, -1.8648e-01,  2.6081e-01],
        [ 2.3824e-01,  1.6993e-01, -2.2117e-01, -3.8173e-02, -9.7529e-02,
          3.3282e-01, -1.6496e-01, -8.5782e-02],
        [-9.7211e-02, -3.3436e-01, -1.9898e-01,  2.4924e-01,  1.3679e-01,
          1.1481e-01, -6.3924e-02,  1.6193e-01],
        [ 2.2916e-01,  4.9370e-02, -1.8349e-01,  1.3742e-01,  1.0850e-01,
         -2.0612e-01,  2.0017e-02,  2.4588e-01],
        [-2.1598e-01, -7.6264e-02, -2.8788e-01,  3.1810e-01,  2.6600e-02,
          2.1965e-01, -1.8297e-01,  3.4277e-01],
        [ 1.8227e-01,  3.3583e-01, -2.0463e-01,  3.3902e-01, -1.8093e-01,
         -2.2672e-01,  1.8999e-02,  3.0242e-01],
        [ 8.3869e-02, -6.1325e-03, -1.3571e-01,  6.4916e-02,  1.3521e-01,
          2.6815e-01,  4.0411e-02,  2.8717e-01],
        [ 4.1363e-01,  6.7584e-02,  2.0079e-01,  2.1569e-01,  1.7039e-01,
         -1.0836e-01,  1.7365e-01,  1.5896e-02],
        [ 7.4773e-02,  8.9730e-02, -1.1601e-01, -1.0491e-02, -1.1000e-02,
         -1.9320e-01, -9.1977e-03,  1.3574e-01],
        [-1.1824e-01,  8.9863e-02,  1.4088e-01, -2.6375e-02, -1.4425e-01,
          1.1849e-01, -2.1743e-02,  2.8028e-01],
        [-1.5242e-01,  6.5213e-02, -1.6995e-01,  1.5860e-01, -3.4863e-01,
          1.8717e-02,  1.6628e-01,  2.4375e-01],
        [-1.6790e-02,  8.2790e-02,  6.6219e-02, -3.4818e-01,  5.1617e-02,
         -2.4743e-01, -1.0346e-01, -1.3875e-01],
        [-2.3437e-02,  7.1932e-02, -2.7826e-01,  5.8797e-02, -1.2599e-01,
         -3.3913e-01, -7.8439e-02, -3.0946e-02],
        [-8.2049e-02,  3.5455e-01, -1.1814e-01, -1.4319e-01,  8.5651e-02,
         -1.9449e-01, -1.1624e-02,  2.4731e-01],
        [-3.7087e-02, -1.7966e-01,  1.2003e-01,  5.1170e-02,  3.0130e-01,
         -6.6118e-02, -1.3340e-01, -1.5793e-01],
        [-2.3704e-01, -2.0829e-01, -3.5237e-01,  3.0182e-01,  9.1852e-02,
         -2.3269e-02, -1.0256e-01,  1.8519e-01],
        [ 3.4994e-01,  7.3979e-02, -2.5747e-01,  4.4526e-02, -1.0657e-01,
         -1.9059e-02, -6.5560e-03, -7.6554e-02],
        [-1.4483e-01, -4.2058e-01,  1.0965e-02, -9.2884e-02,  4.3394e-01,
         -1.8697e-01,  2.2655e-01,  1.7487e-01],
        [-2.4506e-01, -1.9120e-01, -1.5900e-01,  3.0677e-02, -1.3471e-01,
          5.9262e-02,  1.1292e-02,  2.9212e-01],
        [-1.8055e-01,  1.5469e-01,  1.0574e-01, -1.7380e-01,  7.6790e-02,
          1.2606e-01, -2.3397e-01, -4.8477e-02],
        [-9.2069e-02,  1.6892e-01,  7.9442e-02, -1.6695e-01,  2.0261e-01,
         -1.8268e-01,  2.3141e-01,  1.3356e-01],
        [ 2.0154e-01,  8.1012e-02, -4.1491e-01, -1.4117e-01,  1.1975e-01,
         -2.2185e-01,  1.3998e-01, -2.5180e-01],
        [ 2.7501e-01,  3.4197e-01, -2.7118e-01,  2.5818e-01,  8.2765e-02,
          1.1343e-01, -5.0988e-02,  1.8294e-01],
        [-1.0620e-01, -3.1496e-01,  1.9071e-01, -1.9524e-01,  6.5905e-01,
          5.2956e-02,  1.4343e-01, -1.3223e-01],
        [ 1.3202e-01,  7.6060e-02,  3.3736e-02, -1.1166e-01, -1.5518e-01,
         -2.1005e-01,  1.1724e-01, -4.2795e-03],
        [ 2.7274e-01, -7.7087e-02,  2.3468e-01,  1.8099e-01,  1.8415e-01,
         -3.4190e-01, -4.4468e-02,  3.1311e-02],
        [-2.5602e-01,  3.2705e-02,  1.4360e-01, -1.5585e-01,  1.8050e-01,
          5.9051e-02, -8.2165e-02, -2.7837e-01],
        [ 3.0019e-01,  2.4907e-01, -2.9956e-01, -2.9512e-01, -2.3620e-01,
          3.3318e-01,  3.1972e-01,  1.5643e-01],
        [-1.3974e-02, -9.9900e-02,  2.4010e-01,  4.2072e-03,  1.2475e-01,
          1.7358e-03,  8.8789e-02,  2.8585e-01],
        [-1.4158e-01,  2.2316e-01, -1.4120e-01, -2.2771e-01, -4.1884e-02,
          8.2529e-02, -4.8656e-02, -3.0921e-01],
        [ 1.9370e-01,  2.0725e-01,  1.5293e-01,  1.7863e-01,  2.0620e-02,
         -2.4129e-01,  5.0833e-02, -1.3944e-01],
        [ 1.2354e-01,  1.5328e-01, -2.6565e-01, -2.9525e-02,  2.7762e-02,
          4.1553e-02,  3.6538e-02,  1.8043e-02],
        [ 1.0530e-01, -2.5076e-01,  2.1426e-01,  2.2820e-01,  4.2962e-01,
          1.9545e-01, -1.5226e-01, -1.6694e-01],
        [ 5.9090e-02,  1.2784e-01, -3.1142e-01, -1.3108e-02, -2.1195e-01,
         -1.1346e-01,  1.5724e-01,  3.2462e-01],
        [-3.0843e-02, -1.9225e-01,  1.6231e-02,  1.4610e-01, -1.0274e-01,
          7.1579e-03, -3.5256e-02,  1.8611e-01],
        [-7.8258e-02,  9.6892e-02, -8.4827e-02, -5.3993e-02, -7.4223e-03,
          2.2912e-01,  1.1944e-01,  3.3509e-01],
        [-7.4070e-02, -3.1024e-01,  1.5704e-02, -2.5408e-01,  2.4818e-01,
          2.5568e-02,  4.7363e-02, -1.3583e-01],
        [ 7.4144e-02, -1.4542e-01, -1.5498e-01, -5.9018e-02,  1.5204e-02,
          1.6994e-01, -6.4535e-02,  1.8993e-01],
        [-1.2040e-01, -2.8969e-01,  1.7697e-01, -9.0713e-03, -4.9831e-02,
          5.4868e-02, -2.3931e-02, -1.5546e-02],
        [-1.6134e-01,  1.2831e-01, -1.1702e-01,  1.7358e-01,  2.5659e-01,
         -2.8407e-01, -4.2343e-01,  1.1418e-01],
        [-2.2754e-02,  5.4235e-02, -7.1755e-02, -6.0660e-02,  4.9225e-01,
          1.7573e-01,  2.5185e-01, -6.9426e-03],
        [ 1.3838e-02,  6.7593e-02, -6.5747e-02,  1.4342e-01,  1.1320e-01,
         -1.2007e-01,  4.0657e-01,  1.8425e-01],
        [-3.5399e-01, -2.4919e-01, -9.3079e-02, -1.1946e-01,  2.6574e-02,
         -4.5204e-02,  1.4233e-01, -1.7850e-01],
        [-3.5505e-01, -2.5710e-01,  2.6394e-02, -2.0016e-01,  3.5792e-01,
          8.6440e-02,  1.1763e-01, -1.7785e-01],
        [-1.4917e-01,  1.1045e-01,  7.4179e-02, -3.5566e-01,  1.4483e-01,
         -8.4226e-02, -3.7886e-01, -5.1420e-02],
        [-1.2995e-01, -1.0534e-02, -1.6623e-01,  7.2417e-02,  2.4508e-01,
         -3.3751e-03, -1.8847e-01, -2.2474e-02],
        [-2.5592e-01, -5.2720e-02,  8.2948e-02, -5.7655e-02,  5.3854e-01,
         -3.2393e-01, -2.1566e-01, -2.3175e-01],
        [-2.6567e-01, -1.1024e-01, -1.4501e-01, -1.4145e-01,  7.5455e-02,
         -1.8585e-01,  9.5490e-02, -1.1353e-01],
        [-2.0451e-01, -3.9996e-01,  8.7090e-02,  2.3975e-01, -9.2579e-02,
         -1.0901e-01,  2.5318e-01, -6.0464e-02],
        [ 9.4747e-02,  2.0334e-01, -1.3192e-01,  9.0531e-02,  1.9876e-01,
          1.7944e-02, -3.6653e-03,  5.4495e-02],
        [-2.0726e-01, -1.6317e-01, -4.4267e-01,  1.0401e-01,  2.4343e-01,
         -6.4689e-02,  1.4955e-02, -6.7400e-02],
        [-1.9914e-01, -3.3013e-01, -6.0969e-02, -2.3223e-01,  1.9681e-01,
         -1.4250e-01,  8.3178e-02, -3.3445e-01],
        [ 1.9042e-01, -2.7473e-01,  1.8851e-01,  1.0085e-01,  7.3219e-02,
         -5.3045e-02,  3.7700e-01,  3.5615e-01],
        [ 1.2042e-01,  1.2421e-01, -3.6003e-02,  1.2293e-01,  4.4370e-01,
          1.6368e-01, -9.9759e-02, -1.0645e-01],
        [-3.1174e-01, -1.2756e-01, -7.4681e-02, -2.3711e-01,  4.7819e-01,
          2.5242e-02, -2.3735e-01, -3.6669e-01],
        [-3.5980e-02,  3.5241e-01, -2.3217e-01, -2.9262e-01, -4.6691e-01,
         -1.6778e-01,  1.6636e-01,  2.3911e-01],
        [ 6.6319e-02, -2.0843e-01,  2.4881e-01, -2.7859e-01, -6.3295e-02,
          1.9942e-01,  3.2197e-01, -6.0732e-02],
        [-1.3148e-01, -8.9974e-02, -2.5164e-01,  1.3195e-01, -3.2936e-02,
          3.2087e-02,  6.0600e-02,  1.2591e-01],
        [-1.1841e-02, -2.0014e-01,  4.4741e-02,  1.4157e-01, -2.7128e-02,
         -2.4019e-01, -3.7455e-02,  1.9731e-01],
        [-1.1996e-01, -1.5359e-01, -2.9717e-01,  1.5495e-01, -1.1688e-01,
          2.9495e-02,  7.4799e-02, -4.9261e-03],
        [ 2.9969e-02,  3.4976e-01, -2.0075e-01, -1.0801e-01,  7.8798e-02,
         -1.2435e-01, -1.6886e-01,  1.3814e-01],
        [-1.7589e-01, -1.2050e-01, -2.6640e-01,  1.3797e-01,  2.2197e-01,
         -1.3689e-01, -2.0731e-01, -1.2443e-01],
        [-2.5659e-01,  6.9728e-02,  1.6700e-01,  1.0882e-01, -1.4423e-01,
         -1.4509e-02,  3.0169e-01,  6.8175e-02],
        [ 1.5157e-01, -1.2451e-01,  1.7839e-01,  1.3086e-01,  3.3922e-01,
         -1.6424e-01,  2.6900e-01,  2.8261e-01],
        [-4.1723e-01, -1.6192e-01, -3.4243e-01, -6.7421e-02, -2.4672e-01,
         -8.4499e-02, -1.1540e-01,  2.8281e-01],
        [-1.1220e-01, -2.0521e-01,  7.9931e-02, -1.9695e-01,  4.3035e-01,
         -1.3775e-01,  1.9665e-01, -1.6538e-01],
        [ 1.6309e-01,  8.6559e-03,  8.2143e-02, -2.3035e-01,  1.7433e-01,
          1.3129e-01, -2.9369e-01,  2.3209e-01],
        [-1.1632e-01,  1.7739e-01, -2.6040e-01, -6.5521e-02, -1.4454e-01,
         -1.2550e-01,  8.3321e-02,  1.1375e-01],
        [ 3.9474e-01, -3.8488e-01,  1.7376e-01,  1.3080e-01,  3.7445e-01,
         -1.3427e-01, -5.7380e-02, -1.7110e-01]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[-8.0921e-04,  1.5777e-03,  8.1699e-04,  1.2977e-03, -4.0347e-05,
          4.8642e-05,  1.1501e-03,  4.2001e-04],
        [ 8.1693e-03, -1.2974e-02, -8.2226e-03, -1.0387e-02, -2.5568e-03,
         -8.4938e-04, -1.2240e-02, -5.2852e-04],
        [-9.7721e-04,  9.0429e-04,  1.2927e-04,  2.5396e-04,  9.7312e-04,
          2.2552e-04,  1.2489e-03,  4.7822e-04],
        [ 3.4364e-04, -8.4530e-04, -1.8425e-04, -8.2871e-04,  2.3070e-04,
          1.2536e-04, -2.9283e-04, -6.7445e-04],
        [-1.1993e-04,  1.7715e-04,  1.1148e-04,  1.2976e-04,  5.2083e-05,
          2.0086e-05,  1.8376e-04,  1.8857e-06],
        [ 8.7568e-03, -8.8732e-03, -3.8766e-04, -9.7887e-04, -9.2590e-03,
         -2.2799e-03, -1.0448e-02, -6.9413e-03],
        [ 8.2107e-03, -1.3414e-02, -8.2001e-03, -1.1017e-02, -2.1879e-03,
         -6.6181e-04, -1.2100e-02, -1.1711e-03],
        [-7.7811e-06,  1.8269e-05,  3.8580e-05,  3.1688e-05, -1.1360e-05,
          1.1869e-06,  2.5103e-05, -3.9749e-05],
        [-9.0241e-05,  2.2322e-04,  1.9686e-04,  2.4633e-04, -4.6139e-05,
         -5.3370e-06,  1.7463e-04, -4.9121e-05],
        [-5.6777e-03,  4.9472e-03, -2.8520e-04,  9.6620e-05,  6.3164e-03,
          1.4273e-03,  6.6135e-03,  4.1492e-03],
        [ 2.0725e-04, -4.5634e-04, -8.6772e-05, -1.9867e-04, -1.6238e-04,
         -5.2139e-05, -2.8898e-04, -3.9796e-04],
        [ 1.1288e-02, -1.0660e-02, -3.0482e-03, -1.7810e-03, -1.1003e-02,
         -3.0740e-03, -1.4552e-02, -3.7837e-03],
        [ 1.1609e-05, -1.2896e-05,  1.2375e-06, -1.5333e-06, -1.1034e-05,
         -2.8897e-06, -1.2628e-05, -1.3119e-05],
        [-2.5888e-04,  3.1489e-04,  8.0560e-05,  1.1040e-04,  2.2201e-04,
          5.7549e-05,  3.2995e-04,  1.7032e-04],
        [-3.1459e-03,  2.9497e-03,  2.0291e-04,  3.1074e-04,  3.3229e-03,
          8.3067e-04,  3.8462e-03,  2.0000e-03],
        [ 3.4067e-06,  5.5436e-05,  1.5555e-04,  1.4891e-04, -1.0100e-04,
         -1.1560e-05,  5.9998e-05, -1.7112e-04],
        [-3.2816e-04,  4.9036e-04,  2.7914e-04,  3.3762e-04,  1.5808e-04,
          4.8913e-05,  4.8242e-04,  5.9632e-05],
        [ 9.7454e-03, -1.0380e-02, -4.3690e-03, -3.4970e-03, -8.4451e-03,
         -2.7557e-03, -1.3591e-02, -2.0443e-03],
        [-1.1679e-02,  1.8109e-02,  1.6934e-02,  1.7489e-02,  1.3934e-03,
          1.5605e-03,  2.0230e-02, -8.3541e-03],
        [ 2.4853e-03, -3.9758e-03, -2.0701e-03, -3.1953e-03, -8.7195e-04,
         -8.7493e-05, -3.3592e-03, -9.6891e-04],
        [ 2.5463e-03, -2.7243e-03, -7.5344e-05, -3.1217e-04, -2.7206e-03,
         -6.6690e-04, -3.0256e-03, -2.3016e-03],
        [ 6.4952e-04, -1.3572e-03, -7.0031e-04, -1.3751e-03,  1.5690e-04,
          1.1544e-04, -8.3045e-04, -4.3350e-04],
        [ 1.0564e-02, -1.6926e-02, -1.0413e-02, -1.3595e-02, -3.2068e-03,
         -9.7107e-04, -1.5604e-02, -1.2587e-03],
        [ 6.8433e-03, -6.5883e-03, -3.2801e-03, -1.9338e-03, -6.0945e-03,
         -2.1583e-03, -9.8386e-03, -5.2224e-05],
        [-1.4806e-03,  1.0736e-03,  3.0911e-03,  1.8463e-03,  9.8115e-05,
          4.8721e-04,  3.2220e-03, -4.3865e-03],
        [-1.5971e-04,  1.8959e-04, -1.2367e-05,  2.8796e-05,  1.6629e-04,
          3.2834e-05,  1.7188e-04,  2.0019e-04],
        [ 1.2830e-03, -8.5550e-04,  3.4632e-05,  5.1072e-05, -1.4744e-03,
         -3.2450e-04, -1.5845e-03, -4.7812e-04],
        [ 1.0571e-02, -1.6491e-02, -1.0834e-02, -1.2989e-02, -3.6459e-03,
         -1.3272e-03, -1.6144e-02,  4.0679e-05],
        [ 1.2418e-03, -1.0072e-03, -1.8771e-05,  3.6757e-05, -1.3841e-03,
         -3.2938e-04, -1.4772e-03, -6.8961e-04],
        [ 3.2631e-03, -5.0673e-03, -3.1866e-03, -3.9220e-03, -1.1934e-03,
         -4.0366e-04, -4.9046e-03, -2.1508e-04],
        [ 1.4670e-03, -4.2966e-05,  9.4578e-03,  6.0788e-03, -6.0344e-03,
          1.2037e-04,  3.1435e-03, -1.4639e-02],
        [-5.4602e-06,  6.3552e-05,  1.0628e-04,  1.2969e-04, -7.6145e-05,
         -1.8314e-05,  3.9363e-05, -8.3824e-05],
        [ 2.1951e-03, -2.7512e-03, -6.1704e-03, -4.0611e-03,  5.7662e-04,
         -9.6074e-04, -5.7756e-03,  7.4684e-03],
        [ 7.7838e-03, -8.5486e-03,  1.6439e-03,  2.8847e-04, -9.1916e-03,
         -1.9823e-03, -8.1858e-03, -1.0471e-02],
        [ 1.3513e-03, -1.1467e-03, -1.4717e-04, -1.5355e-04, -1.4054e-03,
         -3.3080e-04, -1.6786e-03, -5.9610e-04],
        [-4.5485e-04,  5.9524e-04,  2.3228e-04,  3.0523e-04,  3.2077e-04,
          8.4136e-05,  6.0875e-04,  2.1337e-04],
        [ 3.0951e-03, -4.7218e-03, -2.9873e-03, -3.5667e-03, -1.2241e-03,
         -4.2111e-04, -4.6684e-03, -1.3873e-04],
        [-1.2962e-04,  1.5720e-04,  3.3795e-05,  4.9974e-05,  1.1179e-04,
          3.0919e-05,  1.6412e-04,  9.3421e-05],
        [-4.4534e-03,  8.3450e-03,  7.4182e-03,  8.2679e-03, -2.9353e-04,
          3.4668e-04,  7.9656e-03, -2.6800e-03],
        [ 8.5591e-05, -4.4979e-05,  3.4032e-05,  1.0096e-05, -1.1427e-04,
         -2.0550e-05, -1.0019e-04, -6.2547e-05],
        [ 1.2676e-03, -2.3791e-03, -9.3693e-04, -2.0238e-03,  5.5498e-06,
          6.4111e-05, -1.5657e-03, -1.0941e-03],
        [ 6.2392e-03, -9.7472e-03, -6.2174e-03, -7.5772e-03, -2.1430e-03,
         -7.7507e-04, -9.4365e-03, -2.5025e-04],
        [ 1.7825e-02, -1.7795e-02, -3.6355e-04, -1.2660e-03, -1.9180e-02,
         -4.6446e-03, -2.0942e-02, -1.4532e-02],
        [ 2.0117e-03, -1.7294e-03,  5.0846e-05,  6.5845e-06, -2.2681e-03,
         -5.5975e-04, -2.4143e-03, -1.3527e-03],
        [ 5.5384e-03, -9.0249e-03, -5.5089e-03, -7.2785e-03, -1.4315e-03,
         -5.1432e-04, -8.2113e-03, -7.1704e-04],
        [ 6.1047e-03, -7.5537e-03,  1.3705e-03,  1.7283e-04, -7.3126e-03,
         -1.6648e-03, -6.3897e-03, -9.6236e-03],
        [ 1.2398e-03, -1.4072e-03, -4.9460e-05, -7.7339e-05, -1.3349e-03,
         -3.7097e-04, -1.4363e-03, -1.2471e-03],
        [ 9.4134e-04, -7.2422e-04,  1.4602e-04,  1.5094e-04, -1.1579e-03,
         -2.8305e-04, -1.0939e-03, -7.0998e-04],
        [-9.2848e-03,  1.4115e-02,  1.2277e-02,  1.3096e-02,  1.6828e-03,
          1.1349e-03,  1.5409e-02, -5.0941e-03],
        [ 5.2638e-05, -3.6952e-05,  7.0049e-05,  5.0016e-05, -9.4147e-05,
         -1.2995e-05, -2.8277e-05, -1.3635e-04],
        [ 5.7958e-04, -6.9004e-04, -2.9180e-04, -3.0739e-04, -4.5143e-04,
         -1.3605e-04, -7.9981e-04, -1.7712e-04],
        [-8.6055e-06,  5.8825e-04,  1.6300e-03,  1.1581e-03, -7.5851e-04,
         -3.3686e-05,  7.0055e-04, -1.7613e-03],
        [ 1.1625e-03, -1.4292e-03,  1.4873e-04,  4.8730e-05, -1.3843e-03,
         -3.7136e-04, -1.2947e-03, -1.6510e-03],
        [ 1.1407e-05, -1.7671e-05,  3.2176e-06, -1.5283e-06, -5.8290e-06,
         -4.0340e-06, -1.1984e-05, -2.1131e-05],
        [-1.6395e-02,  2.5341e-02,  2.0050e-02,  2.2109e-02,  3.8433e-03,
          2.0832e-03,  2.6555e-02, -5.7679e-03],
        [-6.9430e-04,  1.1485e-04, -4.6163e-03, -3.0947e-03,  3.0418e-03,
          1.3628e-05, -1.5052e-03,  7.2972e-03],
        [-7.8195e-04,  7.5196e-04,  2.1736e-04,  2.1425e-04,  7.1947e-04,
          1.7824e-04,  1.0124e-03,  2.5313e-04],
        [-5.2847e-03,  1.0054e-02,  1.2713e-02,  1.2790e-02, -2.5072e-03,
          2.7725e-04,  1.1208e-02, -9.3377e-03],
        [ 1.9614e-04, -2.4320e-04, -1.1085e-04, -1.1403e-04, -1.4638e-04,
         -4.2623e-05, -2.7124e-04, -5.6545e-05],
        [ 1.0077e-02, -1.5671e-02, -1.0101e-02, -1.2316e-02, -3.5834e-03,
         -1.1758e-03, -1.5192e-02, -2.9648e-04],
        [ 1.0573e-04, -1.5909e-04, -2.3349e-04, -1.7032e-04, -5.6966e-06,
         -3.7432e-05, -2.4184e-04,  2.1491e-04],
        [-5.2852e-03,  7.7720e-03,  4.7305e-03,  5.3225e-03,  2.5472e-03,
          9.1619e-04,  7.9946e-03,  3.7648e-04],
        [-1.7082e-04,  2.4312e-04,  1.0223e-04,  1.4602e-04,  1.0002e-04,
          2.3905e-05,  2.2844e-04,  8.4020e-05],
        [-9.7079e-03,  1.7481e-02,  1.5763e-02,  1.7751e-02, -6.3705e-04,
          6.7633e-04,  1.7027e-02, -6.1488e-03],
        [ 2.0766e-04, -2.2582e-04, -8.3598e-06, -3.8240e-05, -2.1233e-04,
         -4.7524e-05, -2.4055e-04, -1.9019e-04],
        [-4.2292e-04,  3.3694e-04,  7.1754e-06, -2.3298e-05,  4.5946e-04,
          1.0727e-04,  4.9626e-04,  2.1514e-04],
        [ 6.1914e-03, -9.8723e-03, -5.9923e-03, -7.8551e-03, -1.8673e-03,
         -6.0174e-04, -9.1273e-03, -8.1162e-04],
        [ 2.7880e-06, -1.2733e-04, -5.2041e-05, -8.4701e-05,  1.6224e-05,
         -8.1916e-06, -4.3937e-05, -1.0224e-04],
        [ 1.1155e-02, -1.1354e-02, -3.2153e-03, -2.3959e-03, -1.0703e-02,
         -3.2115e-03, -1.4729e-02, -4.5162e-03],
        [-2.0762e-04,  2.1687e-04,  1.8131e-05,  3.5636e-05,  2.0103e-04,
          4.3967e-05,  2.4006e-04,  1.5839e-04],
        [-1.7703e-04,  3.0640e-04,  2.4405e-04,  2.8164e-04,  2.0419e-05,
          1.5403e-05,  2.9266e-04, -5.7554e-05],
        [-1.8546e-03,  4.5119e-03,  9.9042e-03,  7.7773e-03, -3.2369e-03,
          6.8757e-04,  7.0834e-03, -1.0827e-02],
        [ 8.3262e-03, -1.3446e-02, -7.9766e-03, -1.0773e-02, -2.4182e-03,
         -7.0602e-04, -1.2127e-02, -1.4846e-03],
        [-1.3340e-02,  2.3842e-02,  2.5876e-02,  2.7483e-02, -3.0912e-03,
          7.7073e-04,  2.5470e-02, -1.5690e-02],
        [-1.5211e-02,  2.2743e-02,  1.9512e-02,  2.0616e-02,  3.4455e-03,
          2.0028e-03,  2.5107e-02, -7.8890e-03],
        [ 1.0761e-02, -1.0898e-02, -2.1543e-03, -1.7504e-03, -1.0706e-02,
         -2.9239e-03, -1.3558e-02, -5.8719e-03],
        [-2.6004e-04,  2.9721e-04,  1.3914e-05,  5.1059e-05,  2.6181e-04,
          6.1372e-05,  3.0277e-04,  2.5228e-04],
        [-1.1825e-02,  1.8687e-02,  1.4543e-02,  1.6604e-02,  2.3812e-03,
          1.3236e-03,  1.8992e-02, -3.6789e-03],
        [-1.8478e-02,  3.0517e-02,  2.7434e-02,  3.0262e-02,  8.9017e-04,
          1.6402e-03,  3.1748e-02, -1.1637e-02],
        [-1.6670e-02,  2.0908e-02,  1.2157e-02,  9.8920e-03,  1.1796e-02,
          4.7713e-03,  2.4885e-02,  6.9881e-04],
        [ 2.1127e-03, -3.6015e-03, -1.8177e-03, -3.0158e-03, -4.3532e-04,
         -1.0565e-05, -2.8319e-03, -9.8529e-04],
        [ 4.9181e-03, -6.7138e-03,  1.9193e-03,  3.1956e-04, -6.1999e-03,
         -1.2761e-03, -4.6291e-03, -1.0051e-02],
        [ 5.0934e-03, -6.8694e-03,  1.0601e-03, -2.6587e-04, -5.9976e-03,
         -1.3454e-03, -5.3494e-03, -8.7380e-03],
        [ 2.6662e-03, -4.5100e-03, -2.3262e-03, -3.7475e-03, -5.7746e-04,
         -5.7837e-05, -3.6267e-03, -1.1392e-03],
        [-4.2944e-03,  7.5258e-03,  9.8170e-03,  8.7822e-03, -9.7578e-04,
          8.2906e-04,  9.4110e-03, -7.6750e-03],
        [ 1.9373e-03, -3.5821e-03,  2.2601e-03,  3.6756e-04, -3.0228e-03,
         -3.5145e-04, -1.1204e-03, -7.7638e-03],
        [ 3.0812e-04, -3.7772e-04, -1.2671e-04, -1.6947e-04, -2.3672e-04,
         -6.2798e-05, -4.0485e-04, -1.5458e-04],
        [ 8.3095e-04, -1.4729e-03,  5.7760e-05, -4.0108e-04, -8.3707e-04,
         -1.4545e-04, -8.9671e-04, -1.7592e-03],
        [-3.5865e-04,  4.3570e-04,  1.3403e-04,  1.7253e-04,  2.9611e-04,
          7.6934e-05,  4.6543e-04,  2.0010e-04],
        [ 4.6563e-03, -4.3627e-03, -1.6274e-04, -2.1878e-04, -5.0493e-03,
         -1.2765e-03, -5.5846e-03, -3.2557e-03],
        [-2.3577e-04,  3.0089e-04,  1.0951e-04,  1.3922e-04,  1.7659e-04,
          4.7960e-05,  3.1388e-04,  1.1621e-04],
        [-1.1197e-04,  1.0725e-04, -9.0837e-06, -3.5651e-06,  1.3047e-04,
          3.0961e-05,  1.2795e-04,  1.0415e-04],
        [ 1.0339e-02, -1.0966e-02,  8.1497e-05, -9.3791e-04, -1.1145e-02,
         -2.6158e-03, -1.1922e-02, -9.8789e-03],
        [ 5.1092e-03, -7.5915e-03, -1.7242e-03, -4.7273e-03, -2.6666e-03,
         -1.2014e-04, -5.6573e-03, -5.1181e-03],
        [ 1.3697e-03, -1.7352e-03, -6.5632e-04, -9.3231e-04, -9.5990e-04,
         -2.4781e-04, -1.8152e-03, -6.2692e-04],
        [ 7.4247e-03, -7.5376e-03,  1.5612e-03,  5.5454e-04, -8.8624e-03,
         -1.9207e-03, -7.8920e-03, -9.0515e-03],
        [-1.6743e-02,  2.5714e-02,  1.8842e-02,  2.1821e-02,  4.5048e-03,
          1.9233e-03,  2.6156e-02, -3.4807e-03],
        [ 1.5124e-02, -1.5470e-02, -5.2156e-03, -3.4693e-03, -1.4248e-02,
         -4.4401e-03, -2.0382e-02, -4.8752e-03],
        [ 2.0495e-04, -2.7988e-04, -1.0847e-04, -1.4754e-04, -1.3425e-04,
         -3.5373e-05, -2.7276e-04, -1.0578e-04],
        [ 9.8144e-03, -1.0165e-02, -1.7836e-03, -1.9869e-03, -9.7052e-03,
         -2.6157e-03, -1.2370e-02, -5.8964e-03]], device='cuda:0') 

model.module_8.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.0557, -0.2087, -0.1435, -0.2940, -0.4156, -0.0564, -0.3691,  0.0956,
        -0.2673, -0.1499, -0.0643,  0.3153, -0.2553, -0.1183, -0.2387, -0.2302,
        -0.2568,  0.2776,  0.0747, -0.0454, -0.1065, -0.0374, -0.4462,  0.1572,
        -0.0554, -0.2759, -0.1811, -0.2549, -0.1346, -0.2586,  0.0607, -0.3913,
         0.1191,  0.1761,  0.1167, -0.4296, -0.4930, -0.2150,  0.2329,  0.0351,
        -0.2778, -0.3912,  0.0706, -0.2344, -0.2457, -0.1197,  0.2161, -0.4292,
         0.2512, -0.1866, -0.2075,  0.0051, -0.1375, -0.5867,  0.0351, -0.0328,
        -0.4435,  0.2147, -0.0947, -0.1392, -0.2873,  0.0571, -0.2229,  0.3297,
        -0.1466, -0.4312, -0.2453, -0.2280,  0.3013, -0.3534, -0.3135,  0.1484,
        -0.0668,  0.1585, -0.0113,  0.2468, -0.2835,  0.0619,  0.1831, -0.0656,
        -0.1825,  0.2086, -0.2135, -0.2358,  0.0430, -0.0093, -0.2603, -0.2221,
        -0.2170, -0.1087, -0.2619, -0.2639,  0.2277, -0.2178, -0.0321,  0.3221,
        -0.0645,  0.3502, -0.2392,  0.1937], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 7.5419e-05, -4.8223e-03, -4.9452e-04,  6.7367e-04,  6.6248e-05,
         6.9534e-03, -4.0650e-03,  6.2532e-05,  1.9941e-04, -4.7881e-03,
         2.2663e-04,  3.1439e-03,  1.4905e-05, -1.1303e-04, -2.0580e-03,
         2.6385e-04,  1.3837e-04,  2.2632e-04,  1.7722e-02, -4.7786e-04,
         2.2491e-03,  1.4388e-05, -5.5350e-03, -8.7773e-04,  5.1117e-03,
        -1.9321e-04,  6.9722e-04, -7.1487e-03,  8.3640e-04, -1.8709e-03,
         1.9364e-02,  1.5725e-04, -9.9726e-03,  1.0812e-02,  6.6831e-04,
        -5.9199e-05, -1.8151e-03, -7.3536e-05,  7.6881e-03,  1.0715e-04,
         6.9760e-04, -3.7826e-03,  1.4812e-02,  1.6059e-03, -2.7279e-03,
         9.4031e-03,  1.2496e-03,  9.3152e-04,  1.2050e-02,  1.7248e-04,
         1.1951e-05,  3.0541e-03,  1.6222e-03,  2.7919e-05,  1.7677e-02,
        -9.3165e-03, -1.5141e-04,  1.6838e-02, -1.5571e-05, -6.4416e-03,
        -3.4637e-04,  2.8048e-03, -1.2755e-05,  1.6013e-02,  1.8186e-04,
        -2.2795e-04, -2.9190e-03,  1.7040e-05,  3.3593e-03, -1.3904e-04,
         2.1980e-04,  1.6255e-02, -3.6559e-03,  3.1037e-02,  1.9132e-02,
         5.1083e-03, -2.3321e-04,  1.2170e-02,  2.8210e-02,  6.1717e-03,
        -1.7345e-04,  9.9817e-03,  8.2553e-03, -2.9690e-04,  1.3414e-02,
         7.6450e-03,  8.1001e-05,  1.4118e-03, -1.1049e-04,  3.5289e-03,
        -4.3279e-05, -1.1146e-04,  9.7516e-03,  3.9381e-03,  2.6144e-04,
         9.7475e-03,  1.4887e-02,  2.7623e-03,  3.1596e-05,  5.2432e-03],
       device='cuda:0') 

model.module_10.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[ 0.0939, -0.1612, -0.0062,  ...,  0.0473,  0.0136, -0.0813],
        [-0.0359,  0.0176,  0.0033,  ..., -0.0962, -0.1104, -0.0637],
        [ 0.0305, -0.0870, -0.0746,  ..., -0.0206,  0.1336,  0.0419],
        ...,
        [ 0.1203, -0.0039,  0.1777,  ..., -0.0262, -0.0195, -0.2733],
        [-0.1113,  0.0754,  0.1027,  ...,  0.0683,  0.1218, -0.0085],
        [ 0.0198, -0.0424, -0.0435,  ..., -0.0471, -0.2110,  0.0455]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 4.5649e-06,  1.2426e-05,  1.0443e-05,  ...,  4.9784e-05,
          1.4663e-06,  9.9479e-05],
        [ 1.5086e-06,  5.1477e-06,  8.9561e-06,  ...,  3.3652e-05,
          1.2170e-06,  6.9122e-05],
        [ 1.1120e-04,  1.7948e-04,  4.8758e-04,  ...,  2.1949e-03,
          6.0133e-05,  3.6829e-03],
        ...,
        [-1.9908e-05, -5.9020e-05, -2.3723e-05,  ...,  3.8137e-05,
          3.1063e-06,  1.7126e-04],
        [ 3.9802e-06,  1.4922e-05,  7.1320e-06,  ...,  2.9413e-05,
          1.3479e-06,  6.7884e-05],
        [-1.2536e-05,  1.5390e-04,  1.4515e-05,  ..., -1.0508e-05,
          4.4227e-06, -7.3997e-05]], device='cuda:0') 

model.module_10.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.4874, -0.1516,  0.1524, -0.2851, -0.1189, -0.1023, -0.2162,  0.0545,
        -0.3495,  0.1393, -0.0797, -0.0904, -0.1120, -0.1533, -0.0332,  0.2377,
        -0.1478,  0.1471,  0.2137, -0.3839,  0.1117, -0.0497, -0.0765, -0.0458,
        -0.0612,  0.0953, -0.2159, -0.3439,  0.1230, -0.1254, -0.0697, -0.3436,
        -0.1366, -0.3543, -0.3432,  0.0227, -0.0500, -0.1511,  0.0952,  0.1391,
         0.0580,  0.0290, -0.1465, -0.2493, -0.0686, -0.1445,  0.1910, -0.0701,
        -0.2294, -0.0770,  0.1225, -0.1820,  0.0445, -0.0406, -0.0670, -0.1492,
         0.0839, -0.2575, -0.2670, -0.4358, -0.2687, -0.1863,  0.2780,  0.0943,
        -0.1492, -0.0285, -0.2242, -0.0647, -0.2413, -0.1210, -0.1204, -0.2211,
         0.0080, -0.1270, -0.0794,  0.0194,  0.1155,  0.1562, -0.0600, -0.1039,
        -0.0468, -0.1292, -0.2417, -0.0479,  0.1674,  0.1185, -0.1863, -0.1256,
        -0.1944,  0.1726, -0.1468,  0.2390,  0.1606, -0.0205, -0.1542,  0.2453,
         0.1253, -0.2706, -0.2680, -0.3543], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 8.6193e-05,  7.6383e-05,  3.5266e-03, -2.9709e-03, -1.8614e-03,
         1.0852e-04,  1.5438e-04, -3.2044e-04,  4.2703e-05,  6.4712e-03,
         3.1621e-04, -8.2719e-03, -2.2881e-03, -7.1548e-05, -4.9661e-05,
         4.2572e-03,  9.3869e-05, -2.5742e-03,  2.7752e-03, -3.4308e-03,
         2.1213e-02,  1.8551e-04,  1.6853e-04,  1.7670e-04,  1.0327e-04,
         7.1877e-03, -8.7956e-05, -2.9812e-05,  9.7084e-03, -6.8345e-06,
        -2.2826e-04, -4.9660e-05,  2.4425e-04, -6.0975e-03,  1.3076e-04,
        -7.4198e-03, -5.1074e-05,  3.2723e-05,  7.8656e-03,  6.1497e-04,
         1.7036e-02,  8.7201e-05,  1.6596e-04,  2.2297e-04,  2.2446e-04,
         3.2996e-03,  1.0259e-02, -6.7161e-06, -4.0007e-03,  6.0017e-05,
         7.1714e-03,  3.7732e-04,  3.4108e-03,  2.8452e-04, -1.0041e-04,
        -9.1617e-05,  2.1942e-02,  8.9492e-05, -4.6974e-05, -3.9228e-04,
        -7.9729e-03,  1.4693e-04,  5.6490e-03,  9.8816e-03,  1.1593e-04,
         3.0737e-03, -3.9475e-03,  1.7646e-04,  6.7931e-05,  8.6395e-05,
         8.1330e-05, -1.4488e-04, -1.2917e-03, -7.9583e-04,  1.2847e-04,
         2.6237e-04, -2.5475e-04,  4.0884e-03,  2.7804e-04, -4.6013e-05,
         3.0992e-04,  2.6900e-05, -2.0249e-05, -6.5000e-05,  5.0638e-03,
        -2.3765e-03,  2.7755e-03,  1.3138e-04,  3.4268e-03,  7.0041e-03,
         9.9258e-03, -2.6419e-03, -4.0769e-03,  7.6646e-05,  1.0034e-04,
         5.9705e-03,  3.3972e-03,  6.8700e-05,  1.1012e-04,  9.2003e-04],
       device='cuda:0') 

model.module_12.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0734, -0.0009, -0.1890,  ..., -0.0101, -0.0217,  0.1364],
        [-0.0303, -0.1711, -0.0358,  ..., -0.0818,  0.0063,  0.1585],
        [-0.0548, -0.0912, -0.0957,  ..., -0.0050,  0.0197, -0.0437],
        ...,
        [-0.1328, -0.0563,  0.0861,  ..., -0.1693, -0.0170,  0.0738],
        [ 0.1169, -0.0481,  0.0472,  ...,  0.0508, -0.0126, -0.0745],
        [-0.1022, -0.0197,  0.0609,  ..., -0.2123,  0.0569,  0.0561]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 6.3676e-04,  4.4101e-04,  3.8113e-04,  ...,  4.7056e-04,
          3.2027e-04, -1.7447e-03],
        [-1.5711e-05, -1.0530e-05, -7.7698e-04,  ..., -2.3862e-05,
         -2.7465e-05,  1.8057e-04],
        [-4.4183e-05, -3.1273e-05, -2.4618e-04,  ..., -3.3374e-05,
         -1.9178e-05, -3.0296e-04],
        ...,
        [-4.7124e-06, -4.8842e-06, -1.2269e-04,  ..., -5.3826e-06,
         -6.2411e-06,  9.5926e-05],
        [ 7.3716e-06,  6.5932e-06, -5.1274e-05,  ...,  3.3475e-06,
         -1.5806e-06,  1.1179e-04],
        [ 1.9447e-04,  1.1867e-04,  5.3845e-03,  ...,  2.3548e-04,
          1.5022e-04,  4.2843e-04]], device='cuda:0') 

model.module_12.bias 16 torch.Size([16])
Parameter containing:
tensor([ 0.1772, -0.0858, -0.2042, -0.2574, -0.3238,  0.0846, -0.2850,  0.0786,
        -0.1611,  0.2328, -0.1954,  0.2591,  0.1877, -0.0131, -0.3256,  0.2066],
       device='cuda:0', requires_grad=True) 
grad:  tensor([ 0.0388, -0.0019, -0.0027, -0.0009,  0.0009, -0.0292, -0.0003, -0.0013,
        -0.0053, -0.0517, -0.0018,  0.0662, -0.0180, -0.0005,  0.0003,  0.0148],
       device='cuda:0') 

model.module_14.att 8 torch.Size([1, 1, 8])
Parameter containing:
tensor([[[-1.0964,  0.8854, -0.1293, -2.3469, -2.1796, -2.0205, -1.2674,
           0.2332]]], device='cuda:0', requires_grad=True) 
grad:  tensor([[[ 0.0080,  0.1023,  0.0129,  0.0421, -0.0607,  0.0176,  0.0008,
          -0.0179]]], device='cuda:0') 

model.module_14.bias 8 torch.Size([8])
Parameter containing:
tensor([ 1.2440e-01,  2.8477e-02,  7.7435e-02, -1.3086e-01, -1.2986e-04,
         1.4073e-02, -1.2969e-02, -6.0412e-02], device='cuda:0',
       requires_grad=True) 
grad:  tensor([ 0.0366,  0.0720,  0.0349, -0.0045, -0.0939,  0.0593, -0.0275, -0.0205],
       device='cuda:0') 

model.module_14.lin_l.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[-0.1110, -0.3349,  0.2806,  0.2495, -0.1294,  0.1438,  0.2416, -0.3508,
         -0.2793, -0.1774,  0.2356, -0.3498,  0.1565, -0.1220,  0.1610, -0.4453],
        [ 0.3359, -0.0428, -0.2769,  0.0807,  0.1218, -0.0724,  0.3090, -0.4667,
          0.5482, -0.4960,  0.1532,  0.1793,  0.0388, -0.2623,  0.1647, -0.2673],
        [-0.1501,  0.1394,  0.3606,  0.1591,  0.1224, -0.1995,  0.3116, -0.2118,
         -0.0940, -0.0507,  0.3275,  0.1160, -0.3345,  0.1969,  0.3179, -0.2719],
        [ 0.4308,  0.0213, -0.4226,  0.3524,  0.1833, -0.3805, -0.0352, -0.3923,
          0.4825, -0.1920, -0.2398, -0.2739, -0.4869,  0.2576,  0.2994, -0.2197],
        [-0.3820,  0.2896, -0.1514,  0.0793, -0.2359, -0.0504,  0.2714,  0.2819,
         -0.0133,  0.5345,  0.4041,  0.2503,  0.0811, -0.2533, -0.1131,  0.3469],
        [ 0.0174,  0.4106,  0.1796,  0.1641, -0.0229, -0.1020, -0.0146,  0.3674,
          0.0160, -0.3946,  0.2667, -0.3635, -0.1790, -0.3645,  0.1319, -0.0589],
        [-0.1126,  0.0620,  0.2647,  0.1860,  0.0823,  0.2181, -0.2778, -0.4664,
          0.1409, -0.0308, -0.3314, -0.1197,  0.2195,  0.3377,  0.0128,  0.0825],
        [-0.3286, -0.3879, -0.0283, -0.0922,  0.1129,  0.1860,  0.0397,  0.0425,
         -0.1088,  0.3101, -0.3023,  0.1649,  0.2682, -0.1416, -0.3163, -0.2924]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[ 2.8908e-02,  4.6637e-04,  2.6684e-04,  4.6713e-04,  8.9848e-04,
          7.3187e-03,  2.5217e-04,  2.8502e-04,  1.3730e-02,  2.4107e-02,
          9.5292e-04,  2.2072e-02,  6.7342e-03,  2.9560e-04,  5.3069e-04,
          2.3654e-02],
        [ 1.0999e-01,  1.2750e-03,  1.2762e-03,  2.1968e-03,  3.1804e-03,
          4.4002e-03,  1.5212e-03,  1.8350e-03,  4.5558e-02,  1.6546e-02,
          2.9276e-03,  4.8075e-02,  4.3320e-03,  1.2596e-03,  2.8899e-03,
          1.3822e-02],
        [ 4.9823e-02,  3.4172e-04,  3.1671e-04,  5.9589e-04,  1.2093e-03,
          2.2845e-03,  4.4013e-04,  4.7997e-04,  2.1631e-02,  7.2557e-03,
          9.5522e-04,  1.5706e-02,  2.3549e-03,  3.2416e-04,  8.6626e-04,
          6.4311e-03],
        [-1.9006e-01, -1.5815e-05, -7.3610e-04, -1.6646e-03, -3.7415e-03,
          1.8236e-02, -1.7228e-03, -1.7556e-03, -7.6396e-02,  6.2564e-02,
         -1.7838e-03, -3.7550e-03,  1.4459e-02, -6.9385e-04, -3.1619e-03,
          6.7646e-02],
        [-1.7125e-01,  1.6334e-03, -2.1404e-04, -7.7604e-04, -2.0820e-03,
          5.7563e-02, -1.5794e-03, -1.5198e-03, -6.0957e-02,  1.8568e-01,
          8.9902e-04,  8.0917e-02,  4.9690e-02,  1.0281e-05, -2.6742e-03,
          1.9405e-01],
        [-5.0937e-02,  8.1057e-04,  1.6837e-04,  8.7247e-05, -3.8164e-04,
          1.9667e-02, -3.3718e-04, -2.4781e-04, -1.7787e-02,  6.6754e-02,
          7.3759e-04,  3.4591e-02,  1.6889e-02,  2.3031e-04, -5.2410e-04,
          6.8600e-02],
        [-1.0147e-01,  6.3980e-04, -1.0822e-04, -4.2653e-04, -1.4445e-03,
          2.2664e-02, -7.7324e-04, -7.1422e-04, -3.9045e-02,  7.4428e-02,
          5.1979e-05,  2.8658e-02,  1.9281e-02, -3.2025e-05, -1.3652e-03,
          7.7941e-02],
        [ 1.5835e-02, -6.4282e-04, -3.5437e-04, -4.5918e-04, -1.9869e-04,
         -9.8668e-03, -9.8580e-05, -2.3214e-04,  5.5469e-03, -3.3986e-02,
         -8.1222e-04, -2.3660e-02, -8.4749e-03, -3.6043e-04, -2.2630e-04,
         -3.4341e-02]], device='cuda:0') 

model.module_14.lin_l.bias 8 torch.Size([8])
Parameter containing:
tensor([ 0.1080,  0.0980,  0.2992,  0.0595,  0.0804, -0.0045, -0.2158,  0.0698],
       device='cuda:0', requires_grad=True) 
grad:  tensor([ 0.0280,  0.1179,  0.0347, -0.0951, -0.0460,  0.0047, -0.0273, -0.0228],
       device='cuda:0') 

model.module_14.lin_r.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[-0.4992, -0.1117, -0.5037, -0.5631,  0.6773,  0.1035, -0.5190, -0.1606,
         -0.3561,  0.3591, -0.5184, -0.1098, -0.6689, -0.3922,  0.2517, -0.0734],
        [-0.6507,  0.6041, -0.7409, -0.2866,  0.2242,  0.2492, -0.3520,  0.8385,
          0.0133,  0.5576, -0.2466, -0.3509,  0.0705,  0.0495, -0.3841, -0.4094],
        [-0.3206, -0.2987, -0.5151, -0.1054, -0.2899,  0.0849,  0.4138, -0.4859,
         -0.7663,  0.2583, -0.0525, -0.3498,  0.5631, -0.0680, -0.7317,  0.5468],
        [-0.2782, -0.3041, -0.4264, -0.1311,  0.1894,  0.1395,  0.1618, -0.3737,
         -0.2019,  0.1710,  0.0351, -0.5416,  0.2866, -0.2258, -0.1182,  0.0395],
        [ 0.3728, -0.1932,  0.3269,  0.3812,  0.0986,  0.6103, -0.2303,  0.0750,
         -0.6013, -0.2094,  0.0095,  0.1913,  0.0996,  0.3029,  0.5120, -0.1098],
        [ 0.1817, -0.6426, -0.7446, -0.4506,  0.4788,  1.1896,  0.0972, -0.0567,
          0.0400, -0.2379, -0.2582, -0.0596, -0.1297, -0.4750,  0.8162, -0.0956],
        [-0.6149,  0.2403,  0.0249,  0.0249,  0.1251, -0.2788,  0.7283,  0.5943,
         -0.0567,  0.0920, -0.0870,  0.0368,  0.8475, -0.0374, -0.1065,  0.8186],
        [-0.0629,  0.2330, -0.3068, -0.4112, -0.3400,  0.0026, -0.7259, -0.2470,
         -0.7916, -0.3388, -0.3044, -0.5218, -1.0067,  0.0702,  0.5479, -1.2029]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-9.6250e-04, -2.3637e-04, -1.1458e-04, -1.7840e-04, -2.0569e-04,
         -4.1318e-03, -5.9107e-05, -1.0014e-04, -1.1147e-03, -1.3764e-02,
         -3.6891e-04, -1.0130e-02, -3.7166e-03, -1.3190e-04, -1.2587e-04,
         -1.3541e-02],
        [ 1.7631e-02,  9.3783e-04,  6.1153e-04,  9.3064e-04,  1.0652e-03,
          1.2496e-02,  4.2251e-04,  6.2866e-04,  9.3371e-03,  4.2373e-02,
          1.5633e-03,  3.5948e-02,  1.1252e-02,  6.2658e-04,  8.5399e-04,
          4.1424e-02],
        [-4.0306e-05, -4.6733e-06, -2.7347e-06, -3.9521e-06, -4.3198e-06,
         -6.1627e-05, -1.4266e-06, -2.3326e-06, -3.3301e-05, -2.2560e-04,
         -7.3354e-06, -1.7887e-04, -4.8026e-05, -2.9492e-06, -3.4050e-06,
         -2.2832e-04],
        [-3.3713e-02, -1.8697e-03, -1.2534e-03, -1.8438e-03, -2.0620e-03,
         -2.4555e-02, -8.0705e-04, -1.2449e-03, -1.8428e-02, -8.3009e-02,
         -3.0700e-03, -6.9067e-02, -2.1769e-02, -1.2496e-03, -1.6633e-03,
         -8.2251e-02],
        [ 1.6469e-02,  1.0593e-03,  6.4895e-04,  9.6728e-04,  1.1164e-03,
          1.4964e-02,  4.0194e-04,  6.3116e-04,  9.8697e-03,  5.0939e-02,
          1.7251e-03,  4.0722e-02,  1.3190e-02,  6.7677e-04,  8.4180e-04,
          5.0726e-02],
        [-3.1363e-02, -9.3141e-04, -7.6541e-04, -1.1144e-03, -1.2963e-03,
         -9.7604e-03, -5.5600e-04, -8.1322e-04, -1.4619e-02, -3.2203e-02,
         -1.6341e-03, -3.1166e-02, -8.7474e-03, -7.0278e-04, -1.1327e-03,
         -3.1968e-02],
        [ 5.1834e-05,  2.9498e-06,  2.3714e-06,  2.9833e-06,  2.9892e-06,
          2.5722e-05,  1.3500e-06,  1.7779e-06,  2.3042e-05,  1.0941e-04,
          4.6018e-06,  9.3310e-05,  2.4654e-05,  1.9560e-06,  2.6637e-06,
          1.0485e-04],
        [-2.2654e-03, -2.3296e-05, -2.6369e-05, -4.4017e-05, -6.2486e-05,
         -2.4710e-05, -3.0972e-05, -3.6768e-05, -9.0816e-04, -1.2248e-04,
         -5.5146e-05, -7.8871e-04, -3.7516e-05, -2.4446e-05, -5.8205e-05,
         -4.2468e-05]], device='cuda:0') 

model.module_14.lin_r.bias 8 torch.Size([8])
Parameter containing:
tensor([ 0.0792,  0.4751, -0.1135, -0.0185, -0.1857,  0.0230, -0.0844,  0.3039],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-0.0086,  0.0460, -0.0002, -0.0906,  0.0479, -0.0546,  0.0002, -0.0024],
       device='cuda:0') 

model.module_14.lin_edge.weight 16 torch.Size([8, 2])
Parameter containing:
tensor([[-1.2427,  0.4897],
        [ 1.7641,  0.1962],
        [ 0.1020, -0.6363],
        [-2.1083,  0.5966],
        [ 2.3458,  0.0423],
        [-1.2464,  0.6334],
        [ 0.7108, -0.0120],
        [ 0.2369,  1.6609]], device='cuda:0', requires_grad=True) 
grad:  tensor([[-0.0044, -0.0045],
        [ 0.0098,  0.0214],
        [-0.0019, -0.0010],
        [-0.0245, -0.0443],
        [-0.0592, -0.0052],
        [-0.0143, -0.0280],
        [-0.0199, -0.0097],
        [ 0.0037,  0.0004]], device='cuda:0') 

model.module_15.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[-1.2880e-01, -6.0749e-02, -2.4420e-01,  1.4436e-01,  9.6649e-02,
          6.6689e-02,  1.4990e-01,  1.7746e-01],
        [ 1.5648e-02, -1.9119e-01, -1.2180e-01, -1.4187e-01,  5.9274e-02,
          1.6791e-01,  2.3108e-01, -3.0190e-01],
        [ 1.5820e-01,  7.5267e-02, -1.5656e-01,  1.1861e-01, -1.3400e-01,
          1.8324e-01,  1.7386e-01, -3.8173e-02],
        [ 6.8350e-02, -2.7280e-01,  3.6513e-01, -7.6060e-02,  1.2220e-01,
         -1.3468e-01, -1.1615e-01,  2.6135e-01],
        [-4.4119e-01,  1.2781e-01,  2.2313e-01, -6.2196e-02, -1.2449e-01,
          1.8338e-01, -6.1208e-02,  2.7193e-02],
        [ 8.9765e-02, -2.8258e-01, -3.0857e-02, -2.3757e-02, -1.5357e-01,
          2.9750e-01,  3.8165e-01,  2.3745e-01],
        [ 8.8077e-02, -2.1773e-01, -1.1270e-01,  2.9166e-01, -5.7392e-02,
         -2.1231e-01, -3.6978e-01,  3.7115e-01],
        [-1.0153e-01, -1.0917e-01,  1.5872e-01, -1.9172e-01, -9.9067e-02,
          5.0191e-02,  8.6609e-02, -2.6725e-01],
        [ 1.4876e-01, -1.9171e-01,  2.7878e-01, -3.8450e-02, -1.4027e-01,
          2.1263e-01, -6.9281e-02, -1.8295e-01],
        [ 1.3452e-01, -1.2959e-01, -1.1780e-02, -5.3260e-02, -1.9065e-02,
          1.2474e-01,  3.0957e-01, -3.0003e-01],
        [ 5.7616e-02,  4.2654e-02,  2.8044e-02,  3.8290e-02, -3.4058e-02,
          2.5511e-01,  8.3928e-02, -1.2630e-01],
        [ 1.6000e-01,  9.0502e-02,  3.8510e-02,  1.1172e-01,  3.3224e-01,
         -3.9959e-01,  2.9084e-01, -3.9632e-02],
        [ 1.9153e-01, -6.6672e-02, -1.6201e-01,  1.4883e-01,  5.8571e-02,
         -1.1924e-01,  2.8783e-01,  4.5597e-02],
        [ 1.3668e-01,  1.6487e-01,  8.1563e-02, -2.1030e-01, -8.6803e-02,
          7.0750e-03,  1.5414e-01,  4.0599e-02],
        [ 2.7658e-01,  7.4387e-02, -2.9390e-01,  4.0608e-03,  1.8709e-01,
         -2.0117e-01,  8.6407e-02, -2.6155e-02],
        [ 2.7770e-01,  2.5983e-01,  2.7864e-02, -6.7789e-02,  9.7785e-02,
         -1.4820e-01,  4.3666e-02, -2.1705e-03],
        [-1.5296e-01,  1.6682e-01, -2.4448e-01, -1.6902e-01,  8.7654e-02,
          2.4767e-01,  3.4225e-02,  1.5377e-01],
        [ 2.8939e-01,  1.0293e-01, -5.8373e-02,  5.2348e-02, -1.4382e-01,
          1.1615e-01, -3.3144e-01,  4.3311e-04],
        [ 2.1687e-01, -1.5758e-01,  7.9993e-02, -5.0000e-02, -1.5035e-01,
         -3.9080e-02, -1.3535e-01, -2.4267e-01],
        [ 3.5722e-01, -1.2983e-01, -1.6144e-01,  1.8304e-01,  2.3192e-01,
         -1.7281e-01, -1.3260e-01, -3.8516e-02],
        [ 2.1260e-01,  3.0171e-01,  1.5133e-01, -2.1266e-01,  8.8094e-02,
         -5.3050e-02, -8.9337e-02,  8.9787e-02],
        [-1.9440e-01,  2.2128e-01, -3.3924e-01, -5.9779e-02, -8.4107e-02,
         -1.2451e-01,  2.5270e-01,  1.5996e-01],
        [-1.4315e-01, -2.6951e-01, -6.9873e-02, -3.8057e-02, -2.8114e-01,
          1.9245e-01,  1.1911e-01,  4.4806e-02],
        [ 1.1292e-01, -5.7420e-02, -1.6240e-01, -7.0005e-03,  1.0020e-01,
         -7.2533e-02,  3.0467e-01, -1.5023e-01],
        [ 2.0803e-01, -8.2318e-02,  1.4540e-01,  1.1476e-01, -3.3265e-02,
          6.4101e-02, -1.8094e-01,  2.0560e-01],
        [ 2.0794e-01, -1.8070e-01, -1.1967e-01, -4.2929e-01,  1.8425e-01,
         -1.2781e-01, -2.1181e-01,  8.4057e-02],
        [-1.5051e-01,  2.2559e-01,  9.3879e-02,  1.5627e-01,  1.1166e-01,
         -2.1125e-01, -2.7924e-01, -2.1442e-01],
        [-5.8641e-02, -1.3800e-01,  2.6698e-01, -1.2074e-01, -1.8891e-01,
         -5.6177e-02, -1.3531e-01, -1.6341e-01],
        [ 2.0229e-01,  8.7477e-02, -3.4597e-01,  7.4265e-02,  2.2561e-01,
          2.3922e-02,  3.0769e-01,  2.7527e-01],
        [ 1.6225e-01, -4.8061e-03, -3.6412e-02,  2.5662e-02,  7.8310e-02,
         -1.1543e-01,  2.7208e-01, -6.4538e-02],
        [-1.2217e-01,  5.7129e-02, -5.9181e-02, -1.3572e-01, -1.0064e-01,
         -1.4732e-01, -1.0343e-01, -7.5291e-02],
        [ 6.1193e-02,  1.6527e-01, -1.0332e-01, -1.1761e-01,  1.9018e-01,
         -5.5111e-02,  3.9216e-01, -6.6664e-02],
        [ 1.1960e-01,  1.1820e-01, -1.5362e-01, -1.3112e-01,  5.3307e-02,
          1.3565e-01, -6.4591e-02, -5.0617e-03],
        [-6.8159e-03, -3.0471e-01,  5.0472e-01,  9.8083e-02,  5.8281e-02,
          2.6112e-01,  2.2810e-01, -7.5486e-02],
        [ 1.7036e-01, -2.7894e-01, -1.2132e-01,  2.0463e-01, -6.1828e-02,
         -9.7015e-02, -1.3609e-03, -6.8936e-02],
        [-1.2648e-01, -9.6497e-03, -4.6654e-02, -7.9399e-02, -6.6049e-02,
         -1.3283e-01,  1.2648e-01,  5.1127e-02],
        [-2.5668e-01,  2.9440e-01, -3.0922e-01, -3.1931e-04, -8.5654e-03,
         -1.6332e-01,  3.4319e-01,  7.4033e-02],
        [-1.2974e-01, -1.1790e-01,  3.7033e-01, -7.8586e-02, -2.7384e-01,
         -5.5963e-02, -2.2614e-01,  8.8104e-02],
        [ 2.3409e-02,  7.6904e-03, -1.2263e-01,  1.0407e-01, -1.2840e-01,
         -1.8681e-01,  1.7800e-01,  3.1117e-01],
        [-1.3043e-01, -3.4530e-01,  2.8663e-02,  1.6688e-01, -1.1314e-01,
         -2.3181e-01, -1.4551e-01,  5.0540e-02],
        [ 1.6687e-01, -7.8267e-02, -2.7527e-01,  3.1453e-02, -1.4864e-01,
         -6.9200e-02,  9.5779e-02,  7.5593e-02],
        [-1.6218e-01, -1.9456e-01,  2.4068e-01, -1.1452e-01, -1.7507e-01,
          2.9200e-02, -1.3711e-01, -1.9940e-01],
        [ 4.3925e-01,  8.9005e-02,  4.6628e-01, -1.4831e-01, -2.0518e-01,
          3.0269e-01,  7.3495e-02,  1.1065e-01],
        [-8.7705e-03, -8.2547e-02, -2.1906e-02,  1.1095e-01,  1.5127e-01,
         -1.7658e-01,  1.5791e-01, -1.7548e-01],
        [-2.0370e-01, -1.5255e-01,  2.6981e-01,  1.3932e-01, -1.0473e-01,
         -3.0084e-01, -1.2327e-02,  3.7511e-01],
        [ 9.0604e-02,  2.8239e-01,  8.3571e-02, -6.0087e-02,  1.1022e-01,
          1.7474e-01,  4.5750e-01, -1.4720e-01],
        [-2.4289e-01,  8.4986e-02,  7.2541e-04, -3.3283e-01, -1.4555e-01,
          2.2239e-01,  5.6394e-02,  1.2158e-01],
        [-1.9228e-01, -4.5642e-02,  1.8421e-02, -2.5340e-01, -3.4497e-01,
          2.6925e-01,  1.7831e-01,  2.3735e-01],
        [-3.4292e-01, -3.1982e-02, -1.0762e-01, -1.9822e-02, -2.7850e-01,
         -3.0315e-01, -1.7653e-01,  1.9082e-01],
        [ 1.6386e-01,  3.2305e-01,  1.2582e-01, -2.0748e-01, -6.7630e-03,
          2.5266e-01, -2.6759e-01,  9.0811e-02],
        [ 9.9889e-02, -2.2248e-01,  4.1662e-02,  2.0825e-01,  2.4125e-01,
          2.2804e-01,  1.7794e-02, -1.3198e-01],
        [ 1.8009e-01,  3.6043e-01, -1.3045e-02, -2.2574e-01,  1.3696e-01,
          5.3950e-02,  4.9593e-01, -1.3459e-01],
        [ 2.3068e-01,  8.0934e-02, -1.0555e-01,  2.2188e-01,  2.9299e-01,
          2.0196e-02,  1.1815e-01, -3.4095e-01],
        [ 1.3144e-01, -5.2769e-02, -1.5441e-02, -1.9479e-02,  1.6790e-01,
          1.5654e-01,  4.2545e-01,  4.7249e-02],
        [ 1.3312e-01,  1.9989e-01, -8.2863e-02,  1.3675e-01, -1.8987e-02,
         -1.9276e-01,  3.3946e-01, -4.6555e-02],
        [ 1.4650e-01, -1.7078e-01,  8.2819e-02,  4.0703e-02,  1.3102e-01,
          1.1048e-01,  1.8551e-02, -3.7894e-01],
        [ 6.9851e-02, -1.7210e-02, -2.3916e-01, -1.3280e-01, -2.0847e-03,
          3.8633e-01,  3.8872e-01, -1.7146e-01],
        [ 2.4065e-01,  6.7931e-02,  2.7043e-01, -1.6715e-01,  1.0400e-01,
          4.8138e-02,  2.4764e-01, -2.9091e-01],
        [ 1.7391e-01, -1.8369e-01, -1.1321e-01,  2.3874e-01, -7.8625e-02,
         -1.1273e-01,  2.0084e-02,  4.2592e-01],
        [ 1.7449e-01,  1.7082e-01, -5.3897e-02, -7.8137e-02,  1.4279e-01,
         -4.7271e-02, -1.1469e-02, -2.5128e-02],
        [-6.3323e-02,  6.5888e-03, -7.8690e-02, -1.8703e-01, -8.0281e-02,
          2.3366e-01,  9.1650e-02, -2.3652e-01],
        [-5.8216e-02,  1.0348e-01, -4.1170e-01, -3.5678e-02,  7.5487e-02,
          1.1592e-01, -2.2490e-01,  2.9032e-01],
        [ 2.4245e-01, -1.1671e-01,  2.0309e-01, -3.0580e-01,  2.8769e-01,
         -1.1369e-01, -1.7313e-01,  2.6645e-01],
        [ 2.3988e-02, -5.8100e-02, -2.5014e-02,  1.5823e-02, -5.8574e-02,
         -2.4946e-01,  1.3656e-01, -2.5971e-02],
        [-7.7936e-02, -4.3676e-02, -2.5366e-01, -1.3062e-01,  1.5664e-01,
          2.0305e-01, -5.7947e-03, -2.7981e-01],
        [ 1.5371e-01, -5.9151e-02, -9.5442e-02,  1.4561e-03,  1.1123e-01,
         -1.1239e-01,  4.1216e-01,  4.2838e-01],
        [ 2.5039e-01, -2.7081e-01,  1.7987e-01, -1.1196e-01, -1.6730e-01,
          4.5336e-03, -2.4382e-01, -1.8746e-01],
        [ 3.9061e-01, -1.8727e-01, -1.7891e-01,  1.9221e-01,  6.0862e-02,
          9.5841e-02,  1.0904e-02,  7.4026e-02],
        [ 1.3492e-01,  1.5353e-02, -3.0429e-01, -4.3091e-02,  1.0346e-01,
          1.8674e-01, -1.4012e-01,  1.7067e-03],
        [-4.0561e-02, -2.3234e-01, -1.7849e-01, -1.8354e-01, -4.2304e-02,
          2.7458e-01,  3.7684e-01, -8.1864e-02],
        [ 1.2310e-01,  1.5094e-01, -7.9611e-02,  6.8608e-02,  3.9775e-01,
          1.1271e-01,  2.4667e-01,  2.4312e-01],
        [-1.3954e-01, -8.9113e-02, -1.2547e-01, -2.6146e-01, -2.5927e-01,
         -6.2684e-02,  3.5842e-01, -9.5119e-02],
        [-1.6420e-01, -1.5918e-01, -2.0026e-01, -1.4704e-01, -1.8684e-01,
          2.5700e-02, -7.0012e-02, -1.6558e-01],
        [ 2.7450e-01, -7.8314e-02, -1.3162e-01, -3.5230e-02,  1.0745e-01,
         -3.0552e-02,  4.5376e-02, -2.0006e-01],
        [ 3.7221e-02,  9.0265e-02, -2.8390e-03, -1.3967e-01, -9.3221e-02,
         -2.0046e-01,  2.7863e-01,  1.8411e-01],
        [ 1.2161e-02, -2.0773e-01, -5.1524e-02,  6.9521e-02, -1.4094e-01,
          8.9158e-02, -1.2078e-01, -1.7635e-02],
        [-1.4697e-01,  4.2991e-02, -1.8753e-01,  7.8105e-02,  2.1386e-01,
         -1.5430e-01,  1.5840e-01,  2.5754e-01],
        [ 1.4429e-02,  1.0243e-01,  1.2313e-01,  5.5193e-02,  1.1869e-01,
          7.1004e-02,  3.0085e-01,  1.7913e-01],
        [ 2.4295e-01, -3.1613e-01, -2.4426e-01,  1.3149e-01, -1.5156e-01,
         -3.5568e-02,  1.0442e-01,  3.3278e-01],
        [ 1.8822e-03,  2.1080e-01, -2.7322e-01, -1.4138e-01,  9.4736e-02,
         -4.5403e-02, -1.4900e-01, -6.8106e-02],
        [ 7.6387e-02, -1.1204e-01,  3.0033e-01,  1.2357e-01, -7.4062e-02,
          1.5156e-01, -8.0125e-02,  1.2733e-01],
        [ 6.6037e-02, -2.3636e-01,  1.2215e-01,  3.0164e-01,  2.7108e-01,
         -2.8737e-01, -2.0004e-01,  8.8407e-02],
        [ 4.3662e-01, -1.8430e-02, -9.7545e-02, -1.1197e-01,  8.5970e-02,
          1.2875e-01,  4.8208e-01, -3.6690e-01],
        [ 3.6465e-02, -2.3069e-02, -1.1923e-01, -6.1159e-02, -2.6067e-02,
          2.2056e-01, -3.4986e-01,  2.8793e-01],
        [ 1.4666e-01, -1.1104e-01, -1.6754e-01,  1.8521e-01,  4.0999e-02,
         -1.8905e-01,  2.8105e-01,  2.4631e-01],
        [ 1.4129e-01,  3.1427e-01,  1.2636e-01, -3.1542e-01,  3.3416e-02,
          2.3769e-01,  1.3731e-01,  1.3869e-01],
        [-1.0197e-01, -2.6297e-01, -1.5613e-02, -1.5216e-01, -2.9985e-01,
         -1.2421e-01,  2.2175e-01, -2.9763e-01],
        [ 7.0530e-03,  1.0738e-01, -4.5624e-02, -1.6958e-01,  1.2169e-01,
          4.9906e-02,  6.4520e-03, -1.0515e-01],
        [ 1.6476e-01,  2.5759e-01, -6.9237e-02,  1.3922e-01,  1.9051e-01,
         -1.3618e-02, -1.1701e-01,  3.0910e-01],
        [-1.4638e-01,  2.0720e-01,  6.5663e-02, -1.3828e-01,  2.3696e-01,
          2.2509e-01,  1.6561e-01,  3.7960e-02],
        [ 7.1487e-02, -2.6300e-01, -2.3698e-01, -2.4959e-02,  2.1942e-02,
          1.1907e-01,  1.0253e-01, -3.4364e-01],
        [ 1.1260e-01, -1.9402e-01, -6.7345e-03,  1.7271e-01, -2.4509e-02,
          5.7370e-02,  1.1035e-01,  2.9950e-01],
        [-1.5567e-01,  5.7329e-02, -1.2079e-01,  1.7932e-01,  1.8890e-01,
          2.0189e-01,  3.7006e-01, -2.8848e-01],
        [ 8.1710e-03, -9.6074e-02,  2.3900e-02,  1.3637e-01, -1.1921e-01,
         -1.8971e-02, -1.2468e-01,  2.6368e-01],
        [ 2.9886e-01, -8.2237e-02,  7.5208e-02,  6.7238e-02,  2.4399e-02,
          2.2737e-02,  3.3399e-01, -1.8640e-01],
        [ 1.5492e-01, -3.5293e-01, -6.6421e-02, -2.9338e-01,  2.8859e-01,
         -1.6976e-01,  4.5200e-02,  3.1000e-01],
        [ 4.6077e-01, -1.2338e-01, -1.3939e-01,  3.0692e-01,  2.1738e-01,
          1.8794e-01,  5.7201e-02,  1.7191e-01],
        [-1.0333e-01, -3.7712e-01, -3.3974e-02, -2.1937e-01, -1.0555e-01,
         -1.5396e-02,  7.4820e-02,  1.7065e-01],
        [ 6.9302e-02, -1.0052e-01,  3.0997e-01,  1.6466e-01,  1.0061e-01,
          1.8449e-01, -9.1383e-02,  1.8301e-01],
        [-1.4996e-01, -2.2101e-01,  1.2469e-01, -6.0528e-02, -9.5521e-02,
         -1.9223e-01, -1.9092e-01, -2.7279e-01]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[ 2.0033e-04, -2.0155e-04, -7.6755e-05, -8.8673e-06, -1.6886e-04,
          2.1002e-04,  1.5452e-04,  8.6969e-05],
        [-5.2534e-04,  4.1857e-04,  2.2651e-04, -1.1272e-04,  5.5897e-04,
         -5.9498e-04, -4.0551e-04, -1.6444e-04],
        [ 4.7105e-04, -6.1605e-04, -2.0087e-04, -1.4694e-04, -3.0229e-04,
          4.7035e-04,  3.9978e-04,  2.7155e-04],
        [ 6.8121e-03, -3.6546e-03, -1.9488e-03,  2.4604e-03, -7.6035e-03,
          7.5269e-03,  4.2668e-03,  1.4509e-03],
        [ 1.2875e-02, -1.6159e-02, -5.6664e-03, -3.1413e-03, -8.9953e-03,
          1.3158e-02,  1.0944e-02,  6.9982e-03],
        [-2.6705e-04,  5.1130e-04,  1.2200e-04,  2.4058e-04,  4.7072e-05,
         -2.2991e-04, -2.5735e-04, -2.3441e-04],
        [-1.8733e-04,  3.6380e-04,  9.3537e-05,  1.6665e-04,  3.7348e-05,
         -1.6511e-04, -1.8691e-04, -1.6485e-04],
        [-9.7497e-05,  1.1776e-04,  4.1570e-05,  2.0492e-05,  7.0583e-05,
         -9.9717e-05, -8.1183e-05, -5.1389e-05],
        [ 1.1641e-04, -1.3263e-04, -4.6924e-05, -1.8891e-05, -8.7979e-05,
          1.1964e-04,  9.3885e-05,  5.7830e-05],
        [ 2.1017e-04, -1.6410e-04, -9.4061e-05,  5.1410e-05, -2.3028e-04,
          2.4152e-04,  1.6440e-04,  6.3150e-05],
        [-2.7452e-04, -8.0058e-03,  1.1573e-03, -9.2762e-03,  8.2336e-03,
         -3.1566e-03,  2.7225e-04,  4.3131e-03],
        [ 6.6121e-04, -7.3593e-04, -2.7438e-04, -8.1090e-05, -5.2080e-04,
          6.8819e-04,  5.3532e-04,  3.1644e-04],
        [-3.3463e-05,  1.5009e-05,  1.8150e-05, -2.2910e-05,  4.8678e-05,
         -4.2965e-05, -2.6443e-05, -3.4238e-06],
        [ 5.2716e-04, -3.9112e-04, -2.1904e-04,  1.3516e-04, -5.7495e-04,
          5.9922e-04,  3.9640e-04,  1.5145e-04],
        [ 1.1931e-04, -6.4130e-05, -4.1739e-05,  4.7911e-05, -1.4206e-04,
          1.3702e-04,  8.0620e-05,  2.4255e-05],
        [ 1.9142e-04, -3.0302e-04, -7.7885e-05, -1.1672e-04, -7.5301e-05,
          1.7507e-04,  1.6782e-04,  1.3778e-04],
        [ 2.2342e-04, -2.7891e-04, -9.6675e-05, -5.4361e-05, -1.5555e-04,
          2.2724e-04,  1.8841e-04,  1.2157e-04],
        [-2.2385e-02,  2.1907e-02,  1.1925e-02, -2.6806e-03,  2.3010e-02,
         -2.5839e-02, -1.9559e-02, -8.5093e-03],
        [-9.0596e-03,  7.3154e-03,  5.4948e-03, -3.2624e-03,  1.1364e-02,
         -1.1363e-02, -8.1897e-03, -2.4813e-03],
        [ 6.1006e-05,  8.7293e-05, -1.3204e-05,  1.3965e-04, -1.6181e-04,
          9.5428e-05,  1.6564e-05, -4.7059e-05],
        [-2.9534e-05, -1.8365e-04,  1.3399e-05, -2.1787e-04,  2.0202e-04,
         -8.7679e-05,  8.7290e-06,  9.6945e-05],
        [-1.1079e-02,  3.6869e-03,  3.2396e-03, -6.2405e-03,  1.4281e-02,
         -1.2812e-02, -6.6427e-03, -1.2670e-03],
        [ 1.9821e-05,  1.1702e-04, -1.6098e-05,  1.4623e-04, -1.3873e-04,
          6.2088e-05,  4.2978e-07, -6.3174e-05],
        [ 9.4788e-05, -2.8681e-04, -3.3505e-05, -2.0236e-04,  7.9472e-05,
          4.8302e-05,  1.0107e-04,  1.4022e-04],
        [ 1.4156e-04,  6.0103e-05, -5.9613e-05,  2.0570e-04, -2.9017e-04,
          2.0392e-04,  8.1239e-05, -4.4209e-05],
        [ 1.4197e-02, -1.1008e-02, -5.1184e-03,  2.5632e-03, -1.4186e-02,
          1.5460e-02,  1.0159e-02,  4.4994e-03],
        [-5.1359e-03, -1.3179e-02,  1.9592e-03, -1.8516e-02,  1.9285e-02,
         -1.0074e-02, -1.0743e-03,  7.1849e-03],
        [ 2.3953e-04, -7.9751e-05, -1.0218e-04,  1.6385e-04, -3.4440e-04,
          2.9942e-04,  1.6687e-04,  1.8046e-05],
        [ 2.5733e-04, -2.0971e-04, -1.0706e-04,  4.7368e-05, -2.6533e-04,
          2.8760e-04,  1.9645e-04,  8.3611e-05],
        [-1.3855e-05, -3.9874e-05,  1.1840e-06, -5.0980e-05,  5.0503e-05,
         -2.5474e-05,  9.2625e-07,  2.1138e-05],
        [ 2.3907e-04, -3.5047e-04, -1.0274e-04, -1.1224e-04, -1.2306e-04,
          2.2965e-04,  2.0931e-04,  1.5649e-04],
        [ 5.2308e-04, -5.0862e-04, -2.2259e-04,  1.6023e-05, -4.7815e-04,
          5.6698e-04,  4.1599e-04,  2.1129e-04],
        [ 9.7586e-05,  3.2987e-05, -3.4559e-05,  1.2669e-04, -1.8645e-04,
          1.3425e-04,  5.2865e-05, -2.4056e-05],
        [-8.5595e-05,  3.9770e-04,  4.7596e-05,  3.0771e-04, -1.6694e-04,
         -1.9268e-05, -1.2500e-04, -1.9240e-04],
        [-3.9360e-06,  2.2253e-04,  3.9236e-06,  2.2016e-04, -1.7372e-04,
          5.1024e-05, -3.8383e-05, -1.1238e-04],
        [ 3.6654e-04, -4.0006e-04, -1.5609e-04, -3.3397e-05, -2.9967e-04,
          3.8609e-04,  2.9844e-04,  1.7067e-04],
        [-1.3140e-02,  5.8376e-03,  6.0906e-03, -7.9658e-03,  1.8140e-02,
         -1.6264e-02, -9.6755e-03, -1.6196e-03],
        [-1.8924e-02,  1.9275e-02,  9.7018e-03, -1.0938e-03,  1.8454e-02,
         -2.1428e-02, -1.6415e-02, -7.7158e-03],
        [ 2.1544e-04, -2.3944e-04, -9.4770e-05, -2.0858e-05, -1.7548e-04,
          2.2781e-04,  1.7817e-04,  1.0137e-04],
        [ 3.2051e-04, -5.8462e-04, -1.3661e-04, -2.6906e-04, -7.0678e-05,
          2.7786e-04,  2.9807e-04,  2.6964e-04],
        [ 3.4257e-04, -3.5819e-04, -1.4803e-04, -1.3214e-05, -2.9530e-04,
          3.6670e-04,  2.7819e-04,  1.5067e-04],
        [ 3.7770e-05,  1.9408e-05, -1.7738e-05,  6.0178e-05, -8.2079e-05,
          5.6727e-05,  2.2512e-05, -1.4313e-05],
        [-1.7517e-02,  5.8144e-02,  8.6538e-03,  4.0336e-02, -1.6293e-02,
         -9.2253e-03, -2.1207e-02, -2.7796e-02],
        [ 4.4647e-04, -6.7561e-04, -1.9952e-04, -2.2391e-04, -2.2092e-04,
          4.2815e-04,  3.9946e-04,  3.0122e-04],
        [ 2.2242e-04, -1.7839e-04, -9.5042e-05,  4.5735e-05, -2.3468e-04,
          2.5113e-04,  1.7127e-04,  7.0275e-05],
        [ 5.6632e-03, -1.8626e-02, -1.8917e-03, -1.3724e-02,  6.0984e-03,
          2.4316e-03,  6.1899e-03,  9.1521e-03],
        [-1.2778e-04,  2.8692e-04,  5.4153e-05,  1.6186e-04, -1.6605e-05,
         -9.6285e-05, -1.2671e-04, -1.3506e-04],
        [ 3.9182e-04, -3.9701e-04, -1.8472e-04,  1.2399e-05, -3.6433e-04,
          4.3247e-04,  3.2689e-04,  1.6147e-04],
        [ 7.8752e-04, -9.4356e-04, -3.4424e-04, -1.4878e-04, -5.8425e-04,
          8.1410e-04,  6.6050e-04,  4.0629e-04],
        [-7.5734e-03,  2.2943e-02,  5.6490e-03,  1.3683e-02, -3.0495e-03,
         -5.8611e-03, -1.0272e-02, -1.0539e-02],
        [-2.1558e-04, -1.0958e-05,  9.7368e-05, -2.3752e-04,  3.8269e-04,
         -2.9378e-04, -1.4066e-04,  2.8084e-05],
        [ 4.6920e-04, -4.1454e-04, -2.0232e-04,  5.9734e-05, -4.6569e-04,
          5.2113e-04,  3.6844e-04,  1.6710e-04],
        [ 1.6552e-04,  8.5535e-05, -7.2403e-05,  2.5815e-04, -3.5531e-04,
          2.4432e-04,  9.4759e-05, -5.9700e-05],
        [ 1.9359e-04, -1.9148e-04, -8.0830e-05,  9.4112e-07, -1.7280e-04,
          2.0793e-04,  1.5337e-04,  8.0454e-05],
        [ 5.7824e-03, -2.1190e-02, -1.5587e-03, -1.6512e-02,  8.4546e-03,
          1.6514e-03,  6.3575e-03,  1.0504e-02],
        [-1.7718e-05, -5.4467e-05,  1.2497e-05, -7.8236e-05,  8.0262e-05,
         -4.0811e-05, -6.4430e-06,  3.0664e-05],
        [ 5.5157e-05, -1.7530e-04, -2.7095e-05, -1.1945e-04,  4.4795e-05,
          3.1215e-05,  6.5684e-05,  8.3800e-05],
        [-1.5462e-04,  8.8731e-05,  7.2409e-05, -7.3649e-05,  1.9919e-04,
         -1.8776e-04, -1.1815e-04, -2.9567e-05],
        [ 4.4827e-05,  3.5971e-04, -1.0070e-05,  4.0406e-04, -3.6145e-04,
          1.4689e-04, -3.3381e-05, -1.8601e-04],
        [-1.7641e-04,  3.1254e-04,  9.3851e-05,  1.2088e-04,  6.6195e-05,
         -1.6729e-04, -1.7560e-04, -1.3837e-04],
        [ 1.9805e-04, -1.5983e-04, -8.7826e-05,  4.2850e-05, -2.1168e-04,
          2.2566e-04,  1.5499e-04,  6.2083e-05],
        [ 2.7459e-04, -3.9133e-04, -1.1505e-04, -1.1979e-04, -1.4735e-04,
          2.6443e-04,  2.3642e-04,  1.7500e-04],
        [ 9.4046e-03, -5.0919e-03, -2.8497e-03,  3.4931e-03, -1.0628e-02,
          1.0471e-02,  6.0067e-03,  1.9949e-03],
        [-2.2213e-05,  7.7958e-05,  1.5425e-06,  6.3818e-05, -3.4687e-05,
         -4.0059e-06, -2.0616e-05, -3.9918e-05],
        [ 3.3816e-04, -3.1695e-04, -1.4479e-04,  2.3143e-05, -3.2004e-04,
          3.7039e-04,  2.6786e-04,  1.3039e-04],
        [-3.5895e-04,  5.1759e-04,  1.5942e-04,  1.5457e-04,  1.9708e-04,
         -3.4996e-04, -3.1631e-04, -2.2915e-04],
        [ 8.9383e-04, -6.9222e-03, -2.6010e-03, -4.0099e-03,  1.8702e-03,
          7.6387e-04,  3.1511e-03,  2.7924e-03],
        [-8.8120e-05,  1.6680e-04,  4.4990e-05,  7.2712e-05,  2.1888e-05,
         -7.9558e-05, -8.7873e-05, -7.4562e-05],
        [ 3.3093e-04, -1.3444e-04, -1.4147e-04,  2.0199e-04, -4.5637e-04,
          4.0751e-04,  2.3447e-04,  3.7362e-05],
        [-8.4692e-04,  7.8949e-04,  3.7638e-04, -7.5966e-05,  8.1869e-04,
         -9.3707e-04, -6.7935e-04, -3.1990e-04],
        [ 3.4576e-04, -2.3288e-04, -1.4110e-04,  1.1061e-04, -3.9372e-04,
          3.9726e-04,  2.5446e-04,  8.8163e-05],
        [ 5.4295e-05, -7.7630e-05, -3.2857e-05, -1.5204e-05, -4.0384e-05,
          5.9140e-05,  5.4274e-05,  3.2474e-05],
        [ 2.8436e-04, -3.6413e-04, -1.2116e-04, -8.0569e-05, -1.8839e-04,
          2.8554e-04,  2.3988e-04,  1.5997e-04],
        [ 2.6407e-04, -3.2660e-04, -1.0899e-04, -6.6548e-05, -1.8074e-04,
          2.6628e-04,  2.1862e-04,  1.4324e-04],
        [ 1.8489e-05,  5.3975e-05, -1.0805e-05,  7.6765e-05, -7.8744e-05,
          4.0447e-05,  5.5364e-06, -3.0286e-05],
        [-8.0450e-05,  5.0138e-06,  2.5579e-05, -6.9250e-05,  1.2378e-04,
         -1.0016e-04, -4.6267e-05,  2.8366e-06],
        [ 1.6034e-02, -2.2120e-02, -6.2660e-03, -6.6689e-03, -8.6880e-03,
          1.5322e-02,  1.3359e-02,  9.9439e-03],
        [ 5.1799e-05, -5.6811e-05, -1.5577e-05, -1.1179e-05, -3.5208e-05,
          5.0467e-05,  3.7721e-05,  2.5880e-05],
        [ 1.2887e-04, -2.9263e-04, -5.4087e-05, -1.6801e-04,  1.9177e-05,
          9.6435e-05,  1.2833e-04,  1.3843e-04],
        [ 3.1205e-04, -3.4343e-04, -1.3104e-04, -3.2468e-05, -2.5020e-04,
          3.2677e-04,  2.5305e-04,  1.4659e-04],
        [ 9.4313e-05,  6.3107e-05, -2.6615e-05,  1.4851e-04, -1.9796e-04,
          1.3333e-04,  4.1203e-05, -3.8048e-05],
        [ 1.2089e-02,  1.2671e-02, -5.2106e-03,  2.5382e-02, -3.1062e-02,
          1.9417e-02,  5.8356e-03, -7.6719e-03],
        [ 1.6451e-04, -4.6979e-05, -5.8976e-05,  1.0978e-04, -2.3116e-04,
          2.0043e-04,  1.0555e-04,  1.1609e-05],
        [ 1.7786e-04, -1.8551e-04, -8.7820e-05,  4.5449e-06, -1.6506e-04,
          1.9704e-04,  1.5180e-04,  7.5206e-05],
        [ 3.0232e-04, -1.4326e-04, -1.2515e-04,  1.5976e-04, -3.9581e-04,
          3.6407e-04,  2.1440e-04,  4.5966e-05],
        [-1.3353e-02,  2.3891e-02,  6.8975e-03,  9.5908e-03,  4.5930e-03,
         -1.2468e-02, -1.3181e-02, -1.0642e-02],
        [ 4.0372e-06, -6.6573e-05,  1.8575e-06, -6.7567e-05,  5.0743e-05,
         -1.3750e-05,  1.0769e-05,  3.5167e-05],
        [-3.6208e-04,  2.5506e-04,  1.5635e-04, -1.1174e-04,  4.1288e-04,
         -4.1913e-04, -2.7456e-04, -9.5908e-05],
        [ 1.8926e-04, -1.5714e-04, -7.3164e-05,  2.6545e-05, -1.8690e-04,
          2.0712e-04,  1.4100e-04,  6.4572e-05],
        [ 1.1805e-04, -1.4702e-04, -5.5665e-05, -2.4225e-05, -8.7459e-05,
          1.2342e-04,  1.0286e-04,  6.2665e-05],
        [ 4.5019e-05, -7.9261e-05, -2.1135e-05, -3.2739e-05, -1.4196e-05,
          4.0808e-05,  4.2629e-05,  3.5835e-05],
        [ 1.4979e-05, -8.1780e-05, -2.9591e-06, -7.1511e-05,  4.4803e-05,
         -2.8722e-06,  2.0192e-05,  4.1242e-05],
        [ 4.0602e-03, -1.6194e-02, -8.9699e-04, -1.3120e-02,  7.2186e-03,
          6.9893e-04,  4.5341e-03,  8.1048e-03],
        [-3.2001e-05,  2.8275e-04,  2.5081e-05,  2.4449e-04, -1.6478e-04,
          2.2999e-05, -7.2473e-05, -1.3841e-04],
        [ 3.5244e-04, -3.0351e-04, -1.4193e-04,  4.3192e-05, -3.4555e-04,
          3.8702e-04,  2.6853e-04,  1.2427e-04],
        [ 1.9300e-02, -1.5916e-02, -7.3021e-03,  2.8194e-03, -1.8882e-02,
          2.0992e-02,  1.4205e-02,  6.5252e-03],
        [-1.1812e-04,  1.3109e-04,  5.9102e-05,  4.6745e-06,  1.0414e-04,
         -1.2956e-04, -1.0267e-04, -5.3619e-05],
        [ 3.3004e-04,  1.0569e-03,  2.9544e-04,  1.0384e-03, -9.5872e-04,
          4.3398e-04, -2.6290e-04, -4.6623e-04],
        [ 1.2399e-04,  4.3228e-05, -4.5342e-05,  1.6440e-04, -2.3885e-04,
          1.7163e-04,  6.7640e-05, -3.2292e-05],
        [ 5.1609e-04, -5.7218e-04, -2.2257e-04, -5.3491e-05, -4.1756e-04,
          5.4351e-04,  4.2364e-04,  2.4363e-04]], device='cuda:0') 

model.module_15.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.4296, -0.0055, -0.6801, -0.0280,  0.0190, -0.0456, -0.2859, -0.1649,
        -0.1619, -0.1186,  0.0470, -0.5560, -0.2066, -0.3152, -0.2396, -0.1738,
        -0.2130,  0.0987,  0.0745, -0.1772, -0.2734, -0.0320, -0.1919, -0.1237,
        -0.3227,  0.0788, -0.1553, -0.2006, -0.1239, -0.1642, -0.2186, -0.2929,
        -0.2838, -0.4250, -0.3589, -0.2720, -0.0869, -0.0323,  0.0723, -0.3480,
        -0.1973, -0.1879,  0.2040, -0.3052, -0.3569,  0.0123, -0.1658,  0.1224,
        -0.2747, -0.1116, -0.1005, -0.1093, -0.3375, -0.0336, -0.0900, -0.2718,
        -0.1191, -0.1628, -0.2892, -0.1720, -0.0725, -0.2032, -0.0606, -0.2202,
        -0.2175, -0.0057,  0.0753,  0.0072, -0.1408,  0.1339, -0.2872, -0.1457,
        -0.1361, -0.0941, -0.2129, -0.1403,  0.1045, -0.2164, -0.0245, -0.3795,
        -0.2811,  0.1356, -0.0823,  0.0070, -0.1977,  0.1023, -0.1321, -0.1700,
        -0.4654, -0.2903, -0.0251, -0.2085, -0.0456, -0.2438, -0.1700,  0.2089,
        -0.1664, -0.0118, -0.3695, -0.3047], device='cuda:0',
       requires_grad=True) 
grad:  tensor([-5.8000e-04,  1.5695e-03, -1.4427e-03, -1.7116e-02, -3.9742e-02,
         8.6505e-04,  6.2969e-04,  2.9722e-04, -3.4627e-04, -6.3814e-04,
         2.8931e-03, -1.9786e-03,  1.0670e-04, -1.5434e-03, -3.2541e-04,
        -5.8219e-04, -6.8510e-04,  7.4244e-02,  3.1945e-02, -1.2230e-04,
         5.7732e-05,  2.7760e-02, -6.2728e-05, -2.9946e-04, -3.8879e-04,
        -3.9142e-02,  1.1626e-02, -6.9350e-04, -7.5659e-04,  1.6055e-05,
        -7.3922e-04, -1.5690e-03, -2.5284e-04,  3.3991e-04,  5.0307e-05,
        -1.1080e-03,  3.9335e-02,  6.2012e-02, -6.5886e-04, -1.0107e-03,
        -1.0393e-03, -1.0791e-04,  6.2819e-02, -1.4058e-03, -6.6182e-04,
        -1.7764e-02,  4.0912e-04, -1.2281e-03, -2.4167e-03,  3.2964e-02,
         6.2191e-04, -1.4068e-03, -4.6256e-04, -5.7749e-04, -1.7166e-02,
         5.5757e-05, -1.9771e-04,  4.7384e-04, -4.3697e-05,  6.0536e-04,
        -5.9863e-04, -8.3883e-04, -2.4083e-02,  5.2144e-05, -1.0160e-03,
         1.1216e-03, -9.3154e-03,  2.9671e-04, -9.6307e-04,  2.5771e-03,
        -1.0015e-03, -1.9716e-04, -8.6800e-04, -7.9456e-04, -5.1123e-05,
         2.0341e-04, -4.7465e-02, -1.3865e-04, -4.1524e-04, -9.3575e-04,
        -2.1760e-04, -3.2227e-02, -4.4481e-04, -5.6862e-04, -8.7192e-04,
         4.5261e-02, -1.5540e-05,  1.0769e-03, -5.4176e-04, -3.7503e-04,
        -1.4607e-04, -4.7216e-05, -1.1748e-02,  1.6723e-04, -1.0279e-03,
        -5.4373e-02,  3.8146e-04,  4.8351e-04, -3.2169e-04, -1.5686e-03],
       device='cuda:0') 

model.module_17.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[ 0.0997,  0.0196, -0.0267,  ..., -0.0220, -0.1816,  0.0433],
        [ 0.1424,  0.1161, -0.0513,  ...,  0.0363, -0.0169,  0.0388],
        [ 0.0108, -0.0885,  0.0379,  ..., -0.0925, -0.1326, -0.0380],
        ...,
        [-0.0936, -0.1307, -0.0747,  ...,  0.0477,  0.0107, -0.0536],
        [ 0.0290, -0.0997, -0.0020,  ..., -0.0196, -0.0778, -0.0359],
        [ 0.0932, -0.0094,  0.0744,  ..., -0.0907, -0.0840, -0.0685]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-3.1547e-06, -9.1616e-08, -7.9356e-06,  ...,  1.5358e-06,
         -2.6622e-06, -7.8077e-07],
        [-4.9742e-08,  4.1084e-07, -1.3032e-06,  ...,  1.2637e-06,
         -7.3693e-08,  1.6829e-07],
        [ 3.7201e-06,  1.5432e-06,  5.2719e-06,  ...,  2.5596e-06,
          2.9643e-06,  1.5214e-06],
        ...,
        [-3.6563e-04, -2.2408e-04, -3.1782e-04,  ..., -4.8790e-04,
         -2.9334e-04, -1.8010e-04],
        [ 1.7922e-06,  2.2128e-07,  4.0753e-06,  ..., -3.7414e-07,
          1.5145e-06,  5.0318e-07],
        [ 1.8132e-06,  2.6697e-06, -3.4556e-06,  ...,  7.3022e-06,
          9.3641e-07,  1.6487e-06]], device='cuda:0') 

model.module_17.bias 100 torch.Size([100])
Parameter containing:
tensor([-0.0910, -0.0907, -0.0264, -0.0985, -0.1836,  0.1422, -0.1904, -0.2107,
        -0.0746, -0.0446, -0.2518, -0.2540, -0.1826, -0.0555,  0.0932,  0.1568,
         0.0087, -0.1078, -0.1587, -0.0941, -0.3018, -0.1572, -0.0707, -0.0506,
        -0.0197,  0.0180,  0.0214, -0.1206, -0.0703, -0.1321, -0.0671, -0.1482,
        -0.1950, -0.1974,  0.0238, -0.0839, -0.0634, -0.1718, -0.1496, -0.2762,
        -0.2286, -0.2199,  0.2091, -0.1752, -0.0530, -0.1920, -0.0277, -0.1411,
        -0.1238, -0.1736,  0.0047, -0.0918,  0.1311,  0.0966, -0.1316, -0.0996,
        -0.1441, -0.1034, -0.2771, -0.0210, -0.1797, -0.0571, -0.0754, -0.2077,
         0.0656, -0.1142, -0.1373,  0.0067, -0.2069, -0.1489,  0.0474,  0.0871,
        -0.1720, -0.0563, -0.1659, -0.1050, -0.2856, -0.2069, -0.0374, -0.2205,
         0.1301, -0.2394, -0.2068, -0.1373, -0.0508, -0.1374, -0.1598, -0.1246,
         0.0902, -0.1891, -0.0125, -0.0496, -0.0774,  0.0679,  0.0092, -0.0426,
        -0.2082,  0.0443, -0.0066, -0.1440], device='cuda:0',
       requires_grad=True) 
grad:  tensor([-2.4302e-04, -1.5454e-05,  2.4359e-04,  4.0170e-04, -2.6285e-04,
        -6.3424e-02,  1.9220e-05, -5.0775e-05, -1.8834e-04, -3.7756e-04,
        -3.5790e-04, -3.0532e-04,  1.9651e-05, -9.4356e-06, -4.0086e-02,
        -5.6229e-02, -1.4685e-02,  3.1981e-04,  1.3816e-04, -1.3768e-05,
        -2.6929e-04, -3.3455e-04, -1.1351e-03,  5.6982e-04,  4.1557e-04,
         3.3351e-03, -9.9332e-04,  8.9214e-04,  5.1628e-04, -4.5126e-04,
         8.5306e-05, -3.3221e-04, -7.4827e-04, -4.3032e-04, -1.0931e-04,
         9.8539e-04, -3.7221e-04, -4.7968e-05, -2.2765e-04, -6.6988e-04,
        -3.8930e-04, -6.6635e-04, -7.9797e-02, -4.3690e-04, -3.3109e-04,
        -1.1772e-04, -4.0301e-04,  6.9609e-04,  3.4425e-04,  8.7783e-05,
        -5.9742e-04, -6.8868e-04, -9.5707e-02, -2.4176e-02, -4.8864e-04,
        -1.4031e-04,  8.3491e-05, -6.8718e-04, -7.0470e-04, -4.0722e-04,
         3.5542e-05, -5.8690e-04, -4.4347e-05, -3.7784e-04, -6.4113e-02,
         3.4008e-04, -3.1431e-04,  4.3449e-04, -3.6306e-04, -3.8437e-04,
        -3.2915e-04, -9.2184e-02, -3.3678e-04,  1.2422e-03,  1.2641e-04,
         3.1296e-04, -7.1373e-04, -1.0557e-04,  7.2008e-05, -3.1624e-04,
        -2.7542e-02, -7.0756e-04, -2.0011e-04, -7.8157e-05,  3.1778e-04,
        -6.9899e-04, -1.8068e-04, -5.2822e-04, -2.6903e-03, -3.5561e-04,
         2.1781e-04, -5.7875e-04, -1.9924e-04, -7.2878e-03, -8.3990e-04,
        -1.5534e-04, -9.3580e-05, -2.2090e-02,  1.3362e-04,  5.2346e-05],
       device='cuda:0') 

model.module_19.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0430,  0.0921,  0.0514,  ...,  0.0844, -0.0387,  0.0039],
        [ 0.1276,  0.0067,  0.1679,  ...,  0.1842,  0.0905,  0.1608],
        [ 0.0086, -0.0612,  0.1510,  ...,  0.1016,  0.0532, -0.0392],
        ...,
        [-0.0308,  0.0883,  0.0733,  ...,  0.0548, -0.0051,  0.1515],
        [-0.0719, -0.0739, -0.0468,  ..., -0.0221, -0.2030,  0.0415],
        [ 0.1214,  0.0407, -0.0395,  ...,  0.0043,  0.0050, -0.0066]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[-3.6525e-04, -3.0726e-04,  3.5906e-05,  ..., -1.5117e-02,
         -2.1962e-04, -5.8125e-04],
        [ 8.0742e-05,  1.2534e-04,  3.3332e-05,  ...,  2.5363e-03,
          5.9117e-05,  1.5803e-04],
        [-2.9890e-05, -6.3335e-05, -2.5113e-05,  ...,  1.6450e-05,
         -1.3013e-05, -6.0480e-05],
        ...,
        [-3.5200e-05, -6.5045e-05, -2.2664e-05,  ..., -3.0490e-04,
         -1.6811e-05, -6.8138e-05],
        [ 1.0607e-05,  2.4657e-05,  1.0553e-05,  ..., -1.1648e-04,
          3.7019e-06,  2.1836e-05],
        [ 1.4192e-04,  1.9120e-04,  2.8357e-05,  ...,  1.0002e-03,
          1.9591e-05,  2.2013e-04]], device='cuda:0') 

model.module_19.bias 16 torch.Size([16])
Parameter containing:
tensor([ 0.2791, -0.1871, -0.0398,  0.1296,  0.2646,  0.2204, -0.1928, -0.2572,
        -0.2185,  0.2595,  0.0511, -0.2528,  0.2412, -0.0944, -0.1555,  0.0588],
       device='cuda:0', requires_grad=True) 
grad:  tensor([-0.0451,  0.0204, -0.0126, -0.1535, -0.1272,  0.0905, -0.0114,  0.0028,
         0.0030,  0.0186,  0.0033, -0.0069, -0.0014, -0.0126,  0.0051,  0.0420],
       device='cuda:0') 

