#### INITIAL PARAMETERS ####
W torch.Size([16, 16])
Parameter containing:
tensor([[-0.4302,  0.3687,  0.9997, -0.5315,  0.2587, -1.8771,  0.0354, -0.1098,
          0.5318,  0.4770,  0.8545,  1.9892,  0.1874, -0.0602,  0.0605,  1.0036],
        [-0.0509, -1.1180, -0.6479, -0.9024,  1.6939, -0.5068, -0.6197,  0.0553,
         -0.7579,  0.9126, -0.6797, -1.5200, -0.6306,  0.1642,  0.8298, -0.0099],
        [ 0.5138,  0.8090,  0.7490,  0.7136, -1.7597,  0.4196, -1.6468, -1.6494,
         -0.9853,  1.0660, -1.0165, -0.1740,  0.0920,  0.0711,  0.2465,  0.0279],
        [-0.3550, -1.1083, -0.8363,  0.2644, -0.4524, -1.2884, -0.3272,  0.1582,
         -0.0572, -0.1943, -0.3406,  0.1606,  1.8108, -0.5807,  0.7546, -2.4746],
        [ 0.7404, -0.6631,  2.2499,  0.3662,  1.0253,  0.4002,  0.3449, -0.1774,
         -0.9444, -1.1926,  1.7913, -0.7337,  0.2869,  0.5506, -0.1002,  1.3686],
        [-0.7237, -0.8309,  0.7761, -0.9057,  0.1455, -0.0898,  0.1767, -1.2597,
         -0.1483, -0.0254,  0.0058,  1.1066,  0.7200,  0.0846,  0.9092,  0.1236],
        [ 1.0233,  0.1312,  1.2629, -0.4656,  1.2234, -0.8773, -0.3385, -0.4783,
          0.0750, -0.2637, -0.9865,  1.3847, -0.7035,  1.2508, -1.0840,  1.2586],
        [ 0.1273,  0.2554,  0.8209, -0.3454, -0.2103, -0.9320,  0.5793, -0.4634,
          0.6938,  0.6985,  1.7294, -0.8537,  0.4289, -0.8783, -0.2913, -0.4424],
        [ 0.0663, -1.2942, -1.0915,  0.3428, -1.0596, -0.5278, -0.6353,  1.8757,
         -3.0936, -1.7709, -0.6082,  1.5911, -2.5802,  0.1412, -0.0818, -0.6422],
        [ 0.7586,  1.0863,  0.9513, -0.6014,  1.4494, -2.6784, -0.4512,  0.5662,
         -1.5024,  0.4728, -0.2670, -0.2529, -0.6152, -0.6547, -0.5988,  0.1134],
        [-0.6253,  0.3280, -0.2258, -1.4381,  0.0868,  0.4622,  0.5160,  0.1490,
         -0.8435,  2.0036, -0.8173,  1.6728, -1.0500, -0.5932,  0.5634,  0.4628],
        [-1.5930, -0.9079, -0.4167,  0.2177, -0.0195,  0.3395, -0.6057,  1.6921,
         -1.0462, -0.2805,  0.0358,  0.6549, -0.2078, -0.5423, -1.0097, -0.9926],
        [-0.2325,  0.4165,  0.5214, -1.9139,  1.2638, -0.3496, -0.1001, -1.2562,
          2.9700, -1.2055,  0.4904, -0.5113,  0.0605, -0.9475,  1.0742,  0.3113],
        [ 1.0038, -1.1845,  1.0597, -1.3078,  0.8231,  1.8300,  1.2250, -1.2046,
         -1.8280,  0.6049, -0.6198, -0.8339, -0.9242,  0.3385,  0.2359, -1.3993],
        [-0.8548, -0.8408, -0.6414,  0.8846,  0.4203, -1.3742, -0.6026, -1.6693,
         -1.1850, -0.2326,  0.7188,  1.0783, -2.3696, -0.0140,  2.1216,  1.6650],
        [ 0.1255,  0.8953,  1.5457,  1.9523, -0.2798, -1.0217, -0.4126,  0.1354,
         -0.6747, -0.6496, -0.8285, -0.9308,  0.5570, -0.8284, -0.7417,  0.1958]],
       device='cuda:0', requires_grad=True) 

act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

inner_act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

out_act.weight torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 

encoder.module_0.weight torch.Size([100, 3])
Parameter containing:
tensor([[ 0.4414,  0.4792, -0.1353],
        [ 0.5304, -0.1265,  0.1165],
        [-0.2811,  0.3391,  0.5090],
        [-0.4236,  0.5018,  0.1081],
        [ 0.4266,  0.0782,  0.2784],
        [-0.0815,  0.4451,  0.0853],
        [-0.2695,  0.1472, -0.2660],
        [-0.0677, -0.2345,  0.3830],
        [-0.4557, -0.2662, -0.1630],
        [-0.3471,  0.0545, -0.5702],
        [ 0.5214, -0.4904,  0.4457],
        [ 0.0961, -0.1875,  0.3568],
        [ 0.0900,  0.4665,  0.0631],
        [-0.1821,  0.1551, -0.1566],
        [ 0.2430,  0.5155,  0.3337],
        [-0.2524,  0.3333,  0.1033],
        [ 0.2932, -0.3519, -0.5715],
        [-0.2231, -0.4428,  0.4737],
        [ 0.1663,  0.2391,  0.1826],
        [-0.0100,  0.4518, -0.4102],
        [ 0.0364, -0.3941,  0.1780],
        [-0.1988,  0.1769, -0.1203],
        [ 0.4788, -0.3422, -0.3443],
        [-0.3444,  0.5193,  0.1924],
        [ 0.5556, -0.4765, -0.5727],
        [-0.4517, -0.3884,  0.2339],
        [ 0.2067,  0.4797, -0.2982],
        [-0.3936,  0.3063, -0.2334],
        [ 0.3504, -0.1370,  0.3303],
        [-0.4486, -0.2914,  0.1760],
        [ 0.1221, -0.1472,  0.3441],
        [ 0.3925, -0.4187, -0.3082],
        [ 0.5287, -0.1948, -0.2047],
        [-0.5586, -0.3306,  0.1442],
        [-0.0762, -0.4191,  0.0135],
        [-0.3944, -0.4898, -0.3179],
        [-0.5053, -0.3676,  0.5771],
        [ 0.1090,  0.1779, -0.5385],
        [-0.3792, -0.1922,  0.0903],
        [-0.5080, -0.2488, -0.3456],
        [ 0.0016, -0.2148, -0.0400],
        [-0.3912, -0.3963, -0.3368],
        [-0.1976, -0.4557,  0.4841],
        [-0.1146,  0.4968,  0.1799],
        [-0.4889,  0.3995, -0.1589],
        [-0.2213, -0.4792, -0.5740],
        [ 0.1652, -0.1261,  0.2248],
        [-0.4738,  0.4286, -0.4238],
        [-0.0997,  0.1206,  0.2981],
        [ 0.4661,  0.5259, -0.4578],
        [ 0.1453, -0.2483, -0.0633],
        [-0.4321,  0.5259, -0.4237],
        [ 0.3086,  0.2029,  0.1876],
        [-0.3121,  0.5248,  0.1269],
        [ 0.0743, -0.5088,  0.2424],
        [-0.0866, -0.2645,  0.4959],
        [ 0.1287, -0.3194, -0.2922],
        [-0.0276,  0.3224, -0.1475],
        [-0.3294, -0.1977, -0.4313],
        [ 0.2059,  0.4469, -0.5435],
        [ 0.1341,  0.2983,  0.1047],
        [-0.2056,  0.3013,  0.3034],
        [ 0.2159, -0.1015, -0.1529],
        [ 0.0618, -0.1020, -0.1721],
        [ 0.3690,  0.4962, -0.0572],
        [-0.1293,  0.0084, -0.0345],
        [ 0.1388,  0.1618, -0.5244],
        [-0.2131,  0.4862,  0.2249],
        [-0.0287, -0.3481, -0.3532],
        [-0.5172, -0.1882,  0.1950],
        [ 0.3681,  0.2666, -0.5103],
        [-0.3472, -0.0911,  0.5585],
        [ 0.0835, -0.1495,  0.2389],
        [-0.2199, -0.3737,  0.4214],
        [-0.2625, -0.1157, -0.5744],
        [ 0.3864,  0.4374,  0.2104],
        [-0.4026, -0.5698, -0.4689],
        [ 0.4305,  0.2772,  0.4858],
        [ 0.3025,  0.1461, -0.0057],
        [-0.4391, -0.4947, -0.5400],
        [ 0.2363, -0.2835, -0.1162],
        [-0.3323, -0.1052, -0.4064],
        [-0.3772,  0.1915, -0.1716],
        [ 0.3564, -0.1852, -0.4235],
        [-0.1019, -0.2799, -0.1766],
        [-0.5496,  0.3230, -0.4020],
        [ 0.2902,  0.2620,  0.4125],
        [-0.4429,  0.4152, -0.2729],
        [ 0.2142,  0.5422, -0.0814],
        [-0.0045, -0.1329, -0.4821],
        [ 0.2771, -0.5731,  0.3584],
        [ 0.4320,  0.5460, -0.1362],
        [-0.4744,  0.1298,  0.3189],
        [-0.5746, -0.1310, -0.3461],
        [-0.0505, -0.2842, -0.2360],
        [-0.1833, -0.5487,  0.4737],
        [ 0.4840, -0.0906, -0.0657],
        [-0.2356, -0.5214, -0.5618],
        [ 0.2146, -0.3170, -0.3712],
        [-0.0450, -0.1923, -0.1868]], device='cuda:0', requires_grad=True) 

encoder.module_0.bias torch.Size([100])
Parameter containing:
tensor([ 0.0186, -0.1225, -0.1988, -0.2764, -0.4699,  0.4841, -0.2310,  0.1530,
        -0.2003,  0.0469,  0.5383,  0.2660, -0.5003,  0.2292,  0.5480,  0.1519,
         0.3871,  0.5692, -0.0885,  0.1198, -0.4013, -0.1190,  0.4276,  0.2960,
        -0.3653, -0.4630, -0.3945, -0.5698, -0.4455, -0.1428,  0.3896,  0.0966,
        -0.4391, -0.4632,  0.2872, -0.4295, -0.0711,  0.2770, -0.2672, -0.0630,
        -0.0503, -0.1366, -0.2927, -0.5147, -0.4667, -0.3091,  0.5576, -0.2789,
        -0.3877,  0.1399,  0.1591,  0.3163,  0.4389,  0.3215, -0.5724,  0.0512,
         0.3497, -0.0534, -0.3402,  0.5504, -0.2159, -0.3287, -0.5205,  0.0258,
         0.2558,  0.1278,  0.1142, -0.4379, -0.5392,  0.0102,  0.5264,  0.3331,
        -0.3362, -0.0749, -0.4256, -0.2785,  0.1046,  0.3144,  0.4783, -0.5301,
         0.3860, -0.4072,  0.2162,  0.4886,  0.0081,  0.5253, -0.4919, -0.2205,
         0.3367, -0.1258, -0.1182, -0.2406,  0.3980,  0.2832,  0.1850, -0.3244,
        -0.4687,  0.0624,  0.1711, -0.2666], device='cuda:0',
       requires_grad=True) 

encoder.module_2.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0280,  0.0675,  0.0080,  ...,  0.0930, -0.0259, -0.0423],
        [-0.0242, -0.0483,  0.0170,  ..., -0.0880,  0.0698,  0.0116],
        [-0.0539,  0.0523, -0.0946,  ...,  0.0836, -0.0560,  0.0919],
        ...,
        [ 0.0149, -0.0668, -0.0751,  ...,  0.0350, -0.0560,  0.0757],
        [ 0.0928, -0.0271,  0.0738,  ...,  0.0034,  0.0219,  0.0902],
        [-0.0438, -0.0375,  0.0319,  ..., -0.0964, -0.0224, -0.0814]],
       device='cuda:0', requires_grad=True) 

encoder.module_2.bias torch.Size([100])
Parameter containing:
tensor([ 0.0899, -0.0268,  0.0269, -0.0717,  0.0102, -0.0940,  0.0450,  0.0472,
        -0.0972,  0.0436,  0.0127, -0.0625, -0.0458,  0.0983, -0.0520,  0.0875,
         0.0201,  0.0458, -0.0503,  0.0325,  0.0215,  0.0798, -0.0989, -0.0364,
         0.0025, -0.0718,  0.0170,  0.0645,  0.0603, -0.0516,  0.0404, -0.0728,
         0.0622, -0.0817, -0.0907,  0.0347, -0.0094,  0.0246,  0.0930,  0.0958,
         0.0564, -0.0907, -0.0154,  0.0109, -0.0974,  0.0836,  0.0656, -0.0462,
        -0.0209, -0.0580,  0.0385,  0.0172, -0.0347,  0.0535, -0.0216,  0.0107,
         0.0692, -0.0470, -0.0922,  0.0540, -0.0654,  0.0378, -0.0301,  0.0671,
        -0.0038, -0.0455, -0.0705,  0.0672, -0.0626,  0.0283,  0.0765, -0.0803,
        -0.0839,  0.0102, -0.0393, -0.0734,  0.0661, -0.0930, -0.0456, -0.0831,
         0.0264,  0.0086,  0.0417,  0.0419, -0.0004, -0.0300,  0.0884,  0.0042,
         0.0238, -0.0823, -0.0980, -0.0488, -0.0524,  0.0290, -0.0444,  0.0104,
         0.0927, -0.0295,  0.0255,  0.0012], device='cuda:0',
       requires_grad=True) 

encoder.module_4.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0658,  0.0437, -0.0046,  ..., -0.0985,  0.0879, -0.0389],
        [ 0.0153,  0.0711,  0.0383,  ..., -0.0571, -0.0231,  0.0334],
        [ 0.0378,  0.0129,  0.0656,  ...,  0.0582,  0.0935,  0.0702],
        ...,
        [ 0.0351, -0.0812,  0.0986,  ...,  0.0367, -0.0375, -0.0136],
        [ 0.0063,  0.0894,  0.0749,  ...,  0.0603, -0.0517,  0.0448],
        [ 0.0908, -0.0299, -0.0738,  ..., -0.0864,  0.0315, -0.0033]],
       device='cuda:0', requires_grad=True) 

encoder.module_4.bias torch.Size([16])
Parameter containing:
tensor([-0.0079,  0.0081, -0.0457,  0.0668, -0.0727, -0.0015,  0.0826,  0.0211,
        -0.0720,  0.0993, -0.0593, -0.0425,  0.0614, -0.0601,  0.0040,  0.0369],
       device='cuda:0', requires_grad=True) 

model.module_0.bias torch.Size([8])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

model.module_0.lin.weight torch.Size([8, 16])
Parameter containing:
tensor([[-0.4969, -0.3527,  0.3619, -0.1865, -0.1179,  0.0154, -0.0989, -0.1713,
         -0.0101, -0.2507,  0.3172, -0.0201,  0.2237,  0.0603,  0.3767,  0.2432],
        [-0.2514, -0.1175,  0.1154, -0.1804, -0.3466,  0.4192,  0.3358, -0.2498,
          0.1154,  0.3626, -0.3030, -0.0824, -0.4123, -0.4575,  0.3974,  0.1750],
        [-0.3250, -0.0371, -0.2326, -0.0911, -0.1081,  0.1584,  0.0865, -0.3390,
          0.2505,  0.0368, -0.2611, -0.2905, -0.0110,  0.1740, -0.4618, -0.1163],
        [-0.3613, -0.4675,  0.2680, -0.1718, -0.4766, -0.1440, -0.2762,  0.2703,
         -0.0785, -0.3030, -0.2044, -0.1106,  0.3827,  0.0455, -0.3957, -0.1295],
        [ 0.4608, -0.4272, -0.1875,  0.4355, -0.2017,  0.3809, -0.3274,  0.3785,
          0.3304, -0.0935, -0.4638, -0.1691,  0.1252, -0.1675, -0.3990, -0.4419],
        [ 0.2381,  0.3604, -0.1894,  0.0191, -0.3061,  0.2887, -0.3286, -0.2836,
         -0.2036, -0.0918,  0.0618, -0.4713, -0.1829, -0.2170, -0.1016, -0.0285],
        [ 0.0234,  0.2553, -0.2847,  0.0109,  0.4544,  0.0641, -0.3714,  0.3422,
         -0.4437,  0.2032,  0.4140,  0.0627,  0.2682,  0.3968,  0.2283, -0.1502],
        [ 0.1087,  0.4044,  0.1172, -0.3974,  0.4351,  0.4846,  0.2902,  0.2718,
          0.2809, -0.3036, -0.1501,  0.2161,  0.1273,  0.2125, -0.0095, -0.4818]],
       device='cuda:0', requires_grad=True) 

model.module_1.weight torch.Size([100, 8])
Parameter containing:
tensor([[ 1.6758e-01, -2.2238e-01, -2.9217e-01,  3.4964e-01,  1.5586e-01,
          1.7571e-01, -1.5490e-01,  1.3029e-01],
        [ 3.0048e-02,  2.4116e-01,  4.1357e-02,  3.1600e-01, -8.2809e-02,
          3.2626e-01,  3.5015e-01,  4.1818e-02],
        [-2.5922e-01,  1.3845e-04,  2.8142e-01, -2.4156e-01, -1.2635e-01,
          1.2785e-01,  7.1839e-02,  3.3235e-01],
        [ 5.8234e-02, -2.7037e-03,  4.6467e-02, -7.2723e-02, -3.2548e-01,
         -1.2401e-01, -3.2050e-01,  2.5869e-01],
        [ 2.1392e-02,  4.1168e-02, -2.4537e-02, -1.8141e-01, -2.4943e-01,
         -5.4116e-02,  1.0697e-01, -1.9348e-01],
        [-2.1874e-01,  2.2970e-01, -1.2276e-01,  1.9918e-01,  3.3847e-01,
          3.3231e-01, -2.7335e-01,  2.6224e-02],
        [-2.7722e-01,  1.4592e-02,  4.9167e-02, -1.5303e-01,  1.0494e-01,
         -1.1084e-01,  1.9920e-01,  3.3705e-03],
        [ 2.4541e-01,  2.3897e-01,  7.8949e-02,  6.6004e-02, -1.6002e-01,
         -2.3347e-01,  2.3837e-01,  2.3332e-01],
        [ 5.5444e-02,  2.9664e-01,  1.8461e-01,  2.3095e-01, -6.7814e-02,
          5.0539e-02, -3.1788e-01, -3.2304e-01],
        [ 1.6811e-01, -2.1312e-01,  2.6927e-01, -2.8528e-01, -2.9268e-01,
         -2.9022e-01,  2.2690e-01, -2.3435e-01],
        [-3.0320e-01,  1.4935e-01, -7.1314e-02, -3.3674e-01,  2.5075e-01,
          2.5625e-01,  2.8360e-01,  2.2194e-01],
        [-2.7410e-01, -1.5564e-01, -1.3894e-01, -3.4383e-01,  2.4707e-01,
         -1.4308e-01,  1.2135e-01, -1.7978e-01],
        [ 3.1682e-01,  2.4912e-01,  2.4401e-01,  1.7305e-01,  2.9595e-01,
          1.1559e-01,  6.0417e-02, -7.9720e-02],
        [ 2.8730e-01, -3.4115e-01,  2.5251e-01, -3.3452e-02, -2.3405e-02,
         -2.3243e-01, -1.5458e-01,  6.6692e-02],
        [-1.4407e-01,  1.2587e-01,  4.9807e-02, -3.0096e-01,  1.9323e-01,
         -1.5567e-01, -1.2774e-01, -1.3012e-01],
        [ 1.3969e-01, -3.4863e-01, -2.5480e-01,  1.4228e-01, -1.0713e-01,
         -6.7086e-02, -3.1766e-01,  3.5855e-02],
        [ 1.6639e-01, -1.2762e-01,  2.7022e-02,  1.0027e-02, -7.4866e-02,
          2.8517e-01,  9.1047e-02,  6.7201e-02],
        [-1.0997e-02, -7.4096e-03,  1.8985e-01,  2.0334e-02,  8.0005e-02,
          2.8693e-01,  2.4998e-01, -1.2975e-01],
        [-2.8951e-01,  9.3123e-02, -2.4148e-01, -3.5162e-01,  2.4278e-01,
         -2.9303e-01,  3.4897e-01, -3.2572e-01],
        [-2.8788e-01,  2.0327e-01,  2.7280e-02, -1.5410e-01,  1.3420e-01,
         -2.2971e-01, -1.9487e-01, -3.4049e-01],
        [-1.8110e-01, -3.0367e-01,  3.0295e-01, -1.5370e-01,  5.9986e-02,
         -1.5891e-01, -8.0999e-02,  2.5828e-01],
        [ 7.1954e-02,  1.7070e-01,  1.1552e-01, -2.8815e-01,  2.1233e-01,
          2.8646e-01,  1.0566e-01,  2.8164e-01],
        [-1.6846e-01, -2.3132e-01, -2.8397e-01, -5.5903e-02, -3.4965e-02,
         -2.0096e-01, -1.2091e-01, -1.1386e-01],
        [ 3.4098e-01, -2.5247e-02,  2.8662e-01,  3.4057e-02,  1.2598e-01,
          2.0374e-01, -3.2542e-01, -1.5936e-01],
        [-2.6870e-01,  3.4347e-01,  1.2974e-01, -1.4818e-01, -2.6662e-01,
          1.9579e-01,  8.2067e-02, -1.7394e-01],
        [-2.5659e-01, -1.8451e-01,  8.6095e-02, -2.9767e-01, -3.7308e-02,
          2.0985e-01,  1.8884e-01,  3.8158e-02],
        [ 3.7564e-02,  8.2609e-02,  1.3808e-01,  2.7905e-01,  9.6036e-02,
          1.9436e-01,  2.4645e-01, -2.7426e-01],
        [-1.8871e-01,  1.9411e-01,  7.0835e-02, -2.0408e-01,  1.0448e-01,
         -3.2141e-01, -1.3155e-01,  1.7828e-01],
        [-9.3158e-03, -2.3893e-01,  1.7476e-01,  2.4569e-02, -5.0597e-02,
         -3.4002e-01, -1.2753e-01,  3.9049e-02],
        [-1.9213e-01,  5.9501e-02, -2.5116e-01,  2.7282e-01,  2.7224e-01,
          2.0824e-01, -4.2002e-02, -3.5233e-01],
        [-1.3805e-01, -2.8643e-02, -3.2585e-01,  2.7835e-01,  1.0064e-01,
          2.6823e-01, -3.1632e-01, -1.8153e-01],
        [ 7.9682e-02, -5.3881e-03, -2.0562e-01,  2.5851e-01,  1.4580e-01,
         -1.6859e-02,  3.3694e-01, -3.4480e-01],
        [-3.2114e-01,  7.0511e-02,  3.2086e-01,  1.9987e-01, -1.9456e-01,
          2.5365e-01,  1.8370e-01,  2.0098e-02],
        [ 2.2368e-01,  6.9968e-02,  4.6433e-04, -9.7894e-02, -1.8784e-01,
         -2.2287e-01, -4.6477e-02, -2.4179e-01],
        [ 1.4985e-01,  9.9837e-02, -3.4471e-01, -2.6006e-01,  2.5266e-01,
         -1.8535e-01, -3.6465e-03, -2.2645e-01],
        [-7.7324e-02,  1.7437e-01,  8.9864e-02,  1.7353e-01, -2.0586e-02,
         -2.8209e-01, -4.4497e-03,  2.0961e-01],
        [ 8.2699e-02,  7.3119e-02,  6.9615e-02,  2.9009e-01,  1.7836e-01,
         -5.7825e-02, -1.9182e-01,  2.8770e-01],
        [-1.8393e-01, -2.3635e-01,  1.1044e-01, -2.2577e-01, -3.0507e-01,
         -2.8630e-01,  8.7182e-02, -2.2217e-01],
        [ 3.1276e-01, -1.4188e-02, -1.5016e-01, -2.1679e-01, -1.0570e-01,
          3.0844e-01, -2.2568e-01, -3.2735e-01],
        [ 1.0519e-01,  1.1989e-01, -2.9955e-01, -1.5870e-01,  3.0645e-01,
         -1.6712e-01,  1.4834e-01, -1.6971e-01],
        [-3.1212e-01, -3.4106e-01,  2.6969e-01,  1.0839e-01,  1.0055e-01,
          1.2169e-01,  1.3625e-01,  2.3341e-01],
        [ 2.7125e-01,  2.7264e-01,  1.1361e-01,  6.3141e-02,  7.5899e-02,
         -2.8636e-01,  1.5764e-01,  8.7190e-02],
        [ 1.5368e-01, -8.7242e-02,  2.9366e-01,  4.2472e-02, -8.3804e-02,
         -9.9935e-03, -1.4112e-01, -5.1948e-02],
        [ 3.0008e-01,  1.1728e-01, -3.9515e-02,  1.3352e-02,  8.0762e-02,
         -2.0404e-01, -1.9393e-01,  3.1175e-01],
        [ 1.9266e-03,  1.0523e-01, -1.6270e-01, -2.5988e-01,  7.0136e-02,
          1.9096e-01, -3.3300e-01, -3.4967e-01],
        [-1.1791e-01,  2.2864e-01, -3.1591e-01,  2.8246e-01,  3.1974e-01,
         -7.9345e-02,  2.2583e-02, -1.4602e-02],
        [ 3.4445e-01,  3.9289e-02,  8.6390e-02, -1.2097e-01, -4.3182e-03,
         -1.8749e-01,  1.7775e-02, -4.9060e-02],
        [ 6.5896e-02,  6.8736e-02, -2.8928e-01,  2.3621e-01,  1.9448e-01,
          2.4905e-01,  2.6038e-01,  9.1225e-02],
        [ 1.9327e-01,  1.7427e-01,  2.1080e-01, -2.1291e-01,  1.6751e-01,
         -2.8328e-02,  1.3675e-01,  1.2996e-01],
        [-2.6353e-01, -1.6084e-01, -2.5170e-01, -9.3997e-02,  1.1411e-01,
          8.2468e-02,  2.8072e-01, -2.5526e-01],
        [ 1.1064e-01,  2.8916e-01, -2.7237e-01, -2.6613e-01,  8.5088e-02,
         -1.4350e-01,  9.0416e-02, -1.7088e-01],
        [ 4.5548e-02, -2.9968e-01,  2.8169e-01, -2.2576e-01, -3.2444e-01,
         -1.8311e-01,  7.5088e-03,  3.3225e-01],
        [ 7.3921e-02, -7.3922e-02, -2.5447e-01,  1.6138e-01,  2.5782e-02,
         -1.0239e-01, -9.9146e-02,  5.1839e-02],
        [ 2.0817e-01, -2.1262e-01, -8.5395e-02,  1.6674e-01, -2.4217e-01,
         -8.7369e-03,  2.8634e-01,  2.4688e-01],
        [-2.8366e-01, -1.6594e-01,  5.6884e-02,  2.2332e-01, -1.4203e-01,
         -3.2105e-01, -1.3141e-02,  2.2176e-01],
        [-1.8181e-01, -3.2559e-01,  2.4348e-02,  2.9389e-01, -2.8661e-01,
          7.6081e-02,  2.2393e-01,  1.0643e-02],
        [-1.8948e-01, -1.2793e-01, -2.3255e-01,  2.5698e-02, -1.5385e-01,
          1.1933e-02, -7.7819e-02, -2.4212e-01],
        [ 3.4236e-01,  8.3292e-02,  1.7487e-01,  2.0935e-01,  1.4244e-01,
         -8.3659e-02, -1.0851e-01, -1.9494e-01],
        [-3.1452e-01, -2.6996e-01, -1.3464e-01,  3.3303e-01, -3.3739e-01,
         -2.2269e-01, -2.7503e-01, -2.4772e-01],
        [ 2.8912e-01, -2.7966e-01, -2.5298e-01, -2.0682e-01,  9.4783e-02,
         -1.1052e-01, -2.3542e-01,  2.9227e-01],
        [ 5.4216e-02, -2.5810e-01, -1.3200e-01,  2.1768e-01,  1.2836e-01,
         -2.2525e-01, -1.7963e-01, -1.3868e-01],
        [ 1.3505e-01, -2.8353e-01,  3.3051e-01,  3.4543e-02,  1.4047e-01,
          1.0425e-01,  2.7521e-01, -1.1560e-01],
        [-1.3359e-01, -2.3061e-01,  2.8925e-01, -2.8575e-02, -5.5187e-03,
          3.1155e-01, -8.9138e-02, -1.1863e-01],
        [-1.4762e-01,  2.0311e-01,  4.2854e-02, -1.8889e-01,  2.3232e-01,
          1.3784e-01, -8.1000e-02,  8.1203e-02],
        [-3.2043e-01, -2.5123e-01, -1.2970e-01,  1.7027e-01, -7.7166e-02,
          2.5797e-01, -3.2979e-01,  2.5723e-01],
        [-3.4184e-01, -1.2145e-01,  3.2425e-01, -1.1816e-01, -1.5417e-01,
          1.9100e-01, -1.8942e-01,  7.3279e-02],
        [-1.2684e-01,  1.3855e-01, -2.1679e-01, -1.8503e-01, -2.3486e-01,
         -6.2710e-02,  3.5106e-01,  2.0328e-01],
        [-2.8055e-01,  1.8052e-01,  3.2384e-01,  3.4989e-01,  3.5216e-02,
          9.4374e-02,  2.5660e-01,  3.4022e-01],
        [ 1.2081e-02, -6.2528e-02,  2.8698e-01, -9.4987e-02,  2.8178e-01,
          2.9918e-01,  9.8524e-02, -2.8467e-01],
        [ 2.7603e-01,  1.6887e-01,  8.4909e-02,  7.6556e-02,  1.6637e-01,
          2.0874e-01, -2.3185e-01, -2.7992e-01],
        [ 1.8313e-01, -1.4716e-01, -3.1055e-01,  2.9537e-01, -2.7404e-01,
         -1.2075e-01, -2.2208e-01,  3.0667e-01],
        [-4.5836e-02, -1.8482e-01,  2.9520e-01,  3.2905e-01,  1.8743e-01,
          2.7694e-01, -3.1836e-01, -3.1952e-01],
        [ 1.9321e-01, -7.9382e-02,  1.5033e-01,  3.2856e-01, -8.0777e-02,
         -1.8784e-01,  3.3127e-01, -1.6949e-01],
        [-2.0259e-01,  2.8373e-01, -1.4535e-02, -1.7244e-01,  1.2610e-01,
         -1.7866e-01,  1.2886e-02, -2.7854e-01],
        [-8.5346e-02,  2.7428e-01,  5.0930e-02, -4.7893e-02,  2.6811e-01,
          1.9148e-01,  1.9841e-01,  1.6777e-01],
        [-1.2098e-01, -3.1477e-01, -2.0936e-01, -2.1015e-01,  9.8457e-02,
          2.8353e-01,  3.2682e-01,  2.8311e-01],
        [ 5.0167e-02,  2.4349e-01,  1.7744e-02,  1.6421e-01, -2.3405e-01,
          3.4055e-01,  1.6345e-01,  5.1992e-04],
        [-1.4037e-01,  6.1922e-02, -4.0729e-02, -2.2884e-01, -2.1905e-01,
         -1.4103e-01,  8.1160e-02, -2.2797e-01],
        [ 1.9484e-01, -1.9472e-01,  2.1256e-01,  1.2196e-02,  6.0814e-04,
          4.7747e-02, -2.6664e-03,  1.7475e-01],
        [-2.8274e-02, -1.2482e-01,  3.6858e-02, -2.0702e-01,  1.4152e-01,
          3.5564e-02,  1.7835e-01, -6.2000e-02],
        [-1.9973e-03, -1.6835e-01, -1.5872e-01,  8.7455e-03,  1.8099e-01,
         -1.3377e-01,  2.7785e-01, -1.1937e-01],
        [-7.2682e-02,  2.8331e-01, -6.4173e-02,  1.9229e-01, -3.4812e-02,
          2.1015e-01,  4.5983e-02, -1.6660e-01],
        [-2.3290e-01,  2.0988e-01,  8.6883e-02, -5.4911e-02, -6.7548e-02,
         -1.4676e-01, -2.4489e-01,  7.8434e-02],
        [-3.0062e-01, -4.6911e-03,  2.5265e-01,  1.6131e-01,  1.9101e-01,
          6.5350e-02, -1.9776e-01,  1.8023e-01],
        [ 2.7590e-01,  1.4471e-01,  2.4626e-01, -2.8547e-01, -3.0765e-01,
         -8.1881e-02,  9.3031e-02,  2.2716e-01],
        [-1.0380e-01, -1.5651e-01,  2.2803e-01, -1.0835e-02,  2.3979e-02,
         -3.3733e-01, -3.2840e-02,  1.7152e-01],
        [ 3.4142e-01,  3.2942e-02,  2.2457e-01,  4.9144e-02, -2.7902e-01,
         -1.1914e-02, -1.2082e-01, -4.8013e-02],
        [-1.3752e-01,  2.6430e-01, -2.8862e-01, -2.1251e-01, -1.0978e-01,
          2.9621e-01, -7.2348e-02,  1.4427e-01],
        [ 1.7334e-01,  3.0261e-01, -8.1234e-02,  6.6046e-02, -1.7256e-01,
         -2.6874e-02, -3.0299e-01, -2.8848e-01],
        [ 9.6164e-02, -2.7097e-01,  1.8479e-01,  2.6131e-01,  1.2406e-01,
          1.3534e-01, -3.2122e-01, -1.6350e-01],
        [-2.5528e-01, -3.3525e-01,  1.5030e-01,  8.0955e-02,  3.3640e-01,
         -9.7408e-02, -2.3409e-01, -3.0435e-01],
        [ 2.1772e-02, -1.9376e-01,  6.2723e-02,  2.3387e-01,  3.0230e-01,
         -5.7662e-02, -2.2990e-01, -1.9198e-01],
        [ 2.2453e-01,  9.1495e-02,  2.2386e-02, -3.4351e-01,  1.9043e-01,
          2.2366e-01,  3.6487e-02, -6.3708e-02],
        [-1.6777e-01,  2.8877e-03,  1.7564e-02,  9.9735e-02, -1.4985e-02,
          3.3520e-01,  2.2790e-01,  7.9821e-02],
        [-3.1388e-01, -1.6881e-01,  1.3834e-01, -2.2849e-01,  9.8568e-02,
          8.6824e-02, -2.2228e-01,  7.0133e-02],
        [-4.5727e-02,  2.6334e-01, -7.8000e-02,  3.0854e-01,  3.0718e-01,
         -1.1722e-01,  5.9325e-02, -9.6647e-02],
        [ 2.8312e-01,  1.6951e-01,  9.6917e-04,  2.1381e-01, -2.8388e-01,
         -9.0414e-02,  7.2170e-02, -3.3496e-01],
        [ 3.0902e-01,  2.9047e-02,  3.1234e-01, -1.0290e-01,  2.1051e-02,
         -9.7511e-02, -1.4495e-01, -1.3101e-01],
        [ 2.4452e-01,  3.1767e-01,  1.0174e-01,  1.9742e-01,  1.5379e-01,
          4.4313e-04, -2.6316e-01,  8.8693e-02],
        [-1.2149e-01,  1.3537e-01, -2.3005e-01, -2.4031e-02, -1.3897e-01,
         -3.2707e-01, -3.2686e-01,  3.2620e-01]], device='cuda:0',
       requires_grad=True) 

model.module_1.bias torch.Size([100])
Parameter containing:
tensor([-3.8463e-04, -3.0478e-01,  5.7974e-02, -2.2189e-02,  2.9126e-01,
         3.3321e-01, -9.0874e-02, -2.1215e-01, -2.0261e-01, -9.4006e-02,
        -1.9408e-01,  3.1867e-01, -1.3514e-01,  1.8215e-01,  1.6000e-01,
         8.2664e-02,  1.7236e-01,  2.9939e-01,  1.5043e-01,  1.5557e-01,
        -2.9665e-01, -3.1333e-02,  8.1635e-03,  2.7689e-01,  1.5107e-01,
         2.7496e-01,  2.7347e-01, -1.6492e-01,  5.0157e-02,  3.3712e-01,
         1.2499e-01,  1.9990e-01,  1.4371e-01, -1.1098e-01,  8.4426e-02,
        -2.4429e-01,  3.2617e-01,  2.0229e-02,  2.7398e-01, -2.4854e-01,
        -3.2479e-01,  4.2333e-02, -4.5297e-02, -1.4301e-01,  1.8524e-01,
        -2.2999e-01,  3.0981e-01, -3.4514e-01,  7.2507e-02, -2.0672e-01,
         7.6700e-02,  3.4916e-01, -4.2436e-02,  8.2207e-02, -1.3914e-01,
        -1.8142e-01, -3.0201e-01,  2.0407e-01, -3.9265e-03,  1.2243e-01,
        -2.7192e-01, -2.9436e-01, -3.2148e-01, -2.0375e-01, -4.5971e-02,
        -5.3346e-02,  1.5546e-01, -1.6988e-01,  3.4450e-01, -1.6112e-01,
        -3.3248e-01,  2.6745e-01, -2.2722e-01,  3.3695e-02, -3.4134e-02,
        -7.3750e-02,  2.2907e-04, -3.4767e-01,  3.1793e-01, -2.2952e-01,
         2.1556e-01, -2.0906e-01, -8.7061e-02, -8.3615e-03, -1.3935e-01,
        -1.5317e-01, -2.9760e-01, -2.4283e-01, -1.6589e-02, -1.0335e-01,
        -4.9652e-02,  9.0191e-02, -4.5326e-02, -3.3469e-01, -1.3003e-01,
         1.0822e-01,  1.2724e-01,  1.7109e-01,  1.9579e-02,  2.4172e-01],
       device='cuda:0', requires_grad=True) 

model.module_3.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0684, -0.0839, -0.0267,  ...,  0.0141, -0.0744,  0.0252],
        [-0.0200, -0.0735, -0.0925,  ..., -0.0801, -0.0660, -0.0095],
        [ 0.0212,  0.0074,  0.0961,  ..., -0.0185,  0.0870, -0.0490],
        ...,
        [ 0.0836,  0.0836,  0.0262,  ..., -0.0124,  0.0937, -0.0344],
        [-0.0998, -0.0591,  0.0262,  ...,  0.0155,  0.0849,  0.0046],
        [-0.0929,  0.0576, -0.0187,  ...,  0.0516,  0.0128, -0.0501]],
       device='cuda:0', requires_grad=True) 

model.module_3.bias torch.Size([100])
Parameter containing:
tensor([-0.0779,  0.0531,  0.0296,  0.0260, -0.0370, -0.0976,  0.0137, -0.0172,
        -0.0076,  0.0095, -0.0585, -0.0623, -0.0290,  0.0388, -0.0626,  0.0932,
        -0.0984, -0.0621,  0.0287, -0.0973, -0.0555,  0.0516, -0.0678,  0.0320,
        -0.0533, -0.0473,  0.0174,  0.0097,  0.0907,  0.0208,  0.0174, -0.0519,
         0.0869, -0.0013,  0.0598, -0.0800,  0.0523,  0.0812,  0.0648,  0.0835,
        -0.0455, -0.0717,  0.0360,  0.0433, -0.0608, -0.0321, -0.0013, -0.0084,
         0.0478,  0.0710,  0.0289, -0.0396, -0.0624,  0.0864,  0.0112, -0.0523,
        -0.0746, -0.0679,  0.0934, -0.0630, -0.0974, -0.0749, -0.0475, -0.0031,
        -0.0686,  0.0440, -0.0164, -0.0416, -0.0607, -0.0317,  0.0972,  0.0050,
         0.0282, -0.0969,  0.0611,  0.0158, -0.0111,  0.0018, -0.0462, -0.0776,
        -0.0500,  0.0314,  0.0845, -0.0696,  0.0460, -0.0486,  0.0754,  0.0122,
        -0.0909, -0.0863,  0.0241,  0.0559,  0.0295,  0.0275, -0.0157, -0.0499,
         0.0172, -0.0793,  0.0499, -0.0381], device='cuda:0',
       requires_grad=True) 

model.module_5.weight torch.Size([16, 100])
Parameter containing:
tensor([[-0.0896,  0.0109,  0.0384,  ..., -0.0713, -0.0207, -0.0481],
        [ 0.0197, -0.0986,  0.0931,  ..., -0.0521,  0.0855, -0.0166],
        [ 0.0494, -0.0456, -0.0584,  ..., -0.0272,  0.0233,  0.0812],
        ...,
        [-0.0566,  0.0313, -0.0747,  ...,  0.0287,  0.0282, -0.0924],
        [-0.0077,  0.0880,  0.0084,  ..., -0.0032, -0.0096, -0.0573],
        [ 0.0477, -0.0698,  0.0825,  ..., -0.0027, -0.0697, -0.0981]],
       device='cuda:0', requires_grad=True) 

model.module_5.bias torch.Size([16])
Parameter containing:
tensor([ 0.0439,  0.0473, -0.0163, -0.0916,  0.0850,  0.0872,  0.0966,  0.0595,
         0.0851, -0.0690, -0.0973, -0.0750,  0.0988, -0.0891, -0.0270,  0.0990],
       device='cuda:0', requires_grad=True) 

model.module_7.bias torch.Size([8])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

model.module_7.lin.weight torch.Size([8, 16])
Parameter containing:
tensor([[ 0.1192, -0.2777, -0.4798,  0.0174, -0.1781,  0.4204,  0.1690, -0.2428,
          0.1147, -0.2856,  0.4617,  0.2772,  0.2475,  0.2179, -0.0493, -0.1308],
        [ 0.0461, -0.4993, -0.2613,  0.0579,  0.3661,  0.0011, -0.1715,  0.3398,
          0.1337, -0.3066,  0.2203,  0.1268, -0.4107,  0.0935, -0.3315,  0.4556],
        [-0.3147, -0.0860, -0.2084,  0.0462,  0.4359, -0.2377,  0.1602, -0.1073,
         -0.2117,  0.0166,  0.3756, -0.4518, -0.2084,  0.3795, -0.2403,  0.1155],
        [ 0.1880,  0.0414,  0.0401, -0.3345, -0.0784, -0.0963, -0.0253, -0.0552,
         -0.1170, -0.2973,  0.3562,  0.1451,  0.1668,  0.2481,  0.0103,  0.3248],
        [ 0.1555, -0.1511,  0.0070, -0.4358, -0.2591,  0.4652,  0.4950, -0.3576,
         -0.2177,  0.2751, -0.4470, -0.0555, -0.4582, -0.2366, -0.2622, -0.0237],
        [-0.1329, -0.2756,  0.2613, -0.2213, -0.4918,  0.2434,  0.3285, -0.1081,
          0.0146,  0.0639, -0.0626, -0.1016, -0.4071,  0.2189, -0.0020,  0.2652],
        [ 0.0330, -0.1985, -0.2469,  0.0650,  0.2558,  0.4974,  0.4481,  0.4101,
         -0.3787,  0.0906,  0.4555,  0.2267,  0.3331,  0.4745, -0.1509,  0.2673],
        [ 0.2962,  0.0089, -0.2939,  0.1380,  0.4162,  0.0622,  0.1569,  0.0686,
          0.3531,  0.2662, -0.1120,  0.0814, -0.2340,  0.0783, -0.4312,  0.1714]],
       device='cuda:0', requires_grad=True) 

model.module_8.weight torch.Size([100, 8])
Parameter containing:
tensor([[ 2.1422e-01, -2.9666e-01,  9.6425e-02, -4.8519e-02, -1.4018e-01,
          1.5811e-01,  1.6022e-02, -1.8636e-01],
        [ 2.4251e-01,  9.1977e-02, -2.4447e-01, -5.7527e-02, -1.9176e-01,
         -2.2249e-01,  3.3738e-01, -3.7258e-02],
        [-2.0843e-02, -4.2253e-02, -7.9461e-02, -3.0005e-01, -4.6638e-02,
         -1.4743e-01,  1.4729e-01, -9.8707e-03],
        [-3.4649e-01, -2.0978e-01, -2.6544e-01,  2.1663e-02,  2.1839e-01,
          1.6257e-01,  2.1524e-02,  2.0212e-01],
        [-3.8358e-02,  3.2604e-01, -2.9464e-01, -9.4244e-02, -4.8319e-02,
         -2.6734e-01,  1.1155e-01,  2.4226e-01],
        [ 5.8863e-02,  3.0754e-02,  3.0633e-01, -1.2609e-01, -5.5475e-02,
          1.3129e-01, -1.9344e-01, -2.6718e-01],
        [-7.1604e-02,  2.3059e-01, -1.8194e-01,  1.0159e-01,  6.4494e-03,
          3.2452e-01,  1.8644e-01, -1.8671e-01],
        [-3.4021e-01,  2.1037e-01, -3.2514e-01, -2.0726e-01,  3.4328e-01,
          1.0427e-01, -4.7838e-03, -2.6869e-01],
        [-6.6125e-02,  4.7437e-02,  2.0948e-01, -1.3813e-01, -6.2205e-02,
          7.0352e-02, -3.4768e-01, -1.0933e-01],
        [-3.2314e-01, -1.2711e-01, -2.0909e-01,  1.7330e-01, -2.4435e-01,
         -3.3290e-01, -4.0570e-02, -1.6658e-01],
        [-1.8496e-01, -8.2535e-02,  1.3175e-01, -3.1288e-01, -2.5632e-01,
          2.5772e-02,  1.5837e-01,  1.3895e-02],
        [ 3.5112e-01,  1.7579e-01, -2.3888e-01,  1.9991e-01, -1.8291e-01,
          2.6057e-01, -8.9863e-02,  2.9438e-01],
        [-8.2921e-02, -1.0282e-01, -2.5834e-01,  3.4987e-01, -2.0184e-01,
         -1.5423e-01, -1.9409e-01, -3.4952e-01],
        [-1.7446e-01,  2.9148e-01,  2.2565e-01,  9.0871e-02, -1.0385e-01,
          4.8715e-02, -6.5855e-02, -2.8962e-01],
        [ 2.4011e-01,  1.8546e-01,  3.0529e-01, -3.3025e-01,  5.5493e-02,
          1.9948e-01, -4.8918e-02,  1.6402e-01],
        [ 1.7551e-01, -1.7426e-01,  2.5996e-01,  8.9494e-02, -3.8660e-02,
          1.2790e-01,  2.6713e-01,  6.5763e-02],
        [ 1.7104e-01, -2.3991e-01, -1.6394e-01, -6.0955e-02,  2.0207e-01,
          2.0083e-01, -9.6184e-02, -5.5575e-02],
        [-4.8527e-02, -1.6383e-01,  2.9726e-01,  1.7846e-01,  2.3089e-01,
         -1.1960e-01, -8.4925e-02, -2.9440e-01],
        [ 2.6292e-01, -1.3378e-01, -2.9150e-02, -2.3481e-01,  7.2805e-02,
          1.9347e-01, -3.5145e-01,  2.7132e-01],
        [ 6.4934e-02,  1.6884e-01, -3.0896e-01,  9.0579e-02,  3.4629e-01,
          2.3299e-01, -1.5873e-01,  1.9231e-02],
        [-2.4185e-01,  1.4173e-01,  1.6772e-01,  1.5314e-01, -3.0647e-01,
          1.7185e-01,  1.3422e-02, -2.4691e-01],
        [-1.2084e-01,  3.1076e-01, -2.8404e-01,  2.0900e-01,  3.4434e-01,
         -2.5965e-01, -3.2689e-01, -2.6773e-01],
        [ 6.5414e-03, -3.3149e-01,  2.8938e-01,  3.1475e-01, -3.9611e-02,
          1.9327e-01,  2.9004e-01,  1.1300e-01],
        [-1.7404e-01, -1.1793e-02,  2.4795e-01, -1.4550e-01,  8.1375e-03,
         -4.7505e-02, -6.7571e-02, -5.9149e-02],
        [-1.8256e-01, -1.0984e-01,  3.2409e-01, -1.0875e-01, -5.0106e-02,
          3.0517e-01,  1.2523e-01, -2.4963e-01],
        [-9.9760e-02, -1.3450e-01, -1.9653e-01, -2.9363e-01,  1.7511e-01,
          2.7263e-01, -2.7976e-01,  3.5328e-01],
        [ 1.6403e-01,  3.0770e-01, -2.7869e-01,  1.0516e-01,  2.4410e-01,
          1.9696e-01, -1.0525e-01,  2.3169e-01],
        [ 1.8142e-01, -2.2475e-01,  1.8611e-01, -1.6869e-01,  2.7919e-01,
         -1.1044e-01, -2.1208e-01,  1.6012e-01],
        [-2.0372e-01, -1.4426e-01,  2.2881e-01,  3.1997e-01,  1.1372e-01,
          3.1283e-01,  1.3632e-01, -5.4247e-02],
        [-1.1804e-01, -9.2761e-02,  7.6921e-03, -4.0659e-02,  7.4398e-02,
          9.1032e-02, -2.2861e-01, -1.9980e-01],
        [ 2.9321e-01, -1.5178e-01,  1.8409e-01,  3.3318e-01, -3.2111e-01,
          5.7438e-02,  8.8541e-02, -2.1936e-01],
        [-8.8337e-02, -1.6875e-01, -3.5081e-01, -1.2262e-01,  3.2356e-01,
          3.3616e-01, -2.0833e-01, -1.1267e-01],
        [-1.8318e-01,  2.3738e-01, -2.9034e-01, -1.2031e-01, -1.1305e-01,
         -1.4265e-01,  3.0334e-01, -3.0719e-01],
        [-2.7989e-01, -2.9127e-01, -1.5981e-01,  1.9197e-01,  4.8609e-02,
         -1.6027e-02,  2.7689e-01,  2.4368e-01],
        [ 8.2535e-02,  6.7142e-02, -1.4146e-01, -3.4161e-01,  6.2700e-02,
          3.0405e-01,  2.5679e-01, -3.2966e-02],
        [-9.4640e-03,  3.4149e-01, -3.5317e-01,  3.1045e-01,  3.4562e-01,
          2.2295e-01,  1.4140e-01,  1.4580e-02],
        [ 1.2259e-01, -1.8355e-01, -5.3684e-02, -2.2696e-01,  4.2754e-02,
         -9.4468e-02,  3.1535e-01,  1.2943e-01],
        [ 1.6409e-01, -2.3555e-01, -4.0922e-03,  3.0975e-01,  1.4455e-01,
         -3.0850e-01, -1.4587e-01,  2.0325e-01],
        [ 1.8847e-01,  4.9609e-02, -9.6309e-02,  2.0632e-01,  9.7829e-02,
          3.5831e-02,  1.0897e-01, -2.0260e-01],
        [-2.4494e-01,  2.2822e-01, -1.9297e-01, -2.5686e-01, -2.8594e-01,
          2.7998e-01,  1.4451e-01,  1.5306e-01],
        [ 2.5497e-01, -3.3208e-01, -2.8602e-01,  1.3417e-01,  3.0513e-01,
          1.5952e-01,  3.2990e-02,  3.4335e-01],
        [-1.5468e-01,  3.0411e-01,  2.8896e-01, -2.7557e-01, -3.1049e-02,
          2.9334e-01,  3.2751e-01, -7.0271e-02],
        [ 3.0933e-01, -2.8677e-01,  9.5684e-02,  6.3508e-02,  1.0106e-01,
          1.9150e-01,  6.0829e-02,  1.8182e-01],
        [ 2.7793e-01,  2.0038e-01,  2.2606e-01,  3.5182e-01,  2.7732e-01,
          2.1251e-02, -2.4813e-01,  1.5395e-01],
        [ 3.5851e-02,  3.2288e-01, -1.0186e-01,  1.1558e-02, -3.3008e-01,
         -1.6931e-01,  2.5446e-01, -2.2872e-01],
        [-1.8141e-01,  1.4672e-02,  1.6340e-02,  2.5283e-01, -2.3070e-01,
          6.3871e-02, -2.2174e-01,  1.7657e-01],
        [ 1.3561e-01, -5.1875e-02,  2.5291e-01,  2.4704e-01, -2.0120e-01,
         -3.0689e-01,  1.7374e-01, -2.8963e-01],
        [ 4.4220e-02,  2.9544e-02,  1.2482e-01,  1.7673e-01, -1.8845e-01,
          2.2039e-02, -2.0815e-01,  2.4983e-01],
        [ 1.0398e-01,  3.0863e-01,  2.7907e-01,  1.5813e-01,  2.2357e-01,
          3.4177e-04, -2.6416e-01, -1.4542e-01],
        [-1.3905e-01, -1.5412e-01, -1.7883e-01, -3.4512e-01,  6.5854e-02,
         -2.2433e-01, -3.0828e-01,  1.0984e-01],
        [-3.3117e-01,  7.6654e-02, -2.0599e-02,  1.8661e-01,  2.9290e-01,
          1.7425e-01, -2.8367e-01, -3.3794e-02],
        [ 1.6144e-01, -2.7765e-01, -3.4180e-01, -3.1697e-01, -2.6354e-01,
          1.5320e-01, -1.0492e-01,  1.4333e-01],
        [-1.8829e-01, -8.9449e-02, -5.2713e-02,  3.3989e-01,  4.6724e-02,
         -2.8904e-01,  2.7283e-01,  1.9756e-02],
        [ 3.1914e-01, -3.0243e-03, -2.8622e-01,  5.8572e-02, -1.9366e-01,
         -2.4306e-01,  3.7063e-02,  1.3311e-01],
        [-1.8396e-01, -1.0110e-01, -1.3787e-01,  2.6680e-01,  8.7830e-02,
         -7.6518e-02, -1.1330e-01, -1.2855e-01],
        [-1.2146e-02,  8.5311e-02, -1.3647e-01, -1.4708e-01, -2.6149e-01,
          3.1821e-01, -1.4570e-01,  3.1112e-01],
        [-3.5525e-02, -8.0884e-02, -1.2590e-01, -4.4818e-03, -1.4813e-02,
          8.9845e-02, -1.6738e-01,  3.0448e-01],
        [ 8.1271e-02, -5.7217e-02, -2.4117e-01,  8.7072e-02, -1.9029e-02,
         -5.3339e-02, -3.2264e-01,  1.3544e-01],
        [ 4.1801e-02,  2.1473e-01, -1.9840e-01,  2.1343e-01,  2.7094e-01,
          8.0153e-02,  2.6631e-01, -3.3830e-01],
        [ 2.2964e-01, -1.1118e-01,  1.2445e-01,  2.5842e-01,  4.7427e-02,
         -5.8886e-03,  1.5550e-01,  3.3946e-01],
        [-2.5242e-01,  3.2945e-01,  5.5873e-02,  1.8655e-01, -1.1284e-02,
         -7.3096e-02, -5.5821e-02, -7.7938e-02],
        [-3.0555e-01,  2.5265e-01,  1.7590e-01, -3.5029e-01,  1.7228e-01,
         -2.6646e-01, -1.4690e-01,  3.0368e-01],
        [-3.1247e-02,  2.2572e-01,  2.0423e-01,  3.3143e-02, -3.3900e-01,
          2.4776e-01, -1.4789e-01, -2.3157e-01],
        [-1.1509e-01,  2.8464e-01, -9.6835e-02,  1.4924e-01,  3.8128e-02,
         -1.6969e-01,  5.2441e-02,  2.7847e-01],
        [ 2.8815e-01, -9.0493e-04,  3.2476e-02,  2.1229e-01, -1.2967e-01,
         -6.7788e-02,  1.8420e-01,  2.4869e-01],
        [ 4.3664e-02, -3.4852e-02, -3.0288e-01, -2.7160e-02, -2.3464e-01,
         -6.8697e-02, -5.9211e-03,  1.3539e-01],
        [ 3.0307e-01,  2.3457e-02,  5.4176e-02, -1.5820e-01, -2.5735e-01,
         -3.1578e-01,  7.5959e-02,  5.0132e-02],
        [ 3.1156e-01,  2.0371e-01,  1.2665e-02, -1.1308e-01,  2.4472e-01,
         -3.0693e-01, -1.0672e-02,  1.2441e-01],
        [-3.4619e-01,  2.7270e-01, -8.9835e-02,  3.0272e-01, -6.1860e-02,
         -2.1188e-01,  1.7217e-01, -2.2785e-01],
        [-2.4996e-01, -1.0630e-01,  2.1728e-01,  1.1666e-01,  2.7698e-01,
         -1.2035e-01, -2.8744e-05, -1.1572e-01],
        [ 3.3724e-01,  2.6508e-02, -3.2929e-01,  7.3785e-02, -2.4757e-01,
          4.7897e-02,  9.5569e-02, -1.7447e-01],
        [-3.1463e-01, -3.5294e-02, -2.4127e-01,  3.4564e-01, -1.4478e-01,
         -8.1798e-02,  2.5951e-01, -5.9335e-02],
        [ 2.3666e-03, -3.5177e-01,  1.5391e-01,  2.5112e-01, -3.4394e-01,
          3.4071e-01,  2.3718e-01,  1.7933e-01],
        [-1.1877e-02, -3.7663e-02,  3.2138e-01,  1.7294e-01, -2.0012e-01,
         -1.9374e-01,  3.1573e-01, -1.8702e-01],
        [-1.2220e-01, -2.5323e-01,  1.0893e-01, -6.9692e-02,  3.1677e-01,
         -1.5934e-01,  1.0334e-01, -2.3223e-01],
        [-2.4338e-01, -3.2774e-01,  5.0253e-03,  8.4507e-02,  1.5015e-01,
          3.4630e-01,  1.7120e-01,  5.8453e-04],
        [ 1.9614e-01, -3.2884e-01,  3.3935e-01, -2.9909e-01,  2.0491e-01,
         -2.1360e-01,  3.3754e-01,  9.8990e-02],
        [ 1.6841e-01,  1.1140e-01, -1.5901e-01,  1.7829e-02,  9.3685e-02,
          1.0849e-01,  1.0678e-01,  2.9050e-01],
        [-4.5670e-02, -2.1778e-01,  1.6751e-01,  2.6687e-01,  2.5494e-01,
         -2.4070e-01, -4.6427e-03,  8.5169e-02],
        [-7.0601e-03,  1.6232e-01, -3.2794e-01,  1.9441e-01, -1.0454e-01,
          6.4184e-02, -7.3734e-02, -3.1702e-01],
        [ 1.3948e-01,  6.3399e-03, -3.2149e-02,  2.7352e-01,  3.0241e-01,
         -1.5284e-01, -9.5041e-02, -1.0634e-01],
        [-2.5108e-01, -3.1881e-01, -1.5772e-01, -2.0099e-01, -5.3276e-02,
         -3.0820e-02,  2.5060e-01, -3.0893e-02],
        [ 1.8518e-01, -3.4056e-01, -3.3870e-02, -5.4575e-02,  1.1034e-01,
          2.4316e-01,  2.3784e-01,  6.8589e-02],
        [ 1.5176e-01,  2.5775e-01,  2.9257e-01,  1.4473e-01, -2.4413e-01,
          2.3248e-01,  1.0148e-01,  2.4619e-01],
        [ 1.1512e-01,  9.7542e-02,  2.7334e-02,  2.2856e-01,  2.8086e-01,
          3.5004e-01, -3.0178e-01,  1.7598e-01],
        [ 2.8509e-01, -1.8345e-01, -3.0940e-01,  1.8525e-01,  4.0258e-02,
          2.8964e-01,  1.4843e-01,  2.6978e-01],
        [-2.9583e-01, -1.0828e-01, -3.3590e-01,  5.4678e-02,  2.3327e-01,
         -2.4965e-01,  2.3407e-01, -3.0996e-01],
        [ 2.3846e-01, -2.9543e-01, -2.7520e-01, -1.7961e-01,  1.0040e-01,
         -3.2017e-01,  1.6729e-01, -3.3189e-01],
        [-2.8477e-02, -1.1313e-01, -6.5886e-02, -2.2734e-01,  3.4438e-01,
          3.2584e-01, -3.5274e-01, -4.9578e-02],
        [-2.7405e-01, -2.9973e-01, -1.1943e-01,  2.2385e-01, -3.2727e-01,
          3.2752e-01,  3.1156e-01,  1.4787e-01],
        [ 2.6488e-01,  5.7713e-02,  1.7455e-01,  1.8262e-01, -3.1543e-01,
          9.0601e-02, -1.2865e-02, -3.4150e-01],
        [ 2.7447e-01, -1.1147e-01,  4.8744e-02, -1.7832e-01,  2.2529e-01,
          2.2018e-02, -1.3297e-01, -1.5862e-01],
        [ 8.8634e-02, -3.0970e-01,  1.5014e-01, -2.9890e-01, -2.2227e-01,
          4.8381e-02, -1.9032e-01,  1.1446e-01],
        [-2.2747e-01, -1.1496e-01,  1.4139e-01,  1.8394e-01, -8.1498e-02,
          1.2171e-01, -2.7547e-01, -7.1140e-02],
        [ 2.2125e-01, -3.0823e-02, -3.0921e-01, -3.4435e-02, -5.2811e-02,
          1.2135e-01, -7.3337e-02, -2.4386e-01],
        [ 6.9878e-02,  2.6087e-01, -8.3848e-02,  1.0243e-01,  5.8792e-02,
          5.5866e-02, -5.3563e-02, -2.1740e-02],
        [-3.4060e-01,  2.0966e-01, -2.1200e-01, -2.7537e-01, -2.1222e-01,
          1.0111e-01, -7.1109e-02, -2.0712e-01],
        [ 1.9655e-01, -1.7380e-01, -2.4746e-01,  1.7033e-01, -1.4780e-01,
         -2.3224e-01, -1.0685e-01, -1.7318e-01],
        [ 4.1117e-03, -1.5284e-01,  1.2197e-02, -2.1839e-02,  2.4325e-01,
          2.2117e-01, -1.7195e-01,  1.3500e-01],
        [-3.1475e-01, -2.7706e-01, -2.4125e-01, -1.5143e-01, -3.3724e-01,
          2.0582e-01,  2.9673e-01, -2.7537e-01]], device='cuda:0',
       requires_grad=True) 

model.module_8.bias torch.Size([100])
Parameter containing:
tensor([-0.3233, -0.1064,  0.2763,  0.0960,  0.0200,  0.3375,  0.2820,  0.1690,
        -0.1803, -0.0894, -0.0580, -0.0629,  0.0836,  0.2220, -0.1992, -0.3439,
        -0.3088,  0.0937, -0.2286,  0.1752,  0.1115,  0.1058, -0.1345,  0.1773,
         0.2437,  0.1136,  0.0211,  0.1520,  0.0408,  0.0872,  0.1421,  0.3164,
        -0.0590,  0.1795,  0.2729, -0.2864, -0.0075, -0.2959, -0.2640,  0.2250,
        -0.2726,  0.3309,  0.3139, -0.2354, -0.3138, -0.0575, -0.3200,  0.1830,
        -0.1201,  0.0794, -0.0045, -0.0318, -0.1980,  0.0943,  0.1334,  0.0272,
        -0.0174, -0.1344, -0.1572,  0.1005,  0.1444, -0.1456, -0.1553,  0.2988,
         0.2269, -0.3357, -0.2056, -0.0105, -0.1481,  0.0335, -0.1307, -0.3535,
        -0.2557,  0.2240,  0.0614,  0.3270,  0.2945, -0.0379,  0.2006, -0.0559,
         0.1750, -0.2756, -0.1220,  0.0113,  0.0574,  0.1217,  0.3198,  0.3013,
        -0.2438, -0.0514, -0.0133,  0.1297, -0.2389,  0.1500,  0.1110,  0.2116,
        -0.1021,  0.0510,  0.1905,  0.3177], device='cuda:0',
       requires_grad=True) 

model.module_10.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0296,  0.0552, -0.0351,  ...,  0.0160, -0.0781, -0.0524],
        [-0.0995, -0.0349, -0.0464,  ..., -0.0899, -0.0671, -0.0296],
        [-0.0685,  0.0637, -0.0054,  ..., -0.0668, -0.0258, -0.0290],
        ...,
        [ 0.0103, -0.0274,  0.0294,  ..., -0.0638, -0.0698, -0.0770],
        [-0.0008, -0.0909,  0.0721,  ...,  0.0208, -0.0843, -0.0220],
        [-0.0803,  0.0688, -0.0961,  ...,  0.0578, -0.0505,  0.0378]],
       device='cuda:0', requires_grad=True) 

model.module_10.bias torch.Size([100])
Parameter containing:
tensor([-0.0157, -0.0224, -0.0229,  0.0207, -0.0374,  0.0926,  0.0133,  0.0831,
         0.0029, -0.0320, -0.0212, -0.0529, -0.0065,  0.0879, -0.0031,  0.0770,
        -0.0961, -0.0216,  0.0501,  0.0361,  0.0045, -0.0520, -0.0171, -0.0297,
        -0.0376, -0.0047, -0.0294, -0.0257, -0.0455, -0.0251, -0.0233,  0.0258,
        -0.0318,  0.0301, -0.0144, -0.0878,  0.0206, -0.0727,  0.0846, -0.0435,
         0.0437, -0.0309, -0.0363, -0.0931, -0.0916,  0.0721, -0.0163, -0.0909,
        -0.0822, -0.0290, -0.0169,  0.0342, -0.0008, -0.0222, -0.0713, -0.0855,
         0.0139, -0.0334,  0.0060, -0.0905, -0.0454, -0.0410,  0.0363,  0.0811,
        -0.0631,  0.0018, -0.0146,  0.0105,  0.0262, -0.0028, -0.0576, -0.0736,
         0.0893, -0.0082,  0.0644, -0.0822,  0.0110, -0.0620,  0.0630, -0.0574,
         0.0817,  0.0379, -0.0844,  0.0767, -0.0077,  0.0879, -0.0169,  0.0072,
         0.0043,  0.0954, -0.0448,  0.0431, -0.0213, -0.0763,  0.0595, -0.0799,
        -0.0580, -0.0708,  0.0985,  0.0679], device='cuda:0',
       requires_grad=True) 

model.module_12.weight torch.Size([16, 100])
Parameter containing:
tensor([[-0.0218, -0.0561,  0.0505,  ..., -0.0974,  0.0467,  0.0583],
        [ 0.0505,  0.0220, -0.0839,  ..., -0.0093,  0.0723, -0.0532],
        [ 0.0841,  0.0916, -0.0457,  ..., -0.0735, -0.0836, -0.0631],
        ...,
        [ 0.0542,  0.0732, -0.0270,  ...,  0.0974, -0.0376, -0.0574],
        [ 0.0276,  0.0783, -0.0911,  ..., -0.0791,  0.0565,  0.0299],
        [ 0.0878,  0.0606, -0.0867,  ..., -0.0040, -0.0184, -0.0839]],
       device='cuda:0', requires_grad=True) 

model.module_12.bias torch.Size([16])
Parameter containing:
tensor([ 0.0480, -0.0736,  0.0880,  0.0830, -0.0743,  0.0449,  0.0114, -0.0458,
        -0.0384, -0.0241,  0.0049, -0.0137, -0.0333, -0.0744,  0.0827, -0.0639],
       device='cuda:0', requires_grad=True) 

model.module_14.bias torch.Size([8])
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True) 

model.module_14.lin.weight torch.Size([8, 16])
Parameter containing:
tensor([[ 0.0494,  0.2038, -0.1644, -0.0112, -0.2707,  0.0292, -0.0987,  0.1929,
          0.4930,  0.4196,  0.0338, -0.4551,  0.4588,  0.0045, -0.1087,  0.2355],
        [ 0.1375,  0.2083, -0.1501,  0.3132,  0.0721, -0.3514,  0.3696, -0.1774,
          0.4024,  0.2012,  0.1655,  0.1564,  0.1528,  0.4309,  0.0793,  0.2903],
        [-0.1324,  0.1747,  0.1447, -0.2072,  0.2759,  0.3557,  0.3201,  0.4748,
         -0.4029, -0.1708,  0.2682, -0.0734, -0.1391,  0.1152,  0.3986,  0.2632],
        [-0.1078,  0.3439, -0.4176,  0.3692,  0.1951,  0.1936, -0.0120,  0.0766,
          0.3803,  0.0318, -0.2793,  0.1589,  0.0315, -0.0149, -0.1509,  0.3458],
        [-0.0989, -0.3875, -0.2049, -0.3751, -0.3261, -0.1306,  0.0326,  0.2354,
         -0.0279,  0.4049, -0.4470, -0.2452, -0.2032,  0.3514, -0.0391, -0.1060],
        [ 0.4132, -0.4269,  0.0677,  0.2519,  0.2465,  0.3879,  0.3470,  0.4924,
          0.3909, -0.0294,  0.0129,  0.2568, -0.2018, -0.4833,  0.0639, -0.1592],
        [-0.3602,  0.0915,  0.1613,  0.4631, -0.2037,  0.0767, -0.4252, -0.2351,
          0.1854, -0.2429, -0.0098, -0.4202,  0.1557,  0.1525, -0.2051,  0.4612],
        [-0.4724,  0.2179, -0.3803,  0.1152, -0.1198, -0.0131,  0.0358, -0.4635,
          0.3145, -0.4240,  0.2332, -0.3511, -0.0445, -0.3520,  0.1275,  0.3598]],
       device='cuda:0', requires_grad=True) 

model.module_15.weight torch.Size([100, 8])
Parameter containing:
tensor([[-2.5749e-01,  9.2783e-02,  1.7237e-02, -3.6452e-02, -1.4611e-01,
         -3.2281e-01,  2.5103e-01, -2.6306e-01],
        [ 3.2317e-01, -1.1744e-01,  1.2244e-01,  1.4035e-01, -5.4700e-02,
         -1.8851e-01, -2.1230e-01,  3.1660e-01],
        [-3.2356e-01,  3.2524e-01, -1.2912e-01,  2.2444e-01, -2.8537e-01,
         -1.8870e-02, -1.7085e-01, -1.9306e-01],
        [ 1.2990e-01,  2.3936e-01, -2.6136e-01,  1.6858e-01, -2.9432e-01,
          1.7141e-01,  1.5590e-01,  1.9144e-01],
        [ 2.6024e-01,  1.1696e-01,  3.4392e-01,  6.6399e-02,  2.9736e-01,
          6.9515e-02,  8.0094e-02, -2.2516e-01],
        [-6.3217e-02,  9.3730e-02, -1.2844e-01,  1.5198e-01,  9.7268e-02,
         -1.5849e-01, -2.1235e-01,  1.6444e-01],
        [-2.4890e-01,  1.2919e-01, -2.2004e-01, -3.0806e-01,  3.3485e-03,
         -5.5823e-02,  1.2986e-01, -1.0596e-02],
        [-2.7929e-01, -2.1154e-04, -2.1533e-01,  9.8279e-02,  2.6648e-01,
         -1.5092e-01, -1.9466e-01, -8.2416e-02],
        [-6.9002e-02,  2.6687e-02,  2.4328e-02,  1.1747e-01, -1.3049e-01,
         -1.4568e-01,  3.0466e-01,  2.0155e-01],
        [ 1.7431e-01, -2.3577e-01,  2.3694e-01,  3.3554e-01, -1.3779e-01,
         -3.3683e-01,  1.1740e-01, -1.7460e-01],
        [ 1.3173e-01, -1.1308e-01,  3.1094e-01, -1.0064e-01,  2.2950e-02,
         -6.1074e-02, -1.8092e-01,  1.2623e-01],
        [ 2.4599e-01, -3.0621e-01,  1.2400e-02,  2.2898e-01,  1.1355e-01,
         -3.3932e-01, -1.9767e-02,  1.5737e-01],
        [ 1.1133e-01, -3.5344e-01, -6.9702e-02, -2.2573e-01, -1.5751e-01,
         -6.0756e-03,  3.1733e-01,  1.8839e-01],
        [-2.2583e-01,  1.8728e-01, -1.9012e-01,  8.2666e-02, -2.9707e-01,
          3.4660e-02, -1.3638e-01,  3.4109e-01],
        [-2.5708e-01, -1.7555e-01,  1.9114e-01, -1.3664e-01,  1.0724e-01,
          3.1753e-01, -2.8795e-01, -3.2292e-01],
        [-6.2861e-03,  4.2805e-02,  1.7533e-01,  1.5398e-01, -2.6586e-01,
          2.9689e-01, -8.4860e-02,  2.1917e-01],
        [-2.2358e-01,  1.0053e-01,  2.1813e-01,  2.1323e-01, -2.3896e-01,
         -2.2006e-01,  2.9492e-02,  8.1502e-02],
        [ 2.7416e-01,  1.3839e-03,  3.4751e-01, -1.6841e-01,  1.5545e-01,
          2.2087e-01,  2.4984e-01, -2.1077e-01],
        [ 1.2919e-02,  1.3704e-01, -1.1290e-01,  5.9634e-02,  2.1738e-01,
          6.7488e-02, -1.0636e-01, -3.2899e-01],
        [-2.9780e-01, -1.4648e-01, -2.2127e-01,  1.8668e-01,  6.4377e-02,
          1.1045e-01, -3.1901e-01,  1.3630e-01],
        [ 4.8024e-03, -2.5435e-01, -2.8247e-01,  9.1066e-02,  1.7201e-02,
         -2.4917e-01, -4.8821e-02,  2.0718e-02],
        [ 1.9560e-01, -1.5709e-01, -2.7946e-01,  1.2725e-01, -1.8296e-01,
         -1.3689e-01, -3.9429e-02, -2.0927e-01],
        [-2.7985e-01, -1.7341e-01,  2.6872e-01,  9.3608e-02, -1.5542e-01,
          3.5285e-01, -1.7286e-01, -1.7710e-01],
        [ 2.3557e-01, -2.3350e-01, -2.2215e-01,  3.1105e-01, -1.9616e-01,
          2.5366e-01,  2.6346e-01, -2.4405e-01],
        [-8.4314e-02,  3.3468e-01, -2.5853e-01, -2.3854e-01,  2.8960e-01,
         -3.0474e-01,  6.0055e-02, -1.1278e-01],
        [-3.2325e-01, -2.5352e-01,  1.5129e-01,  1.3868e-01, -4.5477e-02,
         -2.4039e-01,  5.2425e-02, -6.2514e-02],
        [ 1.8490e-01, -1.2500e-01, -1.2346e-01,  2.4446e-01, -1.1186e-01,
         -2.2136e-01,  1.6139e-01,  1.1234e-01],
        [ 1.9103e-02, -1.7628e-01, -2.2637e-01,  3.7387e-02,  7.4439e-02,
         -2.5561e-01,  1.9734e-01, -1.5074e-02],
        [ 1.7044e-01,  2.5277e-01,  2.8917e-01,  3.2793e-01,  1.3728e-02,
          2.0395e-01,  2.2044e-01,  1.1786e-01],
        [-1.9170e-01, -4.4951e-02, -3.2800e-01,  6.5316e-02,  1.3737e-01,
         -1.4726e-01,  1.0796e-01,  2.2112e-01],
        [-3.4873e-01,  2.8261e-01, -2.9479e-01, -5.5377e-02, -2.0258e-01,
         -2.4526e-01,  5.3605e-02, -3.2916e-02],
        [-1.7663e-01, -1.1019e-01,  1.1719e-01,  1.7764e-01, -1.1285e-01,
          1.8941e-01, -2.5422e-01, -3.0905e-01],
        [ 3.2980e-01, -3.0513e-01,  2.6766e-01,  3.3823e-01,  1.2685e-01,
         -1.1184e-01, -1.2557e-01, -2.3544e-01],
        [-2.4913e-02,  2.0210e-01, -1.7070e-01, -1.2712e-01,  5.1715e-02,
          2.2715e-01, -2.0883e-02, -4.0445e-02],
        [-3.3929e-01, -9.8820e-02,  1.5571e-01,  1.3076e-01, -9.4213e-02,
         -1.4367e-01, -3.1491e-02, -7.3620e-02],
        [ 1.5664e-01, -1.8977e-01,  5.2995e-02,  3.1843e-01,  1.3328e-01,
         -1.5929e-01, -1.6427e-01,  9.2516e-03],
        [ 2.4695e-02,  2.7069e-01, -2.6311e-01, -3.2627e-01,  2.1626e-01,
         -1.7415e-01, -2.6630e-01,  9.0207e-02],
        [-3.4313e-01,  2.0423e-01, -1.5436e-01,  2.7768e-01, -3.3647e-01,
         -3.3702e-01, -1.4257e-01,  2.9895e-01],
        [-3.0599e-01, -2.1661e-01,  3.2155e-01,  2.7582e-01,  3.0395e-02,
         -2.9670e-01,  2.6700e-01,  1.8212e-01],
        [ 2.6413e-01,  6.9840e-02, -2.3634e-01, -3.2024e-01, -2.6243e-01,
          3.4637e-01,  8.6203e-02,  1.8141e-01],
        [-1.6448e-01,  3.0768e-01,  1.0375e-01,  2.6375e-01,  1.9672e-01,
         -2.0672e-01,  3.1171e-01, -1.6469e-01],
        [ 2.0514e-01,  3.1993e-03, -1.6631e-01,  2.2121e-01,  1.6822e-01,
          3.8028e-02, -2.6298e-01,  1.7147e-01],
        [ 2.0190e-01, -1.2417e-01,  9.5515e-02, -1.5591e-01,  2.0245e-01,
         -2.6999e-01,  1.4440e-01, -2.7236e-01],
        [ 8.1351e-02,  1.6618e-01,  1.4814e-01,  1.1630e-01,  3.4489e-01,
         -3.3382e-01, -1.4381e-01, -1.3702e-01],
        [ 3.3698e-01,  1.2523e-01, -9.6120e-02,  2.5376e-01,  3.6994e-02,
         -3.2913e-01,  4.9610e-02, -1.4869e-01],
        [-2.3980e-01,  4.1608e-02,  1.7918e-01, -3.2719e-01,  3.2329e-01,
         -2.1883e-03,  9.6458e-03, -3.3071e-01],
        [-6.3635e-03,  9.6894e-02, -2.9695e-01, -2.4985e-01,  9.2970e-02,
         -2.3335e-02,  3.4870e-01,  2.5458e-03],
        [ 3.4278e-02, -1.8142e-01, -1.1262e-01,  2.0305e-01, -3.2615e-01,
          3.4288e-02,  2.4132e-01, -1.0234e-01],
        [-3.3445e-01, -3.1320e-01, -1.8288e-01,  1.8584e-02,  2.3715e-01,
          2.5273e-01,  6.3993e-02, -1.1924e-01],
        [ 7.0622e-02,  2.5682e-02, -6.4396e-02,  9.5872e-02,  3.5412e-02,
          2.5198e-01,  1.5226e-01,  2.5616e-01],
        [ 8.8232e-02, -9.3152e-02, -3.3253e-01, -2.3671e-01, -2.2108e-01,
          1.5518e-01, -1.9188e-01,  3.0629e-01],
        [-8.5114e-02, -2.9620e-01, -1.8133e-01, -1.3152e-01, -1.7376e-01,
         -1.7821e-01,  2.1562e-01, -1.3454e-01],
        [-1.7428e-01,  3.3172e-01, -4.4741e-02, -5.1271e-02,  2.1158e-01,
          3.0244e-01,  2.9449e-02,  3.3624e-01],
        [ 6.5497e-02, -2.6754e-01,  2.0724e-01, -1.0200e-01, -1.9457e-01,
         -2.6481e-01,  3.5294e-01,  1.6113e-01],
        [ 1.1153e-02, -1.4584e-01, -2.5233e-01,  2.7942e-01,  2.6167e-01,
          4.1833e-02, -9.8205e-02,  9.3928e-02],
        [ 3.4235e-02,  7.1245e-02, -6.1575e-02, -1.3937e-01,  8.5945e-02,
          1.9917e-01, -2.3640e-01, -7.2775e-02],
        [-7.4631e-02, -1.0468e-01,  1.6028e-01, -9.8932e-02,  6.5603e-02,
          3.3700e-01, -2.6158e-01,  2.9099e-01],
        [ 5.1671e-02, -1.7019e-02,  1.5680e-01, -1.2053e-01,  1.8085e-01,
         -8.3621e-02, -5.4681e-02, -2.5340e-01],
        [ 2.9617e-01,  2.6350e-01, -2.6974e-01,  3.3459e-01, -3.7623e-02,
         -1.5474e-01, -1.6775e-01,  2.6245e-01],
        [ 4.2293e-02,  1.2244e-01,  1.3457e-01, -1.2916e-01, -5.7835e-02,
         -8.6656e-02,  8.8499e-02,  1.1876e-01],
        [-1.4525e-01, -3.4220e-01,  2.7383e-01, -4.2751e-02, -2.2668e-01,
         -8.7250e-02,  3.2574e-02, -3.4040e-01],
        [-1.6245e-01,  2.7463e-01, -6.9558e-02,  2.4382e-01, -1.5765e-01,
         -5.9532e-02, -2.4074e-01,  1.4932e-01],
        [-2.6500e-01,  2.6793e-03, -2.7560e-01, -8.3124e-02, -1.0871e-01,
          1.8446e-01, -4.4828e-02,  9.3844e-02],
        [-2.2411e-01, -1.7827e-01,  7.6591e-02,  6.6630e-02, -1.3143e-01,
         -1.9194e-01, -6.1875e-02,  3.9675e-02],
        [ 1.2300e-01,  8.5296e-02, -3.0313e-01,  1.7419e-01, -4.0929e-02,
         -1.1426e-01, -1.1985e-01, -1.0668e-01],
        [ 3.5227e-01, -1.8719e-01, -3.4323e-01,  1.3567e-01, -3.4890e-01,
          3.2543e-01,  1.6624e-01,  2.8935e-01],
        [-1.6024e-01,  3.2168e-01,  1.6361e-01,  2.8190e-01, -4.7462e-02,
         -1.1967e-01,  3.5061e-01, -1.4044e-01],
        [ 1.6802e-02,  1.5563e-01,  1.9410e-01,  6.7729e-02, -1.0323e-01,
          8.9286e-02, -1.2903e-01, -1.6830e-01],
        [ 3.6607e-02,  3.6564e-02, -3.2575e-01, -1.7506e-01, -1.3145e-01,
         -1.1831e-02,  3.1060e-01, -2.3872e-01],
        [-1.9911e-01,  3.3796e-01,  5.9013e-02, -1.4993e-01,  2.0279e-02,
         -1.7183e-01,  7.0068e-03, -1.8000e-01],
        [ 2.4789e-02,  4.1592e-02,  3.3281e-01,  1.8451e-01,  4.6386e-02,
          2.7862e-01,  3.5245e-01, -1.8860e-01],
        [-2.5743e-01,  2.5244e-03, -1.3494e-01,  1.3397e-01,  2.8819e-01,
          6.2562e-02, -4.1108e-02,  1.5620e-01],
        [-2.7585e-01,  1.8391e-01, -1.2018e-01, -2.4565e-01, -5.4250e-02,
          3.4190e-01, -1.4695e-01, -2.5227e-01],
        [ 2.2539e-01, -2.3910e-02, -1.0037e-01,  2.2443e-01,  1.5474e-01,
          1.1801e-01,  3.3976e-01, -3.0749e-01],
        [-1.2260e-01,  2.4492e-01, -2.9810e-01, -5.6906e-02,  1.1793e-01,
          2.3465e-02,  7.1297e-02, -1.9174e-01],
        [ 1.0758e-01, -2.3371e-01,  4.7793e-02, -4.7295e-02,  2.7377e-01,
         -3.2652e-01, -2.5033e-01,  3.0718e-01],
        [ 3.4768e-01, -1.1124e-02,  2.4432e-01, -5.4892e-02,  3.2325e-01,
         -1.9136e-01, -1.7273e-01,  4.8044e-02],
        [-1.5764e-01,  2.2756e-01, -1.1737e-01,  2.4200e-01, -3.0029e-01,
         -2.1160e-01, -1.6537e-01,  9.5206e-02],
        [ 3.5213e-01,  1.5380e-01, -2.8429e-01, -3.4819e-01,  1.5093e-01,
          1.9126e-01,  2.6146e-01, -2.8081e-01],
        [-2.4075e-01,  2.8782e-01,  2.8669e-01,  1.5588e-02, -3.4823e-01,
          3.4501e-01,  1.7381e-01, -1.3782e-01],
        [-8.5535e-02, -4.8400e-03,  3.0654e-01,  1.3429e-02,  2.2613e-01,
          1.6283e-01, -1.7099e-01, -3.5249e-01],
        [ 2.2692e-01, -1.9918e-01,  1.3065e-01,  2.0666e-01, -9.2928e-02,
         -2.2062e-01,  3.3986e-01, -1.9426e-01],
        [ 2.9095e-01,  2.8377e-01,  3.2595e-01,  3.2817e-01, -4.7289e-02,
          2.6992e-01, -3.1409e-01,  2.9732e-02],
        [-2.4206e-01, -2.6370e-01,  1.8729e-01, -1.8190e-01, -7.7377e-02,
         -3.2703e-01, -1.8470e-01,  1.2176e-01],
        [ 3.1968e-01,  9.0922e-02, -2.7591e-02, -1.9293e-01, -2.2406e-01,
         -2.0226e-01,  2.6852e-01, -1.5158e-01],
        [ 1.2819e-01,  1.4021e-01, -2.1678e-01, -1.9002e-01, -9.6475e-02,
         -2.4334e-01,  3.5057e-01, -1.7621e-01],
        [-3.0681e-01, -2.3733e-01,  2.7447e-03,  3.3098e-01, -3.1169e-01,
          3.6977e-02,  5.8303e-03, -1.1972e-02],
        [ 5.6004e-02, -1.3493e-01,  1.4102e-01,  7.7917e-02,  3.0392e-01,
          2.8047e-01,  6.2351e-02, -2.0567e-01],
        [ 6.1362e-04, -2.7011e-01,  1.3239e-01,  7.9381e-02, -2.7536e-03,
         -3.3280e-01, -2.0921e-01,  1.7853e-01],
        [ 2.6495e-01, -2.2131e-01, -2.3438e-01,  7.1488e-02,  1.8513e-01,
         -1.2148e-01, -3.4208e-02,  3.2869e-01],
        [-1.4154e-01,  1.5866e-01, -4.9789e-02,  2.8974e-01,  1.4782e-01,
          1.3174e-01,  2.8250e-01, -5.2410e-03],
        [-9.8590e-02, -2.9322e-01,  3.2667e-01,  2.3027e-01, -6.3693e-02,
         -3.0643e-01,  3.5247e-01,  2.7358e-01],
        [-2.9811e-01,  1.0707e-01, -1.8470e-02,  2.1355e-01, -2.0070e-02,
         -1.3234e-01, -2.2292e-02,  3.8919e-02],
        [-2.0335e-01,  2.0687e-01,  3.2705e-01,  3.4618e-01,  2.3614e-01,
         -2.0333e-01,  1.2768e-01, -1.2649e-01],
        [ 1.9415e-02, -2.1172e-01, -1.0515e-01, -2.6661e-01,  6.5684e-03,
          2.9829e-02,  3.2053e-01,  1.2863e-01],
        [ 2.0269e-01, -1.7309e-01,  1.1599e-02, -4.0672e-02,  4.2147e-02,
         -1.4919e-01,  1.8652e-01,  3.3651e-01],
        [ 1.4971e-01,  6.3657e-02, -1.0351e-02, -2.6222e-01, -2.0960e-01,
         -1.6853e-01, -1.6267e-01, -3.2744e-01],
        [ 7.4370e-02, -1.1432e-02,  5.4376e-02,  1.6363e-01, -2.2840e-01,
         -1.9278e-01, -2.6979e-01, -7.7359e-02],
        [-1.3587e-01,  2.1623e-01,  3.8394e-02, -1.3275e-01,  1.0500e-01,
         -2.5641e-02, -2.4126e-02,  2.0483e-01],
        [ 4.9866e-02,  9.6367e-02,  2.8974e-01,  2.5600e-01, -2.1267e-01,
         -8.1154e-02, -1.7673e-01,  1.5948e-01]], device='cuda:0',
       requires_grad=True) 

model.module_15.bias torch.Size([100])
Parameter containing:
tensor([-0.1256, -0.1463, -0.0371,  0.2099, -0.2806, -0.2831,  0.2623,  0.0800,
        -0.0910, -0.3468, -0.0725,  0.1986, -0.1838, -0.1025, -0.2055, -0.0533,
         0.0522,  0.1599, -0.2084, -0.2895,  0.0910, -0.2682,  0.1909, -0.1983,
        -0.2742, -0.0602,  0.1595, -0.2652, -0.0299, -0.1646, -0.1649, -0.2494,
         0.1703, -0.1796, -0.2702, -0.3162,  0.3384,  0.0154, -0.0115,  0.3208,
         0.2514, -0.0942,  0.2575, -0.0361,  0.2809, -0.2168,  0.1167, -0.2873,
        -0.1431, -0.0048, -0.2617,  0.0120, -0.0178,  0.3389,  0.0496,  0.2203,
         0.2071,  0.2117,  0.1886,  0.0969,  0.2622,  0.3097, -0.1054,  0.1882,
         0.1288,  0.2086, -0.1631,  0.0250,  0.0443,  0.1109,  0.0599,  0.2184,
        -0.1465, -0.0686, -0.3322,  0.2529, -0.3295,  0.0994, -0.2638,  0.1088,
        -0.1903,  0.2157, -0.3023,  0.2171, -0.0837, -0.3189, -0.1106, -0.1151,
         0.1158,  0.3020,  0.1154, -0.0068,  0.0322, -0.2774, -0.1727,  0.2997,
         0.2822, -0.0183,  0.1205,  0.2679], device='cuda:0',
       requires_grad=True) 

model.module_17.weight torch.Size([100, 100])
Parameter containing:
tensor([[-0.0635,  0.0025, -0.0733,  ...,  0.0954,  0.0478, -0.0001],
        [ 0.0518,  0.0326,  0.0054,  ..., -0.0093,  0.0549,  0.0826],
        [-0.0021,  0.0017, -0.0694,  ..., -0.0640,  0.0869,  0.0762],
        ...,
        [-0.0434,  0.0301,  0.0465,  ...,  0.0513,  0.0850, -0.0048],
        [ 0.0991, -0.0666, -0.0832,  ..., -0.0391, -0.0708,  0.0176],
        [-0.0020,  0.0815,  0.0031,  ...,  0.0461,  0.0345, -0.0153]],
       device='cuda:0', requires_grad=True) 

model.module_17.bias torch.Size([100])
Parameter containing:
tensor([ 0.0457, -0.0635, -0.0114,  0.0399,  0.0392, -0.0495, -0.0854,  0.0495,
        -0.0500,  0.0548, -0.0947, -0.0864,  0.0930,  0.0899, -0.0329,  0.0594,
         0.0656, -0.0266,  0.0783,  0.0710,  0.0969, -0.0127, -0.0885, -0.0520,
        -0.0160, -0.0414,  0.0632,  0.0834,  0.0767,  0.0223, -0.0467, -0.0607,
        -0.0118, -0.0572,  0.0797, -0.0767, -0.0780, -0.0581, -0.0659, -0.0614,
         0.0367, -0.0414, -0.0640,  0.0729, -0.0406,  0.0895,  0.0753,  0.0857,
        -0.0897,  0.0662, -0.0661,  0.0308, -0.0640,  0.0847,  0.0931, -0.0654,
         0.0370, -0.0482, -0.0117,  0.0910,  0.0819, -0.0849,  0.0450, -0.0589,
        -0.0425,  0.0818, -0.0473,  0.0304, -0.0840, -0.0749, -0.0965,  0.0382,
        -0.0816,  0.0794,  0.0236, -0.0675,  0.0911,  0.0048, -0.0341,  0.0642,
        -0.0636, -0.0614, -0.0439, -0.0188,  0.0692,  0.0006, -0.0617, -0.0819,
        -0.0047,  0.0421, -0.0994,  0.0324,  0.0131, -0.0349,  0.0471, -0.0470,
        -0.0468, -0.0433,  0.0342,  0.0836], device='cuda:0',
       requires_grad=True) 

model.module_19.weight torch.Size([16, 100])
Parameter containing:
tensor([[ 0.0031,  0.0323,  0.0590,  ..., -0.0403,  0.0776, -0.0063],
        [-0.0970, -0.0234, -0.0402,  ..., -0.0428,  0.0980, -0.0627],
        [ 0.0699,  0.0922,  0.0731,  ...,  0.0071, -0.0221, -0.0443],
        ...,
        [ 0.0533, -0.0270, -0.0163,  ..., -0.0014, -0.0029, -0.0208],
        [ 0.0269,  0.0453, -0.0565,  ...,  0.0544,  0.0759,  0.0657],
        [-0.0554, -0.0462, -0.0161,  ..., -0.0488,  0.0849, -0.0990]],
       device='cuda:0', requires_grad=True) 

model.module_19.bias torch.Size([16])
Parameter containing:
tensor([ 0.0834, -0.0360, -0.0069, -0.0002, -0.0276, -0.0229,  0.0246,  0.0193,
         0.0116,  0.0982, -0.0098, -0.0619, -0.0876,  0.0758, -0.0724,  0.0505],
       device='cuda:0', requires_grad=True) 



#### FINAL PARAMETERS ####
W 256 torch.Size([16, 16])
Parameter containing:
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0') 

act.weight 1 torch.Size([1])
Parameter containing:
tensor([nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan], device='cuda:0') 

inner_act.weight 1 torch.Size([1])
Parameter containing:
tensor([nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan], device='cuda:0') 

out_act.weight 1 torch.Size([1])
Parameter containing:
tensor([0.2500], device='cuda:0', requires_grad=True) 
grad:  None 

encoder.module_0.weight 300 torch.Size([100, 3])
Parameter containing:
tensor([[nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan]], device='cuda:0', requires_grad=True) 
grad:  tensor([[nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan],
        [nan, nan, nan]], device='cuda:0') 

encoder.module_0.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

encoder.module_2.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

encoder.module_2.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

encoder.module_4.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

encoder.module_4.bias 16 torch.Size([16])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0') 

model.module_0.bias 8 torch.Size([8])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0') 

model.module_0.lin.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0') 

model.module_1.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0') 

model.module_1.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

model.module_3.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

model.module_3.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

model.module_5.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

model.module_5.bias 16 torch.Size([16])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0') 

model.module_7.bias 8 torch.Size([8])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0') 

model.module_7.lin.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0') 

model.module_8.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0') 

model.module_8.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

model.module_10.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

model.module_10.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

model.module_12.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

model.module_12.bias 16 torch.Size([16])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0') 

model.module_14.bias 8 torch.Size([8])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0') 

model.module_14.lin.weight 128 torch.Size([8, 16])
Parameter containing:
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0', requires_grad=True) 
grad:  tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       device='cuda:0') 

model.module_15.weight 800 torch.Size([100, 8])
Parameter containing:
tensor([[nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0') 

model.module_15.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

model.module_17.weight 10000 torch.Size([100, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

model.module_17.bias 100 torch.Size([100])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan], device='cuda:0') 

model.module_19.weight 1600 torch.Size([16, 100])
Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True) 
grad:  tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0') 

model.module_19.bias 16 torch.Size([16])
Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0', requires_grad=True) 
grad:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
       device='cuda:0') 

