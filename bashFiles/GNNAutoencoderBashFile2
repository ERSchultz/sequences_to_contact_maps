#! /bin/bash
#SBATCH --job-name=GNNAutoencoder2
#SBATCH --output=logFiles/GNNAutoencoder2.out
#SBATCH --time=20:00:00
#SBATCH --partition=depablo-gpu
#SBATCH --gres=gpu:1
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=4
#SBATCH --mem-per-cpu=2000

dirname="/../../../project2/depablo/erschultz/dataset_04_18_21"
deleteRoot='false'
modelType='GNNAutoencoder'
GNNMode='true'
autoencoderMode='true'

# architecture
k=2
n=1024
yPreprocessing='diag'
yNorm='instance'
useNodeFeatures='false'
hiddenSizesList='16-8'
MLPHiddenSizesList='200-25'
headArchitecture='MLP'
transforms='constant-weighted_LDP'
topK=500
loss='mse'
outAct='relu'

# hyperparameters
nEpochs=20
batchSize=8
numWorkers=4
milestones=None
gamma=0.1

useScratch='true'
verbose='false'

cd ~/sequences_to_contact_maps
source activate python3.8_pytorch1.8.1_cuda10.2


for lr in 1e-1 1e-2 1e-3
do
python3 core_test_train.py --data_folder $dirname --root_name $modelType --delete_root $deleteRoot --model_type $modelType --GNN_mode $GNNMode --autoencoder_mode $autoencoderMode --k $k --n $n --y_preprocessing ${yPreprocessing} --y_norm $yNorm --use_node_features $useNodeFeatures --hidden_sizes_list $hiddenSizesList --MLP_hidden_sizes_list $MLPHiddenSizesList --head_architecture $headArchitecture --transforms $transforms --top_k $topK --loss $loss --out_act $outAct --n_epochs $nEpochs --lr $lr --batch_size $batchSize --num_workers $numWorkers --milestones $milestones --gamma $gamma --verbose $verbose --use_scratch $useScratch
done

python3 cleanDirectories.py --data_folder $dirname --root_name $modelType --use_scratch $useScratch
